[
  {
    "paperId": "53c9f3c34d8481adaf24df3b25581ccf1bc53f5c",
    "title": "Physics-informed machine learning",
    "venue": "Nature Reviews Physics",
    "year": 2021,
    "citationCount": 4858,
    "openAccessPdf": {
      "url": "https://www.osti.gov/biblio/2282016",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42254-021-00314-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42254-021-00314-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1720124",
        "name": "G. Karniadakis"
      },
      {
        "authorId": "3439407",
        "name": "I. Kevrekidis"
      },
      {
        "authorId": "2149373363",
        "name": "Lu Lu"
      },
      {
        "authorId": "3410970",
        "name": "P. Perdikaris"
      },
      {
        "authorId": "118188801",
        "name": "Sifan Wang"
      },
      {
        "authorId": "2145494483",
        "name": "Liu Yang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f9c602cc436a9ea2f9e7db48c77d924e09ce3c32",
    "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 9801,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1708.07747, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145642373",
        "name": "Han Xiao"
      },
      {
        "authorId": "4565995",
        "name": "Kashif Rasul"
      },
      {
        "authorId": "2742129",
        "name": "Roland Vollgraf"
      }
    ],
    "abstract": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL"
  },
  {
    "paperId": "0090023afc66cd2741568599057f4e82b566137c",
    "title": "A Survey on Bias and Fairness in Machine Learning",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 5046,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1908.09635",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1908.09635, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51997673",
        "name": "Ninareh Mehrabi"
      },
      {
        "authorId": "2775559",
        "name": "Fred Morstatter"
      },
      {
        "authorId": "51884035",
        "name": "N. Saxena"
      },
      {
        "authorId": "1782658",
        "name": "Kristina Lerman"
      },
      {
        "authorId": "143728483",
        "name": "A. Galstyan"
      }
    ],
    "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields."
  },
  {
    "paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
    "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 11472,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.04467, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2057642721",
        "name": "Martín Abadi"
      },
      {
        "authorId": "2078528337",
        "name": "Ashish Agarwal"
      },
      {
        "authorId": "144758007",
        "name": "P. Barham"
      },
      {
        "authorId": "2445241",
        "name": "E. Brevdo"
      },
      {
        "authorId": "2545358",
        "name": "Z. Chen"
      },
      {
        "authorId": "48738717",
        "name": "C. Citro"
      },
      {
        "authorId": "32131713",
        "name": "G. Corrado"
      },
      {
        "authorId": "36347083",
        "name": "Andy Davis"
      },
      {
        "authorId": "49959210",
        "name": "J. Dean"
      },
      {
        "authorId": "145139947",
        "name": "M. Devin"
      },
      {
        "authorId": "1780892",
        "name": "S. Ghemawat"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "2064102917",
        "name": "A. Harp"
      },
      {
        "authorId": "2060655766",
        "name": "G. Irving"
      },
      {
        "authorId": "2090818",
        "name": "M. Isard"
      },
      {
        "authorId": "39978391",
        "name": "Yangqing Jia"
      },
      {
        "authorId": "1944541",
        "name": "R. Józefowicz"
      },
      {
        "authorId": "40527594",
        "name": "Lukasz Kaiser"
      },
      {
        "authorId": "1942300",
        "name": "M. Kudlur"
      },
      {
        "authorId": "3369421",
        "name": "J. Levenberg"
      },
      {
        "authorId": "30415265",
        "name": "Dandelion Mané"
      },
      {
        "authorId": "3089272",
        "name": "R. Monga"
      },
      {
        "authorId": "144375552",
        "name": "Sherry Moore"
      },
      {
        "authorId": "20154699",
        "name": "D. Murray"
      },
      {
        "authorId": "2357599490",
        "name": "C. Olah"
      },
      {
        "authorId": "144927151",
        "name": "M. Schuster"
      },
      {
        "authorId": "1789737",
        "name": "Jonathon Shlens"
      },
      {
        "authorId": "32163737",
        "name": "Benoit Steiner"
      },
      {
        "authorId": "1701686",
        "name": "I. Sutskever"
      },
      {
        "authorId": "35210462",
        "name": "Kunal Talwar"
      },
      {
        "authorId": "2080690",
        "name": "P. Tucker"
      },
      {
        "authorId": "2657155",
        "name": "Vincent Vanhoucke"
      },
      {
        "authorId": "2053781980",
        "name": "Vijay Vasudevan"
      },
      {
        "authorId": "1765169",
        "name": "F. Viégas"
      },
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      },
      {
        "authorId": "47941411",
        "name": "Pete Warden"
      },
      {
        "authorId": "145233583",
        "name": "M. Wattenberg"
      },
      {
        "authorId": "35078078",
        "name": "M. Wicke"
      },
      {
        "authorId": "2117163698",
        "name": "Yuan Yu"
      },
      {
        "authorId": "2152198093",
        "name": "Xiaoqiang Zheng"
      }
    ],
    "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org."
  },
  {
    "paperId": "bc00ff34ec7772080c7039b17f7069a2f7df0889",
    "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
    "venue": "Nature Machine Intelligence",
    "year": 2018,
    "citationCount": 7213,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-019-0048-x.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-019-0048-x?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-019-0048-x, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48395540",
        "name": "C. Rudin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d",
    "title": "Membership Inference Attacks Against Machine Learning Models",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2016,
    "citationCount": 4647,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1610.05820",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1610.05820, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2520493",
        "name": "R. Shokri"
      },
      {
        "authorId": "34828439",
        "name": "M. Stronati"
      },
      {
        "authorId": "3469125",
        "name": "Congzheng Song"
      },
      {
        "authorId": "1723945",
        "name": "Vitaly Shmatikov"
      }
    ],
    "abstract": "We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial \"machine learning as a service\" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies."
  },
  {
    "paperId": "794b3ffd28d28606230efc975eeec9f0522fb139",
    "title": "An Introduction to Machine Learning",
    "venue": "Cambridge International Law Journal",
    "year": 2017,
    "citationCount": 4393,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-319-63913-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-319-63913-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713687",
        "name": "M. Kubát"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5c39e37022661f81f79e481240ed9b175dec6513",
    "title": "Towards A Rigorous Science of Interpretable Machine Learning",
    "venue": "",
    "year": 2017,
    "citationCount": 4335,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1702.08608, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1388372395",
        "name": "F. Doshi-Velez"
      },
      {
        "authorId": "3351164",
        "name": "Been Kim"
      }
    ],
    "abstract": "As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning."
  },
  {
    "paperId": "f9c990b1b5724e50e5632b94fdb7484ece8a6ce7",
    "title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting",
    "venue": "Neural Information Processing Systems",
    "year": 2015,
    "citationCount": 8835,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1506.04214, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3008587",
        "name": "Xingjian Shi"
      },
      {
        "authorId": "2192200",
        "name": "Zhourong Chen"
      },
      {
        "authorId": "49528584",
        "name": "Hao Wang"
      },
      {
        "authorId": "1739816",
        "name": "D. Yeung"
      },
      {
        "authorId": "145771919",
        "name": "W. Wong"
      },
      {
        "authorId": "2183294",
        "name": "W. Woo"
      }
    ],
    "abstract": "The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting."
  },
  {
    "paperId": "597bd2e45427563cdf025e53a3239006aa364cfc",
    "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
    "venue": "Neural Information Processing Systems",
    "year": 2020,
    "citationCount": 3144,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.00687, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48594758",
        "name": "Weihua Hu"
      },
      {
        "authorId": "3410500",
        "name": "Matthias Fey"
      },
      {
        "authorId": "2095762",
        "name": "M. Zitnik"
      },
      {
        "authorId": "2047998",
        "name": "Yuxiao Dong"
      },
      {
        "authorId": "40046694",
        "name": "Hongyu Ren"
      },
      {
        "authorId": "2156641189",
        "name": "Bowen Liu"
      },
      {
        "authorId": "1754926",
        "name": "Michele Catasta"
      },
      {
        "authorId": "1702139",
        "name": "J. Leskovec"
      }
    ],
    "abstract": "We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL ."
  },
  {
    "paperId": "7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
    "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions",
    "venue": "SN Computer Science",
    "year": 2021,
    "citationCount": 3709,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s42979-021-00592-x.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7983091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3456687",
        "name": "Iqbal H. Sarker"
      }
    ],
    "abstract": "In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this paper aims to serve as a reference point for both academia and industry professionals as well as for decision-makers in various real-world situations and application areas, particularly from the technical point of view."
  },
  {
    "paperId": "9f5b82d9915d0752957602224c5056be7e749c83",
    "title": "Foundations of Machine Learning",
    "venue": "Introduction to AI Techniques for Renewable Energy Systems",
    "year": 2021,
    "citationCount": 3366,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3399990?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3399990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "36203548",
        "name": "N. Nathani"
      },
      {
        "authorId": "2242477024",
        "name": "Abhishek Singh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8e3c872076750bcce868808f9d4d7a038f950040",
    "title": "Pattern Recognition And Machine Learning",
    "venue": "",
    "year": 2016,
    "citationCount": 6765,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2345603162",
        "name": "Laura Strauss"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ad4fd2c149f220a62441576af92a8a669fe81246",
    "title": "Scikit-learn: Machine Learning in Python",
    "venue": "Journal of machine learning research",
    "year": 2011,
    "citationCount": 83260,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1201.0490, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2570016",
        "name": "Fabian Pedregosa"
      },
      {
        "authorId": "3025780",
        "name": "G. Varoquaux"
      },
      {
        "authorId": "1797840",
        "name": "Alexandre Gramfort"
      },
      {
        "authorId": "52200573",
        "name": "V. Michel"
      },
      {
        "authorId": "8493461",
        "name": "B. Thirion"
      },
      {
        "authorId": "2958756",
        "name": "O. Grisel"
      },
      {
        "authorId": "27257992",
        "name": "Mathieu Blondel"
      },
      {
        "authorId": "1881041",
        "name": "Gilles Louppe"
      },
      {
        "authorId": "2780213",
        "name": "P. Prettenhofer"
      },
      {
        "authorId": "2067827437",
        "name": "Ron Weiss"
      },
      {
        "authorId": "39571582",
        "name": "Ron J. Weiss"
      },
      {
        "authorId": "2081469",
        "name": "J. Vanderplas"
      },
      {
        "authorId": "144720379",
        "name": "Alexandre Passos"
      },
      {
        "authorId": "3084321",
        "name": "D. Cournapeau"
      },
      {
        "authorId": "2423884",
        "name": "M. Brucher"
      },
      {
        "authorId": "35243423",
        "name": "M. Perrot"
      },
      {
        "authorId": "1710398",
        "name": "E. Duchesnay"
      }
    ],
    "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net."
  },
  {
    "paperId": "d422df8bff4e677a3077635db116679d25142bfc",
    "title": "Machine learning: Trends, perspectives, and prospects",
    "venue": "Science",
    "year": 2015,
    "citationCount": 7508,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aaa8415?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aaa8415, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      },
      {
        "authorId": "2066277988",
        "name": "T. Mitchell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f156ecbbb9243522275490d698c6825f4d2e01af",
    "title": "Explainable AI: A Review of Machine Learning Interpretability Methods",
    "venue": "Entropy",
    "year": 2020,
    "citationCount": 2255,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7824368, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1582428254",
        "name": "Pantelis Linardatos"
      },
      {
        "authorId": "1753333150",
        "name": "Vasilis Papastefanopoulos"
      },
      {
        "authorId": "1697867",
        "name": "S. Kotsiantis"
      }
    ],
    "abstract": "Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners."
  },
  {
    "paperId": "53b047e503f4c24602f376a774d653f7ed56c024",
    "title": "Practical Black-Box Attacks against Machine Learning",
    "venue": "ACM Asia Conference on Computer and Communications Security",
    "year": 2016,
    "citationCount": 3844,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1602.02697",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1602.02697, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367796356",
        "name": "Nicolas Papernot"
      },
      {
        "authorId": "144061974",
        "name": "P. Mcdaniel"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "1680133",
        "name": "S. Jha"
      },
      {
        "authorId": "144643812",
        "name": "Z. B. Celik"
      },
      {
        "authorId": "144231976",
        "name": "A. Swami"
      }
    ],
    "abstract": "Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder."
  },
  {
    "paperId": "b0c34618ffd1154f35863e2ce7250ac6b6f2c424",
    "title": "Interpretable Machine Learning",
    "venue": "Hands-On Machine Learning with R",
    "year": 2019,
    "citationCount": 2867,
    "openAccessPdf": {
      "url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12184120880002346/13184120870002346",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1201/9780367816377-16?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/9780367816377-16, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46216076",
        "name": "Bradley C. Boehmke"
      },
      {
        "authorId": "35664117",
        "name": "Brandon M. Greenwell"
      }
    ],
    "abstract": "Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners."
  },
  {
    "paperId": "807c1f19047f96083e13614f7ce20f2ac98c239a",
    "title": "C4.5: Programs for Machine Learning",
    "venue": "",
    "year": 1992,
    "citationCount": 24412,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145341779",
        "name": "J. R. Quinlan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9e27190f2d9b2167d4a66b88696def4585072fd5",
    "title": "SoilGrids250m: Global gridded soil information based on machine learning",
    "venue": "PLoS ONE",
    "year": 2017,
    "citationCount": 3312,
    "openAccessPdf": {
      "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5313206, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2856207",
        "name": "T. Hengl"
      },
      {
        "authorId": "7549589",
        "name": "Jorge Mendes de Jesus"
      },
      {
        "authorId": "145253407",
        "name": "G. Heuvelink"
      },
      {
        "authorId": "9583743",
        "name": "Maria Ruiperez González"
      },
      {
        "authorId": "30504500",
        "name": "M. Kilibarda"
      },
      {
        "authorId": "9030720",
        "name": "Aleksandar Blagotić"
      },
      {
        "authorId": "2228185935",
        "name": "Shangguan Wei"
      },
      {
        "authorId": "3376186",
        "name": "Marvin N. Wright"
      },
      {
        "authorId": "3018223",
        "name": "X. Geng"
      },
      {
        "authorId": "1402912902",
        "name": "B. Bauer-Marschallinger"
      },
      {
        "authorId": "145669099",
        "name": "M. Guevara"
      },
      {
        "authorId": "145632581",
        "name": "R. Vargas"
      },
      {
        "authorId": "145028966",
        "name": "R. MacMillan"
      },
      {
        "authorId": "49399380",
        "name": "N. Batjes"
      },
      {
        "authorId": "100653750",
        "name": "J. Leenaars"
      },
      {
        "authorId": "32830771",
        "name": "E. Ribeiro"
      },
      {
        "authorId": "2924968",
        "name": "Ichsani Wheeler"
      },
      {
        "authorId": "2146245",
        "name": "S. Mantel"
      },
      {
        "authorId": "4953836",
        "name": "B. Kempen"
      }
    ],
    "abstract": "This paper describes the technical development and accuracy assessment of the most recent and improved version of the SoilGrids system at 250m resolution (June 2016 update). SoilGrids provides global predictions for standard numeric soil properties (organic carbon, bulk density, Cation Exchange Capacity (CEC), pH, soil texture fractions and coarse fragments) at seven standard depths (0, 5, 15, 30, 60, 100 and 200 cm), in addition to predictions of depth to bedrock and distribution of soil classes based on the World Reference Base (WRB) and USDA classification systems (ca. 280 raster layers in total). Predictions were based on ca. 150,000 soil profiles used for training and a stack of 158 remote sensing-based soil covariates (primarily derived from MODIS land products, SRTM DEM derivatives, climatic images and global landform and lithology maps), which were used to fit an ensemble of machine learning methods—random forest and gradient boosting and/or multinomial logistic regression—as implemented in the R packages ranger, xgboost, nnet and caret. The results of 10–fold cross-validation show that the ensemble models explain between 56% (coarse fragments) and 83% (pH) of variation with an overall average of 61%. Improvements in the relative accuracy considering the amount of variation explained, in comparison to the previous version of SoilGrids at 1 km spatial resolution, range from 60 to 230%. Improvements can be attributed to: (1) the use of machine learning instead of linear regression, (2) to considerable investments in preparing finer resolution covariate layers and (3) to insertion of additional soil profiles. Further development of SoilGrids could include refinement of methods to incorporate input uncertainties and derivation of posterior probability distributions (per pixel), and further automation of spatial modeling so that soil maps can be generated for potentially hundreds of soil variables. Another area of future research is the development of methods for multiscale merging of SoilGrids predictions with local and/or national gridded soil products (e.g. up to 50 m spatial resolution) so that increasingly more accurate, complete and consistent global soil information can be produced. SoilGrids are available under the Open Data Base License."
  },
  {
    "paperId": "730ca170962a58607e092035beb2afc4b5fa6242",
    "title": "Data Mining Practical Machine Learning Tools and Techniques",
    "venue": "",
    "year": 2014,
    "citationCount": 17557,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "71619391",
        "name": "อนิรุธ สืบสิงห์"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "360ca02e6f5a5e1af3dce4866a257aafc2d6d6f5",
    "title": "Machine learning - a probabilistic perspective",
    "venue": "Adaptive computation and machine learning series",
    "year": 2012,
    "citationCount": 9866,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2056417995",
        "name": "Kevin P. Murphy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e2a85a6766b982ff7c8980e57ca6342d22493827",
    "title": "Adversarial Machine Learning at Scale",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "citationCount": 3295,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.01236, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145714153",
        "name": "Alexey Kurakin"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "1751569",
        "name": "Samy Bengio"
      }
    ],
    "abstract": "Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a \"label leaking\" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process."
  },
  {
    "paperId": "d21703674ae562bae4a849a75847cdd9ead417df",
    "title": "Optimization Methods for Large-Scale Machine Learning",
    "venue": "SIAM Review",
    "year": 2016,
    "citationCount": 3476,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1606.04838",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.04838, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "52184096",
        "name": "L. Bottou"
      },
      {
        "authorId": "2198436",
        "name": "Frank E. Curtis"
      },
      {
        "authorId": "2784955",
        "name": "J. Nocedal"
      }
    ],
    "abstract": "This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations."
  },
  {
    "paperId": "5d433da6d0f143f20936379910104d2bb139d4ae",
    "title": "ilastik: interactive machine learning for (bio)image analysis",
    "venue": "Nature Methods",
    "year": 2019,
    "citationCount": 2563,
    "openAccessPdf": {
      "url": "http://archiv.ub.uni-heidelberg.de/volltextserver/28283/7/Berg_ilastik_2020.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41592-019-0582-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41592-019-0582-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48275624",
        "name": "S. Berg"
      },
      {
        "authorId": "145708428",
        "name": "D. Kutra"
      },
      {
        "authorId": "2066522012",
        "name": "Thorben Kroeger"
      },
      {
        "authorId": "145486652",
        "name": "C. Straehle"
      },
      {
        "authorId": "2834950",
        "name": "Bernhard X. Kausler"
      },
      {
        "authorId": "2057581",
        "name": "Carsten Haubold"
      },
      {
        "authorId": "1725192",
        "name": "Martin Schiegg"
      },
      {
        "authorId": "144560453",
        "name": "J. Ales"
      },
      {
        "authorId": "46478540",
        "name": "T. Beier"
      },
      {
        "authorId": "1391661732",
        "name": "Markus Rudy"
      },
      {
        "authorId": "47829712",
        "name": "Kemal Eren"
      },
      {
        "authorId": "2062532551",
        "name": "Jaime I Cervantes"
      },
      {
        "authorId": "1968352",
        "name": "Buote Xu"
      },
      {
        "authorId": "1397152727",
        "name": "Fynn Beuttenmueller"
      },
      {
        "authorId": "67091521",
        "name": "A. Wolny"
      },
      {
        "authorId": "2111387698",
        "name": "Chong Zhang"
      },
      {
        "authorId": "1708103",
        "name": "U. Köthe"
      },
      {
        "authorId": "1685187",
        "name": "F. Hamprecht"
      },
      {
        "authorId": "3190177",
        "name": "A. Kreshuk"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "56e8863838b4dcc4790108cd1e7e680a104a7c30",
    "title": "Machine Learning Algorithms: A Review",
    "venue": "International Journal of Science and Research (IJSR)",
    "year": 2022,
    "citationCount": 1869,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.21275/sr22815163219?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21275/sr22815163219, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50349508",
        "name": "Ayon Dey"
      }
    ],
    "abstract": "."
  },
  {
    "paperId": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
    "title": "Multimodal Machine Learning: A Survey and Taxonomy",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2017,
    "citationCount": 3438,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1705.09406",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1705.09406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1756344",
        "name": "T. Baltrušaitis"
      },
      {
        "authorId": "118242121",
        "name": "Chaitanya Ahuja"
      },
      {
        "authorId": "49933077",
        "name": "Louis-philippe Morency"
      }
    ],
    "abstract": "Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research."
  },
  {
    "paperId": "2e2089ae76fe914706e6fa90081a79c8fe01611e",
    "title": "Practical Bayesian Optimization of Machine Learning Algorithms",
    "venue": "Neural Information Processing Systems",
    "year": 2012,
    "citationCount": 8639,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1206.2944, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144108062",
        "name": "Jasper Snoek"
      },
      {
        "authorId": "1777528",
        "name": "H. Larochelle"
      },
      {
        "authorId": "1722180",
        "name": "Ryan P. Adams"
      }
    ],
    "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."
  },
  {
    "paperId": "2e62d1345b340d5fda3b092c460264b9543bc4b5",
    "title": "Genetic Algorithms in Search Optimization and Machine Learning",
    "venue": "",
    "year": 1988,
    "citationCount": 60941,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5860/choice.27-0936?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5860/choice.27-0936, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1715339",
        "name": "D. Goldberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "668b1277fbece28c4841eeab1c97e4ebd0079700",
    "title": "Pattern Recognition and Machine Learning",
    "venue": "J. Electronic Imaging",
    "year": 2006,
    "citationCount": 38327,
    "openAccessPdf": {
      "url": "http://cds.cern.ch/record/998831/files/9780387310732_TOC.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1117/1.2819119?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1117/1.2819119, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1764325",
        "name": "Radford M. Neal"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c292e473b3825eeb9db03c70b2e1c033aea190d5",
    "title": "Machine learning for molecular and materials science",
    "venue": "Nature",
    "year": 2018,
    "citationCount": 3285,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41586-018-0337-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41586-018-0337-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3300287",
        "name": "K. Butler"
      },
      {
        "authorId": "48592354",
        "name": "D. Davies"
      },
      {
        "authorId": "2527511",
        "name": "H. Cartwright"
      },
      {
        "authorId": "2385206",
        "name": "O. Isayev"
      },
      {
        "authorId": "144485183",
        "name": "A. Walsh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4954fa180728932959997a4768411ff9136aac81",
    "title": "This Paper Is Included in the Proceedings of the 12th Usenix Symposium on Operating Systems Design and Implementation (osdi '16). Tensorflow: a System for Large-scale Machine Learning Tensorflow: a System for Large-scale Machine Learning",
    "venue": "",
    "year": null,
    "citationCount": 19032,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2057642721",
        "name": "Martín Abadi"
      },
      {
        "authorId": "144758007",
        "name": "P. Barham"
      },
      {
        "authorId": "2108406634",
        "name": "Jianmin Chen"
      },
      {
        "authorId": "2545358",
        "name": "Z. Chen"
      },
      {
        "authorId": "36347083",
        "name": "Andy Davis"
      },
      {
        "authorId": "49959210",
        "name": "J. Dean"
      },
      {
        "authorId": "145139947",
        "name": "M. Devin"
      },
      {
        "authorId": "1780892",
        "name": "S. Ghemawat"
      },
      {
        "authorId": "2060655766",
        "name": "G. Irving"
      },
      {
        "authorId": "2090818",
        "name": "M. Isard"
      },
      {
        "authorId": "1942300",
        "name": "M. Kudlur"
      },
      {
        "authorId": "3369421",
        "name": "J. Levenberg"
      },
      {
        "authorId": "3089272",
        "name": "R. Monga"
      },
      {
        "authorId": "144375552",
        "name": "Sherry Moore"
      },
      {
        "authorId": "20154699",
        "name": "D. Murray"
      },
      {
        "authorId": "32163737",
        "name": "Benoit Steiner"
      },
      {
        "authorId": "2080690",
        "name": "P. Tucker"
      },
      {
        "authorId": "2053781980",
        "name": "Vijay Vasudevan"
      },
      {
        "authorId": "47941411",
        "name": "Pete Warden"
      },
      {
        "authorId": "35078078",
        "name": "M. Wicke"
      },
      {
        "authorId": "2117163698",
        "name": "Yuan Yu"
      },
      {
        "authorId": "2108113547",
        "name": "Xiaoqiang Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "db0cc2f21b20cbc0ab8946090967399c25709614",
    "title": "Practical Secure Aggregation for Privacy-Preserving Machine Learning",
    "venue": "IACR Cryptology ePrint Archive",
    "year": 2017,
    "citationCount": 3443,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3133956.3133982?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3133956.3133982, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2039588",
        "name": "Keith Bonawitz"
      },
      {
        "authorId": "2072422622",
        "name": "Vladimir Ivanov"
      },
      {
        "authorId": "4908509",
        "name": "Ben Kreuter"
      },
      {
        "authorId": "2212030",
        "name": "Antonio Marcedone"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "34521172",
        "name": "Sarvar Patel"
      },
      {
        "authorId": "1878835",
        "name": "Daniel Ramage"
      },
      {
        "authorId": "2064203013",
        "name": "Aaron Segal"
      },
      {
        "authorId": "34185195",
        "name": "Karn Seth"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2e5d2f2dc01b150dffc163a9f457848e9b5b5c38",
    "title": "On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice",
    "venue": "Neurocomputing",
    "year": 2020,
    "citationCount": 2460,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2007.15745",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2007.15745, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1624030637",
        "name": "Li Yang"
      },
      {
        "authorId": "1743065",
        "name": "A. Shami"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2936cbd6a90d7153a9fa34e8e4fd947907fe7f6c",
    "title": "Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems",
    "venue": "",
    "year": 2017,
    "citationCount": 3004,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2078716805",
        "name": "Aurélien Géron"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "46f74231b9afeb0c290d6d550043c55045284e5f",
    "title": "The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]",
    "venue": "IEEE Signal Processing Magazine",
    "year": 2012,
    "citationCount": 5246,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MSP.2012.2211477?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MSP.2012.2211477, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144718788",
        "name": "L. Deng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
    "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2002,
    "citationCount": 9454,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.3115/1118693.1118704",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/cs/0205070, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144865353",
        "name": "B. Pang"
      },
      {
        "authorId": "145810617",
        "name": "Lillian Lee"
      },
      {
        "authorId": "2066721",
        "name": "Shivakumar Vaithyanathan"
      }
    ],
    "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging."
  },
  {
    "paperId": "7ae2783a9196fb4bc2a610ae812d19722daddce5",
    "title": "Applications of machine learning to machine fault diagnosis: A review and roadmap",
    "venue": "",
    "year": 2020,
    "citationCount": 2133,
    "openAccessPdf": {
      "url": "http://bura.brunel.ac.uk/bitstream/2438/20040/1/FullText.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.ymssp.2019.106587?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.ymssp.2019.106587, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1829456",
        "name": "Y. Lei"
      },
      {
        "authorId": "2118581438",
        "name": "Bin Yang"
      },
      {
        "authorId": "2144793979",
        "name": "Xinwei Jiang"
      },
      {
        "authorId": "46691607",
        "name": "Feng Jia"
      },
      {
        "authorId": "2217450625",
        "name": "Naipeng Li"
      },
      {
        "authorId": "145720325",
        "name": "A. Nandi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4087e84fc695bb6433d0104ee94f9d7e9f4b7da5",
    "title": "Machine Learning for Fluid Mechanics",
    "venue": "Annual Review of Fluid Mechanics",
    "year": 2019,
    "citationCount": 2383,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1905.11075",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.11075, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3083169",
        "name": "S. Brunton"
      },
      {
        "authorId": "144875384",
        "name": "B. R. Noack"
      },
      {
        "authorId": "1802604",
        "name": "P. Koumoutsakos"
      }
    ],
    "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications."
  },
  {
    "paperId": "f75b70c9d7078724b592ec3e21de705e7b6ff73f",
    "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
    "venue": "",
    "year": 2017,
    "citationCount": 2863,
    "openAccessPdf": {
      "url": "https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1111/ectj.12097?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/ectj.12097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "26331346",
        "name": "V. Chernozhukov"
      },
      {
        "authorId": "88741529",
        "name": "D. Chetverikov"
      },
      {
        "authorId": "88741890",
        "name": "Mert Demirer"
      },
      {
        "authorId": "2259683",
        "name": "E. Duflo"
      },
      {
        "authorId": "144613163",
        "name": "Christian Hansen"
      },
      {
        "authorId": "3646527",
        "name": "Whitney K. Newey"
      },
      {
        "authorId": "145607066",
        "name": "J. Robins"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fbc6562814e08e416e28a268ce7beeaa3d0708c8",
    "title": "Large-Scale Machine Learning with Stochastic Gradient Descent",
    "venue": "International Conference on Computational Statistics",
    "year": 2010,
    "citationCount": 6110,
    "openAccessPdf": {
      "url": "http://leon.bottou.org/publications/pdf/compstat-2010.pdf",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-7908-2604-3_16?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-7908-2604-3_16, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "52184096",
        "name": "L. Bottou"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e068be31ded63600aea068eacd12931efd2a1029",
    "title": "UCI Repository of machine learning databases",
    "venue": "",
    "year": 1998,
    "citationCount": 14391,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145298005",
        "name": "Catherine Blake"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "62ccd99a65bfc7c735ae1f33b75b107665de95df",
    "title": "Federated Machine Learning",
    "venue": "ACM Transactions on Intelligent Systems and Technology",
    "year": 2019,
    "citationCount": 2606,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1902.04885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      },
      {
        "authorId": "1614034792",
        "name": "Yang Liu"
      },
      {
        "authorId": "11573257",
        "name": "Tianjian Chen"
      },
      {
        "authorId": "8230559",
        "name": "Yongxin Tong"
      }
    ],
    "abstract": "Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy."
  },
  {
    "paperId": "9583ac53a19cdf0db81fef6eb0b63e66adbe2324",
    "title": "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 2165,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3094352",
        "name": "Peva Blanchard"
      },
      {
        "authorId": "9623412",
        "name": "El Mahdi El Mhamdi"
      },
      {
        "authorId": "1727558",
        "name": "R. Guerraoui"
      },
      {
        "authorId": "1718150",
        "name": "J. Stainer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7feb0fc888cd55360949554db032d7d1cba9e947",
    "title": "Programs for Machine Learning",
    "venue": "",
    "year": 1994,
    "citationCount": 9146,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1744109",
        "name": "S. Salzberg"
      },
      {
        "authorId": "1800681",
        "name": "Alberto Maria Segre"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6b20af22b0734757d9ead382b201a65f9dd637cc",
    "title": "Machine learning in automated text categorization",
    "venue": "CSUR",
    "year": 2001,
    "citationCount": 8975,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/cs/0110053",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/cs/0110053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145077269",
        "name": "F. Sebastiani"
      }
    ],
    "abstract": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation."
  },
  {
    "paperId": "df70977e0347b76fb049c17c3956f643bcb43a55",
    "title": "Understanding of Machine Learning with Deep Learning: Architectures, Workflow, Applications and Future Directions",
    "venue": "De Computis",
    "year": 2023,
    "citationCount": 705,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/computers12050091?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/computers12050091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2013359",
        "name": "Mohammad Mustafa Taye"
      }
    ],
    "abstract": "In recent years, deep learning (DL) has been the most popular computational approach in the field of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artificial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the benefits of deep learning. In the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. Moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work."
  },
  {
    "paperId": "35b1d79993f0e4fbfcb3b86c5013c5e2a7e3117c",
    "title": "Small data machine learning in materials science",
    "venue": "npj Computational Materials",
    "year": 2023,
    "citationCount": 450,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41524-023-01000-z.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41524-023-01000-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41524-023-01000-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2046108691",
        "name": "Pengcheng Xu"
      },
      {
        "authorId": "2212548000",
        "name": "Xiaobo Ji"
      },
      {
        "authorId": "2145962665",
        "name": "Minjie Li"
      },
      {
        "authorId": "2111608481",
        "name": "Wencong Lu"
      }
    ],
    "abstract": "This review discussed the dilemma of small data faced by materials machine learning. First, we analyzed the limitations brought by small data. Then, the workflow of materials machine learning has been introduced. Next, the methods of dealing with small data were introduced, including data extraction from publications, materials database construction, high-throughput computations and experiments from the data source level; modeling algorithms for small data and imbalanced learning from the algorithm level; active learning and transfer learning from the machine learning strategy level. Finally, the future directions for small data machine learning in materials science were proposed."
  },
  {
    "paperId": "20f63033e8775cbab0692aed92d38da7e725d64e",
    "title": "Understanding Machine Learning - From Theory to Algorithms",
    "venue": "",
    "year": 2014,
    "citationCount": 3534,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1389955537",
        "name": "Shai Shalev-Shwartz"
      },
      {
        "authorId": "1401829700",
        "name": "Shai Ben-David"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d0ab11de3077490c80a08abd0fb8827bac84c454",
    "title": "MoleculeNet: a benchmark for molecular machine learning",
    "venue": "Chemical Science",
    "year": 2017,
    "citationCount": 2136,
    "openAccessPdf": {
      "url": "https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a",
      "status": "GOLD",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.00564, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9957625",
        "name": "Zhenqin Wu"
      },
      {
        "authorId": "2378027",
        "name": "Bharath Ramsundar"
      },
      {
        "authorId": "5932099",
        "name": "Evan N. Feinberg"
      },
      {
        "authorId": "145986494",
        "name": "Joseph Gomes"
      },
      {
        "authorId": "2347660128",
        "name": "Caleb Geniesse"
      },
      {
        "authorId": "5929246",
        "name": "Aneesh S. Pappu"
      },
      {
        "authorId": "40867019",
        "name": "K. Leswing"
      },
      {
        "authorId": "1806271",
        "name": "V. Pande"
      }
    ],
    "abstract": "A large scale benchmark for molecular machine learning consisting of multiple public datasets, metrics, featurizations and learning algorithms."
  },
  {
    "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
    "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
    "venue": "International Conference on Learning Representations",
    "year": 2014,
    "citationCount": 28422,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1409.0473, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3335364",
        "name": "Dzmitry Bahdanau"
      },
      {
        "authorId": "1979489",
        "name": "Kyunghyun Cho"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
  },
  {
    "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
    "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2014,
    "citationCount": 24935,
    "openAccessPdf": {
      "url": "https://aclanthology.org/D14-1179.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1406.1078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1979489",
        "name": "Kyunghyun Cho"
      },
      {
        "authorId": "3158246",
        "name": "B. V. Merrienboer"
      },
      {
        "authorId": "1854385",
        "name": "Çaglar Gülçehre"
      },
      {
        "authorId": "3335364",
        "name": "Dzmitry Bahdanau"
      },
      {
        "authorId": "2076086",
        "name": "Fethi Bougares"
      },
      {
        "authorId": "144518416",
        "name": "Holger Schwenk"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
  },
  {
    "paperId": "e0408181bccb7e3754dd5e6785ec47d8beb8b6bd",
    "title": "Machine Learning for High-Speed Corner Detection",
    "venue": "European Conference on Computer Vision",
    "year": 2006,
    "citationCount": 4939,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/11744023_34.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/11744023_34?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/11744023_34, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1721991",
        "name": "E. Rosten"
      },
      {
        "authorId": "144418842",
        "name": "T. Drummond"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2afa490dde7a8c582d889530c7f8b042fef6a8b7",
    "title": "Machine learning–accelerated computational fluid dynamics",
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "year": 2021,
    "citationCount": 998,
    "openAccessPdf": {
      "url": "https://doi.org/10.1073/pnas.2101784118",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2102.01010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40833997",
        "name": "Dmitrii Kochkov"
      },
      {
        "authorId": "2119124568",
        "name": "Jamie A. Smith"
      },
      {
        "authorId": "2078196952",
        "name": "Ayya Alieva"
      },
      {
        "authorId": "2286764736",
        "name": "Qing Wang"
      },
      {
        "authorId": "36397553",
        "name": "M. Brenner"
      },
      {
        "authorId": "2257229905",
        "name": "Stephan Hoyer"
      }
    ],
    "abstract": "Significance Accurate simulation of fluids is important for many science and engineering problems but is very computationally demanding. In contrast, machine-learning models can approximate physics very quickly but at the cost of accuracy. Here we show that using machine learning inside traditional fluid simulations can improve both accuracy and speed, even on examples very different from the training data. Our approach opens the door to applying machine learning to large-scale physical modeling tasks like airplane design and climate prediction. Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier–Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10× finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization."
  },
  {
    "paperId": "0d6ef817813d04a3b3ec6c3ce008e104fb3e587a",
    "title": "Classification Based on Decision Tree Algorithm for Machine Learning",
    "venue": "Journal of Applied Science and Technology Trends",
    "year": 2021,
    "citationCount": 1395,
    "openAccessPdf": {
      "url": "https://www.jastt.org/index.php/jasttpath/article/download/65/24",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.38094/JASTT20165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.38094/JASTT20165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2087620751",
        "name": "Bahzad Charbuty"
      },
      {
        "authorId": "35323115",
        "name": "A. Abdulazeez"
      }
    ],
    "abstract": "Decision tree classifiers are regarded to be a standout of the most well-known methods to data classification representation of classifiers. Different researchers from various fields and backgrounds have considered the problem of extending a decision tree from available data, such as machine study, pattern recognition, and statistics. In various fields such as medical disease analysis, text classification, user smartphone classification, images, and many more the employment of Decision tree classifiers has been proposed in many ways. This paper provides a detailed approach to the decision trees. Furthermore, paper specifics, such as algorithms/approaches used, datasets, and outcomes achieved, are evaluated and outlined comprehensively. In addition, all of the approaches analyzed were discussed to illustrate the themes of the authors and identify the most accurate classifiers. As a result, the uses of different types of datasets are discussed and their findings are analyzed."
  },
  {
    "paperId": "a0f303b6e22ef52943355993f57d65938997066a",
    "title": "Machine learning and deep learning",
    "venue": "Electronic Markets",
    "year": 2021,
    "citationCount": 1472,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2104.05314, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3012649",
        "name": "Christian Janiesch"
      },
      {
        "authorId": "2148733",
        "name": "Patrick Zschech"
      },
      {
        "authorId": "30004936",
        "name": "K. Heinrich"
      }
    ],
    "abstract": "Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization."
  },
  {
    "paperId": "8fedd23c1604dfeed02b75f8d38c1d7e33beee3a",
    "title": "Machine learning-aided engineering of hydrolases for PET depolymerization",
    "venue": "Nature",
    "year": 2022,
    "citationCount": 758,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41586-022-04599-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41586-022-04599-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47896740",
        "name": "Hongyuan Lu"
      },
      {
        "authorId": "146482230",
        "name": "Daniel J. Diaz"
      },
      {
        "authorId": "1581626498",
        "name": "Natalie J. Czarnecki"
      },
      {
        "authorId": "11308819",
        "name": "Congzhi Zhu"
      },
      {
        "authorId": "2143948699",
        "name": "Wantae Kim"
      },
      {
        "authorId": "145230191",
        "name": "Raghav Shroff"
      },
      {
        "authorId": "2133560828",
        "name": "Daniel J. Acosta"
      },
      {
        "authorId": "2133614006",
        "name": "Brad Alexander"
      },
      {
        "authorId": "2133153248",
        "name": "Hannah O. Cole"
      },
      {
        "authorId": "2152822214",
        "name": "Yan Zhang"
      },
      {
        "authorId": "4805394",
        "name": "Nathaniel A. Lynd"
      },
      {
        "authorId": "3210657",
        "name": "A. Ellington"
      },
      {
        "authorId": "48532409",
        "name": "H. Alper"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6a6ad9eb495739f4c80e7c09598720c3d5c5dff7",
    "title": "Federated Learning: Collaborative Machine Learning without\nCentralized Training Data",
    "venue": "International Journal of Engineering Technology and Management Sciences",
    "year": 2022,
    "citationCount": 741,
    "openAccessPdf": {
      "url": "https://doi.org/10.46647/ijetms.2022.v06i05.052",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.46647/ijetms.2022.v06i05.052?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.46647/ijetms.2022.v06i05.052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2181966147",
        "name": "Abhishek V A"
      },
      {
        "authorId": "2238323908",
        "name": "Binny S"
      },
      {
        "authorId": "2181972275",
        "name": "Johan T R"
      },
      {
        "authorId": "2181974014",
        "name": "Nithin Raj"
      },
      {
        "authorId": "2181972083",
        "name": "Vishal Thomas"
      }
    ],
    "abstract": "Federated learning (also known as collaborative learning) is a machine learning technique that trains\nan algorithm without transferring data samples across numerous decentralized edge devices or\nservers. This strategy differs from standard centralized machine learning techniques in which all local\ndatasets are uploaded to a single server, as well as more traditional decentralized alternatives, which\nfrequently presume that local data samples are uniformly distributed.\nFederated learning allows several actors to collaborate on the development of a single, robust\nmachine learning model without sharing data, allowing crucial issues such as data privacy, data\nsecurity, data access rights, and access to heterogeneous data to be addressed. Defence,\ntelecommunications, internet of things, and pharmaceutical industries are just a few of the sectors\nwhere it has applications."
  },
  {
    "paperId": "f64670a5f54fcce339a916497a001cbf02a9a04f",
    "title": "A Review on Fairness in Machine Learning",
    "venue": "ACM Computing Surveys",
    "year": 2022,
    "citationCount": 570,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3494672?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3494672, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2130148626",
        "name": "Dana Pessach"
      },
      {
        "authorId": "1824816",
        "name": "E. Shmueli"
      }
    ],
    "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification."
  },
  {
    "paperId": "80d9f0eb47b712988d19cbe29a7bfa63f2a175d0",
    "title": "A guide to machine learning for biologists",
    "venue": "Nature reviews. Molecular cell biology",
    "year": 2021,
    "citationCount": 1371,
    "openAccessPdf": {
      "url": "https://discovery.ucl.ac.uk/10134478/1/NRMCB-review-accepted-forRPS.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41580-021-00407-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41580-021-00407-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "36526409",
        "name": "Joe G. Greener"
      },
      {
        "authorId": "2262107",
        "name": "S. Kandathil"
      },
      {
        "authorId": "50881145",
        "name": "Lewis Moffat"
      },
      {
        "authorId": "2118729790",
        "name": "David T. Jones"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6bc43977fb11cceed0b9aa55b23c6dd29dd9a132",
    "title": "Correlation-based Feature Selection for Machine Learning",
    "venue": "",
    "year": 2003,
    "citationCount": 4038,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "118860642",
        "name": "M. Hall"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "76473802cd427a8efcc9958ef86f897eccf3af58",
    "title": "Introduction to Machine Learning",
    "venue": "Big Data and Artificial Intelligence for Healthcare Applications",
    "year": 2018,
    "citationCount": 2491,
    "openAccessPdf": {
      "url": "https://www.intechopen.com/citation-pdf-url/10703",
      "status": "GREEN",
      "license": "CCBYNCSA",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2409.02668, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1691898",
        "name": "Ethem Alpaydin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7eb733c8ac1b3d1dd8b50e066ddae10769e3b46e",
    "title": "CrypTen: Secure Multi-Party Computation Meets Machine Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2021,
    "citationCount": 451,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2109.00984, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2713842",
        "name": "Brian Knott"
      },
      {
        "authorId": "2262405",
        "name": "Shobha Venkataraman"
      },
      {
        "authorId": "144479015",
        "name": "Awni Y. Hannun"
      },
      {
        "authorId": "2264597",
        "name": "Shubho Sengupta"
      },
      {
        "authorId": "3407874",
        "name": "Mark Ibrahim"
      },
      {
        "authorId": "1803520",
        "name": "L. Maaten"
      }
    ],
    "abstract": "Secure multi-party computation (MPC) allows parties to perform computations on data while keeping that data private. This capability has great potential for machine-learning applications: it facilitates training of machine-learning models on private data sets owned by different parties, evaluation of one party's private model using another party's private data, etc. Although a range of studies implement machine-learning models via secure MPC, such implementations are not yet mainstream. Adoption of secure MPC is hampered by the absence of flexible software frameworks that\"speak the language\"of machine-learning researchers and engineers. To foster adoption of secure MPC in machine learning, we present CrypTen: a software framework that exposes popular secure MPC primitives via abstractions that are common in modern machine-learning frameworks, such as tensor computations, automatic differentiation, and modular neural networks. This paper describes the design of CrypTen and measure its performance on state-of-the-art models for text classification, speech recognition, and image classification. Our benchmarks show that CrypTen's GPU support and high-performance communication between (an arbitrary number of) parties allows it to perform efficient private evaluation of modern machine-learning models under a semi-honest threat model. For example, two parties using CrypTen can securely predict phonemes in speech recordings using Wav2Letter faster than real-time. We hope that CrypTen will spur adoption of secure MPC in the machine-learning community."
  },
  {
    "paperId": "256db9dba1978f004a67c86ffc321563b1aee79a",
    "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",
    "venue": "Statistics Survey",
    "year": 2021,
    "citationCount": 824,
    "openAccessPdf": {
      "url": "https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2103.11251, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48395540",
        "name": "C. Rudin"
      },
      {
        "authorId": null,
        "name": "Chaofan Chen"
      },
      {
        "authorId": "2143786389",
        "name": "Zhi Chen"
      },
      {
        "authorId": "2146285954",
        "name": "Haiyang Huang"
      },
      {
        "authorId": "151489878",
        "name": "Lesia Semenova"
      },
      {
        "authorId": "1750932565",
        "name": "Chudi Zhong"
      }
    ],
    "abstract": "Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the\"Rashomon set\"of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning."
  },
  {
    "paperId": "f1b962fb4070fedd46758e334db3ba4f00ddc3ec",
    "title": "Supervised Machine Learning: A Review of Classification Techniques",
    "venue": "Informatica",
    "year": 2007,
    "citationCount": 4900,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1697867",
        "name": "S. Kotsiantis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4d8f0ae904779a50b2e18fec49e51a5661a98d8a",
    "title": "MRI-Based Brain Tumor Classification Using Ensemble of Deep Features and Machine Learning Classifiers",
    "venue": "Italian National Conference on Sensors",
    "year": 2021,
    "citationCount": 435,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1424-8220/21/6/2222/pdf?version=1616574103",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8004778, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2837279",
        "name": "Jaeyong Kang"
      },
      {
        "authorId": "48740398",
        "name": "Z. Ullah"
      },
      {
        "authorId": "1969352",
        "name": "Jeonghwan Gwak"
      }
    ],
    "abstract": "Brain tumor classification plays an important role in clinical diagnosis and effective treatment. In this work, we propose a method for brain tumor classification using an ensemble of deep features and machine learning classifiers. In our proposed framework, we adopt the concept of transfer learning and uses several pre-trained deep convolutional neural networks to extract deep features from brain magnetic resonance (MR) images. The extracted deep features are then evaluated by several machine learning classifiers. The top three deep features which perform well on several machine learning classifiers are selected and concatenated as an ensemble of deep features which is then fed into several machine learning classifiers to predict the final output. To evaluate the different kinds of pre-trained models as a deep feature extractor, machine learning classifiers, and the effectiveness of an ensemble of deep feature for brain tumor classification, we use three different brain magnetic resonance imaging (MRI) datasets that are openly accessible from the web. Experimental results demonstrate that an ensemble of deep features can help improving performance significantly, and in most cases, support vector machine (SVM) with radial basis function (RBF) kernel outperforms other machine learning classifiers, especially for large datasets."
  },
  {
    "paperId": "48ddd9101a90fe65e3061de69626741b843ff5e4",
    "title": "The use of the area under the ROC curve in the evaluation of machine learning algorithms",
    "venue": "Pattern Recognition",
    "year": 1997,
    "citationCount": 6852,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0031-3203(96)00142-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0031-3203(96)00142-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1720617",
        "name": "A. Bradley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
    "title": "SecureML: A System for Scalable Privacy-Preserving Machine Learning",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2017,
    "citationCount": 1984,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/SP.2017.12?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SP.2017.12, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1773836",
        "name": "Payman Mohassel"
      },
      {
        "authorId": "2108473999",
        "name": "Yupeng Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8ca86e941da7254613a5d03dd7a6c36886fadc1d",
    "title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)",
    "venue": "",
    "year": 2005,
    "citationCount": 4294,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2247411478",
        "name": "Carl E. Rasmussen"
      },
      {
        "authorId": "2248834664",
        "name": "Christopher K. I. Williams"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "05c5b732fb92546c7d6eeabfadb5c14610d07373",
    "title": "Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 2278,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.06570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144272231",
        "name": "G. Lemaître"
      },
      {
        "authorId": "2054680697",
        "name": "Fernando Nogueira"
      },
      {
        "authorId": "3451187",
        "name": "Christos K. Aridas"
      }
    ],
    "abstract": "Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: this https URL."
  },
  {
    "paperId": "eb9e0da8b7170e3ca4364f2f9010599c2d2556f1",
    "title": "Machine Learning With Python",
    "venue": "",
    "year": 2019,
    "citationCount": 2149,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144470846",
        "name": "Ajit Singh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "62cadbc4fcc73204a72847300cb2214f4401efad",
    "title": "Human-in-the-loop machine learning: a state of the art",
    "venue": "Artificial Intelligence Review",
    "year": 2022,
    "citationCount": 561,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10462-022-10246-w.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-022-10246-w?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-022-10246-w, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1402122878",
        "name": "E. Mosqueira-Rey"
      },
      {
        "authorId": "1401777431",
        "name": "Elena Hernández-Pereira"
      },
      {
        "authorId": "1403901547",
        "name": "David Alonso-Ríos"
      },
      {
        "authorId": "1403863088",
        "name": "José Bobes-Bascarán"
      },
      {
        "authorId": "1402123073",
        "name": "Á. Fernández-Leal"
      }
    ],
    "abstract": "Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them."
  },
  {
    "paperId": "0ad4189bdddfa32ecf7b1c9122eba57c8d8bbc7f",
    "title": "Educational data mining: prediction of students' academic performance using machine learning algorithms",
    "venue": "Smart Learning Environments",
    "year": 2022,
    "citationCount": 463,
    "openAccessPdf": {
      "url": "https://slejournal.springeropen.com/track/pdf/10.1186/s40561-022-00192-z",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1186/s40561-022-00192-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s40561-022-00192-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35731745",
        "name": "M. Yağcı"
      }
    ],
    "abstract": "Educational data mining has become an effective tool for exploring the hidden relationships in educational data and predicting students' academic achievements. This study proposes a new model based on machine learning algorithms to predict the final exam grades of undergraduate students, taking their midterm exam grades as the source data. The performances of the random forests, nearest neighbour, support vector machines, logistic regression, Naïve Bayes, and k-nearest neighbour algorithms, which are among the machine learning algorithms, were calculated and compared to predict the final exam grades of the students. The dataset consisted of the academic achievement grades of 1854 students who took the Turkish Language-I course in a state University in Turkey during the fall semester of 2019–2020. The results show that the proposed model achieved a classification accuracy of 70–75%. The predictions were made using only three types of parameters; midterm exam grades, Department data and Faculty data. Such data-driven studies are very important in terms of establishing a learning analysis framework in higher education and contributing to the decision-making processes. Finally, this study presents a contribution to the early prediction of students at high risk of failure and determines the most effective machine learning methods."
  },
  {
    "paperId": "911fbaec109f72130815e05e2633ec879590382c",
    "title": "A Review of Feature Selection Methods for Machine Learning-Based Disease Risk Prediction",
    "venue": "Frontiers in Bioinformatics",
    "year": 2022,
    "citationCount": 545,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fbinf.2022.927312/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9580915, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2173960876",
        "name": "N. Pudjihartono"
      },
      {
        "authorId": "26981228",
        "name": "T. Fadason"
      },
      {
        "authorId": "2121964257",
        "name": "Andreas W. Kempa-Liehr"
      },
      {
        "authorId": "1395754308",
        "name": "J. O’Sullivan"
      }
    ],
    "abstract": "Machine learning has shown utility in detecting patterns within large, unstructured, and complex datasets. One of the promising applications of machine learning is in precision medicine, where disease risk is predicted using patient genetic data. However, creating an accurate prediction model based on genotype data remains challenging due to the so-called “curse of dimensionality” (i.e., extensively larger number of features compared to the number of samples). Therefore, the generalizability of machine learning models benefits from feature selection, which aims to extract only the most “informative” features and remove noisy “non-informative,” irrelevant and redundant features. In this article, we provide a general overview of the different feature selection methods, their advantages, disadvantages, and use cases, focusing on the detection of relevant features (i.e., SNPs) for disease risk prediction."
  },
  {
    "paperId": "ab06951251e0abfdb866694f9a23a79c72784317",
    "title": "Challenges and opportunities in quantum machine learning",
    "venue": "Nature Computational Science",
    "year": 2022,
    "citationCount": 572,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2303.09491, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2192840743",
        "name": "M. Cerezo"
      },
      {
        "authorId": "102620709",
        "name": "Guillaume Verdon"
      },
      {
        "authorId": "2343654",
        "name": "Hsin-Yuan Huang"
      },
      {
        "authorId": "49556529",
        "name": "L. Cincio"
      },
      {
        "authorId": "50721537",
        "name": "Patrick J. Coles"
      }
    ],
    "abstract": "At the intersection of machine learning and quantum computing, quantum machine learning has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry and high-energy physics. Nevertheless, challenges remain regarding the trainability of quantum machine learning models. Here we review current methods and applications for quantum machine learning. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with quantum machine learning. Quantum machine learning has become an essential tool to process and analyze the increased amount of quantum data. Despite recent progress, there are still many challenges to be addressed and myriad future avenues of research."
  },
  {
    "paperId": "89e5b63ade995059cf3dfd9580a59b2291e63564",
    "title": "Machine Learning for Electrocatalyst and Photocatalyst Design and Discovery.",
    "venue": "Chemical Reviews",
    "year": 2022,
    "citationCount": 307,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1021/acs.chemrev.2c00061?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acs.chemrev.2c00061, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "37238544",
        "name": "Haoxin Mai"
      },
      {
        "authorId": "2044181",
        "name": "T. Le"
      },
      {
        "authorId": "10247825",
        "name": "Dehong Chen"
      },
      {
        "authorId": "2105939165",
        "name": "D. Winkler"
      },
      {
        "authorId": "39714040",
        "name": "R. Caruso"
      }
    ],
    "abstract": "Electrocatalysts and photocatalysts are key to a sustainable future, generating clean fuels, reducing the impact of global warming, and providing solutions to environmental pollution. Improved processes for catalyst design and a better understanding of electro/photocatalytic processes are essential for improving catalyst effectiveness. Recent advances in data science and artificial intelligence have great potential to accelerate electrocatalysis and photocatalysis research, particularly the rapid exploration of large materials chemistry spaces through machine learning. Here a comprehensive introduction to, and critical review of, machine learning techniques used in electrocatalysis and photocatalysis research are provided. Sources of electro/photocatalyst data and current approaches to representing these materials by mathematical features are described, the most commonly used machine learning methods summarized, and the quality and utility of electro/photocatalyst models evaluated. Illustrations of how machine learning models are applied to novel electro/photocatalyst discovery and used to elucidate electrocatalytic or photocatalytic reaction mechanisms are provided. The review offers a guide for materials scientists on the selection of machine learning methods for electrocatalysis and photocatalysis research. The application of machine learning to catalysis science represents a paradigm shift in the way advanced, next-generation catalysts will be designed and synthesized."
  },
  {
    "paperId": "09c72d9d46f6750e487afdb5f7cae7693ffccc10",
    "title": "The Shapley Value in Machine Learning",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2022,
    "citationCount": 272,
    "openAccessPdf": {
      "url": "https://www.ijcai.org/proceedings/2022/0778.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2202.05594, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35806328",
        "name": "Benedek Rozemberczki"
      },
      {
        "authorId": "2058604454",
        "name": "Lauren Watson"
      },
      {
        "authorId": "2056355686",
        "name": "Péter Bayer"
      },
      {
        "authorId": "2820299",
        "name": "Hao-Tsung Yang"
      },
      {
        "authorId": "104031520",
        "name": "Oliver Kiss"
      },
      {
        "authorId": "2136371907",
        "name": "Sebastian Nilsson"
      },
      {
        "authorId": "2056781762",
        "name": "Rik Sarkar"
      }
    ],
    "abstract": "Over the last few years, the Shapley value, a solution concept from cooperative game theory, has found numerous applications in machine learning. In this paper, we first discuss fundamental concepts of cooperative game theory and axiomatic properties of the Shapley value. Then we give an overview of the most important applications of the Shapley value in machine learning: feature selection, explainability, multi-agent reinforcement learning, ensemble pruning, and data valuation. We examine the most crucial limitations of the Shapley value and point out directions for future research."
  },
  {
    "paperId": "db5ca8699d5a3a0cbd72e7118072e41c3d6b621e",
    "title": "Interpretable machine learning for knowledge generation in heterogeneous catalysis",
    "venue": "Nature Catalysis",
    "year": 2022,
    "citationCount": 259,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41929-022-00744-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41929-022-00744-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144292869",
        "name": "J. Esterhuizen"
      },
      {
        "authorId": "8797649",
        "name": "B. Goldsmith"
      },
      {
        "authorId": "3673517",
        "name": "S. Linic"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2346d121f38fc19c77e0b062415519843f478163",
    "title": "Machine Learning in Medicine",
    "venue": "Mach. Learn. under Resour. Constraints Vol. 3",
    "year": 2015,
    "citationCount": 3377,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc5831252?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1161/CIRCULATIONAHA.115.001593?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/CIRCULATIONAHA.115.001593, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2077989",
        "name": "Rahul C. Deo"
      },
      {
        "authorId": null,
        "name": "Karsten M. Borgwardt"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b5904cd5dbf73b8d5ff13517de490c292d877ee0",
    "title": "Applications of machine learning in drug discovery and development",
    "venue": "Nature reviews. Drug discovery",
    "year": 2019,
    "citationCount": 2027,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6552674",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41573-019-0024-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41573-019-0024-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3793520",
        "name": "J. Vamathevan"
      },
      {
        "authorId": "47420092",
        "name": "Dominic Clark"
      },
      {
        "authorId": "1927408",
        "name": "P. Czodrowski"
      },
      {
        "authorId": "144312222",
        "name": "I. Dunham"
      },
      {
        "authorId": "2064181672",
        "name": "Edgardo Ferran"
      },
      {
        "authorId": "2166424886",
        "name": "George Lee"
      },
      {
        "authorId": "2185912448",
        "name": "Bin Li"
      },
      {
        "authorId": "1705442",
        "name": "A. Madabhushi"
      },
      {
        "authorId": "34243620",
        "name": "Parantu K. Shah"
      },
      {
        "authorId": "144357385",
        "name": "M. Spitzer"
      },
      {
        "authorId": "3926122",
        "name": "Shanrong Zhao"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "24d21ecaeb2d2ecc20e26a5e3f5128247704ccfe",
    "title": "Swarm Learning for decentralized and confidential clinical machine learning",
    "venue": "Nature",
    "year": 2021,
    "citationCount": 661,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41586-021-03583-3.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41586-021-03583-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41586-021-03583-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1441363881",
        "name": "Stefanie Warnat-Herresthal"
      },
      {
        "authorId": "1491641853",
        "name": "Hartmut Schultze"
      },
      {
        "authorId": "39126788",
        "name": "Krishnaprasad Shastry"
      },
      {
        "authorId": "2530831",
        "name": "Sathyanarayanan Manamohan"
      },
      {
        "authorId": "3040289",
        "name": "Saikat Mukherjee"
      },
      {
        "authorId": "2067125343",
        "name": "Vishesh Garg"
      },
      {
        "authorId": "7765742",
        "name": "Ravi Sarveswara"
      },
      {
        "authorId": "48648791",
        "name": "K. Händler"
      },
      {
        "authorId": "5953896",
        "name": "P. Pickkers"
      },
      {
        "authorId": "31528430",
        "name": "N. Aziz"
      },
      {
        "authorId": "8297290",
        "name": "S. Ktena"
      },
      {
        "authorId": "12668727",
        "name": "F. Tran"
      },
      {
        "authorId": "2220233",
        "name": "M. Bitzer"
      },
      {
        "authorId": "32478749",
        "name": "S. Ossowski"
      },
      {
        "authorId": "3818521",
        "name": "Nicolas Casadei"
      },
      {
        "authorId": "6317095",
        "name": "C. Herr"
      },
      {
        "authorId": "51327074",
        "name": "Daniel Petersheim"
      },
      {
        "authorId": "4829125",
        "name": "U. Behrends"
      },
      {
        "authorId": "37417418",
        "name": "Fabian Kern"
      },
      {
        "authorId": "4846639",
        "name": "Tobias Fehlmann"
      },
      {
        "authorId": "10371954",
        "name": "P. Schommers"
      },
      {
        "authorId": "4764355",
        "name": "C. Lehmann"
      },
      {
        "authorId": "30137838",
        "name": "M. Augustin"
      },
      {
        "authorId": "5775372",
        "name": "J. Rybniker"
      },
      {
        "authorId": "1963213",
        "name": "J. Altmüller"
      },
      {
        "authorId": "150247497",
        "name": "N. Mishra"
      },
      {
        "authorId": "1820956545",
        "name": "J. P. Bernardes"
      },
      {
        "authorId": "5634144",
        "name": "B. Krämer"
      },
      {
        "authorId": "145567472",
        "name": "L. Bonaguro"
      },
      {
        "authorId": "1397963301",
        "name": "J. Schulte-Schrepping"
      },
      {
        "authorId": "5342859",
        "name": "Elena De Domenico"
      },
      {
        "authorId": "1780746912",
        "name": "Christian Siever"
      },
      {
        "authorId": "50333718",
        "name": "Michael Kraut"
      },
      {
        "authorId": "153555977",
        "name": "Milind Desai"
      },
      {
        "authorId": "1780578787",
        "name": "Bruno Monnet"
      },
      {
        "authorId": "2128923813",
        "name": "M. Saridaki"
      },
      {
        "authorId": "144307851",
        "name": "Charles Siegel"
      },
      {
        "authorId": "49572483",
        "name": "A. Drews"
      },
      {
        "authorId": "1780708283",
        "name": "Melanie Nuesch-Germano"
      },
      {
        "authorId": "4505843",
        "name": "Heidi Theis"
      },
      {
        "authorId": "5172855",
        "name": "J. Heyckendorf"
      },
      {
        "authorId": "2172440244",
        "name": "S. Schreiber"
      },
      {
        "authorId": "2257989566",
        "name": "Sarah Kim-Hellmuth"
      },
      {
        "authorId": "6316085",
        "name": "J. Nattermann"
      },
      {
        "authorId": "6273548",
        "name": "D. Skowasch"
      },
      {
        "authorId": "6177275",
        "name": "I. Kurth"
      },
      {
        "authorId": "145122867",
        "name": "A. Keller"
      },
      {
        "authorId": "6664655",
        "name": "R. Bals"
      },
      {
        "authorId": "1701925",
        "name": "P. Nürnberg"
      },
      {
        "authorId": "2070590037",
        "name": "O. Riess"
      },
      {
        "authorId": "144883195",
        "name": "P. Rosenstiel"
      },
      {
        "authorId": "145123820",
        "name": "M. Netea"
      },
      {
        "authorId": "2051758169",
        "name": "F. Theis"
      },
      {
        "authorId": "145807368",
        "name": "S. Mukherjee"
      },
      {
        "authorId": "145598514",
        "name": "Michael Backes"
      },
      {
        "authorId": "143690088",
        "name": "A. Aschenbrenner"
      },
      {
        "authorId": "4796855",
        "name": "T. Ulas"
      },
      {
        "authorId": "145189483",
        "name": "M. Breteler"
      },
      {
        "authorId": "1381717153",
        "name": "E. Giamarellos‐Bourboulis"
      },
      {
        "authorId": "4713521",
        "name": "M. Kox"
      },
      {
        "authorId": "144332474",
        "name": "M. Becker"
      },
      {
        "authorId": "34936176",
        "name": "S. Cheran"
      },
      {
        "authorId": "2546502",
        "name": "M. Woodacre"
      },
      {
        "authorId": "17836661",
        "name": "E. L. Goh"
      },
      {
        "authorId": "2356294",
        "name": "J. Schultze"
      }
    ],
    "abstract": "Fast and reliable detection of patients with severe and heterogeneous illnesses is a major goal of precision medicine1,2. Patients with leukaemia can be identified using machine learning on the basis of their blood transcriptomes3. However, there is an increasing divide between what is technically possible and what is allowed, because of privacy legislation4,5. Here, to facilitate the integration of any medical data from any data owner worldwide without violating privacy laws, we introduce Swarm Learning—a decentralized machine-learning approach that unites edge computing, blockchain-based peer-to-peer networking and coordination while maintaining confidentiality without the need for a central coordinator, thereby going beyond federated learning. To illustrate the feasibility of using Swarm Learning to develop disease classifiers using distributed data, we chose four use cases of heterogeneous diseases (COVID-19, tuberculosis, leukaemia and lung pathologies). With more than 16,400 blood transcriptomes derived from 127 clinical studies with non-uniform distributions of cases and controls and substantial study biases, as well as more than 95,000 chest X-ray images, we show that Swarm Learning classifiers outperform those developed at individual sites. In addition, Swarm Learning completely fulfils local confidentiality regulations by design. We believe that this approach will notably accelerate the introduction of precision medicine. Swarm Learning is a decentralized machine learning approach that outperforms classifiers developed at individual sites for COVID-19 and other diseases while preserving confidentiality and privacy."
  },
  {
    "paperId": "60caa5b3d066e13feac496fd0736e976970eb09f",
    "title": "Overview of Machine Learning",
    "venue": "International Journal of Advanced Research in Science, Communication and Technology",
    "year": 2022,
    "citationCount": 203,
    "openAccessPdf": {
      "url": "https://doi.org/10.48175/ijarsct-4844",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.48175/ijarsct-4844?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48175/ijarsct-4844, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2256303860",
        "name": "Daniel Hsu"
      }
    ],
    "abstract": "The machine learning field, which can be briefly defined as enabling computers make successful predictions using past experiences, has exhibited an impressive development recently with the help of the rapid increase in the storage capacity and processing power of computers. Together with many other disciplines, machine learning methods have been widely employed in bioinformatics. The difficulties and cost of biological analyses have led to the development of sophisticated machine learning approaches for this application area. In this chapter, we first review the fundamental concepts of machine learning such as feature assessment, unsupervised versus supervised learning and types of classification. Then, we point out the main issues of designing machine learning experiments and their performance evaluation. Finally, we introduce some supervised learning methods"
  },
  {
    "paperId": "b631ba962b4403a9c0fd9cce446ef3b1e21ea059",
    "title": "Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods",
    "venue": "Machine-mediated learning",
    "year": 2019,
    "citationCount": 1673,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-021-05946-3.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1910.09457, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1691955",
        "name": "Eyke Hüllermeier"
      },
      {
        "authorId": "3249834",
        "name": "W. Waegeman"
      }
    ],
    "abstract": "The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular."
  },
  {
    "paperId": "6e23398447a022fb9495c44fa80e9de593a574bc",
    "title": "Machine Learning in Agriculture: A Review",
    "venue": "Italian National Conference on Sensors",
    "year": 2018,
    "citationCount": 2108,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6111295, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2752858",
        "name": "Konstantinos G. Liakos"
      },
      {
        "authorId": "3375011",
        "name": "P. Busato"
      },
      {
        "authorId": "3201660",
        "name": "D. Moshou"
      },
      {
        "authorId": "145802955",
        "name": "S. Pearson"
      },
      {
        "authorId": "2345652",
        "name": "D. Bochtis"
      }
    ],
    "abstract": "Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action."
  },
  {
    "paperId": "f86f1748d1b6d22870f4347fd5d65314ba800583",
    "title": "Reconciling modern machine-learning practice and the classical bias–variance trade-off",
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "year": 2018,
    "citationCount": 1823,
    "openAccessPdf": {
      "url": "https://www.pnas.org/content/pnas/116/32/15849.full.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1812.11118, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145520115",
        "name": "M. Belkin"
      },
      {
        "authorId": "143724861",
        "name": "Daniel J. Hsu"
      },
      {
        "authorId": "143791100",
        "name": "Siyuan Ma"
      },
      {
        "authorId": "151213231",
        "name": "Soumik Mandal"
      }
    ],
    "abstract": "Significance While breakthroughs in machine learning and artificial intelligence are changing society, our fundamental understanding has lagged behind. It is traditionally believed that fitting models to the training data exactly is to be avoided as it leads to poor performance on unseen data. However, powerful modern classifiers frequently have near-perfect fit in training, a disconnect that spurred recent intensive research and controversy on whether theory provides practical insights. In this work, we show how classical theory and modern practice can be reconciled within a single unified performance curve and propose a mechanism underlying its emergence. We believe this previously unknown pattern connecting the structure and performance of learning architectures will help shape design and understanding of learning algorithms. Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias–variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias–variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This “double-descent” curve subsumes the textbook U-shaped bias–variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning."
  },
  {
    "paperId": "15eded04386a8982ccd5627bd1efe70bbf624c02",
    "title": "Quantum machine learning",
    "venue": "Nature",
    "year": 2016,
    "citationCount": 2258,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.09347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2353247",
        "name": "J. Biamonte"
      },
      {
        "authorId": "1756871",
        "name": "P. Wittek"
      },
      {
        "authorId": "2347529678",
        "name": "Nicola Pancotti"
      },
      {
        "authorId": "3157522",
        "name": "P. Rebentrost"
      },
      {
        "authorId": "3253856",
        "name": "N. Wiebe"
      },
      {
        "authorId": "145762777",
        "name": "S. Lloyd"
      }
    ],
    "abstract": "Fuelled by increasing computer power and algorithmic advances, machine learning techniques have become powerful tools for finding patterns in data. Quantum systems produce atypical patterns that classical systems are thought not to produce efficiently, so it is reasonable to postulate that quantum computers may outperform classical computers on machine learning tasks. The field of quantum machine learning explores how to devise and implement quantum software that could enable machine learning that is faster than that of classical computers. Recent work has produced quantum algorithms that could act as the building blocks of machine learning programs, but the hardware and software challenges are still considerable."
  },
  {
    "paperId": "4d1fdd81f033cd58f3723bfc61e7d12079647a7a",
    "title": "Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.",
    "venue": "New England Journal of Medicine",
    "year": 2016,
    "citationCount": 2519,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc5070532?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1056/NEJMp1606181?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1056/NEJMp1606181, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3797258",
        "name": "Z. Obermeyer"
      },
      {
        "authorId": "39714312",
        "name": "E. Emanuel"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "caf9e0fa2c340fb07cef8d547ea8849508e5c358",
    "title": "Empirical Asset Pricing Via Machine Learning",
    "venue": "The Review of financial studies",
    "year": 2018,
    "citationCount": 1699,
    "openAccessPdf": {
      "url": "http://www.nber.org/papers/w25398.pdf",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3159577?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3159577, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "90255997",
        "name": "Shihao Gu"
      },
      {
        "authorId": "152467398",
        "name": "B. Kelly"
      },
      {
        "authorId": "90286912",
        "name": "D. Xiu"
      }
    ],
    "abstract": "\n We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.\n Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online."
  },
  {
    "paperId": "2bc3644ce4de7fce5812c1455e056649a47c1bbf",
    "title": "Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques",
    "venue": "IEEE Access",
    "year": 2019,
    "citationCount": 1227,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08740989.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2923707?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2923707, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "150302778",
        "name": "Senthilkumar Mohan"
      },
      {
        "authorId": "9727014",
        "name": "Chandrasegar Thirumalai"
      },
      {
        "authorId": "144369609",
        "name": "Gautam Srivastava"
      }
    ],
    "abstract": "Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM)."
  },
  {
    "paperId": "b9518627db25f05930e931f56497602363a75491",
    "title": "Definitions, methods, and applications in interpretable machine learning",
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "year": 2019,
    "citationCount": 1577,
    "openAccessPdf": {
      "url": "https://www.pnas.org/content/pnas/116/44/22071.full.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1901.04592, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144585578",
        "name": "W. James Murdoch"
      },
      {
        "authorId": "145229121",
        "name": "Chandan Singh"
      },
      {
        "authorId": "19225295",
        "name": "Karl Kumbier"
      },
      {
        "authorId": "1405625449",
        "name": "R. Abbasi-Asl"
      },
      {
        "authorId": "2116415778",
        "name": "Bin Yu"
      }
    ],
    "abstract": "Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods."
  },
  {
    "paperId": "74bc39003e65119eaa6ba339a61b45b417a638b7",
    "title": "Machine Learning in Healthcare",
    "venue": "Deep Learning, Machine Learning and IoT in Biomedical and Health Informatics",
    "year": 2022,
    "citationCount": 209,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1201/9780367548445-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/9780367548445-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2353935",
        "name": "A. Ojha"
      },
      {
        "authorId": "2265544711",
        "name": "C. Vinitha"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "57e6cca1479a4642f867e69b4dee93d14259dc3d",
    "title": "Power of data in quantum machine learning",
    "venue": "Nature Communications",
    "year": 2020,
    "citationCount": 780,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41467-021-22539-9.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.01938, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2343654",
        "name": "Hsin-Yuan Huang"
      },
      {
        "authorId": "96014865",
        "name": "M. Broughton"
      },
      {
        "authorId": "145233982",
        "name": "M. Mohseni"
      },
      {
        "authorId": "47066334",
        "name": "R. Babbush"
      },
      {
        "authorId": "48703443",
        "name": "S. Boixo"
      },
      {
        "authorId": "2665814",
        "name": "H. Neven"
      },
      {
        "authorId": "1933508",
        "name": "J. McClean"
      }
    ],
    "abstract": "The use of quantum computing for machine learning is among the most exciting prospective applications of quantum technologies. However, machine learning tasks where data is provided can be considerably different than commonly studied computational tasks. In this work, we show that some problems that are classically hard to compute can be easily predicted by classical machines learning from data. Using rigorous prediction error bounds as a foundation, we develop a methodology for assessing potential quantum advantage in learning tasks. The bounds are tight asymptotically and empirically predictive for a wide range of learning models. These constructions explain numerical results showing that with the help of data, classical machine learning models can be competitive with quantum models even if they are tailored to quantum problems. We then propose a projected quantum model that provides a simple and rigorous quantum speed-up for a learning problem in the fault-tolerant regime. For near-term implementations, we demonstrate a significant prediction advantage over some classical models on engineered data sets designed to demonstrate a maximal quantum advantage in one of the largest numerical tests for gate-based quantum machine learning to date, up to 30 qubits. Expectations for quantum machine learning are high, but there is currently a lack of rigorous results on which scenarios would actually exhibit a quantum advantage. Here, the authors show how to tell, for a given dataset, whether a quantum model would give any prediction advantage over a classical one."
  },
  {
    "paperId": "c5c4142a01981787a71bf6ebcb791520c458ab5d",
    "title": "FedML: A Research Library and Benchmark for Federated Machine Learning",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 641,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2007.13518, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "31927890",
        "name": "Chaoyang He"
      },
      {
        "authorId": "2239461",
        "name": "Songze Li"
      },
      {
        "authorId": "144491689",
        "name": "Jinhyun So"
      },
      {
        "authorId": "2328615169",
        "name": "Mi Zhang"
      },
      {
        "authorId": "2109798334",
        "name": "Hongyi Wang"
      },
      {
        "authorId": "2118775509",
        "name": "Xiaoyang Wang"
      },
      {
        "authorId": "2927870",
        "name": "Praneeth Vepakomma"
      },
      {
        "authorId": "2034349211",
        "name": "Abhishek Singh"
      },
      {
        "authorId": null,
        "name": "Hang Qiu"
      },
      {
        "authorId": "2144035454",
        "name": "Li Shen"
      },
      {
        "authorId": "144259957",
        "name": "P. Zhao"
      },
      {
        "authorId": "1505828520",
        "name": "Yan Kang"
      },
      {
        "authorId": "1614034792",
        "name": "Yang Liu"
      },
      {
        "authorId": "145711633",
        "name": "R. Raskar"
      },
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      },
      {
        "authorId": "145599558",
        "name": "M. Annavaram"
      },
      {
        "authorId": "121011351",
        "name": "S. Avestimehr"
      }
    ],
    "abstract": "Federated learning is a rapidly growing research field in the machine learning domain. Although considerable research efforts have been made, existing libraries cannot adequately support diverse algorithmic development (e.g., diverse topology and flexible message exchange), and inconsistent dataset and model usage in experiments make fair comparisons difficult. In this work, we introduce FedML, an open research library and benchmark that facilitates the development of new federated learning algorithms and fair performance comparisons. FedML supports three computing paradigms (distributed training, mobile on-device training, and standalone simulation) for users to conduct experiments in different system environments. FedML also promotes diverse algorithmic research with flexible and generic API design and reference baseline implementations. A curated and comprehensive benchmark dataset for the non-I.I.D setting aims at making a fair comparison. We believe FedML can provide an efficient and reproducible means of developing and evaluating algorithms for the federated learning research community. We maintain the source code, documents, and user community at this https URL."
  },
  {
    "paperId": "696b388ee6221c6dbcfd647a06883b2bfee773d9",
    "title": "Universal Differential Equations for Scientific Machine Learning",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 680,
    "openAccessPdf": {
      "url": "https://www.researchsquare.com/article/rs-55125/v1.pdf?c=1631854486000",
      "status": "GREEN",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2001.04385, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5365695",
        "name": "Christopher Rackauckas"
      },
      {
        "authorId": "20859037",
        "name": "Yingbo Ma"
      },
      {
        "authorId": "118225834",
        "name": "Julius Martensen"
      },
      {
        "authorId": "1482544386",
        "name": "Collin Warner"
      },
      {
        "authorId": "123251938",
        "name": "K. Zubov"
      },
      {
        "authorId": "93421340",
        "name": "R. Supekar"
      },
      {
        "authorId": "2056678977",
        "name": "Dominic J. Skinner"
      },
      {
        "authorId": "37288593",
        "name": "A. Ramadhan"
      }
    ],
    "abstract": "\n In the context of science, the well-known adage “a picture is worth a thousand words” might well be “a model is worth a thousand datasets.” Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring \"big data\". In this work demonstrate how a mathematical object, which we denote universal differential equations (UDEs), can be utilized as a theoretical underpinning to a diverse array of problems in scientific machine learning to yield efficient algorithms and generalized approaches. The UDE model augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating the training of physics-informed neural networks and large-eddy simulations, can all be transformed into UDE training problems that are efficiently solved by a single software methodology."
  },
  {
    "paperId": "2ea6a93199c9227fa0c1c7de13725f918c9be3a4",
    "title": "Dlib-ml: A Machine Learning Toolkit",
    "venue": "Journal of machine learning research",
    "year": 2009,
    "citationCount": 3393,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1577069.1755843?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1577069.1755843, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2065224236",
        "name": "Davis E. King"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fee8f63972906214b77f16cfeca0b93ee8f36ba2",
    "title": "Fairness in Machine Learning: A Survey",
    "venue": "ACM Computing Surveys",
    "year": 2020,
    "citationCount": 769,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3616865",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.04053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2452441",
        "name": "Simon Caton"
      },
      {
        "authorId": "152864672",
        "name": "C. Haas"
      }
    ],
    "abstract": "When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research."
  },
  {
    "paperId": "e6b733b960cc1800487203af61de1c58b6299d5a",
    "title": "Heart Disease Prediction using Machine Learning Techniques",
    "venue": "SN Computer Science",
    "year": 2020,
    "citationCount": 690,
    "openAccessPdf": {
      "url": "https://doi.org/10.35940/ijitee.e2862.039520",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s42979-020-00365-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s42979-020-00365-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2082676186",
        "name": "Devansh Shah"
      },
      {
        "authorId": "2109520477",
        "name": "Samir B. Patel"
      },
      {
        "authorId": "2153846883",
        "name": "S. Bharti"
      }
    ],
    "abstract": "Heart disease, alternatively known as cardiovascular disease, encases various conditions that impact the heart and is the primary basis of death worldwide over the span of the past few decades. It associates many risk factors in heart disease and a need of the time to get accurate, reliable, and sensible approaches to make an early diagnosis to achieve prompt management of the disease. Data mining is a commonly used technique for processing enormous data in the healthcare domain. Researchers apply several data mining and machine learning techniques to analyse huge complex medical data, helping healthcare professionals to predict heart disease. This research paper presents various attributes related to heart disease, and the model on basis of supervised learning algorithms as Naïve Bayes, decision tree, K-nearest neighbor, and random forest algorithm. It uses the existing dataset from the Cleveland database of UCI repository of heart disease patients. The dataset comprises 303 instances and 76 attributes. Of these 76 attributes, only 14 attributes are considered for testing, important to substantiate the performance of different algorithms. This research paper aims to envision the probability of developing heart disease in the patients. The results portray that the highest accuracy score is achieved with K-nearest neighbor."
  },
  {
    "paperId": "46c266b3d1274dacd7fce27ee8cb4d587f087a58",
    "title": "Machine Learning Interpretability: A Survey on Methods and Metrics",
    "venue": "Electronics",
    "year": 2019,
    "citationCount": 1485,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/ELECTRONICS8080832?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/ELECTRONICS8080832, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "33791144",
        "name": "D. V. Carvalho"
      },
      {
        "authorId": "35153466",
        "name": "E. M. Pereira"
      },
      {
        "authorId": "3698192",
        "name": "Jaime S. Cardoso"
      }
    ],
    "abstract": "Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field."
  },
  {
    "paperId": "e24b8a9531573d284647239affc6c855505b0de4",
    "title": "Adversarial machine learning",
    "venue": "Security and Artificial Intelligence",
    "year": 2019,
    "citationCount": 1505,
    "openAccessPdf": {
      "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/74B5A8002ED9DDF469BF51E789FB0EB5/9781107338548c2_p20-28_CBO.pdf/background_and_notation.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2046684.2046692?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2046684.2046692, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50055322",
        "name": "Ling Huang"
      },
      {
        "authorId": "1687701",
        "name": "A. Joseph"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "2064046776",
        "name": "Benjamin I. P. Rubinstein"
      },
      {
        "authorId": "1787610",
        "name": "J. D. Tygar"
      }
    ],
    "abstract": "In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning---the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques."
  },
  {
    "paperId": "a9cbbef8f4426329d0687025b34287c35bdd8b38",
    "title": "Machine learning and the physical sciences",
    "venue": "Reviews of Modern Physics",
    "year": 2019,
    "citationCount": 1700,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1903.10563",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.10563, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50666189",
        "name": "Giuseppe Carleo"
      },
      {
        "authorId": "119628938",
        "name": "I. Cirac"
      },
      {
        "authorId": "2258272369",
        "name": "Kyle Cranmer"
      },
      {
        "authorId": "1742040",
        "name": "L. Daudet"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "1777660",
        "name": "Naftali Tishby"
      },
      {
        "authorId": "1445956232",
        "name": "Leslie Vogt-Maranto"
      },
      {
        "authorId": "2065813820",
        "name": "Lenka Zdeborov'a"
      }
    ],
    "abstract": "Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges."
  },
  {
    "paperId": "a9cbbef8f4426329d0687025b34287c35bdd8b38",
    "title": "Machine learning and the physical sciences",
    "venue": "Reviews of Modern Physics",
    "year": 2019,
    "citationCount": 1700,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1903.10563",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.10563, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50666189",
        "name": "Giuseppe Carleo"
      },
      {
        "authorId": "119628938",
        "name": "I. Cirac"
      },
      {
        "authorId": "2258272369",
        "name": "Kyle Cranmer"
      },
      {
        "authorId": "1742040",
        "name": "L. Daudet"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "1777660",
        "name": "Naftali Tishby"
      },
      {
        "authorId": "1445956232",
        "name": "Leslie Vogt-Maranto"
      },
      {
        "authorId": "2065813820",
        "name": "Lenka Zdeborov'a"
      }
    ],
    "abstract": "Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges."
  },
  {
    "paperId": "a8d76d84408c1fe6b1543084e6cec3dfc4ede429",
    "title": "Stable learning establishes some common ground between causal inference and machine learning",
    "venue": "Nature Machine Intelligence",
    "year": 2022,
    "citationCount": 180,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-022-00445-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-022-00445-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153522384",
        "name": "Peng Cui"
      },
      {
        "authorId": "2631417",
        "name": "S. Athey"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "09227e0251dad7b972878720131ddaecfec6c47f",
    "title": "Amnesiac Machine Learning",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2020,
    "citationCount": 352,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/17371/17178",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.10981, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2060122415",
        "name": "Laura Graves"
      },
      {
        "authorId": "1502108335",
        "name": "Vineel Nagisetty"
      },
      {
        "authorId": "145520209",
        "name": "Vijay Ganesh"
      }
    ],
    "abstract": "The Right to be Forgotten is part of the recently enacted General Data Protection Regulation (GDPR) law that affects any data holder that has data on European Union residents. It gives EU residents the ability to request deletion of their personal data, including training records used to train machine learning models. Unfortunately, Deep Neural Network models are vulnerable to information leaking attacks such as model inversion attacks which extract class information from a trained model and membership inference attacks which determine the presence of an example in a model's training data. If a malicious party can mount an attack and learn private information that was meant to be removed, then it implies that the model owner has not properly protected their user's rights and their models may not be compliant with the GDPR law. In this paper, we present two efficient methods that address this question of how a model owner or data holder may delete personal data from models in such a way that they may not be vulnerable to model inversion and membership inference attacks while maintaining model efficacy. We start by presenting a real-world threat model that shows that simply removing training data is insufficient to protect users. We follow that up with two data removal methods, namely Unlearning and Amnesiac Unlearning, that enable model owners to protect themselves against such attacks while being compliant with regulations. We provide extensive empirical analysis that show that these methods are indeed efficient, safe to apply, effectively remove learned information about sensitive data from trained models while maintaining model efficacy."
  },
  {
    "paperId": "ec6200bdcc23b79a71555962cde50306c4029f1a",
    "title": "Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization",
    "venue": "",
    "year": 2019,
    "citationCount": 1454,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.11989/JEST.1674-862X.80904120?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.11989/JEST.1674-862X.80904120, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153171583",
        "name": "Jia Wu"
      },
      {
        "authorId": "2109243152",
        "name": "Xiuyun Chen"
      },
      {
        "authorId": "1682058",
        "name": "H. Zhang"
      },
      {
        "authorId": "2068236437",
        "name": "Li-Dong Xiong"
      },
      {
        "authorId": "1878461",
        "name": "Hang Lei"
      },
      {
        "authorId": "48136123",
        "name": "S. Deng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "643da4c4de1954daeac571a82367241db012a8bf",
    "title": "Automatic differentiation in machine learning: a survey",
    "venue": "Journal of machine learning research",
    "year": 2015,
    "citationCount": 3184,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1502.05767, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1739503",
        "name": "A. G. Baydin"
      },
      {
        "authorId": "1700974",
        "name": "Barak A. Pearlmutter"
      },
      {
        "authorId": "1767709",
        "name": "Alexey Radul"
      },
      {
        "authorId": "1737754",
        "name": "J. Siskind"
      }
    ],
    "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply “auto-diff”, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until \nvery recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other’s results. Despite its \nrelevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational \ngraphs” and “differentiable programming”. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main imple- \nmentation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiff”, “automatic differentiation”, and “symbolic differentiation” as these are encountered more and more in machine learning settings."
  },
  {
    "paperId": "223846b7b56e250e1b6f521997b4c1b809cc0da7",
    "title": "An open source machine learning framework for efficient and transparent systematic reviews",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 664,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-020-00287-7.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2006.12166, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "66653634",
        "name": "R. Schoot"
      },
      {
        "authorId": "143648044",
        "name": "J. D. Bruin"
      },
      {
        "authorId": "2066568846",
        "name": "Raoul Schram"
      },
      {
        "authorId": "11495902",
        "name": "Parisa Zahedi"
      },
      {
        "authorId": "41180074",
        "name": "J. D. Boer"
      },
      {
        "authorId": "2064876694",
        "name": "F. Weijdema"
      },
      {
        "authorId": "2053218561",
        "name": "Bianca Kramer"
      },
      {
        "authorId": "1723386137",
        "name": "M. Huijts"
      },
      {
        "authorId": "143743446",
        "name": "M. Hoogerwerf"
      },
      {
        "authorId": "1723386134",
        "name": "Gerbrich Ferdinands"
      },
      {
        "authorId": "1723395276",
        "name": "Albert Harkema"
      },
      {
        "authorId": "1753624056",
        "name": "Joukje E. Willemsen"
      },
      {
        "authorId": "2115772424",
        "name": "Yongchao Ma"
      },
      {
        "authorId": "1720986506",
        "name": "Qixiang Fang"
      },
      {
        "authorId": "2031946546",
        "name": "Sybren Hindriks"
      },
      {
        "authorId": "3689165",
        "name": "L. Tummers"
      },
      {
        "authorId": "2140937833",
        "name": "D. Oberski"
      }
    ],
    "abstract": "To help researchers conduct a systematic review or meta-analysis as efficiently and transparently as possible, we designed a tool to accelerate the step of screening titles and abstracts. For many tasks—including but not limited to systematic reviews and meta-analyses—the scientific literature needs to be checked systematically. Scholars and practitioners currently screen thousands of studies by hand to determine which studies to include in their review or meta-analysis. This is error prone and inefficient because of extremely imbalanced data: only a fraction of the screened studies is relevant. The future of systematic reviewing will be an interaction with machine learning algorithms to deal with the enormous increase of available text. We therefore developed an open source machine learning-aided pipeline applying active learning: ASReview. We demonstrate by means of simulation studies that active learning can yield far more efficient reviewing than manual reviewing while providing high quality. Furthermore, we describe the options of the free and open source research software and present the results from user experience tests. We invite the community to contribute to open source projects such as our own that provide measurable and reproducible improvements over current practice. It is a challenging task for any research field to screen the literature and determine what needs to be included in a systematic review in a transparent way. A new open source machine learning framework called ASReview, which employs active learning and offers a range of machine learning models, can check the literature efficiently and systemically."
  },
  {
    "paperId": "69d49a06f09cf934310ccbf3bb2a360fa719272d",
    "title": "Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 820,
    "openAccessPdf": {
      "url": "https://doi.org/10.1038/s42256-021-00307-0",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2008.06388, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2048167730",
        "name": "M. Roberts"
      },
      {
        "authorId": "100893630",
        "name": "D. Driggs"
      },
      {
        "authorId": "2999959",
        "name": "Matthew Thorpe"
      },
      {
        "authorId": "2086383772",
        "name": "J. Gilbey"
      },
      {
        "authorId": "2067479253",
        "name": "Michael Yeung"
      },
      {
        "authorId": "1490690684",
        "name": "S. Ursprung"
      },
      {
        "authorId": "1388720262",
        "name": "Angelica I. Avilés-Rivero"
      },
      {
        "authorId": "11371884",
        "name": "Christian Etmann"
      },
      {
        "authorId": "1393265427",
        "name": "C. McCague"
      },
      {
        "authorId": "37894256",
        "name": "L. Beer"
      },
      {
        "authorId": "2302027994",
        "name": "J. Weir-McCall"
      },
      {
        "authorId": "1833839",
        "name": "Z. Teng"
      },
      {
        "authorId": "2126342450",
        "name": "Effrosyni Gkrania-Klotsas"
      },
      {
        "authorId": null,
        "name": "Alessandro Anna Emily Emmanuel Georg Ghassem Guang Helmut Jac Ruggiero Korhonen Jefferson Ako Langs Gozaliasl Ya"
      },
      {
        "authorId": "145860112",
        "name": "A. Ruggiero"
      },
      {
        "authorId": "145762466",
        "name": "A. Korhonen"
      },
      {
        "authorId": "2082907063",
        "name": "E. Jefferson"
      },
      {
        "authorId": "2141320829",
        "name": "E. Ako"
      },
      {
        "authorId": "2328333",
        "name": "G. Langs"
      },
      {
        "authorId": "2325727242",
        "name": "G. Gozaliasl"
      },
      {
        "authorId": "2149521326",
        "name": "Guang Yang"
      },
      {
        "authorId": "3078382",
        "name": "H. Prosch"
      },
      {
        "authorId": "8757752",
        "name": "J. Preller"
      },
      {
        "authorId": "2051804565",
        "name": "Jan Stanczuk"
      },
      {
        "authorId": "2212196329",
        "name": "Jingjing Tang"
      },
      {
        "authorId": "2214806",
        "name": "J. Hofmanninger"
      },
      {
        "authorId": "3604967",
        "name": "J. Babar"
      },
      {
        "authorId": "2147320751",
        "name": "L. E. Sanchez"
      },
      {
        "authorId": "6017571",
        "name": "M. Thillai"
      },
      {
        "authorId": "2209951776",
        "name": "Paula Martin Gonzalez"
      },
      {
        "authorId": "114246606",
        "name": "P. Teare"
      },
      {
        "authorId": "2210029087",
        "name": "Xiaoxiang Zhu"
      },
      {
        "authorId": "2273184",
        "name": "Mishal N. Patel"
      },
      {
        "authorId": "2209951481",
        "name": "Conor Cafolla"
      },
      {
        "authorId": "2380844740",
        "name": "Hojjat Azadbakht"
      },
      {
        "authorId": "2053597278",
        "name": "Joseph Jacob"
      },
      {
        "authorId": "2209951631",
        "name": "Josh Lowe"
      },
      {
        "authorId": "49481165",
        "name": "Kang Zhang"
      },
      {
        "authorId": "2077484140",
        "name": "Kyle Bradley"
      },
      {
        "authorId": "2209951470",
        "name": "Marcel Wassin"
      },
      {
        "authorId": "144899986",
        "name": "Markus Holzer"
      },
      {
        "authorId": "2209951543",
        "name": "Kangyu Ji"
      },
      {
        "authorId": "2122130929",
        "name": "Maria Delgado Ortet"
      },
      {
        "authorId": "31958609",
        "name": "T. Ai"
      },
      {
        "authorId": "145132572",
        "name": "N. Walton"
      },
      {
        "authorId": "2256105295",
        "name": "Pietro Liò"
      },
      {
        "authorId": "4494854",
        "name": "S. Stranks"
      },
      {
        "authorId": "3316722",
        "name": "Tolou Shadbahr"
      },
      {
        "authorId": "1454363000",
        "name": "Weizhe Lin"
      },
      {
        "authorId": "152457211",
        "name": "Y. Zha"
      },
      {
        "authorId": "2068562807",
        "name": "Zhangming Niu"
      },
      {
        "authorId": "145912651",
        "name": "J. H. Rudd"
      },
      {
        "authorId": "145628407",
        "name": "E. Sala"
      },
      {
        "authorId": "1711104",
        "name": "C. Schönlieb"
      }
    ],
    "abstract": "Machine learning methods offer great promise for fast and accurate detection and prognostication of coronavirus disease 2019 (COVID-19) from standard-of-care chest radiographs (CXR) and chest computed tomography (CT) images. Many articles have been published in 2020 describing new machine learning-based models for both of these tasks, but it is unclear which are of potential clinical utility. In this systematic review, we consider all published papers and preprints, for the period from 1 January 2020 to 3 October 2020, which describe new machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images. All manuscripts uploaded to bioRxiv, medRxiv and arXiv along with all entries in EMBASE and MEDLINE in this timeframe are considered. Our search identified 2,212 studies, of which 415 were included after initial screening and, after quality screening, 62 studies were included in this systematic review. Our review finds that none of the models identified are of potential clinical use due to methodological flaws and/or underlying biases. This is a major weakness, given the urgency with which validated COVID-19 models are needed. To address this, we give many recommendations which, if followed, will solve these issues and lead to higher-quality model development and well-documented manuscripts. Many machine learning-based approaches have been developed for the prognosis and diagnosis of COVID-19 from medical images and this Analysis identifies over 2,200 relevant published papers and preprints in this area. After initial screening, 62 studies are analysed and the authors find they all have methodological flaws standing in the way of clinical utility. The authors have several recommendations to address these issues."
  },
  {
    "paperId": "74b4f16c5ac91e3e7c88ae81cc8c91416b71d151",
    "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 549,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.05651, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40068904",
        "name": "Peter Henderson"
      },
      {
        "authorId": "2143911040",
        "name": "Jie Hu"
      },
      {
        "authorId": "8365320",
        "name": "Joshua Romoff"
      },
      {
        "authorId": "2563117",
        "name": "E. Brunskill"
      },
      {
        "authorId": "1746807",
        "name": "Dan Jurafsky"
      },
      {
        "authorId": "145134886",
        "name": "Joelle Pineau"
      }
    ],
    "abstract": "Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms."
  },
  {
    "paperId": "6068d39e92aef1bb0e1291e9931894c35692a85e",
    "title": "Counterfactual Explanations for Machine Learning: A Review",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 449,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1780214785",
        "name": "Sahil Verma"
      },
      {
        "authorId": "1718974",
        "name": "John P. Dickerson"
      },
      {
        "authorId": "4634403",
        "name": "Keegan E. Hines"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "62df84d6a4d26f95e4714796c2337c9848cc13b5",
    "title": "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems",
    "venue": "arXiv.org",
    "year": 2015,
    "citationCount": 2296,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1512.01274, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1913774",
        "name": "Tianqi Chen"
      },
      {
        "authorId": "2124778071",
        "name": "Mu Li"
      },
      {
        "authorId": "2110420880",
        "name": "Yutian Li"
      },
      {
        "authorId": "1491081747",
        "name": "Min Lin"
      },
      {
        "authorId": "48246959",
        "name": "Naiyan Wang"
      },
      {
        "authorId": "1508337194",
        "name": "Minjie Wang"
      },
      {
        "authorId": "39102205",
        "name": "Tianjun Xiao"
      },
      {
        "authorId": "2113742783",
        "name": "Bing Xu"
      },
      {
        "authorId": "151505981",
        "name": "Chiyuan Zhang"
      },
      {
        "authorId": "38448016",
        "name": "Zheng Zhang"
      }
    ],
    "abstract": "MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. \nThis paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines."
  },
  {
    "paperId": "a1f57b760b7d4c44490f0bb86ee5462c3e7c7272",
    "title": "Machine Learning Force Fields",
    "venue": "Chemical Reviews",
    "year": 2020,
    "citationCount": 1096,
    "openAccessPdf": {
      "url": "https://doi.org/10.1021/acs.chemrev.0c01111",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.07067, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9914431",
        "name": "Oliver T. Unke"
      },
      {
        "authorId": "7631063",
        "name": "Stefan Chmiela"
      },
      {
        "authorId": "10667063",
        "name": "H. Sauceda"
      },
      {
        "authorId": "5742764",
        "name": "M. Gastegger"
      },
      {
        "authorId": "5667638",
        "name": "I. Poltavsky"
      },
      {
        "authorId": "33075217",
        "name": "Kristof T. Schütt"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": "In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs."
  },
  {
    "paperId": "0273507eb05f1135f3a05f9c7adc9a56f12c7c5c",
    "title": "Recent advances and applications of machine learning in solid-state materials science",
    "venue": "npj Computational Materials",
    "year": 2019,
    "citationCount": 1847,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41524-019-0221-0.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41524-019-0221-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41524-019-0221-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2149390974",
        "name": "Jonathan Schmidt"
      },
      {
        "authorId": "143837407",
        "name": "Mário R. G. Marques"
      },
      {
        "authorId": "5517714",
        "name": "S. Botti"
      },
      {
        "authorId": "2147106902",
        "name": "Miguel A. L. Marques"
      }
    ],
    "abstract": "One of the most exciting tools that have entered the material science toolbox in recent years is machine learning. This collection of statistical methods has already proved to be capable of considerably speeding up both fundamental and applied research. At present, we are witnessing an explosion of works that develop and apply machine learning to solid-state systems. We provide a comprehensive overview and analysis of the most recent research in this topic. As a starting point, we introduce machine learning principles, algorithms, descriptors, and databases in materials science. We continue with the description of different machine learning approaches for the discovery of stable materials and the prediction of their crystal structure. Then we discuss research in numerous quantitative structure–property relationships and various approaches for the replacement of first-principle methods by machine learning. We review how active learning and surrogate-based optimization can be applied to improve the rational design process and related examples of applications. Two major questions are always the interpretability of and the physical understanding gained from machine learning models. We consider therefore the different facets of interpretability and their importance in materials science. Finally, we propose solutions and future research paths for various challenges in computational materials science."
  },
  {
    "paperId": "b55e490637babd50dab3cdaaa3a60a2be6eb1cbb",
    "title": "Automated Machine Learning - Methods, Systems, Challenges",
    "venue": "Automated Machine Learning",
    "year": 2019,
    "citationCount": 1338,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "5fca8bbec714e403fa0f95a56b355c8ca835bcc0",
    "title": "A Survey on the Explainability of Supervised Machine Learning",
    "venue": "Journal of Artificial Intelligence Research",
    "year": 2020,
    "citationCount": 866,
    "openAccessPdf": {
      "url": "https://jair.org/index.php/jair/article/download/12228/26647",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.07876, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1500529117",
        "name": "Nadia Burkart"
      },
      {
        "authorId": "1959068",
        "name": "Marco F. Huber"
      }
    ],
    "abstract": "Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions."
  },
  {
    "paperId": "1800404340d43ba185f2b0e2b4f94201c2eeadaa",
    "title": "Machine Learning",
    "venue": "International Scientific Journal of Engineering and Management",
    "year": 2023,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "https://doi.org/10.55041/isjem00268",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.55041/isjem00268?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55041/isjem00268, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2053853389",
        "name": "K. K"
      }
    ],
    "abstract": "We are pleased to inform you that your research paper, entitled \" Machine Learning \", has been successfully published in the International Scientific Journal of Engineering and Management (ISJEM) on Volume 02 Issue 04 April 2023. We would like to congratulate you on this achievement, as it is a testament to the hard work and dedication that you have put into your research. With this email, we enclose e-certificates & Published Paper for all the authors as a token from us."
  },
  {
    "paperId": "e2e8ea9bcdb83deb2787ce89db1b51f7ccb1bd1e",
    "title": "A survey on missing data in machine learning",
    "venue": "Journal of Big Data",
    "year": 2021,
    "citationCount": 753,
    "openAccessPdf": {
      "url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-021-00516-9",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8549433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2120757061",
        "name": "Tlamelo Emmanuel"
      },
      {
        "authorId": "9714951",
        "name": "Thabiso M. Maupong"
      },
      {
        "authorId": "3164693",
        "name": "Dimane Mpoeleng"
      },
      {
        "authorId": "9206611",
        "name": "Thabo Semong"
      },
      {
        "authorId": "2120747873",
        "name": "Mphago Banyatsang"
      },
      {
        "authorId": "9223868",
        "name": "Oteng Tabona"
      }
    ],
    "abstract": "Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5% to 20%. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction."
  },
  {
    "paperId": "d9b34c6b616f75485856794478bfbeab1ea93b81",
    "title": "Perspectives in machine learning for wildlife conservation",
    "venue": "Nature Communications",
    "year": 2021,
    "citationCount": 509,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41467-022-27980-y.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2110.12951, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2977931",
        "name": "D. Tuia"
      },
      {
        "authorId": "31394603",
        "name": "B. Kellenberger"
      },
      {
        "authorId": "2134791809",
        "name": "Sara Beery"
      },
      {
        "authorId": "11937434",
        "name": "Blair R. Costelloe"
      },
      {
        "authorId": "2133988",
        "name": "S. Zuffi"
      },
      {
        "authorId": "2306022759",
        "name": "Benjamin Risse"
      },
      {
        "authorId": "2068891",
        "name": "Alexander Mathis"
      },
      {
        "authorId": "4058359",
        "name": "Mackenzie W. Mathis"
      },
      {
        "authorId": "7844231",
        "name": "F. Langevelde"
      },
      {
        "authorId": "1717278",
        "name": "T. Burghardt"
      },
      {
        "authorId": "10206188",
        "name": "R. Kays"
      },
      {
        "authorId": "2986263",
        "name": "H. Klinck"
      },
      {
        "authorId": "2844950",
        "name": "M. Wikelski"
      },
      {
        "authorId": "3191663",
        "name": "I. Couzin"
      },
      {
        "authorId": "2996914",
        "name": "Grant Van Horn"
      },
      {
        "authorId": "1696086",
        "name": "M. Crofoot"
      },
      {
        "authorId": "2057207171",
        "name": "Chuck Stewart"
      },
      {
        "authorId": "1399635506",
        "name": "T. Berger-Wolf"
      }
    ],
    "abstract": "Inexpensive and accessible sensors are accelerating data acquisition in animal ecology. These technologies hold great potential for large-scale ecological understanding, but are limited by current processing approaches which inefficiently distill data into relevant information. We argue that animal ecologists can capitalize on large datasets generated by modern sensors by combining machine learning approaches with domain knowledge. Incorporating machine learning into ecological workflows could improve inputs for ecological models and lead to integrated hybrid modeling tools. This approach will require close interdisciplinary collaboration to ensure the quality of novel approaches and train a new generation of data scientists in ecology and conservation. Animal ecologists are increasingly limited by constraints in data processing. Here, Tuia and colleagues discuss how collaboration between ecologists and data scientists can harness machine learning to capitalize on the data generated from technological advances and lead to novel modeling approaches."
  },
  {
    "paperId": "f1664bbaddedea8c250873e7610ab07e53fa7132",
    "title": "Machine learning pipeline for battery state-of-health estimation",
    "venue": "Nature Machine Intelligence",
    "year": 2021,
    "citationCount": 446,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2102.00837, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "80025697",
        "name": "D. Roman"
      },
      {
        "authorId": "49730050",
        "name": "Saurabh Saxena"
      },
      {
        "authorId": "1718021",
        "name": "V. Robu"
      },
      {
        "authorId": "145937021",
        "name": "Michael G. Pecht"
      },
      {
        "authorId": "143836960",
        "name": "D. Flynn"
      }
    ],
    "abstract": "Lithium-ion batteries are ubiquitous in applications ranging from portable electronics to electric vehicles. Irrespective of the application, reliable real-time estimation of battery state of health (SOH) by on-board computers is crucial to the safe operation of the battery, ultimately safeguarding asset integrity. In this Article, we design and evaluate a machine learning pipeline for estimation of battery capacity fade—a metric of battery health—on 179 cells cycled under various conditions. The pipeline estimates battery SOH with an associated confidence interval by using two parametric and two non-parametric algorithms. Using segments of charge voltage and current curves, the pipeline engineers 30 features, performs automatic feature selection and calibrates the algorithms. When deployed on cells operated under the fast-charging protocol, the best model achieves a root-mean-squared error of 0.45%. This work provides insights into the design of scalable data-driven models for battery SOH estimation, emphasizing the value of confidence bounds around the prediction. The pipeline methodology combines experimental data with machine learning modelling and could be applied to other critical components that require real-time estimation of SOH. Rechargeable lithium-ion batteries play a crucial role in many modern-day applications, including portable electronics and electric vehicles, but they degrade over time. To ensure safe operation, a battery’s ‘state of health’ should be monitored in real time, and this machine learning pipeline, tested on a variety of charging conditions, can provide such an online estimation of battery state of health."
  },
  {
    "paperId": "b415e836d447ea9efb7629a1de67cd2a6f9e7ba8",
    "title": "Machine Learning in Agriculture: A Comprehensive Updated Review",
    "venue": "Italian National Conference on Sensors",
    "year": 2021,
    "citationCount": 526,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1424-8220/21/11/3758/pdf?version=1622446805",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8198852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "88679617",
        "name": "Lefteris Benos"
      },
      {
        "authorId": "50742688",
        "name": "A. Tagarakis"
      },
      {
        "authorId": "2106650552",
        "name": "Georgios Dolias"
      },
      {
        "authorId": "2076743",
        "name": "R. Berruto"
      },
      {
        "authorId": "1942212",
        "name": "D. Kateris"
      },
      {
        "authorId": "2345652",
        "name": "D. Bochtis"
      }
    ],
    "abstract": "The digital transformation of agriculture has evolved various aspects of management into artificial intelligent systems for the sake of making value from the ever-increasing data originated from numerous sources. A subset of artificial intelligence, namely machine learning, has a considerable potential to handle numerous challenges in the establishment of knowledge-based farming systems. The present study aims at shedding light on machine learning in agriculture by thoroughly reviewing the recent scholarly literature based on keywords’ combinations of “machine learning” along with “crop management”, “water management”, “soil management”, and “livestock management”, and in accordance with PRISMA guidelines. Only journal papers were considered eligible that were published within 2018–2020. The results indicated that this topic pertains to different disciplines that favour convergence research at the international level. Furthermore, crop management was observed to be at the centre of attention. A plethora of machine learning algorithms were used, with those belonging to Artificial Neural Networks being more efficient. In addition, maize and wheat as well as cattle and sheep were the most investigated crops and animals, respectively. Finally, a variety of sensors, attached on satellites and unmanned ground and aerial vehicles, have been utilized as a means of getting reliable input data for the data analyses. It is anticipated that this study will constitute a beneficial guide to all stakeholders towards enhancing awareness of the potential advantages of using machine learning in agriculture and contributing to a more systematic research on this topic."
  },
  {
    "paperId": "3a191f45f6c0e8ecc598dc349022b253a652b7f2",
    "title": "Machine Learning in Drug Discovery: A Review",
    "venue": "Artificial Intelligence Review",
    "year": 2021,
    "citationCount": 496,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10462-021-10058-4.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8356896, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3177642",
        "name": "Suresh Dara"
      },
      {
        "authorId": "2123040737",
        "name": "Swetha Dhamercherla"
      },
      {
        "authorId": "4276179",
        "name": "S. S. Jadav"
      },
      {
        "authorId": "1938585156",
        "name": "Christy M Babu"
      },
      {
        "authorId": "2176878",
        "name": "M. Ahsan"
      }
    ],
    "abstract": "This review provides the feasible literature on drug discovery through ML tools and techniques that are enforced in every phase of drug development to accelerate the research process and deduce the risk and expenditure in clinical trials. Machine learning techniques improve the decision-making in pharmaceutical data across various applications like QSAR analysis, hit discoveries, de novo drug architectures to retrieve accurate outcomes. Target validation, prognostic biomarkers, digital pathology are considered under problem statements in this review. ML challenges must be applicable for the main cause of inadequacy in interpretability outcomes that may restrict the applications in drug discovery. In clinical trials, absolute and methodological data must be generated to tackle many puzzles in validating ML techniques, improving decision-making, promoting awareness in ML approaches, and deducing risk failures in drug discovery."
  },
  {
    "paperId": "287ba5bf00d96af1596aaf80c178392a9c4fcc28",
    "title": "Machine Learning Basics",
    "venue": "Intelligent Computing for Interactive System Design",
    "year": 2021,
    "citationCount": 326,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3447404.3447414?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3447404.3447414, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2075619",
        "name": "Konstantinos Chatzilygeroudis"
      },
      {
        "authorId": "1778545",
        "name": "I. Hatzilygeroudis"
      },
      {
        "authorId": "1776159",
        "name": "I. Perikos"
      }
    ],
    "abstract": "coined in 1959 by Arthur Samuel [Samuel 1959], Tom Mitchell [Mitchell 1997] provided a more formal definition: “A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.” ML has be applied to many real-world problems or tasks, like medical diagno­ sis, robotics, recommendation systems, facial recognition, stock prices prediction, and sentiment analysis, with great success. We can divide ML algorithms into three main categories (see Figure 4.1): Machine Learning Basics"
  },
  {
    "paperId": "c2c0205b1476107db2ec6129c79d919095a748bf",
    "title": "What Is Machine Learning",
    "venue": "",
    "year": 2015,
    "citationCount": 2954,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781119183464.CH1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781119183464.CH1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2382869796",
        "name": "Jason Bell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e32a2519b59d62cff6cb8136ee242dc3754ed57b",
    "title": "Second opinion needed: communicating uncertainty in medical machine learning",
    "venue": "npj Digital Medicine",
    "year": 2021,
    "citationCount": 342,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41746-020-00367-3.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7785732, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "17850015",
        "name": "Benjamin Kompa"
      },
      {
        "authorId": "144108062",
        "name": "Jasper Snoek"
      },
      {
        "authorId": "1507094362",
        "name": "A. Beam"
      }
    ],
    "abstract": "There is great excitement that medical artificial intelligence (AI) based on machine learning (ML) can be used to improve decision making at the patient level in a variety of healthcare settings. However, the quantification and communication of uncertainty for individual predictions is often neglected even though uncertainty estimates could lead to more principled decision-making and enable machine learning models to automatically or semi-automatically abstain on samples for which there is high uncertainty. In this article, we provide an overview of different approaches to uncertainty quantification and abstention for machine learning and highlight how these techniques could improve the safety and reliability of current ML systems being used in healthcare settings. Effective quantification and communication of uncertainty could help to engender trust with healthcare workers, while providing safeguards against known failure modes of current machine learning approaches. As machine learning becomes further integrated into healthcare environments, the ability to say “I’m not sure” or “I don’t know” when uncertain is a necessary capability to enable safe clinical deployment."
  },
  {
    "paperId": "f938cffd498ffb81ee9d66b4cd473e82c2e12c72",
    "title": "From distributed machine learning to federated learning: a survey",
    "venue": "Knowledge and Information Systems",
    "year": 2021,
    "citationCount": 304,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2104.14362, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40478933",
        "name": "Ji Liu"
      },
      {
        "authorId": "2864855",
        "name": "Jizhou Huang"
      },
      {
        "authorId": "2145499198",
        "name": "Yang Zhou"
      },
      {
        "authorId": "48568841",
        "name": "Xuhong Li"
      },
      {
        "authorId": "2086828705",
        "name": "Shilei Ji"
      },
      {
        "authorId": "2093122747",
        "name": "Haoyi Xiong"
      },
      {
        "authorId": "1721158",
        "name": "D. Dou"
      }
    ],
    "abstract": "In recent years, data and computing resources are typically distributed in the devices of end users, various regions or organizations. Because of laws or regulations, the distributed data and computing resources cannot be aggregated or directly shared among different regions or organizations for machine learning tasks. Federated learning emerges as an efficient approach to exploit distributed data and computing resources, so as to collaboratively train machine learning models. At the same time, federated learning obeys the laws and regulations and ensures data security and data privacy. In this paper, we provide a comprehensive survey of existing works for federated learning. First, we propose a functional architecture of federated learning systems and a taxonomy of related techniques. Second, we explain the federated learning systems from four aspects: diverse types of parallelism, aggregation algorithms, data communication, and the security of federated learning systems. Third, we present four widely used federated systems based on the functional architecture. Finally, we summarize the limitations and propose future research directions."
  },
  {
    "paperId": "f4eb1de428295e9743a0b4754776813df6e951da",
    "title": "When physics meets machine learning: a survey of physics-informed machine learning",
    "venue": "Machine Learning for Computational Science and Engineering",
    "year": 2022,
    "citationCount": 100,
    "openAccessPdf": {
      "url": "https://doi.org/10.1007/s44379-025-00016-0",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.16797, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "27737939",
        "name": "Chuizheng Meng"
      },
      {
        "authorId": "145260557",
        "name": "Sungyong Seo"
      },
      {
        "authorId": "120783624",
        "name": "Defu Cao"
      },
      {
        "authorId": "2160884182",
        "name": "Sam Griesemer"
      },
      {
        "authorId": "2156649635",
        "name": "Yan Liu"
      }
    ],
    "abstract": "Physics-informed machine learning (PIML), the combination of prior physics knowledge with data-driven machine learning models, has emerged as an effective means of mitigating a shortage of training data, increasing model generalizability, and ensuring physical plausibility of results. In this paper, we survey a wide variety of recent works in PIML and summarize them from three key aspects: 1) motivations of PIML, 2) physics knowledge in PIML, and 3) methods of physics knowledge integration in PIML. We additionally discuss current challenges and corresponding research opportunities in PIML."
  },
  {
    "paperId": "6aae0dc122102693e8136856ffc8b72df7f78386",
    "title": "A study of the behavior of several methods for balancing machine learning training data",
    "venue": "SKDD",
    "year": 2004,
    "citationCount": 3819,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1007730.1007735?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1007730.1007735, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145666101",
        "name": "Gustavo E. A. P. A. Batista"
      },
      {
        "authorId": "1793286",
        "name": "R. Prati"
      },
      {
        "authorId": "1737677",
        "name": "M. C. Monard"
      }
    ],
    "abstract": "There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods."
  },
  {
    "paperId": "5c7e5248d9eb7f373f10277410bf8506160907ea",
    "title": "All-optical machine learning using diffractive deep neural networks",
    "venue": "Science",
    "year": 2018,
    "citationCount": 1901,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1804.08711",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1804.08711, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143746845",
        "name": "Xing Lin"
      },
      {
        "authorId": "48156295",
        "name": "Y. Rivenson"
      },
      {
        "authorId": "3913651",
        "name": "N. Yardimci"
      },
      {
        "authorId": "4901769",
        "name": "Muhammed Veli"
      },
      {
        "authorId": "5602194",
        "name": "Yilin Luo"
      },
      {
        "authorId": "2146359",
        "name": "M. Jarrahi"
      },
      {
        "authorId": "2660014",
        "name": "A. Ozcan"
      }
    ],
    "abstract": "All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science, this issue p. 1004 All-optical deep learning can be implemented with 3D-printed passive optical components. Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning–based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs."
  },
  {
    "paperId": "c8ac6060d34179871b81ecd19621c63360347f8e",
    "title": "Comparing different supervised machine learning algorithms for disease prediction",
    "venue": "BMC Medical Informatics and Decision Making",
    "year": 2019,
    "citationCount": 1226,
    "openAccessPdf": {
      "url": "https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-1004-8",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6925840, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1798025",
        "name": "S. Uddin"
      },
      {
        "authorId": "2108514783",
        "name": "Arif Khan"
      },
      {
        "authorId": "52224520",
        "name": "Md Ekramul Hossain"
      },
      {
        "authorId": "145781245",
        "name": "M. A. Moni"
      }
    ],
    "abstract": "BackgroundSupervised machine learning algorithms have been a dominant method in the data mining field. Disease prediction using health data has recently shown a potential application area for these methods. This study ai7ms to identify the key trends among different types of supervised machine learning algorithms, and their performance and usage for disease risk prediction.MethodsIn this study, extensive research efforts were made to identify those studies that applied more than one supervised machine learning algorithm on single disease prediction. Two databases (i.e., Scopus and PubMed) were searched for different types of search items. Thus, we selected 48 articles in total for the comparison among variants supervised machine learning algorithms for disease prediction.ResultsWe found that the Support Vector Machine (SVM) algorithm is applied most frequently (in 29 studies) followed by the Naïve Bayes algorithm (in 23 studies). However, the Random Forest (RF) algorithm showed superior accuracy comparatively. Of the 17 studies where it was applied, RF showed the highest accuracy in 9 of them, i.e., 53%. This was followed by SVM which topped in 41% of the studies it was considered.ConclusionThis study provides a wide overview of the relative performance of different variants of supervised machine learning algorithms for disease prediction. This important information of relative performance can be used to aid researchers in the selection of an appropriate supervised machine learning algorithm for their studies."
  },
  {
    "paperId": "561269a24f2f2a06409109723a8ab93a01696efc",
    "title": "Federated Optimization: Distributed Machine Learning for On-Device Intelligence",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 2078,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1610.02527, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32139366",
        "name": "Jakub Konecný"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "1878835",
        "name": "Daniel Ramage"
      },
      {
        "authorId": "2662221",
        "name": "Peter Richtárik"
      }
    ],
    "abstract": "We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. \nA motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. \nWe show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \\federated optimization."
  },
  {
    "paperId": "f8ec29fb9933219e0949c59ddd7220fd1e2a1b89",
    "title": "Enhancing computational fluid dynamics with machine learning",
    "venue": "Nature Computational Science",
    "year": 2021,
    "citationCount": 464,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2110.02085, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2351290252",
        "name": "Ricardo Vinuesa"
      },
      {
        "authorId": "3083169",
        "name": "S. Brunton"
      }
    ],
    "abstract": "Machine learning is rapidly becoming a core technology for scientific computing, with numerous opportunities to advance the field of computational fluid dynamics. Here we highlight some of the areas of highest potential impact, including to accelerate direct numerical simulations, to improve turbulence closure modeling and to develop enhanced reduced-order models. We also discuss emerging areas of machine learning that are promising for computational fluid dynamics, as well as some potential limitations that should be taken into account. Machine learning has been used to accelerate the simulation of fluid dynamics. However, despite the recent developments in this field, there are still challenges to be addressed by the community, a fact that creates research opportunities."
  },
  {
    "paperId": "b3de1062d8a462dfdc2938558258f8884abe9f4e",
    "title": "Implementation of machine-learning classification in remote sensing: an applied review",
    "venue": "",
    "year": 2018,
    "citationCount": 1523,
    "openAccessPdf": {
      "url": "https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/01431161.2018.1433343?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/01431161.2018.1433343, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "26339328",
        "name": "Aaron E. Maxwell"
      },
      {
        "authorId": "5875612",
        "name": "T. Warner"
      },
      {
        "authorId": "2014814754",
        "name": "Fang Fang"
      }
    ],
    "abstract": "ABSTRACT Machine learning offers the potential for effective and efficient classification of remotely sensed imagery. The strengths of machine learning include the capacity to handle data of high dimensionality and to map classes with very complex characteristics. Nevertheless, implementing a machine-learning classification is not straightforward, and the literature provides conflicting advice regarding many key issues. This article therefore provides an overview of machine learning from an applied perspective. We focus on the relatively mature methods of support vector machines, single decision trees (DTs), Random Forests, boosted DTs, artificial neural networks, and k-nearest neighbours (k-NN). Issues considered include the choice of algorithm, training data requirements, user-defined parameter selection and optimization, feature space impacts and reduction, and computational costs. We illustrate these issues through applying machine-learning classification to two publically available remotely sensed data sets."
  },
  {
    "paperId": "3e8b2f4ad4121679e31776633628bef603c6c2a7",
    "title": "Enhancing the prediction of student performance based on the machine learning XGBoost algorithm",
    "venue": "Interactive Learning Environments",
    "year": 2021,
    "citationCount": 358,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/10494820.2021.1928235?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/10494820.2021.1928235, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "28313711",
        "name": "Amal Asselman"
      },
      {
        "authorId": "47516055",
        "name": "Mohamed Khaldi"
      },
      {
        "authorId": "1802844",
        "name": "S. Aammou"
      }
    ],
    "abstract": "ABSTRACT Performance Factors Analysis (PFA) is considered one of the most important Knowledge Tracing (KT) approaches used for constructing adaptive educational hypermedia systems. It has shown a high prediction accuracy against many other KT approaches. While, the desire to estimate more accurately the student level leads researchers to enhance PFA by inventing several advanced extensions. However, most of the proposed extensions have exclusively been improved in a pedagogical sense, as the improvements have mostly been limited to the analysis of students’ behaviour during their learning process. In contrast, Machine Learning provides many powerful methods that could be efficient to enhance, in the technical sense, the prediction of student performance. Our goal is to focus on the exploitation of Ensemble Learning methods as an extremely effective Machine Learning paradigm used to create many advanced solutions in several fields. In this sense, we propose a new PFA approach based on different models (Random Forest, AdaBoost, and XGBoost) in order to increase the predictive accuracy of student performance. Our models have been evaluated on three different datasets. The experimental results show that the scalable XGBoost has outperformed the other evaluated models and substantially improved the performance prediction compared to the original PFA algorithm."
  },
  {
    "paperId": "8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e",
    "title": "Stealing Machine Learning Models via Prediction APIs",
    "venue": "USENIX Security Symposium",
    "year": 2016,
    "citationCount": 1950,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.02943, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2444919",
        "name": "Florian Tramèr"
      },
      {
        "authorId": "2153304355",
        "name": "Fan Zhang"
      },
      {
        "authorId": "1687161",
        "name": "A. Juels"
      },
      {
        "authorId": "1746214",
        "name": "M. Reiter"
      },
      {
        "authorId": "1707461",
        "name": "Thomas Ristenpart"
      }
    ],
    "abstract": "Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (\"predictive analytics\") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis. \nThe tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., \"steal\") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures."
  },
  {
    "paperId": "21dfbc88b21b27fe8a245ab1df98edd45f655ae7",
    "title": "Machine Learning in Medicine",
    "venue": "New England Journal of Medicine",
    "year": 2019,
    "citationCount": 1342,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1056/NEJMra1814259?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1056/NEJMra1814259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8638650",
        "name": "A. Rajkomar"
      },
      {
        "authorId": "2056947059",
        "name": "Jeffrey Dean"
      },
      {
        "authorId": "1740538",
        "name": "I. Kohane"
      }
    ],
    "abstract": "Machine Learning in Medicine In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. The..."
  },
  {
    "paperId": "53eef24a59b12107e6188e121c85f85fa8a78100",
    "title": "Explainable machine-learning predictions for the prevention of hypoxaemia during surgery",
    "venue": "Nature Biomedical Engineering",
    "year": 2018,
    "citationCount": 1527,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6467492",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6467492, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "23451726",
        "name": "Scott M. Lundberg"
      },
      {
        "authorId": "2447936",
        "name": "B. Nair"
      },
      {
        "authorId": "145552173",
        "name": "M. Vavilala"
      },
      {
        "authorId": "2062639",
        "name": "M. Horibe"
      },
      {
        "authorId": "5615276",
        "name": "Michael J. Eisses"
      },
      {
        "authorId": "2052327253",
        "name": "Trevor L. Adams"
      },
      {
        "authorId": "35577567",
        "name": "D. Liston"
      },
      {
        "authorId": "2135149452",
        "name": "Daniel King-Wai Low"
      },
      {
        "authorId": "87906368",
        "name": "Shu-Fang Newman"
      },
      {
        "authorId": "2135608343",
        "name": "Jerry H. Kim"
      },
      {
        "authorId": "2180463",
        "name": "Su-In Lee"
      }
    ],
    "abstract": "Although anaesthesiologists strive to avoid hypoxaemia during surgery, reliably predicting future intraoperative hypoxaemia is not possible at present. Here, we report the development and testing of a machine-learning-based system that predicts the risk of hypoxaemia and provides explanations of the risk factors in real time during general anaesthesia. The system, which was trained on minute-by-minute data from the electronic medical records of over 50,000 surgeries, improved the performance of anaesthesiologists by providing interpretable hypoxaemia risks and contributing factors. The explanations for the predictions are broadly consistent with the literature and with prior knowledge from anaesthesiologists. Our results suggest that if anaesthesiologists currently anticipate 15% of hypoxaemia events, with the assistance of this system they could anticipate 30%, a large portion of which may benefit from early intervention because they are associated with modifiable factors. The system can help improve the clinical understanding of hypoxaemia risk during anaesthesia care by providing general insights into the exact changes in risk induced by certain characteristics of the patient or procedure. An alert system based on machine learning and trained on surgical data from electronic medical records helps anaesthesiologists prevent hypoxaemia during surgery by providing interpretable real-time predictions."
  },
  {
    "paperId": "c8f216f663660ff3bc195ecd3a8ad61f0ed1d9d7",
    "title": "Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting",
    "venue": "IEEE Computer Security Foundations Symposium",
    "year": 2017,
    "citationCount": 1305,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1709.01604",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/CSF.2018.00027?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CSF.2018.00027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "26378728",
        "name": "Samuel Yeom"
      },
      {
        "authorId": "3025831",
        "name": "Irene Giacomelli"
      },
      {
        "authorId": "2623167",
        "name": "Matt Fredrikson"
      },
      {
        "authorId": "1680133",
        "name": "S. Jha"
      }
    ],
    "abstract": "Machine learning algorithms, when applied to sensitive data, pose a distinct threat to privacy. A growing body of prior work demonstrates that models produced by these algorithms may leak specific private information in the training data to an attacker, either through the models' structure or their observable behavior. However, the underlying cause of this privacy risk is not well understood beyond a handful of anecdotal accounts that suggest overfitting and influence might play a role. This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about the training data from machine learning models, either through training set membership inference or attribute inference attacks. Using both formal and empirical analyses, we illustrate a clear relationship between these factors and the privacy risk that arises in several popular machine learning algorithms. We find that overfitting is sufficient to allow an attacker to perform membership inference and, when the target attribute meets certain conditions about its influence, attribute inference attacks. Interestingly, our formal analysis also shows that overfitting is not necessary for these attacks and begins to shed light on what other factors may be in play. Finally, we explore the connection between membership inference and attribute inference, showing that there are deep connections between the two that lead to effective new attacks."
  },
  {
    "paperId": "5123717445799d8137327f4041e8d5a5a2c91379",
    "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 1032,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-020-0186-1.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-020-0186-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-020-0186-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9555451",
        "name": "Georgios Kaissis"
      },
      {
        "authorId": "2380008",
        "name": "M. Makowski"
      },
      {
        "authorId": "2066492996",
        "name": "D. Rückert"
      },
      {
        "authorId": "4516701",
        "name": "R. Braren"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a453ce8a3de86a170c79a1082ef358c3adf4e612",
    "title": "Combining Machine Learning and Computational Chemistry for Predictive Insights Into Chemical Systems",
    "venue": "Chemical Reviews",
    "year": 2021,
    "citationCount": 562,
    "openAccessPdf": {
      "url": "https://doi.org/10.1021/acs.chemrev.1c00107",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2102.06321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143795913",
        "name": "J. Keith"
      },
      {
        "authorId": "1421725853",
        "name": "V. Vassilev-Galindo"
      },
      {
        "authorId": "39557864",
        "name": "Bingqing Cheng"
      },
      {
        "authorId": "7631063",
        "name": "Stefan Chmiela"
      },
      {
        "authorId": "5742764",
        "name": "M. Gastegger"
      },
      {
        "authorId": "2113612432",
        "name": "Klaus-Robert Müller"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      }
    ],
    "abstract": "Machine learning models are poised to make a transformative impact on chemical sciences by dramatically accelerating computational algorithms and amplifying insights available from computational chemistry methods. However, achieving this requires a confluence and coaction of expertise in computer science and physical sciences. This Review is written for new and experienced researchers working at the intersection of both fields. We first provide concise tutorials of computational chemistry and machine learning methods, showing how insights involving both can be achieved. We follow with a critical review of noteworthy applications that demonstrate how computational chemistry and machine learning can be used together to provide insightful (and useful) predictions in molecular and materials modeling, retrosyntheses, catalysis, and drug design."
  },
  {
    "paperId": "d3f9a39e49abfdf084da558e305be5473c8740e5",
    "title": "Machine learning for alloys",
    "venue": "Nature Reviews Materials",
    "year": 2021,
    "citationCount": 497,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41578-021-00340-w?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41578-021-00340-w, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2437145",
        "name": "G. Hart"
      },
      {
        "authorId": "152456169",
        "name": "Tim Mueller"
      },
      {
        "authorId": "3954852",
        "name": "C. Toher"
      },
      {
        "authorId": "3445901",
        "name": "S. Curtarolo"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "22733aac53e89446aed76dd1983bf2d74567ba88",
    "title": "Darts: User-Friendly Modern Machine Learning for Time Series",
    "venue": "Journal of machine learning research",
    "year": 2021,
    "citationCount": 263,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2110.03224, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35536780",
        "name": "J. Herzen"
      },
      {
        "authorId": "2133472159",
        "name": "Francesco Lässig"
      },
      {
        "authorId": "1388057242",
        "name": "Samuele Giuliano Piazzetta"
      },
      {
        "authorId": "41069949",
        "name": "T. Neuer"
      },
      {
        "authorId": "2131095260",
        "name": "L'eo Tafti"
      },
      {
        "authorId": "1585847171",
        "name": "Guillaume Raille"
      },
      {
        "authorId": "41051315",
        "name": "Tomas Van Pottelbergh"
      },
      {
        "authorId": "19318705",
        "name": "Marek Pasieka"
      },
      {
        "authorId": "2131095567",
        "name": "Andrzej Skrodzki"
      },
      {
        "authorId": "2131069208",
        "name": "Nicolas Huguenin"
      },
      {
        "authorId": "2131148053",
        "name": "Maxime Dumonal"
      },
      {
        "authorId": "2131095249",
        "name": "Jan Ko'scisz"
      },
      {
        "authorId": "2131119517",
        "name": "Dennis Bader"
      },
      {
        "authorId": "1384525065",
        "name": "Frédérick Gusset"
      },
      {
        "authorId": "2131107748",
        "name": "Mounir Benheddi"
      },
      {
        "authorId": "2131147861",
        "name": "Camila Williamson"
      },
      {
        "authorId": "2654865",
        "name": "Michal Kosinski"
      },
      {
        "authorId": "92879593",
        "name": "M. Petrik"
      },
      {
        "authorId": "2133473064",
        "name": "Gaël Grosch"
      }
    ],
    "abstract": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn."
  },
  {
    "paperId": "f381c53aeb7742e4047d06d84f9e0c4f523231a3",
    "title": "Coronavirus disease (COVID-19) cases analysis using machine-learning applications",
    "venue": "Applied Nanoscience",
    "year": 2021,
    "citationCount": 291,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8138510",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8138510, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2100113493",
        "name": "Ameer Sardar Kwekha-Rashid"
      },
      {
        "authorId": "66680362",
        "name": "H. N. Abduljabbar"
      },
      {
        "authorId": "98174258",
        "name": "Bilal S. A. Alhayani"
      }
    ],
    "abstract": "Today world thinks about coronavirus disease that which means all even this pandemic disease is not unique. The purpose of this study is to detect the role of machine-learning applications and algorithms in investigating and various purposes that deals with COVID-19. Review of the studies that had been published during 2020 and were related to this topic by seeking in Science Direct, Springer, Hindawi, and MDPI using COVID-19, machine learning, supervised learning, and unsupervised learning as keywords. The total articles obtained were 16,306 overall but after limitation; only 14 researches of these articles were included in this study. Our findings show that machine learning can produce an important role in COVID-19 investigations, prediction, and discrimination. In conclusion, machine learning can be involved in the health provider programs and plans to assess and triage the COVID-19 cases. Supervised learning showed better results than other Unsupervised learning algorithms by having 92.9% testing accuracy. In the future recurrent supervised learning can be utilized for superior accuracy."
  },
  {
    "paperId": "4afa7d8e2de43b0b67366b1bce8768f5a246d153",
    "title": "Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020",
    "venue": "Neural Information Processing Systems",
    "year": 2021,
    "citationCount": 347,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2104.10201, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2072787126",
        "name": "Ryan Turner"
      },
      {
        "authorId": "152534486",
        "name": "David Eriksson"
      },
      {
        "authorId": "145849642",
        "name": "M. McCourt"
      },
      {
        "authorId": "2080026426",
        "name": "J. Kiili"
      },
      {
        "authorId": "2054108513",
        "name": "Eero Laaksonen"
      },
      {
        "authorId": "1819682268",
        "name": "Zhen Xu"
      },
      {
        "authorId": "1743797",
        "name": "Isabelle M Guyon"
      }
    ],
    "abstract": "This paper presents the results and insights from the black-box optimization (BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The challenge emphasized the importance of evaluating derivative-free optimizers for tuning the hyperparameters of machine learning models. This was the first black-box optimization challenge with a machine learning emphasis. It was based on tuning (validation set) performance of standard machine learning models on real datasets. This competition has widespread impact as black-box optimization (e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost every machine learning project as well as many applications outside of machine learning. The final leaderboard was determined using the optimization performance on held-out (hidden) objective functions, where the optimizers ran without human intervention. Baselines were set using the default settings of several open-source black-box optimization packages as well as random search."
  },
  {
    "paperId": "0c8c500cec9b74ebc7be44c52b79d2bd78234605",
    "title": "Best practices in machine learning for chemistry",
    "venue": "Nature Chemistry",
    "year": 2021,
    "citationCount": 333,
    "openAccessPdf": {
      "url": "https://hal.archives-ouvertes.fr/hal-03243917/file/revised.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41557-021-00716-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41557-021-00716-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "11413392",
        "name": "Nongnuch Artrith"
      },
      {
        "authorId": "3300287",
        "name": "K. Butler"
      },
      {
        "authorId": "144646737",
        "name": "François-Xavier Coudert"
      },
      {
        "authorId": "1964642",
        "name": "Seungwu Han"
      },
      {
        "authorId": "2385206",
        "name": "O. Isayev"
      },
      {
        "authorId": "2541031",
        "name": "Anubhav Jain"
      },
      {
        "authorId": "2143601680",
        "name": "Aron Walsh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4f97e87512eb8bf48ce695443e958725c54908b6",
    "title": "Mathematics for Machine Learning",
    "venue": "Journal of Mathematical Sciences & Computational Mathematics",
    "year": 2020,
    "citationCount": 480,
    "openAccessPdf": {
      "url": "https://mml-book.github.io/book/mml-book.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1017/9781108679930?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/9781108679930, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48700773",
        "name": "Gaurav Kumar"
      },
      {
        "authorId": "2128150752",
        "name": "Rishav Banerjee"
      },
      {
        "authorId": "2127420955",
        "name": "Deepak Kr Singh"
      },
      {
        "authorId": "2127639930",
        "name": "Nitesh Choubey"
      },
      {
        "authorId": "2127607412",
        "name": "Arnaw"
      }
    ],
    "abstract": "Machine learning is a way to study the algorithm and statistical model that is used by computer to perform a specific task through pattern and deduction [1]. It builds a mathematical model from a sample data which may come under either supervised or unsupervised learning. It is closely\n related to computational statistics which is an interface between statistics and computer science. Also, linear algebra and probability theory are two tools of mathematics which form the basis of machine learning. In general, statistics is a science concerned with collecting, analysing, interpreting\n the data. Data are the facts and figure that can be classified as either quantitative or qualitative. From the given set of data, we can predict the expected observation, difference between the outcome of two observations and how data look like which can help in better decision making process\n [2]. Descriptive and inferential statistics are the two methods of data analysis. Descriptive statistics summarize the raw data into information through which common expectation and variation of data can be taken. It also provides graphical methods that can be used to visualize the sample\n of data and qualitative understanding of observation whereas inferential statistics refers to drawing conclusions from data. Inferences are made under the framework of probability theory. So, understanding of data and interpretation of result are two important aspects of machine learning.\n In this paper, we have reviewed the different methods of ML, mathematics behind ML, its application in day to day life and future aspects."
  },
  {
    "paperId": "97ac11e5a6440eccb70ae7146392ac138c36fa6c",
    "title": "Fairness in Machine Learning",
    "venue": "INNSBDDL",
    "year": 2020,
    "citationCount": 530,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2012.15816, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1682762",
        "name": "L. Oneto"
      },
      {
        "authorId": "48880818",
        "name": "S. Chiappa"
      }
    ],
    "abstract": "Machine learning based systems are reaching society at large and in many aspects of everyday life. This phenomenon has been accompanied by concerns about the ethical issues that may arise from the adoption of these technologies. ML fairness is a recently established area of machine learning that studies how to ensure that biases in the data and model inaccuracies do not lead to models that treat individuals unfavorably on the basis of characteristics such as e.g. race, gender, disabilities, and sexual or political orientation. In this manuscript, we discuss some of the limitations present in the current reasoning about fairness and in methods that deal with it, and describe some work done by the authors to address them. More specifically, we show how causal Bayesian networks can play an important role to reason about and deal with fairness, especially in complex unfairness scenarios. We describe how optimal transport theory can be leveraged to develop methods that impose constraints on the full shapes of distributions corresponding to different sensitive attributes, overcoming the limitation of most approaches that approximate fairness desiderata by imposing constraints on the lower order moments or other functions of those distributions. We present a unified framework that encompasses methods that can deal with different settings and fairness criteria, and that enjoys strong theoretical guarantees. We introduce an approach to learn fair representations that can generalize to unseen tasks. Finally, we describe a technique that accounts for legal restrictions about the use of sensitive attributes."
  },
  {
    "paperId": "4a7eea3ec3080ecb277bfe466afce4822a1071d7",
    "title": "Quantum embeddings for machine learning",
    "venue": "",
    "year": 2020,
    "citationCount": 392,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2001.03622, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145762777",
        "name": "S. Lloyd"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "35323164",
        "name": "Aroosa Ijaz"
      },
      {
        "authorId": "2070140",
        "name": "J. Izaac"
      },
      {
        "authorId": "3399181",
        "name": "N. Killoran"
      }
    ],
    "abstract": "Quantum classifiers are trainable quantum circuits used as machine learning models. The first part of the circuit implements a quantum feature map that encodes classical inputs into quantum states, embedding the data in a high-dimensional Hilbert space; the second part of the circuit executes a quantum measurement interpreted as the output of the model. Usually, the measurement is trained to distinguish quantum-embedded data. We propose to instead train the first part of the circuit---the embedding---with the objective of maximally separating data classes in Hilbert space, a strategy we call quantum metric learning. As a result, the measurement minimizing a linear classification loss is already known and depends on the metric used: for embeddings separating data using the l1 or trace distance, this is the Helstrom measurement, while for the l2 or Hilbert-Schmidt distance, it is a simple overlap measurement. This approach provides a powerful analytic framework for quantum machine learning and eliminates a major component in current models, freeing up more precious resources to best leverage the capabilities of near-term quantum information processors."
  },
  {
    "paperId": "71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
    "title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning",
    "venue": "Journal of machine learning research",
    "year": 2020,
    "citationCount": 748,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.03395, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1396841807",
        "name": "A. D'Amour"
      },
      {
        "authorId": "145993598",
        "name": "K. Heller"
      },
      {
        "authorId": "40497400",
        "name": "D. Moldovan"
      },
      {
        "authorId": "1874006",
        "name": "Ben Adlam"
      },
      {
        "authorId": "2327021506",
        "name": "Babak Alipanahi"
      },
      {
        "authorId": "2638246",
        "name": "Alex Beutel"
      },
      {
        "authorId": "2110195795",
        "name": "Christina Chen"
      },
      {
        "authorId": "1695378",
        "name": "Jonathan Deaton"
      },
      {
        "authorId": "144154709",
        "name": "Jacob Eisenstein"
      },
      {
        "authorId": "28552618",
        "name": "M. Hoffman"
      },
      {
        "authorId": "2420527",
        "name": "F. Hormozdiari"
      },
      {
        "authorId": "2815290",
        "name": "N. Houlsby"
      },
      {
        "authorId": "3108448",
        "name": "Shaobo Hou"
      },
      {
        "authorId": "3451901",
        "name": "Ghassen Jerfel"
      },
      {
        "authorId": "6413143",
        "name": "A. Karthikesalingam"
      },
      {
        "authorId": "34302129",
        "name": "Mario Lucic"
      },
      {
        "authorId": "2146275249",
        "name": "Yi-An Ma"
      },
      {
        "authorId": "6322777",
        "name": "Cory Y. McLean"
      },
      {
        "authorId": "2007712128",
        "name": "Diana Mincu"
      },
      {
        "authorId": "4836115",
        "name": "A. Mitani"
      },
      {
        "authorId": "145071265",
        "name": "A. Montanari"
      },
      {
        "authorId": "81408931",
        "name": "Zachary Nado"
      },
      {
        "authorId": "144223091",
        "name": "Vivek Natarajan"
      },
      {
        "authorId": "2065412355",
        "name": "Christopher Nielson"
      },
      {
        "authorId": "25897803",
        "name": "T. Osborne"
      },
      {
        "authorId": "2035210",
        "name": "R. Raman"
      },
      {
        "authorId": "88478180",
        "name": "K. Ramasamy"
      },
      {
        "authorId": "144042306",
        "name": "R. Sayres"
      },
      {
        "authorId": "3212089",
        "name": "Jessica Schrouff"
      },
      {
        "authorId": "6454443",
        "name": "Martin G. Seneviratne"
      },
      {
        "authorId": "2007741250",
        "name": "Shannon Sequeira"
      },
      {
        "authorId": "46537606",
        "name": "Harini Suresh"
      },
      {
        "authorId": "2974320",
        "name": "Victor Veitch"
      },
      {
        "authorId": "3316311",
        "name": "Max Vladymyrov"
      },
      {
        "authorId": "1524732527",
        "name": "Xuezhi Wang"
      },
      {
        "authorId": "20825661",
        "name": "Kellie Webster"
      },
      {
        "authorId": "2856607",
        "name": "Steve Yadlowsky"
      },
      {
        "authorId": "2520251",
        "name": "T. Yun"
      },
      {
        "authorId": "2743563",
        "name": "Xiaohua Zhai"
      },
      {
        "authorId": "1733143",
        "name": "D. Sculley"
      }
    ],
    "abstract": "ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain."
  },
  {
    "paperId": "d70b4a2f3c43a834f6d52279ab0f8621897ef880",
    "title": "Nanoparticle synthesis assisted by machine learning",
    "venue": "Nature Reviews Materials",
    "year": 2021,
    "citationCount": 348,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41578-021-00337-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41578-021-00337-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "14075791",
        "name": "Huachen Tao"
      },
      {
        "authorId": "2112663859",
        "name": "Tianyi Wu"
      },
      {
        "authorId": "3372027",
        "name": "Matteo Aldeghi"
      },
      {
        "authorId": "1473214251",
        "name": "Tony C Wu"
      },
      {
        "authorId": "1380248954",
        "name": "Alán Aspuru-Guzik"
      },
      {
        "authorId": "46288374",
        "name": "E. Kumacheva"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2a41589895b84f6225bba43d928355eb2fd52c1d",
    "title": "Machine Learning for Chemical Reactions.",
    "venue": "Chemical Reviews",
    "year": 2021,
    "citationCount": 290,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1021/acs.chemrev.1c00033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acs.chemrev.1c00033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2609300",
        "name": "M. Meuwly"
      }
    ],
    "abstract": "Machine learning (ML) techniques applied to chemical reactions have a long history. The present contribution discusses applications ranging from small molecule reaction dynamics to computational platforms for reaction planning. ML-based techniques can be particularly relevant for problems involving both computation and experiments. For one, Bayesian inference is a powerful approach to develop models consistent with knowledge from experiments. Second, ML-based methods can also be used to handle problems that are formally intractable using conventional approaches, such as exhaustive characterization of state-to-state information in reactive collisions. Finally, the explicit simulation of reactive networks as they occur in combustion has become possible using machine-learned neural network potentials. This review provides an overview of the questions that can and have been addressed using machine learning techniques, and an outlook discusses challenges in this diverse and stimulating field. It is concluded that ML applied to chemistry problems as practiced and conceived today has the potential to transform the way with which the field approaches problems involving chemical reactions, in both research and academic teaching."
  },
  {
    "paperId": "7649af7bf6e9d277ed045930fc08d79247e02375",
    "title": "Gaussian Processes in Machine Learning",
    "venue": "Advanced Lectures on Machine Learning",
    "year": 2003,
    "citationCount": 3913,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-28650-9_4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-28650-9_4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2247411478",
        "name": "Carl E. Rasmussen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d7701e78e0bfc92b03a89582e80cfb751ac03f26",
    "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning",
    "venue": "International Conference on Data Science and Advanced Analytics",
    "year": 2018,
    "citationCount": 2057,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1806.00069",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1806.00069, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145019478",
        "name": "Leilani H. Gilpin"
      },
      {
        "authorId": "144159726",
        "name": "David Bau"
      },
      {
        "authorId": "144002190",
        "name": "Ben Z. Yuan"
      },
      {
        "authorId": "50397921",
        "name": "Ayesha Bajwa"
      },
      {
        "authorId": "144417360",
        "name": "Michael A. Specter"
      },
      {
        "authorId": "1735243",
        "name": "Lalana Kagal"
      }
    ],
    "abstract": "There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence."
  },
  {
    "paperId": "e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772",
    "title": "Some Studies in Machine Learning Using the Game of Checkers",
    "venue": "IBM Journal of Research and Development",
    "year": 1995,
    "citationCount": 5044,
    "openAccessPdf": {
      "url": "http://www.cs.virginia.edu/~evans/greatworks/samuel1959.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1147/rd.33.0210?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1147/rd.33.0210, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7991309",
        "name": "A. Samuel"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d1e701665e73faa648cb15473952576f40e8e122",
    "title": "The Machine‐Learning Approach",
    "venue": "Machine Learning for iOS Developers",
    "year": 2020,
    "citationCount": 544,
    "openAccessPdf": {
      "url": "http://cbio.ensmp.fr/~jvert/svn/bibli/local/Zhou2004Recognizing.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781119602927.ch2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781119602927.ch2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "b50d99925701a88ce998323af1307b92a5b87258",
    "title": "Machine Learning in Healthcare",
    "venue": "Current Genomics",
    "year": 2021,
    "citationCount": 258,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8822225",
      "status": "GREEN",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8822225, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2129202155",
        "name": "Hafsa Habehh"
      },
      {
        "authorId": "145543581",
        "name": "S. Gohel"
      }
    ],
    "abstract": "Recent advancements in Artificial Intelligence (AI) and Machine Learning (ML) technology have brought on substantial strides in predicting and identifying health emergencies, disease populations, and disease state and immune response, amongst a few. Although, skepticism remains regarding the practical application and interpretation of results from ML-based approaches in healthcare settings, the inclusion of these approaches is increasing at a rapid pace. Here we provide a brief overview of machine learning-based approaches and learning algorithms including supervised, unsupervised, and reinforcement learning along with examples. Second, we discuss the application of ML in several healthcare fields, including radiology, genetics, electronic health records, and neuroimaging. We also briefly discuss the risks and challenges of ML application to healthcare such as system privacy and ethical concerns and provide suggestions for future applications."
  },
  {
    "paperId": "b5b98051b65da6b1b3b579862b0407d48c5bef48",
    "title": "Principles and Practice of Explainable Machine Learning",
    "venue": "Frontiers in Big Data",
    "year": 2020,
    "citationCount": 513,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2009.11698, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144893617",
        "name": "Vaishak Belle"
      },
      {
        "authorId": "40911590",
        "name": "I. Papantonis"
      }
    ],
    "abstract": "Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions."
  },
  {
    "paperId": "f2df0c1026ffa474f603a535e48e5c115d3d8629",
    "title": "Extreme learning machine: Theory and applications",
    "venue": "Neurocomputing",
    "year": 2006,
    "citationCount": 12296,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.NEUCOM.2005.12.126?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.NEUCOM.2005.12.126, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "50736254",
        "name": "Q. Zhu"
      },
      {
        "authorId": "1683268",
        "name": "C. Siew"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bb0cec8f2d34cfb9dbf8bffd1a5de499311ae098",
    "title": "Understanding Machine Learning",
    "venue": "Machine Learning for Cyber Agents",
    "year": 2022,
    "citationCount": 163,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-91585-8_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-91585-8_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50462631",
        "name": "Stanislav Abaimov"
      },
      {
        "authorId": "8094734",
        "name": "M. Martellini"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1b225474e7a5794f98cdfbde8b12ccbc56799409",
    "title": "Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",
    "venue": "International Conference on Learning Representations",
    "year": 2017,
    "citationCount": 1449,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1712.04248, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40634590",
        "name": "Wieland Brendel"
      },
      {
        "authorId": "19237612",
        "name": "Jonas Rauber"
      },
      {
        "authorId": "1731199",
        "name": "M. Bethge"
      }
    ],
    "abstract": "Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL ."
  },
  {
    "paperId": "ff8eea01cbb5de505672cf9bbda3a6a91624cf52",
    "title": "Quantum Machine Learning",
    "venue": "",
    "year": 2018,
    "citationCount": 2081,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "2258749",
        "name": "Francesco Petruccione"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "99afa67e28780754907b19b688bf2b35eb22e578",
    "title": "A Review on Linear Regression Comprehensive in Machine Learning",
    "venue": "",
    "year": 2020,
    "citationCount": 913,
    "openAccessPdf": {
      "url": "https://jastt.org/index.php/jasttpath/article/download/57/20",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.38094/jastt1457?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.38094/jastt1457, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2082062721",
        "name": "Dastan Maulud"
      },
      {
        "authorId": "35323115",
        "name": "A. Abdulazeez"
      }
    ],
    "abstract": "Perhaps one of the most common and comprehensive statistical and machine learning algorithms are linear regression. Linear regression is used to find a linear relationship between one or more predictors. The linear regression has two types: simple regression and multiple regression (MLR). This paper discusses various works by different researchers on linear regression and polynomial regression and compares their performance using the best approach to optimize prediction and precision. Almost all of the articles analyzed in this review is focused on datasets; in order to determine a model's efficiency, it must be correlated with the actual values obtained for the explanatory variables."
  },
  {
    "paperId": "efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
    "title": "Big Data and Machine Learning in Health Care.",
    "venue": "Journal of the American Medical Association (JAMA)",
    "year": 2018,
    "citationCount": 1521,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1001/jama.2017.18391?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jama.2017.18391, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143649421",
        "name": "Andrew Beam"
      },
      {
        "authorId": "1740538",
        "name": "I. Kohane"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "739769f4862753fc80057194456d758d2a148ee3",
    "title": "Extreme Learning Machine for Regression and Multiclass Classification",
    "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",
    "year": 2012,
    "citationCount": 5151,
    "openAccessPdf": {
      "url": "http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Unified-Learning.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSMCB.2011.2168604?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSMCB.2011.2168604, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "2986982",
        "name": "Hongming Zhou"
      },
      {
        "authorId": "3210833",
        "name": "Xiaojian Ding"
      },
      {
        "authorId": "2118403946",
        "name": "Rui Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "175e37bca3762b3a52c6a0e153060b98a251d061",
    "title": "Inverse molecular design using machine learning: Generative models for matter engineering",
    "venue": "Science",
    "year": 2018,
    "citationCount": 1545,
    "openAccessPdf": {
      "url": "https://science.sciencemag.org/content/sci/361/6400/360.full.pdf",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aat2663?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aat2663, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1380248978",
        "name": "Benjamín Sánchez-Lengeling"
      },
      {
        "authorId": "1380248954",
        "name": "Alán Aspuru-Guzik"
      }
    ],
    "abstract": "The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials."
  },
  {
    "paperId": "102ebe229df18c8733ea1b8def56cd79996e2178",
    "title": "A Survey of Human-in-the-loop for Machine Learning",
    "venue": "Future generations computer systems",
    "year": 2021,
    "citationCount": 618,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2108.00941",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2108.00941, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153028502",
        "name": "Xingjiao Wu"
      },
      {
        "authorId": "2110506578",
        "name": "Luwei Xiao"
      },
      {
        "authorId": "2339538029",
        "name": "Yixuan Sun"
      },
      {
        "authorId": "2144181836",
        "name": "Junhang Zhang"
      },
      {
        "authorId": "1805932704",
        "name": "Tianlong Ma"
      },
      {
        "authorId": "2112480319",
        "name": "Liangbo He"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "430f3c265935abb45bc84f3ae81c570ef778aac0",
    "title": "Machine learning and data mining in manufacturing",
    "venue": "Expert systems with applications",
    "year": 2021,
    "citationCount": 529,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.ESWA.2020.114060?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.ESWA.2020.114060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153298784",
        "name": "Alican Dogan"
      },
      {
        "authorId": "2808975",
        "name": "Derya Birant"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "31a61d009442436d04b9d4e1c5beee37172289ae",
    "title": "Machine Learning",
    "venue": "",
    "year": 2021,
    "citationCount": 448,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-981-15-1967-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-981-15-1967-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2149133516",
        "name": "Zhi-Hua Zhou"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
    "title": "Introduction to Machine Learning, Neural Networks, and Deep Learning",
    "venue": "Translational Vision Science & Technology",
    "year": 2020,
    "citationCount": 740,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7347027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2113872426",
        "name": "Rene Y. Choi"
      },
      {
        "authorId": "3719099",
        "name": "Aaron S. Coyner"
      },
      {
        "authorId": "1401724111",
        "name": "Jayashree Kalpathy-Cramer"
      },
      {
        "authorId": "1764601",
        "name": "M. Chiang"
      },
      {
        "authorId": "2107231340",
        "name": "J. Campbell"
      }
    ],
    "abstract": "Purpose To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning. Methods A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology. Results A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background. Conclusions Artificial intelligence has a promising future in medicine; however, many challenges remain. Translational Relevance The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine."
  },
  {
    "paperId": "8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8",
    "title": "Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification",
    "venue": "Bioinform.",
    "year": 2017,
    "citationCount": 1897,
    "openAccessPdf": {
      "url": "https://academic.oup.com/bioinformatics/article-pdf/33/15/2424/25157856/btx180.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1093/bioinformatics/btx180?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/bioinformatics/btx180, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1398461214",
        "name": "Ignacio Arganda-Carreras"
      },
      {
        "authorId": "2129065",
        "name": "V. Kaynig"
      },
      {
        "authorId": "1680265",
        "name": "C. Rueden"
      },
      {
        "authorId": "2504157",
        "name": "K. Eliceiri"
      },
      {
        "authorId": "3032174",
        "name": "J. Schindelin"
      },
      {
        "authorId": "145844120",
        "name": "Albert Cardona"
      },
      {
        "authorId": "144924970",
        "name": "H. Seung"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e8d330f11df9c69f38b78a7cc4b1333ebecf7c55",
    "title": "Ethical Machine Learning in Health Care",
    "venue": "Annual Review of Biomedical Data Science",
    "year": 2020,
    "citationCount": 457,
    "openAccessPdf": {
      "url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-biodatasci-092820-114757",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2009.10576, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34574044",
        "name": "I. Chen"
      },
      {
        "authorId": "145192191",
        "name": "E. Pierson"
      },
      {
        "authorId": "48345067",
        "name": "Sherri Rose"
      },
      {
        "authorId": "34287745",
        "name": "Shalmali Joshi"
      },
      {
        "authorId": "6745873",
        "name": "Kadija S. Ferryman"
      },
      {
        "authorId": "2804918",
        "name": "M. Ghassemi"
      }
    ],
    "abstract": "The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges."
  },
  {
    "paperId": "b1f574c47d0b6e3032246770b9cbebb9c7bd0c7f",
    "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
    "venue": "ACM Computing Surveys",
    "year": 2020,
    "citationCount": 476,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3533378",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.09926, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "133643337",
        "name": "Andrei Paleyes"
      },
      {
        "authorId": "2000207",
        "name": "Raoul-Gabriel Urma"
      },
      {
        "authorId": "145306271",
        "name": "Neil D. Lawrence"
      }
    ],
    "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges."
  },
  {
    "paperId": "72d3ddf1f7210d7e70144bbc09f770ec411fe909",
    "title": "Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence",
    "venue": "Inf.",
    "year": 2020,
    "citationCount": 580,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2078-2489/11/4/193/pdf?version=1587379966",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.04803, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2562040",
        "name": "S. Raschka"
      },
      {
        "authorId": "2055466552",
        "name": "Joshua Patterson"
      },
      {
        "authorId": "1491910676",
        "name": "Corey Nolet"
      }
    ],
    "abstract": "Smarter applications are making better use of the insights gleaned from data, having an impact on every industry and research discipline. At the core of this revolution lies the tools and the methods that are driving it, from processing the massive piles of data generated each day to learning from and taking useful action. Deep neural networks, along with advancements in classical machine learning and scalable general-purpose graphics processing unit (GPU) computing, have become critical components of artificial intelligence, enabling many of these astounding breakthroughs and lowering the barrier to adoption. Python continues to be the most preferred language for scientific computing, data science, and machine learning, boosting both performance and productivity by enabling the use of low-level libraries and clean high-level APIs. This survey offers insight into the field of machine learning with Python, taking a tour through important topics to identify some of the core hardware and software paradigms that have enabled it. We cover widely-used libraries and concepts, collected together for holistic comparison, with the goal of educating the reader and driving the field of Python machine learning forward."
  },
  {
    "paperId": "89998030721e58ade6349b9426cc8c8d81103028",
    "title": "A Comprehensive Survey of Loss Functions in Machine Learning",
    "venue": "Annals of Data Science",
    "year": 2020,
    "citationCount": 603,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40745-020-00253-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40745-020-00253-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2151570286",
        "name": "Qi Wang"
      },
      {
        "authorId": "2109386966",
        "name": "Yue Ma"
      },
      {
        "authorId": "2074108386",
        "name": "Kun Zhao"
      },
      {
        "authorId": "143790318",
        "name": "Ying-jie Tian"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "86788a38467e1f2f1df713f5d5694bfee9f8ae29",
    "title": "Predicting the state of charge and health of batteries using data-driven machine learning",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 556,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-020-0156-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-020-0156-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2713133",
        "name": "M. Ng"
      },
      {
        "authorId": "2109972064",
        "name": "Jin Zhao"
      },
      {
        "authorId": "50442603",
        "name": "Qingyu Yan"
      },
      {
        "authorId": "6600632",
        "name": "G. Conduit"
      },
      {
        "authorId": "4761605",
        "name": "Z. Seh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "62d4aaaf562df94c4bdb116ee1e5cc2843c88bec",
    "title": "What Role Does Hydrological Science Play in the Age of Machine Learning?",
    "venue": "Water Resources Research",
    "year": 2020,
    "citationCount": 458,
    "openAccessPdf": {
      "url": "https://eartharxiv.org/repository/object/422/download/3646/",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1029/2020WR028091?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1029/2020WR028091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8451065",
        "name": "G. Nearing"
      },
      {
        "authorId": "67249817",
        "name": "Frederik Kratzert"
      },
      {
        "authorId": "1579255098",
        "name": "A. Sampson"
      },
      {
        "authorId": "34983296",
        "name": "C. Pelissier"
      },
      {
        "authorId": "40270530",
        "name": "D. Klotz"
      },
      {
        "authorId": "1492153172",
        "name": "J. Frame"
      },
      {
        "authorId": "1750699488",
        "name": "Cristina Prieto"
      },
      {
        "authorId": "2055614078",
        "name": "H. Gupta"
      }
    ],
    "abstract": "This paper is derived from a keynote talk given at the Google's 2020 Flood Forecasting Meets Machine Learning Workshop. Recent experiments applying deep learning to rainfall‐runoff simulation indicate that there is significantly more information in large‐scale hydrological data sets than hydrologists have been able to translate into theory or models. While there is a growing interest in machine learning in the hydrological sciences community, in many ways, our community still holds deeply subjective and nonevidence‐based preferences for models based on a certain type of “process understanding” that has historically not translated into accurate theory, models, or predictions. This commentary is a call to action for the hydrology community to focus on developing a quantitative understanding of where and when hydrological process understanding is valuable in a modeling discipline increasingly dominated by machine learning. We offer some potential perspectives and preliminary examples about how this might be accomplished."
  },
  {
    "paperId": "80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
    "title": "Tslearn, A Machine Learning Toolkit for Time Series Data",
    "venue": "Journal of machine learning research",
    "year": 2020,
    "citationCount": 479,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2576923",
        "name": "R. Tavenard"
      },
      {
        "authorId": "2315904947",
        "name": "Johann Faouzi"
      },
      {
        "authorId": "7876438",
        "name": "Gilles Vandewiele"
      },
      {
        "authorId": "2083496889",
        "name": "Felix Divo"
      },
      {
        "authorId": "2064934605",
        "name": "Guillaume Androz"
      },
      {
        "authorId": "2109765",
        "name": "Chester Holtz"
      },
      {
        "authorId": "2052418358",
        "name": "Marie Payne"
      },
      {
        "authorId": "8657082",
        "name": "R. Yurchak"
      },
      {
        "authorId": "35469144",
        "name": "Marc Rußwurm"
      },
      {
        "authorId": "1402250456",
        "name": "Kushal Kolar"
      },
      {
        "authorId": "102818944",
        "name": "E. Woods"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
    "title": "Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)",
    "venue": "Journal of machine learning research",
    "year": 2020,
    "citationCount": 418,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.12206, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145134886",
        "name": "Joelle Pineau"
      },
      {
        "authorId": "1399113403",
        "name": "Philippe Vincent-Lamarre"
      },
      {
        "authorId": "40910779",
        "name": "Koustuv Sinha"
      },
      {
        "authorId": "1784327",
        "name": "V. Larivière"
      },
      {
        "authorId": "2624289",
        "name": "A. Beygelzimer"
      },
      {
        "authorId": "1389671466",
        "name": "Florence d'Alché-Buc"
      },
      {
        "authorId": "2394622",
        "name": "E. Fox"
      },
      {
        "authorId": "1777528",
        "name": "H. Larochelle"
      }
    ],
    "abstract": "One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative."
  },
  {
    "paperId": "6965bc6d26fc910a6387cd6d423b35fd9e1d358b",
    "title": "Integrating Physics-Based Modeling with Machine Learning: A Survey",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 369,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "51439518",
        "name": "J. Willard"
      },
      {
        "authorId": "38139853",
        "name": "X. Jia"
      },
      {
        "authorId": "4632515",
        "name": "Shaoming Xu"
      },
      {
        "authorId": "1707756",
        "name": "M. Steinbach"
      },
      {
        "authorId": "2107978833",
        "name": "Vipin Kumar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
    "title": "Advancing Biosensors with Machine Learning.",
    "venue": "ACS Sensors",
    "year": 2020,
    "citationCount": 477,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1021/acssensors.0c01424?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acssensors.0c01424, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "11555660",
        "name": "Feiyun Cui"
      },
      {
        "authorId": "51315458",
        "name": "Yun Yue"
      },
      {
        "authorId": "2153913604",
        "name": "Yi Zhang"
      },
      {
        "authorId": "7969330",
        "name": "Ziming Zhang"
      },
      {
        "authorId": "2217668317",
        "name": "H. S. Zhou"
      }
    ],
    "abstract": "Chemometrics play a critical role in biosensors-based detection, analysis, and diagnosis. Nowadays, as a branch of artificial intelligence (AI), machine learning (ML) have achieved impressive advances. However, novel advanced ML methods, especially deep learning, which is famous for image analysis, facial recognition, and speech recognition, has remained relatively elusive to the biosensor community. Herein, how ML can be beneficial to biosensors is systematically discussed. The advantages and drawbacks of most popular ML algorithms are summarized on the basis of sensing data analysis. Specially, deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN) are emphasized. Diverse ML-assisted electrochemical biosensors, wearable electronics, SERS and other spectra-based biosensors, fluorescence biosensors and colorimetric biosensors are comprehensively discussed. Furthermore, biosensor networks and multibiosensor data fusion are introduced. This review will nicely bridge ML with biosensors, and greatly expand chemometrics for detection, analysis, and diagnosis."
  },
  {
    "paperId": "c0bc4ef587b4cbebd5839baeed95274fbf26c43a",
    "title": "Applications of machine learning to diagnosis and treatment of neurodegenerative diseases",
    "venue": "Nature Reviews Neurology",
    "year": 2020,
    "citationCount": 406,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41582-020-0377-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41582-020-0377-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5569230",
        "name": "Monika A. Myszczynska"
      },
      {
        "authorId": "10753629",
        "name": "P. Ojamies"
      },
      {
        "authorId": "2003831275",
        "name": "A. Lacoste"
      },
      {
        "authorId": "145243593",
        "name": "Daniel Neil"
      },
      {
        "authorId": "1741702",
        "name": "Amir Saffari"
      },
      {
        "authorId": "2059872991",
        "name": "R. Mead"
      },
      {
        "authorId": "4080239",
        "name": "Guillaume M. Hautbergue"
      },
      {
        "authorId": "2602146",
        "name": "J. Holbrook"
      },
      {
        "authorId": "6346151",
        "name": "L. Ferraiuolo"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "821fde6dc36d1264c765d249d4247ea66daff55f",
    "title": "Edge Machine Learning for AI-Enabled IoT Devices: A Review",
    "venue": "Italian National Conference on Sensors",
    "year": 2020,
    "citationCount": 354,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1424-8220/20/9/2533/pdf?version=1589338738",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7273223, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34547690",
        "name": "M. Merenda"
      },
      {
        "authorId": "1675347329",
        "name": "Carlo Porcaro"
      },
      {
        "authorId": "31174303",
        "name": "D. Iero"
      }
    ],
    "abstract": "In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors’ data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”."
  },
  {
    "paperId": "3f13a5148f7caa51ea946193d261d4f8ed32d81a",
    "title": "Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon",
    "venue": "European Journal of Operational Research",
    "year": 2018,
    "citationCount": 1566,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1811.06128",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.06128, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "144390922",
        "name": "Andrea Lodi"
      },
      {
        "authorId": "51902590",
        "name": "Antoine Prouvost"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9ac715af98e8a3bffe95ac081622f16e1a03f42a",
    "title": "A Review on Machine Learning for EEG Signal Processing in Bioengineering",
    "venue": "IEEE Reviews in Biomedical Engineering",
    "year": 2020,
    "citationCount": 343,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/RBME.2020.2969915?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/RBME.2020.2969915, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3461396",
        "name": "M. Hosseini"
      },
      {
        "authorId": "2064886624",
        "name": "Amin Hosseini"
      },
      {
        "authorId": "3460483",
        "name": "Kiarash Ahi"
      }
    ],
    "abstract": "Electroencephalography (EEG) has been a staple method for identifying certain health conditions in patients since its discovery. Due to the many different types of classifiers available to use, the analysis methods are also equally numerous. In this review, we will be examining specifically machine learning methods that have been developed for EEG analysis with bioengineering applications. We reviewed literature from 1988 to 2018 to capture previous and current classification methods for EEG in multiple applications. From this information, we are able to determine the overall effectiveness of each machine learning method as well as the key characteristics. We have found that all the primary methods used in machine learning have been applied in some form in EEG classification. This ranges from Naive-Bayes to Decision Tree/Random Forest, to Support Vector Machine (SVM). Supervised learning methods are on average of higher accuracy than their unsupervised counterparts. This includes SVM and KNN. While each of the methods individually is limited in their accuracy in their respective applications, there is hope that the combination of methods when implemented properly has a higher overall classification accuracy. This paper provides a comprehensive overview of Machine Learning applications used in EEG analysis. It also gives an overview of each of the methods and general applications that each is best suited to."
  },
  {
    "paperId": "78aa018ee7d52360e15d103390ea1cdb3a0beb41",
    "title": "Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 1826,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1605.07277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367796356",
        "name": "Nicolas Papernot"
      },
      {
        "authorId": "144061974",
        "name": "P. Mcdaniel"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      }
    ],
    "abstract": "Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19% misclassification rate) and Google (88.94%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure."
  },
  {
    "paperId": "b7a717233ec3ff37385ab1b06816d0ca375f5bb3",
    "title": "Data Shapley: Equitable Valuation of Data for Machine Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "citationCount": 928,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1904.02868, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "27316199",
        "name": "Amirata Ghorbani"
      },
      {
        "authorId": "145085305",
        "name": "James Y. Zou"
      }
    ],
    "abstract": "As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on $n$ data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley value uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor."
  },
  {
    "paperId": "f70b2f20be241f445a61f33c4b8e76e554760340",
    "title": "Software Engineering for Machine Learning: A Case Study",
    "venue": "2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
    "year": 2019,
    "citationCount": 887,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICSE-SEIP.2019.00042?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICSE-SEIP.2019.00042, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1719124",
        "name": "Saleema Amershi"
      },
      {
        "authorId": "1776779",
        "name": "Andrew Begel"
      },
      {
        "authorId": "145193818",
        "name": "C. Bird"
      },
      {
        "authorId": "1710751",
        "name": "R. Deline"
      },
      {
        "authorId": "50355692",
        "name": "H. Gall"
      },
      {
        "authorId": "1783184",
        "name": "Ece Kamar"
      },
      {
        "authorId": "1693689",
        "name": "Nachiappan Nagappan"
      },
      {
        "authorId": "2571049",
        "name": "Besmira Nushi"
      },
      {
        "authorId": "143609903",
        "name": "Thomas Zimmermann"
      }
    ],
    "abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations."
  },
  {
    "paperId": "bc386debfedf3b16101b6c3274485cea78ad6bb7",
    "title": "Machine Learning for Precision Medicine.",
    "venue": "Genome",
    "year": 2020,
    "citationCount": 334,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1139/gen-2020-0131?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1139/gen-2020-0131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145933120",
        "name": "S. MacEachern"
      },
      {
        "authorId": "144578371",
        "name": "N. Forkert"
      }
    ],
    "abstract": "Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multimodal or 'multi-omics' data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine's multimodal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine's \"big data\", in the context of genetics, genomics, and beyond."
  },
  {
    "paperId": "ede72940ae0246a292d644bd3c7e0ebf1e12a01a",
    "title": "Opportunities and Challenges for Machine Learning in Materials Science",
    "venue": "Annual review of materials research (Print)",
    "year": 2020,
    "citationCount": 363,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2006.14604",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2006.14604, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "79150910",
        "name": "D. Morgan"
      },
      {
        "authorId": "46940104",
        "name": "R. Jacobs"
      }
    ],
    "abstract": "Advances in machine learning have impacted myriad areas of materials science, such as the discovery of novel materials and the improvement of molecular simulations, with likely many more important developments to come. Given the rapid changes in this field, it is challenging to understand both the breadth of opportunities and the best practices for their use. In this review, we address aspects of both problems by providing an overview of the areas in which machine learning has recently had significant impact in materials science, and then we provide a more detailed discussion on determining the accuracy and domain of applicability of some common types of machine learning models. Finally, we discuss some opportunities and challenges for the materials community to fully utilize the capabilities of machine learning."
  },
  {
    "paperId": "7e7eb0f93c9550d7336f4bbfad5fe89604295705",
    "title": "Quantum Machine Learning in Feature Hilbert Spaces.",
    "venue": "Physical Review Letters",
    "year": 2018,
    "citationCount": 1308,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1803.07128",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.07128, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "3399181",
        "name": "N. Killoran"
      }
    ],
    "abstract": "A basic idea of quantum computing is surprisingly similar to that of kernel methods in machine learning, namely, to efficiently perform computations in an intractably large Hilbert space. In this Letter we explore some theoretical foundations of this link and show how it opens up a new avenue for the design of quantum machine learning algorithms. We interpret the process of encoding inputs in a quantum state as a nonlinear feature map that maps data to quantum Hilbert space. A quantum computer can now analyze the input data in this feature space. Based on this link, we discuss two approaches for building a quantum model for classification. In the first approach, the quantum device estimates inner products of quantum states to compute a classically intractable kernel. The kernel can be fed into any classical kernel method such as a support vector machine. In the second approach, we use a variational quantum circuit as a linear model that classifies data explicitly in Hilbert space. We illustrate these ideas with a feature map based on squeezing in a continuous-variable system, and visualize the working principle with two-dimensional minibenchmark datasets."
  },
  {
    "paperId": "e3c221ee33f9082d8d47a363ed763d62044b60f6",
    "title": "Introduction to Machine Learning with Python",
    "venue": "Textbooks on Political Analysis",
    "year": 2020,
    "citationCount": 288,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-36826-5_10?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-36826-5_10, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50821287",
        "name": "Josh Cutler"
      },
      {
        "authorId": "145785478",
        "name": "Matt Dickenson"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d7d9107de19eba8228bc599f53f013245760caee",
    "title": "A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection",
    "venue": "",
    "year": 2017,
    "citationCount": 1535,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "100818765",
        "name": "Lalu Banoth"
      },
      {
        "authorId": "2383206617",
        "name": "M. P. S. K. Teja"
      },
      {
        "authorId": "2102149819",
        "name": "M. Saicharan"
      },
      {
        "authorId": "143612469",
        "name": "N. Chandra"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2abdca069a95add94f5c0c540c09efb7adeee230",
    "title": "Reproducibility in machine learning for health research: Still a ways to go",
    "venue": "Science Translational Medicine",
    "year": 2021,
    "citationCount": 225,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1126/scitranslmed.abb1655?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/scitranslmed.abb1655, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "41153596",
        "name": "Matthew B. A. McDermott"
      },
      {
        "authorId": "118188980",
        "name": "Shirly Wang"
      },
      {
        "authorId": "150247231",
        "name": "N. Marinsek"
      },
      {
        "authorId": "2615814",
        "name": "R. Ranganath"
      },
      {
        "authorId": "1748978",
        "name": "L. Foschini"
      },
      {
        "authorId": "2804918",
        "name": "M. Ghassemi"
      }
    ],
    "abstract": "Machine learning applied to health falls short on several reproducibility metrics compared to other machine learning subfields. Machine learning for health must be reproducible to ensure reliable clinical use. We evaluated 511 scientific papers across several machine learning subfields and found that machine learning for health compared poorly to other areas regarding reproducibility metrics, such as dataset and code accessibility. We propose recommendations to address this problem."
  },
  {
    "paperId": "fbf9812f29156024ec693b4633a21303eead309d",
    "title": "Machine learning algorithm validation with a limited sample size",
    "venue": "PLoS ONE",
    "year": 2019,
    "citationCount": 1188,
    "openAccessPdf": {
      "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0224365&type=printable",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6837442, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8452323",
        "name": "A. Vabalas"
      },
      {
        "authorId": "2283643",
        "name": "E. Gowen"
      },
      {
        "authorId": "2910758",
        "name": "E. Poliakoff"
      },
      {
        "authorId": "1807736",
        "name": "A. Casson"
      }
    ],
    "abstract": "Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used."
  },
  {
    "paperId": "9ceae85a0bd4231cd2efe14884c40b7bc04d3dac",
    "title": "Accounting for Variance in Machine Learning Benchmarks",
    "venue": "Conference on Machine Learning and Systems",
    "year": 2021,
    "citationCount": 171,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2103.03098, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2900675",
        "name": "Xavier Bouthillier"
      },
      {
        "authorId": "2097176461",
        "name": "Pierre Delaunay"
      },
      {
        "authorId": "1760944",
        "name": "Mirko Bronzi"
      },
      {
        "authorId": "49860096",
        "name": "Assya Trofimov"
      },
      {
        "authorId": "2051891988",
        "name": "B. Nichyporuk"
      },
      {
        "authorId": "2073094612",
        "name": "Justin Szeto"
      },
      {
        "authorId": "2051892157",
        "name": "Naz Sepah"
      },
      {
        "authorId": "34885007",
        "name": "Edward Raff"
      },
      {
        "authorId": "51054293",
        "name": "Kanika Madan"
      },
      {
        "authorId": "2961618",
        "name": "Vikram S. Voleti"
      },
      {
        "authorId": "3127597",
        "name": "Samira Ebrahimi Kahou"
      },
      {
        "authorId": "1748421",
        "name": "Vincent Michalski"
      },
      {
        "authorId": "1862138",
        "name": "Dmitriy Serdyuk"
      },
      {
        "authorId": "1699104",
        "name": "T. Arbel"
      },
      {
        "authorId": "1972076",
        "name": "C. Pal"
      },
      {
        "authorId": "3025780",
        "name": "G. Varoquaux"
      },
      {
        "authorId": "120247189",
        "name": "Pascal Vincent"
      }
    ],
    "abstract": "Strong empirical evidence that one machine-learning algorithm A outperforms another one B ideally calls for multiple trials optimizing the learning pipeline over sources of variation such as data sampling, data augmentation, parameter initialization, and hyperparameters choices. This is prohibitively expensive, and corners are cut to reach conclusions. We model the whole benchmarking process, revealing that variance due to data sampling, parameter initialization and hyperparameter choice impact markedly the results. We analyze the predominant comparison methods used today in the light of this variance. We show a counter-intuitive result that adding more sources of variation to an imperfect estimator approaches better the ideal estimator at a 51 times reduction in compute cost. Building on these results, we study the error rate of detecting improvements, on five different deep-learning tasks/architectures. This study leads us to propose recommendations for performance comparisons."
  },
  {
    "paperId": "c370197b15fcd382094132bde4daa2c248b7cedf",
    "title": "DOME: recommendations for supervised machine learning validation in biology",
    "venue": "Nature Methods",
    "year": 2021,
    "citationCount": 171,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41592-021-01205-4.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41592-021-01205-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41592-021-01205-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144218611",
        "name": "Ian Walsh"
      },
      {
        "authorId": "39084373",
        "name": "D. Fishman"
      },
      {
        "authorId": "1389953200",
        "name": "D. García-Gasulla"
      },
      {
        "authorId": "6544704",
        "name": "T. Titma"
      },
      {
        "authorId": "2028880",
        "name": "G. Pollastri"
      },
      {
        "authorId": "1988753275",
        "name": "The Elixir Machine Learning focus group"
      },
      {
        "authorId": "3119529",
        "name": "J. Harrow"
      },
      {
        "authorId": "71018930",
        "name": "Fotis Psomopoulos"
      },
      {
        "authorId": "1801645",
        "name": "Silvio C. E. Tosatto"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa",
    "title": "When Machine Learning Meets Privacy",
    "venue": "ACM Computing Surveys",
    "year": 2020,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "https://opus.lib.uts.edu.au/bitstream/10453/146941/2/Privacy_and_machine_learning_survey_accepted%20version.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.11819, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145306564",
        "name": "B. Liu"
      },
      {
        "authorId": "145633124",
        "name": "Ming Ding"
      },
      {
        "authorId": "40221713",
        "name": "Sina Shaham"
      },
      {
        "authorId": "2352525327",
        "name": "Wenny Rahayu"
      },
      {
        "authorId": "1803792",
        "name": "F. Farokhi"
      },
      {
        "authorId": "1740858",
        "name": "Zihuai Lin"
      }
    ],
    "abstract": "The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field."
  },
  {
    "paperId": "24864a7f899718477c04ede9c0bea906c5dc2667",
    "title": "Machine learning with a reject option: a survey",
    "venue": "Machine-mediated learning",
    "year": 2021,
    "citationCount": 151,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2107.11277",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2107.11277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "90958315",
        "name": "Kilian Hendrickx"
      },
      {
        "authorId": "2073552588",
        "name": "Lorenzo Perini"
      },
      {
        "authorId": "2120815740",
        "name": "Dries Van der Plas"
      },
      {
        "authorId": "1718583",
        "name": "Wannes Meert"
      },
      {
        "authorId": "144815446",
        "name": "Jesse Davis"
      }
    ],
    "abstract": "Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model’s predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machine learning research areas."
  },
  {
    "paperId": "98a0ea52ccc31bacbb59c2e26ece9f7389abb00f",
    "title": "How the machine ‘thinks’: Understanding opacity in machine learning algorithms",
    "venue": "Big Data & Society",
    "year": 2016,
    "citationCount": 1941,
    "openAccessPdf": {
      "url": "https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1177/2053951715622512?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/2053951715622512, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48129731",
        "name": "J. Burrell"
      }
    ],
    "abstract": "This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm."
  },
  {
    "paperId": "e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
    "title": "River: machine learning for streaming data in Python",
    "venue": "Journal of machine learning research",
    "year": 2020,
    "citationCount": 246,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2012.04740, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35479220",
        "name": "Jacob Montiel"
      },
      {
        "authorId": "104920778",
        "name": "Max Halford"
      },
      {
        "authorId": "31757587",
        "name": "S. Mastelini"
      },
      {
        "authorId": "2034015026",
        "name": "Geoffrey Bolmier"
      },
      {
        "authorId": "2302563473",
        "name": "Raphael Sourty"
      },
      {
        "authorId": "2135111114",
        "name": "Robin Vaysse"
      },
      {
        "authorId": "103370422",
        "name": "Adil Zouitine"
      },
      {
        "authorId": "13645563",
        "name": "Heitor Murilo Gomes"
      },
      {
        "authorId": "1383995365",
        "name": "Jesse Read"
      },
      {
        "authorId": "2831624",
        "name": "T. Abdessalem"
      },
      {
        "authorId": "1762931",
        "name": "A. Bifet"
      }
    ],
    "abstract": "River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of the two most popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river."
  },
  {
    "paperId": "d3992c3d89e5ec05e0a6c96c4956f2ff9f7da023",
    "title": "Machine learning and algorithmic fairness in public and population health",
    "venue": "Nature Machine Intelligence",
    "year": 2021,
    "citationCount": 161,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-021-00373-4.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-021-00373-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-021-00373-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51429443",
        "name": "Vishwali Mhasawade"
      },
      {
        "authorId": "2110150937",
        "name": "Yuan Zhao"
      },
      {
        "authorId": "3144230",
        "name": "R. Chunara"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f6d9106b0e169204a506eb1deec2b85e0f296e4a",
    "title": "Feature selection in machine learning: A new perspective",
    "venue": "Neurocomputing",
    "year": 2018,
    "citationCount": 1675,
    "openAccessPdf": {
      "url": "http://manuscript.elsevier.com/S0925231218302911/pdf/S0925231218302911.pdf",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neucom.2017.11.077?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neucom.2017.11.077, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2115669825",
        "name": "Jie Cai"
      },
      {
        "authorId": "145619609",
        "name": "Jiawei Luo"
      },
      {
        "authorId": "2117017967",
        "name": "Shulin Wang"
      },
      {
        "authorId": "144823698",
        "name": "Sheng Yang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "83e89d56d0d0e1dfd8b52213e6cc2e191aaaf34b",
    "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy",
    "venue": "Journal of machine learning research",
    "year": 2020,
    "citationCount": 319,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.03675, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3442125",
        "name": "Ines Chami"
      },
      {
        "authorId": "1389570466",
        "name": "Sami Abu-El-Haija"
      },
      {
        "authorId": "2271808",
        "name": "Bryan Perozzi"
      },
      {
        "authorId": "1803218",
        "name": "Christopher Ré"
      },
      {
        "authorId": "1702318",
        "name": "K. Murphy"
      }
    ],
    "abstract": "There has been a surge of recent interest in learning representations for graph-structured data. Graph representation learning methods have generally fallen into three main categories, based on the availability of labeled data. The first, network embedding (such as shallow graph embedding or graph auto-encoders), focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topologies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph regularization models. We propose a comprehensive taxonomy of representation learning methods for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks), and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single consistent approach. To illustrate the generality of this approach, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area."
  },
  {
    "paperId": "e8aa24d9c64f1215a97e8118905fad0189a53b97",
    "title": "Machine learning and applications in ultrafast photonics",
    "venue": "Nature Photonics",
    "year": 2020,
    "citationCount": 304,
    "openAccessPdf": {
      "url": "https://publications.aston.ac.uk/id/eprint/42145/1/20404_3_art_file_208064_qgnykn.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41566-020-00716-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41566-020-00716-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32921446",
        "name": "G. Genty"
      },
      {
        "authorId": "51042841",
        "name": "L. Salmela"
      },
      {
        "authorId": "31295217",
        "name": "J. Dudley"
      },
      {
        "authorId": "145711155",
        "name": "D. Brunner"
      },
      {
        "authorId": "2320464706",
        "name": "Alexey Kokhanovskiy"
      },
      {
        "authorId": "145335010",
        "name": "S. Kobtsev"
      },
      {
        "authorId": "2408477",
        "name": "S. Turitsyn"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cf15c1898c81594165d74de465605aa9f559c769",
    "title": "A survey on machine learning for data fusion",
    "venue": "Information Fusion",
    "year": 2020,
    "citationCount": 523,
    "openAccessPdf": {
      "url": "https://research.aalto.fi/files/40174084/ELEC_Meng_Survey_on_Machine_InFFUS.pdf",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.inffus.2019.12.001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.inffus.2019.12.001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2056088353",
        "name": "Tong Meng"
      },
      {
        "authorId": "49737894",
        "name": "Xuyang Jing"
      },
      {
        "authorId": "2152532566",
        "name": "Zheng Yan"
      },
      {
        "authorId": "1731634",
        "name": "W. Pedrycz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "528ecb0f88a9ea6110ba309b98cc2f0678f257c9",
    "title": "Data Mining Practical Machine Learning Tools And Techniques With Java Implementations",
    "venue": "",
    "year": 2016,
    "citationCount": 1589,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "49882421",
        "name": "Marcel Abendroth"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1",
    "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
    "venue": "Neural Information Processing Systems",
    "year": 2019,
    "citationCount": 47568,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.01703, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3407277",
        "name": "Adam Paszke"
      },
      {
        "authorId": "39793298",
        "name": "Sam Gross"
      },
      {
        "authorId": "1403239967",
        "name": "Francisco Massa"
      },
      {
        "authorId": "1977806",
        "name": "Adam Lerer"
      },
      {
        "authorId": "2065251344",
        "name": "James Bradbury"
      },
      {
        "authorId": "114250963",
        "name": "Gregory Chanan"
      },
      {
        "authorId": "2059271276",
        "name": "Trevor Killeen"
      },
      {
        "authorId": "3370429",
        "name": "Zeming Lin"
      },
      {
        "authorId": "3365851",
        "name": "N. Gimelshein"
      },
      {
        "authorId": "3029482",
        "name": "L. Antiga"
      },
      {
        "authorId": "3050846",
        "name": "Alban Desmaison"
      },
      {
        "authorId": "1473151134",
        "name": "Andreas Köpf"
      },
      {
        "authorId": "2052812305",
        "name": "E. Yang"
      },
      {
        "authorId": "2253681376",
        "name": "Zachary DeVito"
      },
      {
        "authorId": "10707709",
        "name": "Martin Raison"
      },
      {
        "authorId": "41203992",
        "name": "Alykhan Tejani"
      },
      {
        "authorId": "22236100",
        "name": "Sasank Chilamkurthy"
      },
      {
        "authorId": "32163737",
        "name": "Benoit Steiner"
      },
      {
        "authorId": "152599430",
        "name": "Lu Fang"
      },
      {
        "authorId": "2113829116",
        "name": "Junjie Bai"
      },
      {
        "authorId": "2127604",
        "name": "Soumith Chintala"
      }
    ],
    "abstract": "Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks."
  },
  {
    "paperId": "775a4e375cc79b53b94e37fa3eedff481823e4a6",
    "title": "Efficient and Robust Automated Machine Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2015,
    "citationCount": 1805,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2868444",
        "name": "Matthias Feurer"
      },
      {
        "authorId": "145227684",
        "name": "Aaron Klein"
      },
      {
        "authorId": "2607675",
        "name": "Katharina Eggensperger"
      },
      {
        "authorId": "2060551",
        "name": "Jost Tobias Springenberg"
      },
      {
        "authorId": "2058090778",
        "name": "Manuel Blum"
      },
      {
        "authorId": "144661829",
        "name": "F. Hutter"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "df0e4a76513636a05f0530e55ffe4991e4957478",
    "title": "Supervised Machine Learning: A Brief Primer.",
    "venue": "The Behavior Therapist",
    "year": 2020,
    "citationCount": 555,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7431677",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.beth.2020.05.002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.beth.2020.05.002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "13111966",
        "name": "T. Jiang"
      },
      {
        "authorId": "3544883",
        "name": "J. Gradus"
      },
      {
        "authorId": "3670643",
        "name": "A. J. Rosellini"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4c75b748911ddcd888c5122f7672f69caa5d661f",
    "title": "Statistical Learning Theory",
    "venue": "Technometrics",
    "year": 2021,
    "citationCount": 21595,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/00401706.1999.10485951?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/00401706.1999.10485951, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2378903149",
        "name": "Yuhai Wu"
      }
    ],
    "abstract": "A machine learning system, in general, learns from the environment, but statistical machine learning programs (systems) learn from the data. This chapter presents techniques for statistical machine learning using Support Vector Machines (SVM) to recognize the patterns and classify them, predicting structured objects using SVM, k-nearest neighbor method for classification, and Naive Bayes classifiers. The artificial neural networks are presented with brief introduction to error-correction rules, Boltzmann learning, Hebbian rule, competitive learning rule, and deep learning. The instance-based learning is treated in details with its algorithm and learning task. The chapter concludes with a summary, and a set of practice exercises."
  },
  {
    "paperId": "9d75cc322a4e06d0a3a868cb91b04219a289c12c",
    "title": "Machine Learning: An Applied Econometric Approach",
    "venue": "Journal of Economic Perspectives",
    "year": 2017,
    "citationCount": 1532,
    "openAccessPdf": {
      "url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1257/JEP.31.2.87?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1257/JEP.31.2.87, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2062143",
        "name": "S. Mullainathan"
      },
      {
        "authorId": "47281276",
        "name": "Jann Spiess"
      }
    ],
    "abstract": "Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied."
  },
  {
    "paperId": "3df952d4a724655f7520ff95d4b2cef90fff0cae",
    "title": "Techniques for interpretable machine learning",
    "venue": "Communications of the ACM",
    "year": 2018,
    "citationCount": 1171,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1808.00033",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1808.00033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3432460",
        "name": "Mengnan Du"
      },
      {
        "authorId": "47717322",
        "name": "Ninghao Liu"
      },
      {
        "authorId": "2283100826",
        "name": "X. Hu"
      }
    ],
    "abstract": "Uncovering the mysterious ways machine learning models make decisions."
  },
  {
    "paperId": "638e41912f314c74436205aa8d332dca963ab1dc",
    "title": "Parameterized quantum circuits as machine learning models",
    "venue": "Quantum Science and Technology",
    "year": 2019,
    "citationCount": 1034,
    "openAccessPdf": {
      "url": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5/pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.07682, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3468759",
        "name": "Marcello Benedetti"
      },
      {
        "authorId": "39853731",
        "name": "Erika Lloyd"
      },
      {
        "authorId": "2071662750",
        "name": "Stefan H. Sack"
      },
      {
        "authorId": "103837672",
        "name": "Mattia Fiorentini"
      }
    ],
    "abstract": "Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications."
  },
  {
    "paperId": "2bac6b71d252f93c4841e325ca111f2752109931",
    "title": "Certified Data Removal from Machine Learning Models",
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "citationCount": 554,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.03030, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2110228691",
        "name": "Chuan Guo"
      },
      {
        "authorId": "1962083",
        "name": "T. Goldstein"
      },
      {
        "authorId": "144479015",
        "name": "Awni Y. Hannun"
      },
      {
        "authorId": "1803520",
        "name": "L. Maaten"
      }
    ],
    "abstract": "Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to \"remove\" data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical."
  },
  {
    "paperId": "f15367ed93c3505b1d62d802f3f4b769ae0f4ba5",
    "title": "Machine learning for neuroimaging with scikit-learn",
    "venue": "Front. Neuroinform.",
    "year": 2014,
    "citationCount": 1953,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1412.3919, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2958954",
        "name": "Alexandre Abraham"
      },
      {
        "authorId": "2570016",
        "name": "Fabian Pedregosa"
      },
      {
        "authorId": "2304944910",
        "name": "Michael Eickenberg"
      },
      {
        "authorId": "1643887240",
        "name": "Philippe Gervais"
      },
      {
        "authorId": "2086994888",
        "name": "A. Mueller"
      },
      {
        "authorId": "3125761",
        "name": "Jean Kossaifi"
      },
      {
        "authorId": "1797840",
        "name": "Alexandre Gramfort"
      },
      {
        "authorId": "8493461",
        "name": "B. Thirion"
      },
      {
        "authorId": "3025780",
        "name": "G. Varoquaux"
      }
    ],
    "abstract": "Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g., multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g., resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain."
  },
  {
    "paperId": "4ec953de1331fe5f720320c9f2f82884b2512701",
    "title": "Machine Learning Methods in Drug Discovery",
    "venue": "Molecules",
    "year": 2020,
    "citationCount": 281,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/1420-3049/25/22/5277/pdf?version=1605176714",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7696134, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2026124178",
        "name": "Lauv Patel"
      },
      {
        "authorId": "51466154",
        "name": "T. Shukla"
      },
      {
        "authorId": "38820495",
        "name": "Xiuzhen Huang"
      },
      {
        "authorId": "2251733",
        "name": "D. Ussery"
      },
      {
        "authorId": "5954673",
        "name": "Shanzhi Wang"
      }
    ],
    "abstract": "The advancements of information technology and related processing techniques have created a fertile base for progress in many scientific fields and industries. In the fields of drug discovery and development, machine learning techniques have been used for the development of novel drug candidates. The methods for designing drug targets and novel drug discovery now routinely combine machine learning and deep learning algorithms to enhance the efficiency, efficacy, and quality of developed outputs. The generation and incorporation of big data, through technologies such as high-throughput screening and high through-put computational analysis of databases used for both lead and target discovery, has increased the reliability of the machine learning and deep learning incorporated techniques. The use of these virtual screening and encompassing online information has also been highlighted in developing lead synthesis pathways. In this review, machine learning and deep learning algorithms utilized in drug discovery and associated techniques will be discussed. The applications that produce promising results and methods will be reviewed."
  },
  {
    "paperId": "1696cbf7da0ee845c50591843993e6605adec177",
    "title": "A few useful things to know about machine learning",
    "venue": "Communications of the ACM",
    "year": 2012,
    "citationCount": 3078,
    "openAccessPdf": {
      "url": "http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2347736.2347755?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2347736.2347755, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1740213",
        "name": "Pedro M. Domingos"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4a17a8ab29ecffde5e8280382dd858c75d5bb6b6",
    "title": "Teachable Machine: Approachable Web-Based Tool for Exploring Machine Learning Classification",
    "venue": "CHI Extended Abstracts",
    "year": 2020,
    "citationCount": 274,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3334480.3382839?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3334480.3382839, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1664904153",
        "name": "Michelle Carney"
      },
      {
        "authorId": "72500270",
        "name": "Barron Webster"
      },
      {
        "authorId": "2062749837",
        "name": "Irene Alvarado"
      },
      {
        "authorId": "2056288455",
        "name": "Kyle Phillips"
      },
      {
        "authorId": "39707815",
        "name": "Noura Howell"
      },
      {
        "authorId": "2055443643",
        "name": "Jordan Griffith"
      },
      {
        "authorId": "153631211",
        "name": "J. Jongejan"
      },
      {
        "authorId": "2156576",
        "name": "Amit Pitaru"
      },
      {
        "authorId": "2116403860",
        "name": "Alexander Chen"
      }
    ],
    "abstract": "Teachable Machine (teachablemachine.withgoogle.com) is a web-based GUI tool for creating custom machine learning classification models without specialized technical expertise. (Machine learning, or ML, lets systems learn to analyze data without being explicitly programmed.) We created it to help students, teachers, designers, and others learn about ML by creating and using their own classification models. Its broad uptake suggests it has empowered people to learn, teach, and explore ML concepts: People have created curriculum, tutorials, and other resources using Teachable Machine on topics like AI ethics at institutions including the Stanford d.school, NYU's Interactive Telecommunications Program, the MIT Media Lab, as well as creative experiments. Users in 201 countries have created over 125,000 classification models. Here we outline the project and its key contributions of (1) a flexible, approachable interface for ML classification models without ML or coding expertise, (2) a set of technical and design decisions that can inform future interactive machine learning tools, and (3) an example of how structured learning content surrounding the tool supports people accessing ML concepts."
  },
  {
    "paperId": "218062f45c15f39bc8f4fb2c930ddf20b5809b11",
    "title": "Machine Learning Testing: Survey, Landscapes and Horizons",
    "venue": "IEEE Transactions on Software Engineering",
    "year": 2019,
    "citationCount": 807,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1906.10742",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.10742, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51250527",
        "name": "J Zhang"
      },
      {
        "authorId": "145836176",
        "name": "M. Harman"
      },
      {
        "authorId": "2109704789",
        "name": "Lei Ma"
      },
      {
        "authorId": "144440741",
        "name": "Yang Liu"
      }
    ],
    "abstract": "This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing."
  },
  {
    "paperId": "b3ea2d9c8e5ea3b87ace121f0bece71565abc187",
    "title": "Quantifying the Carbon Emissions of Machine Learning",
    "venue": "arXiv.org",
    "year": 2019,
    "citationCount": 810,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1910.09700, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8651990",
        "name": "Alexandre Lacoste"
      },
      {
        "authorId": "2993731",
        "name": "A. Luccioni"
      },
      {
        "authorId": "97574153",
        "name": "Victor Schmidt"
      },
      {
        "authorId": "2526021",
        "name": "Thomas Dandres"
      }
    ],
    "abstract": "From an environmental standpoint, there are a few crucial aspects of training a neural network that have a major impact on the quantity of carbon that it emits. These factors include: the location of the server used for training and the energy grid that it uses, the length of the training procedure, and even the make and model of hardware on which the training takes place. In order to approximate these emissions, we present our Machine Learning Emissions Calculator, a tool for our community to better understand the environmental impact of training ML models. We accompany this tool with an explanation of the factors cited above, as well as concrete actions that individual practitioners and organizations can take to mitigate their carbon emissions."
  },
  {
    "paperId": "86713aa23ad99039ba76a670797df40ad65a64b2",
    "title": "An Introduction to Machine Learning",
    "venue": "Clinical pharmacology and therapy",
    "year": 2020,
    "citationCount": 287,
    "openAccessPdf": {
      "url": "https://ascpt.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cpt.1796",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7189875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2383814",
        "name": "Solveig Badillo"
      },
      {
        "authorId": "49842626",
        "name": "B. Bánfai"
      },
      {
        "authorId": "3232090",
        "name": "Fabian Birzele"
      },
      {
        "authorId": "91987714",
        "name": "I. I. Davydov"
      },
      {
        "authorId": "2023123740",
        "name": "L. Hutchinson"
      },
      {
        "authorId": "2321617293",
        "name": "Tony Kam-Thong"
      },
      {
        "authorId": "1436740047",
        "name": "Juliane Siebourg-Polster"
      },
      {
        "authorId": "3258307",
        "name": "Bernhard Steiert"
      },
      {
        "authorId": "2108489886",
        "name": "J. Zhang"
      }
    ],
    "abstract": "In the last few years, machine learning (ML) and artificial intelligence have seen a new wave of publicity fueled by the huge and ever‐increasing amount of data and computational power as well as the discovery of improved learning algorithms. However, the idea of a computer learning some abstract concept from data and applying them to yet unseen situations is not new and has been around at least since the 1950s. Many of these basic principles are very familiar to the pharmacometrics and clinical pharmacology community. In this paper, we want to introduce the foundational ideas of ML to this community such that readers obtain the essential tools they need to understand publications on the topic. Although we will not go into the very details and theoretical background, we aim to point readers to relevant literature and put applications of ML in molecular biology as well as the fields of pharmacometrics and clinical pharmacology into perspective."
  },
  {
    "paperId": "7c63a6e6d3b31b14ae4236bfbd574ea37cab18a7",
    "title": "Choosing Prediction Over Explanation in Psychology: Lessons From Machine Learning",
    "venue": "Perspectives on Psychological Science",
    "year": 2017,
    "citationCount": 1438,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc6603289?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1177/1745691617693393?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/1745691617693393, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2075675",
        "name": "T. Yarkoni"
      },
      {
        "authorId": "48804181",
        "name": "Jacob Westfall"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4eabb5b4cf137c27917a8b91c471a6a2b9407469",
    "title": "A Review of Android Malware Detection Approaches Based on Machine Learning",
    "venue": "IEEE Access",
    "year": 2020,
    "citationCount": 250,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09130686.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.3006143?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.3006143, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1828725529",
        "name": "Kaijun Liu"
      },
      {
        "authorId": "50433409",
        "name": "Shengwei Xu"
      },
      {
        "authorId": "3027277",
        "name": "Guoai Xu"
      },
      {
        "authorId": "2108160165",
        "name": "Miao Zhang"
      },
      {
        "authorId": "2112672824",
        "name": "Dawei Sun"
      },
      {
        "authorId": "2109497722",
        "name": "Haifeng Liu"
      }
    ],
    "abstract": "Android applications are developing rapidly across the mobile ecosystem, but Android malware is also emerging in an endless stream. Many researchers have studied the problem of Android malware detection and have put forward theories and methods from different perspectives. Existing research suggests that machine learning is an effective and promising way to detect Android malware. Notwithstanding, there exist reviews that have surveyed different issues related to Android malware detection based on machine learning. We believe our work complements the previous reviews by surveying a wider range of aspects of the topic. This paper presents a comprehensive survey of Android malware detection approaches based on machine learning. We briefly introduce some background on Android applications, including the Android system architecture, security mechanisms, and classification of Android malware. Then, taking machine learning as the focus, we analyze and summarize the research status from key perspectives such as sample acquisition, data preprocessing, feature selection, machine learning models, algorithms, and the evaluation of detection effectiveness. Finally, we assess the future prospects for research into Android malware detection based on machine learning. This review will help academics gain a full picture of Android malware detection based on machine learning. It could then serve as a basis for subsequent researchers to start new work and help to guide research in the field more generally."
  },
  {
    "paperId": "60baa46784e8e9a30a57e1875907d008fbdc817b",
    "title": "InterpretML: A Unified Framework for Machine Learning Interpretability",
    "venue": "arXiv.org",
    "year": 2019,
    "citationCount": 541,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.09223, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40900039",
        "name": "Harsha Nori"
      },
      {
        "authorId": "2057108610",
        "name": "Samuel Jenkins"
      },
      {
        "authorId": "143831110",
        "name": "Paul Koch"
      },
      {
        "authorId": "145727186",
        "name": "R. Caruana"
      }
    ],
    "abstract": "InterpretML is an open-source Python package which exposes machine learning interpretability algorithms to practitioners and researchers. InterpretML exposes two types of interpretability - glassbox models, which are machine learning models designed for interpretability (ex: linear models, rule lists, generalized additive models), and blackbox explainability techniques for explaining existing systems (ex: Partial Dependence, LIME). The package enables practitioners to easily compare interpretability algorithms by exposing multiple methods under a unified API, and by having a built-in, extensible visualization platform. InterpretML also includes the first implementation of the Explainable Boosting Machine, a powerful, interpretable, glassbox model that can be as accurate as many blackbox models. The MIT licensed source code can be downloaded from github.com/microsoft/interpret."
  },
  {
    "paperId": "6bf623e772d5634e33a035a3586dbab41e29c78b",
    "title": "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch",
    "venue": "International Conference on Machine Learning",
    "year": 2020,
    "citationCount": 246,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.03384, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2892780",
        "name": "Esteban Real"
      },
      {
        "authorId": "145246869",
        "name": "Chen Liang"
      },
      {
        "authorId": "48165870",
        "name": "David R. So"
      },
      {
        "authorId": "2827616",
        "name": "Quoc V. Le"
      }
    ],
    "abstract": "Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field."
  },
  {
    "paperId": "bd9ecc05a12563445a2ef4fe758a39d7f2bcda0d",
    "title": "DeltaGrad: Rapid retraining of machine learning models",
    "venue": "International Conference on Machine Learning",
    "year": 2020,
    "citationCount": 236,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2006.14755, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3037003",
        "name": "Yinjun Wu"
      },
      {
        "authorId": "2694895",
        "name": "Edgar Dobriban"
      },
      {
        "authorId": "49702692",
        "name": "S. Davidson"
      }
    ],
    "abstract": "Machine learning models are not static and may need to be retrained on slightly changed datasets, for instance, with the addition or deletion of a set of data points. This has many applications, including privacy, robustness, bias reduction, and uncertainty quantifcation. However, it is expensive to retrain models from scratch. To address this problem, we propose the DeltaGrad algorithm for rapid retraining machine learning models based on information cached during the training phase. We provide both theoretical and empirical support for the effectiveness of DeltaGrad, and show that it compares favorably to the state of the art."
  },
  {
    "paperId": "3fc9cff6ad55986de180204b98613af42f8ac37d",
    "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology",
    "venue": "Machine Learning and Knowledge Extraction",
    "year": 2020,
    "citationCount": 211,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2504-4990/3/2/20/pdf?version=1619340878",
      "status": "GREEN",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.05155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2066100848",
        "name": "Stefan Studer"
      },
      {
        "authorId": "4667865",
        "name": "T. Bui"
      },
      {
        "authorId": "40117299",
        "name": "C. Drescher"
      },
      {
        "authorId": "3332452",
        "name": "A. Hanuschkin"
      },
      {
        "authorId": "2065341843",
        "name": "Ludwig Winkler"
      },
      {
        "authorId": "2050675924",
        "name": "S. Peters"
      },
      {
        "authorId": "2113612432",
        "name": "Klaus-Robert Müller"
      }
    ],
    "abstract": "Machine learning is an established and frequently used technique in industry and academia, but a standard process model to improve success and efficiency of machine learning applications is still missing. Project organizations and machine learning practitioners face manifold challenges and risks when developing machine learning applications and have a need for guidance to meet business expectations. This paper therefore proposes a process model for the development of machine learning applications, covering six phases from defining the scope to maintaining the deployed machine learning application. Business and data understanding are executed simultaneously in the first phase, as both have considerable impact on the feasibility of the project. The next phases are comprised of data preparation, modeling, evaluation, and deployment. Special focus is applied to the last phase, as a model running in changing real-time environments requires close monitoring and maintenance to reduce the risk of performance degradation over time. With each task of the process, this work proposes quality assurance methodology that is suitable to address challenges in machine learning development that are identified in the form of risks. The methodology is drawn from practical experience and scientific literature, and has proven to be general and stable. The process model expands on CRISP-DM, a data mining process model that enjoys strong industry support, but fails to address machine learning specific tasks. The presented work proposes an industry- and application-neutral process model tailored for machine learning applications with a focus on technical tasks for quality assurance."
  },
  {
    "paperId": "206261db1196e4e391ca42077f6fca6b3ece34d0",
    "title": "The Non-IID Data Quagmire of Decentralized Machine Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "citationCount": 621,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1910.00189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145115422",
        "name": "Kevin Hsieh"
      },
      {
        "authorId": "3078275",
        "name": "Amar Phanishayee"
      },
      {
        "authorId": "145929920",
        "name": "O. Mutlu"
      },
      {
        "authorId": "1974678",
        "name": "Phillip B. Gibbons"
      }
    ],
    "abstract": "Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization."
  },
  {
    "paperId": "8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e",
    "title": "Evaluating Differentially Private Machine Learning in Practice",
    "venue": "USENIX Security Symposium",
    "year": 2019,
    "citationCount": 549,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2348109",
        "name": "Bargav Jayaraman"
      },
      {
        "authorId": "2116658506",
        "name": "David E. Evans"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5416463537f8c6be1199951b4fd6f8d5dae14920",
    "title": "Plans and Situated Actions: The Problem of Human-Machine Communication (Learning in Doing: Social,",
    "venue": "",
    "year": 1987,
    "citationCount": 7227,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.2307/1423221?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2307/1423221, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1694083",
        "name": "L. Suchman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "790985a4bee821046992ff3d5322ff11dd1b4262",
    "title": "Coresets for Data-efficient Training of Machine Learning Models",
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "citationCount": 433,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2389094",
        "name": "Baharan Mirzasoleiman"
      },
      {
        "authorId": "1748118",
        "name": "J. Bilmes"
      },
      {
        "authorId": "1702139",
        "name": "J. Leskovec"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4f975da00a5b2a2f7236e34edcb7274e5fdab937",
    "title": "Combining satellite imagery and machine learning to predict poverty",
    "venue": "Science",
    "year": 2016,
    "citationCount": 1485,
    "openAccessPdf": {
      "url": "https://science.sciencemag.org/content/sci/353/6301/790.full.pdf",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aaf7894?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aaf7894, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2752609",
        "name": "Neal Jean"
      },
      {
        "authorId": "49240687",
        "name": "M. Burke"
      },
      {
        "authorId": "46215055",
        "name": "Sang Michael Xie"
      },
      {
        "authorId": "120334004",
        "name": "W. Davis"
      },
      {
        "authorId": "2465182",
        "name": "D. Lobell"
      },
      {
        "authorId": "2490652",
        "name": "Stefano Ermon"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c7b08c2e69a338e8d0c8444ce081b51caa50b273",
    "title": "Monte Carlo Gradient Estimation in Machine Learning",
    "venue": "Journal of machine learning research",
    "year": 2019,
    "citationCount": 459,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.10652, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "14594344",
        "name": "S. Mohamed"
      },
      {
        "authorId": "35578586",
        "name": "Mihaela Rosca"
      },
      {
        "authorId": "73776617",
        "name": "Michael Figurnov"
      },
      {
        "authorId": "1714004",
        "name": "A. Mnih"
      }
    ],
    "abstract": "This paper is a broad and accessible survey of the methods we have at our disposal for Monte Carlo gradient estimation in machine learning and across the statistical sciences: the problem of computing the gradient of an expectation of a function with respect to parameters defining the distribution that is integrated; the problem of sensitivity analysis. In machine learning research, this gradient problem lies at the core of many learning problems, in supervised, unsupervised and reinforcement learning. We will generally seek to rewrite such gradients in a form that allows for Monte Carlo estimation, allowing them to be easily and efficiently used and analysed. We explore three strategies--the pathwise, score function, and measure-valued gradient estimators--exploring their historical developments, derivation, and underlying assumptions. We describe their use in other fields, show how they are related and can be combined, and expand on their possible generalisations. Wherever Monte Carlo gradient estimators have been derived and deployed in the past, important advances have followed. A deeper and more widely-held understanding of this problem will lead to further advances, and it is these advances that we wish to support."
  },
  {
    "paperId": "998039a4876edc440e0cabb0bc42239b0eb29644",
    "title": "Tackling Climate Change with Machine Learning",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 935,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3485128",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.05433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2346588776",
        "name": "D. Rolnick"
      },
      {
        "authorId": "49698491",
        "name": "P. Donti"
      },
      {
        "authorId": "12736608",
        "name": "L. Kaack"
      },
      {
        "authorId": "80536011",
        "name": "K. Kochanski"
      },
      {
        "authorId": "8651990",
        "name": "Alexandre Lacoste"
      },
      {
        "authorId": "46769963",
        "name": "K. Sankaran"
      },
      {
        "authorId": "2068943123",
        "name": "A. Ross"
      },
      {
        "authorId": "1417437895",
        "name": "Nikola Milojevic-Dupont"
      },
      {
        "authorId": "3106683",
        "name": "Natasha Jaques"
      },
      {
        "authorId": "2387573844",
        "name": "Anna Waldman-Brown"
      },
      {
        "authorId": "2993731",
        "name": "A. Luccioni"
      },
      {
        "authorId": "3422058",
        "name": "Tegan Maharaj"
      },
      {
        "authorId": "74936246",
        "name": "Evan D. Sherwin"
      },
      {
        "authorId": "103485736",
        "name": "S. Mukkavilli"
      },
      {
        "authorId": "3282030",
        "name": "Konrad Paul Kording"
      },
      {
        "authorId": "2064532325",
        "name": "Carla P. Gomes"
      },
      {
        "authorId": "2067948334",
        "name": "Andrew Y. Ng"
      },
      {
        "authorId": "48987704",
        "name": "D. Hassabis"
      },
      {
        "authorId": "144189092",
        "name": "John C. Platt"
      },
      {
        "authorId": "47628266",
        "name": "F. Creutzig"
      },
      {
        "authorId": "1695997",
        "name": "J. Chayes"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change."
  },
  {
    "paperId": "e67121cd31e95fba6c892724e619323ad7564b03",
    "title": "A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning",
    "venue": "Archives of Computational Methods in Engineering",
    "year": 2019,
    "citationCount": 937,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11831-019-09344-w?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11831-019-09344-w, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "104394731",
        "name": "Shaveta Dargan"
      },
      {
        "authorId": "2109645645",
        "name": "Munish Kumar"
      },
      {
        "authorId": "103435006",
        "name": "Maruthi Rohit Ayyagari"
      },
      {
        "authorId": "145627436",
        "name": "G. Kumar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5d093bd376ba63495ea442241bc8bc2f0ff30c2b",
    "title": "Machine learning in medicine: a practical introduction",
    "venue": "BMC Medical Research Methodology",
    "year": 2019,
    "citationCount": 937,
    "openAccessPdf": {
      "url": "https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-019-0681-4",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6425557, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1435552642",
        "name": "Jenni A. M. Sidey-Gibbons"
      },
      {
        "authorId": "1404920372",
        "name": "C. Sidey-Gibbons"
      }
    ],
    "abstract": "BackgroundFollowing visible successes on a wide range of predictive tasks, machine learning techniques are attracting substantial interest from medical researchers and clinicians. We address the need for capacity development in this area by providing a conceptual introduction to machine learning alongside a practical guide to developing and evaluating predictive algorithms using freely-available open source software and public domain data.MethodsWe demonstrate the use of machine learning techniques by developing three predictive models for cancer diagnosis using descriptions of nuclei sampled from breast masses. These algorithms include regularized General Linear Model regression (GLMs), Support Vector Machines (SVMs) with a radial basis function kernel, and single-layer Artificial Neural Networks. The publicly-available dataset describing the breast mass samples (N=683) was randomly split into evaluation (n=456) and validation (n=227) samples.We trained algorithms on data from the evaluation sample before they were used to predict the diagnostic outcome in the validation dataset. We compared the predictions made on the validation datasets with the real-world diagnostic decisions to calculate the accuracy, sensitivity, and specificity of the three models. We explored the use of averaging and voting ensembles to improve predictive performance. We provide a step-by-step guide to developing algorithms using the open-source R statistical programming environment.ResultsThe trained algorithms were able to classify cell nuclei with high accuracy (.94 -.96), sensitivity (.97 -.99), and specificity (.85 -.94). Maximum accuracy (.96) and area under the curve (.97) was achieved using the SVM algorithm. Prediction performance increased marginally (accuracy =.97, sensitivity =.99, specificity =.95) when algorithms were arranged into a voting ensemble.ConclusionsWe use a straightforward example to demonstrate the theory and practice of machine learning for clinicians and medical researchers. The principals which we demonstrate here can be readily applied to other complex tasks including natural language processing and image recognition."
  },
  {
    "paperId": "236dfdeb4511754cf71ba220ac569b11973502cd",
    "title": "Machine Learning and Deep Learning Methods for Intrusion Detection Systems: A Survey",
    "venue": "Applied Sciences",
    "year": 2019,
    "citationCount": 813,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2076-3417/9/20/4396/pdf?version=1571308126",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/app9204396?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app9204396, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2145593249",
        "name": "Hongyu Liu"
      },
      {
        "authorId": "2055226664",
        "name": "Bo Lang"
      }
    ],
    "abstract": "Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is fit for cyber security researchers. The survey first clarifies the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies."
  },
  {
    "paperId": "9909975dec989fcd55d99533c712c28bab99040e",
    "title": "Machine learning for active matter",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 236,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-020-0146-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-020-0146-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "4762628",
        "name": "F. Cichos"
      },
      {
        "authorId": "32008891",
        "name": "K. Gustavsson"
      },
      {
        "authorId": "4527913",
        "name": "B. Mehlig"
      },
      {
        "authorId": "50571400",
        "name": "G. Volpe"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e718828e8f776d9f80daa3f8e0af6895f5d34c44",
    "title": "Adversarial attacks on medical machine learning",
    "venue": "Science",
    "year": 2019,
    "citationCount": 841,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aaw4399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aaw4399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50478054",
        "name": "S. G. Finlayson"
      },
      {
        "authorId": "2066570629",
        "name": "John Bowers"
      },
      {
        "authorId": "35553861",
        "name": "Joichi Ito"
      },
      {
        "authorId": "46714697",
        "name": "Jonathan Zittrain"
      },
      {
        "authorId": "143649421",
        "name": "Andrew Beam"
      },
      {
        "authorId": "1740538",
        "name": "I. Kohane"
      }
    ],
    "abstract": "Emerging vulnerabilities demand new conversations With public and academic attention increasingly focused on the new role of machine learning in the health information economy, an unusual and no-longer-esoteric category of vulnerabilities in machine-learning systems could prove important. These vulnerabilities allow a small, carefully designed change in how inputs are presented to a system to completely alter its output, causing it to confidently arrive at manifestly wrong conclusions. These advanced techniques to subvert otherwise-reliable machine-learning systems—so-called adversarial attacks—have, to date, been of interest primarily to computer science researchers (1). However, the landscape of often-competing interests within health care, and billions of dollars at stake in systems' outputs, implies considerable problems. We outline motivations that various players in the health care system may have to use adversarial attacks and begin a discussion of what to do about them. Far from discouraging continued innovation with medical machine learning, we call for active engagement of medical, technical, legal, and ethical experts in pursuit of efficient, broadly available, and effective health care that machine learning will enable."
  },
  {
    "paperId": "efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695",
    "title": "Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2018,
    "citationCount": 827,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418594.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1804.00308, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40844378",
        "name": "Matthew Jagielski"
      },
      {
        "authorId": "3046437",
        "name": "Alina Oprea"
      },
      {
        "authorId": "1684175",
        "name": "B. Biggio"
      },
      {
        "authorId": "2118484076",
        "name": "Chang Liu"
      },
      {
        "authorId": "1398550766",
        "name": "C. Nita-Rotaru"
      },
      {
        "authorId": "2165247199",
        "name": "Bo Li"
      }
    ],
    "abstract": "As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains."
  },
  {
    "paperId": "eef183687fab4d762a381f2e80e357e08e923f0a",
    "title": "Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning",
    "venue": "arXiv.org",
    "year": 2018,
    "citationCount": 929,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.12808, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2562040",
        "name": "S. Raschka"
      }
    ],
    "abstract": "The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small."
  },
  {
    "paperId": "4eca52f892f288c0b33b74aa4cfed56ed968fb4e",
    "title": "Explainable Machine Learning for Scientific Insights and Discoveries",
    "venue": "IEEE Access",
    "year": 2019,
    "citationCount": 753,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09007737.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.08883, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46525320",
        "name": "R. Roscher"
      },
      {
        "authorId": "34832887",
        "name": "B. Bohn"
      },
      {
        "authorId": "1888626",
        "name": "Marco F. Duarte"
      },
      {
        "authorId": "2279864",
        "name": "J. Garcke"
      }
    ],
    "abstract": "Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas."
  },
  {
    "paperId": "3119ea9c7ad7a5e044dc7c267329a4bbf00d0158",
    "title": "A Survey of Optimization Methods From a Machine Learning Perspective",
    "venue": "IEEE Transactions on Cybernetics",
    "year": 2019,
    "citationCount": 616,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1906.06821",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.06821, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "20632291",
        "name": "Shiliang Sun"
      },
      {
        "authorId": "12076996",
        "name": "Zehui Cao"
      },
      {
        "authorId": "2122172099",
        "name": "Han Zhu"
      },
      {
        "authorId": "46509200",
        "name": "Jing Zhao"
      }
    ],
    "abstract": "Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this article, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Finally, we explore and give some challenges and open problems for the optimization in machine learning."
  },
  {
    "paperId": "f9a855ae59579d16dca6a5133cd8daddd3305582",
    "title": "A Survey on Distributed Machine Learning",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 797,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3377454",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.09789, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1470488636",
        "name": "Joost Verbraeken"
      },
      {
        "authorId": "1470488392",
        "name": "Matthijs Wolting"
      },
      {
        "authorId": "2251635781",
        "name": "J. Katzy"
      },
      {
        "authorId": "1470485471",
        "name": "Jeroen Kloppenburg"
      },
      {
        "authorId": "2413244",
        "name": "Tim Verbelen"
      },
      {
        "authorId": "2342602",
        "name": "Jan S. Rellermeyer"
      }
    ],
    "abstract": "The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available."
  },
  {
    "paperId": "8db8166249dfb94dd8d52f88d27917b5755ae049",
    "title": "A Quick Review of Machine Learning Algorithms",
    "venue": "International Conference Machine Learning, Big Data, Cloud and Parallel Computing",
    "year": 2019,
    "citationCount": 662,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/COMITCon.2019.8862451?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/COMITCon.2019.8862451, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "28530119",
        "name": "Susmita Ray"
      }
    ],
    "abstract": "Machine learning is predominantly an area of Artificial Intelligence which has been a key component of digitalization solutions that has caught major attention in the digital arena. In this paper author intends to do a brief review of various machine learning algorithms which are most frequently used and therefore are the most popular ones. The author intends to highlight the merits and demerits of the machine learning algorithms from their application perspective to aid in an informed decision making towards selecting the appropriate learning algorithm to meet the specific requirement of the application."
  },
  {
    "paperId": "d75356e2bf674902a06a14bb55d18ee88af5b4bb",
    "title": "Machine Learning Methods That Economists Should Know About",
    "venue": "Annual Review of Economics",
    "year": 2019,
    "citationCount": 748,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.10075, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2631417",
        "name": "S. Athey"
      },
      {
        "authorId": "47166531",
        "name": "G. Imbens"
      }
    ],
    "abstract": "We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models."
  },
  {
    "paperId": "7d291d5fca0e9cd9e0ed72fb6f82289a197f7f02",
    "title": "Machine Learning and Deep Learning",
    "venue": "Cybersecurity in Digital Transformation",
    "year": 2019,
    "citationCount": 734,
    "openAccessPdf": {
      "url": "https://doi.org/10.35940/ijitee.l3550.1081219",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.35940/ijitee.l3550.1081219?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35940/ijitee.l3550.1081219, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2285802602",
        "name": "Dietmar P. F. Möller"
      }
    ],
    "abstract": "Now-a-days artificial intelligence has become an asset for engineering and experimental studies, just like statistics and calculus. Data science is a growing field for researchers and artificial intelligence, machine learning and deep learning are roots of it. This paper describes the relation between these roots of data science. There is a need of machine learning if any kind of analysis is to be performed. This study describes machine learning from the scratch. It also focuses on Deep Learning. Deep learning can also be known as new trend of machine learning. This paper gives a light on basic architecture of Deep learning. A comparative study of machine learning and deep learning is also given in the paper and allows researcher to have a broad view on these techniques so that they can understand which one will be preferable solution for a particular problem."
  },
  {
    "paperId": "2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",
    "title": "Informed Machine Learning – A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2019,
    "citationCount": 748,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/69/4358933/09429985.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.12394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7440202",
        "name": "Laura von Rueden"
      },
      {
        "authorId": "145001529",
        "name": "S. Mayer"
      },
      {
        "authorId": "1583348396",
        "name": "Katharina Beckh"
      },
      {
        "authorId": "88714212",
        "name": "B. Georgiev"
      },
      {
        "authorId": "51065069",
        "name": "Sven Giesselbach"
      },
      {
        "authorId": "72453217",
        "name": "R. Heese"
      },
      {
        "authorId": "36891596",
        "name": "Birgit Kirsch"
      },
      {
        "authorId": "2046830943",
        "name": "Julius Pfrommer"
      },
      {
        "authorId": "1380036932",
        "name": "Annika Pick"
      },
      {
        "authorId": "21780262",
        "name": "Rajkumar Ramamurthy"
      },
      {
        "authorId": "51879558",
        "name": "Michal Walczak"
      },
      {
        "authorId": "2279864",
        "name": "J. Garcke"
      },
      {
        "authorId": "1692283",
        "name": "C. Bauckhage"
      },
      {
        "authorId": "4488139",
        "name": "Jannis Schuecker"
      }
    ],
    "abstract": "Despite its great success, machine learning can have its limits when dealing with insufficient training data. A potential solution is the additional integration of prior knowledge into the training process which leads to the notion of informed machine learning. In this paper, we present a structured overview of various approaches in this field. We provide a definition and propose a concept for informed machine learning which illustrates its building blocks and distinguishes it from conventional machine learning. We introduce a taxonomy that serves as a classification framework for informed machine learning approaches. It considers the source of knowledge, its representation, and its integration into the machine learning pipeline. Based on this taxonomy, we survey related research and describe how different knowledge representations such as algebraic equations, logic rules, or simulation results can be used in learning systems. This evaluation of numerous papers on the basis of our taxonomy uncovers key methods in the field of informed machine learning."
  },
  {
    "paperId": "4490ffac416692ab827c5a30e5f3a4b4fd6be949",
    "title": "Explainable machine learning in deployment",
    "venue": "FAT*",
    "year": 2019,
    "citationCount": 632,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3375624",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.06342, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32326200",
        "name": "Umang Bhatt"
      },
      {
        "authorId": "4990825",
        "name": "Alice Xiang"
      },
      {
        "authorId": "2034354321",
        "name": "Shubham Sharma"
      },
      {
        "authorId": "145689461",
        "name": "Adrian Weller"
      },
      {
        "authorId": "40511120",
        "name": "Ankur Taly"
      },
      {
        "authorId": "12488214",
        "name": "Yunhan Jia"
      },
      {
        "authorId": "34724702",
        "name": "Joydeep Ghosh"
      },
      {
        "authorId": "1718933",
        "name": "R. Puri"
      },
      {
        "authorId": "51283515",
        "name": "J. Moura"
      },
      {
        "authorId": "2654106",
        "name": "P. Eckersley"
      }
    ],
    "abstract": "Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability."
  },
  {
    "paperId": "b5461f9c5d65e87561e00848921ee797902dae14",
    "title": "Causality for Machine Learning",
    "venue": "Probabilistic and Causal Inference",
    "year": 2019,
    "citationCount": 506,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1911.10500",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.10500, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      }
    ],
    "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. \nThis article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them."
  },
  {
    "paperId": "a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f",
    "title": "A Survey of Machine Learning Techniques Applied to Software Defined Networking (SDN): Research Issues and Challenges",
    "venue": "IEEE Communications Surveys and Tutorials",
    "year": 2019,
    "citationCount": 503,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/COMST.2018.2866942?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/COMST.2018.2866942, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153741316",
        "name": "Jun-feng Xie"
      },
      {
        "authorId": "29953431",
        "name": "F. Yu"
      },
      {
        "authorId": "102628601",
        "name": "Tao Huang"
      },
      {
        "authorId": "144814372",
        "name": "Renchao Xie"
      },
      {
        "authorId": "2119611603",
        "name": "Jiang Liu"
      },
      {
        "authorId": "3334549",
        "name": "Chen-meng Wang"
      },
      {
        "authorId": "2117417872",
        "name": "Yun-jie Liu"
      }
    ],
    "abstract": "In recent years, with the rapid development of current Internet and mobile communication technologies, the infrastructure, devices and resources in networking systems are becoming more complex and heterogeneous. In order to efficiently organize, manage, maintain and optimize networking systems, more intelligence needs to be deployed. However, due to the inherently distributed feature of traditional networks, machine learning techniques are hard to be applied and deployed to control and operate networks. Software defined networking (SDN) brings us new chances to provide intelligence inside the networks. The capabilities of SDN (e.g., logically centralized control, global view of the network, software-based traffic analysis, and dynamic updating of forwarding rules) make it easier to apply machine learning techniques. In this paper, we provide a comprehensive survey on the literature involving machine learning algorithms applied to SDN. First, the related works and background knowledge are introduced. Then, we present an overview of machine learning algorithms. In addition, we review how machine learning algorithms are applied in the realm of SDN, from the perspective of traffic classification, routing optimization, quality of service/quality of experience prediction, resource management and security. Finally, challenges and broader perspectives are discussed."
  },
  {
    "paperId": "b4b1cbd74029f46ef9b462290a46111217552761",
    "title": "Understanding the Effect of Accuracy on Trust in Machine Learning Models",
    "venue": "International Conference on Human Factors in Computing Systems",
    "year": 2019,
    "citationCount": 511,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300509?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300509, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2053888438",
        "name": "Ming Yin"
      },
      {
        "authorId": "4006636",
        "name": "Jennifer Wortman Vaughan"
      },
      {
        "authorId": "1831395",
        "name": "Hanna M. Wallach"
      }
    ],
    "abstract": "We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline."
  },
  {
    "paperId": "91ed985917cf4c317b7d91e15c1ec55e746153bf",
    "title": "What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use",
    "venue": "Machine Learning in Health Care",
    "year": 2019,
    "citationCount": 478,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.05134, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "23152217",
        "name": "S. Tonekaboni"
      },
      {
        "authorId": "34287745",
        "name": "Shalmali Joshi"
      },
      {
        "authorId": "2383816329",
        "name": "M. McCradden"
      },
      {
        "authorId": "49800482",
        "name": "A. Goldenberg"
      }
    ],
    "abstract": "Translating machine learning (ML) models effectively to clinical practice requires establishing clinicians' trust. Explainability, or the ability of an ML model to justify its outcomes and assist clinicians in rationalizing the model prediction, has been generally understood to be critical to establishing trust. However, the field suffers from the lack of concrete definitions for usable explanations in different settings. To identify specific aspects of explainability that may catalyze building trust in ML models, we surveyed clinicians from two distinct acute care specialties (Intenstive Care Unit and Emergency Department). We use their feedback to characterize when explainability helps to improve clinicians' trust in ML models. We further identify the classes of explanations that clinicians identified as most relevant and crucial for effective translation to clinical practice. Finally, we discern concrete metrics for rigorous evaluation of clinical explainability methods. By integrating perceptions of explainability between clinicians and ML researchers we hope to facilitate the endorsement and broader adoption and sustained use of ML systems in healthcare."
  },
  {
    "paperId": "60446c372811c25acc1e47b044e8e7458f0a4986",
    "title": "A Performance and Cost Assessment of Machine Learning Interatomic Potentials.",
    "venue": "Journal of Physical Chemistry A",
    "year": 2019,
    "citationCount": 716,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1906.08888",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.08888, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "11844524",
        "name": "Yunxing Zuo"
      },
      {
        "authorId": "143915066",
        "name": "Chi Chen"
      },
      {
        "authorId": "2108568792",
        "name": "Xiang-Guo Li"
      },
      {
        "authorId": "98796862",
        "name": "Z. Deng"
      },
      {
        "authorId": "2109366932",
        "name": "Yiming Chen"
      },
      {
        "authorId": "144136091",
        "name": "J. Behler"
      },
      {
        "authorId": "2559761",
        "name": "Gábor Csányi"
      },
      {
        "authorId": "2810901",
        "name": "A. Shapeev"
      },
      {
        "authorId": "144056220",
        "name": "A. Thompson"
      },
      {
        "authorId": "47817335",
        "name": "M. Wood"
      },
      {
        "authorId": "2381325",
        "name": "S. Ong"
      }
    ],
    "abstract": "Machine learning of the quantitative relationship between local environment descriptors and the potential energy surface of a system of atoms has emerged as a new frontier in the development of interatomic potentials (IAPs). Here, we present a comprehensive evaluation of ML-IAPs based on four local environment descriptors --- atom-centered symmetry functions (ACSF), smooth overlap of atomic positions (SOAP), the Spectral Neighbor Analysis Potential (SNAP) bispectrum components, and moment tensors --- using a diverse data set generated using high-throughput density functional theory (DFT) calculations. The data set comprising bcc (Li, Mo) and fcc (Cu, Ni) metals and diamond group IV semiconductors (Si, Ge) is chosen to span a range of crystal structures and bonding. All descriptors studied show excellent performance in predicting energies and forces far surpassing that of classical IAPs, as well as predicting properties such as elastic constants and phonon dispersion curves. We observe a general trade-off between accuracy and the degrees of freedom of each model, and consequently computational cost. We will discuss these trade-offs in the context of model selection for molecular dynamics and other applications."
  },
  {
    "paperId": "b0f8a829450e782fe879d9d48a188d611b6dd74d",
    "title": "Do no harm: a roadmap for responsible machine learning for health care",
    "venue": "Nature Network Boston",
    "year": 2019,
    "citationCount": 699,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41591-019-0548-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41591-019-0548-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "38556322",
        "name": "J. Wiens"
      },
      {
        "authorId": "1932128",
        "name": "S. Saria"
      },
      {
        "authorId": "47057856",
        "name": "M. Sendak"
      },
      {
        "authorId": "2804918",
        "name": "M. Ghassemi"
      },
      {
        "authorId": "39717165",
        "name": "V. Liu"
      },
      {
        "authorId": "1388372395",
        "name": "F. Doshi-Velez"
      },
      {
        "authorId": "145064562",
        "name": "Kenneth Jung"
      },
      {
        "authorId": "145993598",
        "name": "K. Heller"
      },
      {
        "authorId": "2107807",
        "name": "David C. Kale"
      },
      {
        "authorId": "2073359011",
        "name": "Mohammed Saeed"
      },
      {
        "authorId": "4136467",
        "name": "P. Ossorio"
      },
      {
        "authorId": "1404837859",
        "name": "Sonoo Thadaney-Israni"
      },
      {
        "authorId": "49800482",
        "name": "A. Goldenberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b674a7aee72e9b9cc5390eca13f9c5c7812f2ba0",
    "title": "Machine learning for molecular simulation",
    "venue": "Annual review of physical chemistry (Print)",
    "year": 2019,
    "citationCount": 727,
    "openAccessPdf": {
      "url": "https://orbilu.uni.lu/bitstream/10993/45768/1/159-ML-molecular-simulations-ARPhysChem-2020.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.02792, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1967674",
        "name": "F. Noé"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "2839696",
        "name": "C. Clementi"
      }
    ],
    "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML methods. Here we review recent ML methods for molecular simulation, with particular focus on (deep) neural networks for the prediction of quantum-mechanical energies and forces, on coarse-grained molecular dynamics, on the extraction of free energy surfaces and kinetics, and on generative network approaches to sample molecular equilibrium structures and compute thermodynamics. To explain these methods and illustrate open methodological problems, we review some important principles of molecular physics and describe how they can be incorporated into ML structures. Finally, we identify and describe a list of open challenges for the interface between ML and molecular simulation. Expected final online publication date for the Annual Review of Physical Chemistry, Volume 71 is April 20, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates."
  },
  {
    "paperId": "7ac8f533a18f584387dd412a0a27feb9af1c5c93",
    "title": "A Systematic Review on Imbalanced Data Challenges in Machine Learning",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 613,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3343440?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3343440, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2061225608",
        "name": "H. kaur"
      },
      {
        "authorId": "2506803",
        "name": "H. Pannu"
      },
      {
        "authorId": "2718975",
        "name": "A. Malhi"
      }
    ],
    "abstract": "In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas."
  },
  {
    "paperId": "d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c",
    "title": "A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection",
    "venue": "IEEE Communications Surveys and Tutorials",
    "year": 2019,
    "citationCount": 570,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/COMST.2018.2847722?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/COMST.2018.2847722, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "4268597",
        "name": "Preeti Mishra"
      },
      {
        "authorId": "1693037",
        "name": "V. Varadharajan"
      },
      {
        "authorId": "1707996",
        "name": "U. Tupakula"
      },
      {
        "authorId": "2371703",
        "name": "Emmanuel S. PIlli"
      }
    ],
    "abstract": "Intrusion detection is one of the important security problems in todays cyber world. A significant number of techniques have been developed which are based on machine learning approaches. However, they are not very successful in identifying all types of intrusions. In this paper, a detailed investigation and analysis of various machine learning techniques have been carried out for finding the cause of problems associated with various machine learning techniques in detecting intrusive activities. Attack classification and mapping of the attack features is provided corresponding to each attack. Issues which are related to detecting low-frequency attacks using network attack dataset are also discussed and viable methods are suggested for improvement. Machine learning techniques have been analyzed and compared in terms of their detection capability for detecting the various category of attacks. Limitations associated with each category of them are also discussed. Various data mining tools for machine learning have also been included in the paper. At the end, future directions are provided for attack detection using machine learning techniques."
  },
  {
    "paperId": "4ce2f55585f3156e332721b8ab4f449389dc2a3c",
    "title": "Hidden stratification causes clinically meaningful failures in machine learning for medical imaging",
    "venue": "ACM Conference on Health, Inference, and Learning",
    "year": 2019,
    "citationCount": 419,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7665161",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.12475, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2280312774",
        "name": "Luke Oakden-Rayner"
      },
      {
        "authorId": "12322385",
        "name": "Jared A. Dunnmon"
      },
      {
        "authorId": "145575177",
        "name": "G. Carneiro"
      },
      {
        "authorId": "1803218",
        "name": "Christopher Ré"
      }
    ],
    "abstract": "Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging."
  },
  {
    "paperId": "3e9a40a567c4a95b591530ff5771296b478a0f0c",
    "title": "Machine Learning at the Network Edge: A Survey",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 446,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1908.00080",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1908.00080, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144854067",
        "name": "M. G. Sarwar Murshed"
      },
      {
        "authorId": "2064797442",
        "name": "Chris Murphy"
      },
      {
        "authorId": "145588259",
        "name": "Daqing Hou"
      },
      {
        "authorId": "2093292636",
        "name": "Nazar Khan"
      },
      {
        "authorId": "2849491",
        "name": "Ganesh Ananthanarayanan"
      },
      {
        "authorId": "1725422928",
        "name": "Faraz Hussain"
      }
    ],
    "abstract": "Resource-constrained IoT devices, such as sensors and actuators, have become ubiquitous in recent years. This has led to the generation of large quantities of data in real-time, which is an appealing target for AI systems. However, deploying machine learning models on such end-devices is nearly impossible. A typical solution involves offloading data to external computing systems (such as cloud servers) for further processing but this worsens latency, leads to increased communication costs, and adds to privacy concerns. To address this issue, efforts have been made to place additional computing devices at the edge of the network, i.e., close to the IoT devices where the data is generated. Deploying machine learning systems on such edge computing devices alleviates the above issues by allowing computations to be performed close to the data sources. This survey describes major research efforts where machine learning systems have been deployed at the edge of computer networks, focusing on the operational aspects including compression techniques, tools, frameworks, and hardware used in successful applications of intelligent edge systems."
  },
  {
    "paperId": "792d90c2ed5ebbe050bd80b9c865dc416b574c09",
    "title": "Machine Learning–Based Model for Prediction of Outcomes in Acute Stroke",
    "venue": "Stroke",
    "year": 2019,
    "citationCount": 437,
    "openAccessPdf": {
      "url": "https://www.ahajournals.org/doi/pdf/10.1161/STROKEAHA.118.024293",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1161/STROKEAHA.118.024293?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/STROKEAHA.118.024293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5980849",
        "name": "Joonnyung Heo"
      },
      {
        "authorId": "32745548",
        "name": "Jihoon G. Yoon"
      },
      {
        "authorId": "4994655",
        "name": "Hyungjong Park"
      },
      {
        "authorId": "34471989",
        "name": "Y. Kim"
      },
      {
        "authorId": "2185414",
        "name": "H. Nam"
      },
      {
        "authorId": "34508977",
        "name": "J. Heo"
      }
    ],
    "abstract": "Background and Purpose— The prediction of long-term outcomes in ischemic stroke patients may be useful in treatment decisions. Machine learning techniques are being increasingly adapted for use in the medical field because of their high accuracy. This study investigated the applicability of machine learning techniques to predict long-term outcomes in ischemic stroke patients. Methods— This was a retrospective study using a prospective cohort that enrolled patients with acute ischemic stroke. Favorable outcome was defined as modified Rankin Scale score 0, 1, or 2 at 3 months. We developed 3 machine learning models (deep neural network, random forest, and logistic regression) and compared their predictability. To evaluate the accuracy of the machine learning models, we also compared them to the Acute Stroke Registry and Analysis of Lausanne (ASTRAL) score. Results— A total of 2604 patients were included in this study, and 2043 (78%) of them had favorable outcomes. The area under the curve for the deep neural network model was significantly higher than that of the ASTRAL score (0.888 versus 0.839; P<0.001), while the areas under the curves of the random forest (0.857; P=0.136) and logistic regression (0.849; P=0.413) models were not significantly higher than that of the ASTRAL score. Using only the 6 variables that are used for the ASTRAL score, the performance of the machine learning models did not significantly differ from that of the ASTRAL score. Conclusions— Machine learning algorithms, particularly the deep neural network, can improve the prediction of long-term outcomes in ischemic stroke patients."
  },
  {
    "paperId": "97f4a6f87f258053f2677504647696f1803c6794",
    "title": "How to Read Articles That Use Machine Learning: Users' Guides to the Medical Literature.",
    "venue": "Journal of the American Medical Association (JAMA)",
    "year": 2019,
    "citationCount": 428,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1001/jama.2019.16489?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jama.2019.16489, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2118113191",
        "name": "Yun Liu"
      },
      {
        "authorId": "1406206167",
        "name": "Po-Hsuan Cameron Chen"
      },
      {
        "authorId": "2058373914",
        "name": "Jonathan Krause"
      },
      {
        "authorId": "49506408",
        "name": "L. Peng"
      }
    ],
    "abstract": "In recent years, many new clinical diagnostic tools have been developed using complicated machine learning methods. Irrespective of how a diagnostic tool is derived, it must be evaluated using a 3-step process of deriving, validating, and establishing the clinical effectiveness of the tool. Machine learning-based tools should also be assessed for the type of machine learning model used and its appropriateness for the input data type and data set size. Machine learning models also generally have additional prespecified settings called hyperparameters, which must be tuned on a data set independent of the validation set. On the validation set, the outcome against which the model is evaluated is termed the reference standard. The rigor of the reference standard must be assessed, such as against a universally accepted gold standard or expert grading."
  },
  {
    "paperId": "89f88f324bb3775f63f87cec90a4283a3522ab44",
    "title": "Machine learning-assisted directed protein evolution with combinatorial libraries",
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "year": 2019,
    "citationCount": 461,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc6500146?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1902.07231, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51125091",
        "name": "Zachary Wu"
      },
      {
        "authorId": "2055706731",
        "name": "S. Kan"
      },
      {
        "authorId": "144475958",
        "name": "Russell D. Lewis"
      },
      {
        "authorId": "8641455",
        "name": "Bruce J. Wittmann"
      },
      {
        "authorId": "2795724",
        "name": "F. Arnold"
      }
    ],
    "abstract": "Significance Proteins often function poorly when used outside their natural contexts; directed evolution can be used to engineer them to be more efficient in new roles. We propose that the expense of experimentally testing a large number of protein variants can be decreased and the outcome can be improved by incorporating machine learning with directed evolution. Simulations on an empirical fitness landscape demonstrate that the expected performance improvement is greater with this approach. Machine learning-assisted directed evolution from a single parent produced enzyme variants that selectively synthesize the enantiomeric products of a new-to-nature chemical transformation. By exploring multiple mutations simultaneously, machine learning efficiently navigates large regions of sequence space to identify improved proteins and also produces diverse solutions to engineering problems. To reduce experimental effort associated with directed protein evolution and to explore the sequence space encoded by mutating multiple positions simultaneously, we incorporate machine learning into the directed evolution workflow. Combinatorial sequence space can be quite expensive to sample experimentally, but machine-learning models trained on tested variants provide a fast method for testing sequence space computationally. We validated this approach on a large published empirical fitness landscape for human GB1 binding protein, demonstrating that machine learning-guided directed evolution finds variants with higher fitness than those found by other directed evolution approaches. We then provide an example application in evolving an enzyme to produce each of the two possible product enantiomers (i.e., stereodivergence) of a new-to-nature carbene Si–H insertion reaction. The approach predicted libraries enriched in functional enzymes and fixed seven mutations in two rounds of evolution to identify variants for selective catalysis with 93% and 79% ee (enantiomeric excess). By greatly increasing throughput with in silico modeling, machine learning enhances the quality and diversity of sequence solutions for a protein engineering problem."
  },
  {
    "paperId": "3b16bcb226bb1c87a6e63e0658be30067ed03f57",
    "title": "A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science",
    "venue": "Unsupervised and Semi-Supervised Learning",
    "year": 2019,
    "citationCount": 434,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-22475-2_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-22475-2_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9147815",
        "name": "M. Alloghani"
      },
      {
        "authorId": "1398585056",
        "name": "D. Al-Jumeily"
      },
      {
        "authorId": "123894038",
        "name": "J. Mustafina"
      },
      {
        "authorId": "145463079",
        "name": "A. Hussain"
      },
      {
        "authorId": "2013933",
        "name": "A. Aljaaf"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "330b5844d170b6b77f5f9fa4c2024150cef2af18",
    "title": "Benchmark and Survey of Automated Machine Learning Frameworks",
    "venue": "Journal of Artificial Intelligence Research",
    "year": 2019,
    "citationCount": 394,
    "openAccessPdf": {
      "url": "https://www.jair.org/index.php/jair/article/download/11854/26651",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1613/jair.1.11854?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1613/jair.1.11854, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "114984566",
        "name": "M. Zöller"
      },
      {
        "authorId": "1959068",
        "name": "Marco F. Huber"
      }
    ],
    "abstract": "Machine learning (ML) has become a vital part in many aspects of our daily life. However, building well performing machine learning applications requires highly specialized data scientists and domain experts. Automated machine learning (AutoML) aims to reduce the demand for data scientists by enabling domain experts to automatically build machine learning applications without extensive knowledge of statistics and machine learning. This paper is a combination of a survey on current AutoML methods and a benchmark of popular AutoML frameworks on real data sets. Driven by the selected frameworks for evaluation, we summarize and review important AutoML techniques and methods concerning every step in building an ML pipeline. The selected AutoML frameworks are evaluated on 137 different data sets."
  },
  {
    "paperId": "a8fadb33a38f1096f84f64bd66345717a5bc3241",
    "title": "Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language",
    "venue": "Journal of educational and behavioral statistics",
    "year": 2019,
    "citationCount": 398,
    "openAccessPdf": {
      "url": "http://repository.unimilitar.edu.co/bitstream/10654/44324/6/RinconValbuenaFernandoAdolfo2022.pdf",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3102/1076998619832248?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3102/1076998619832248, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3433417",
        "name": "J. Hao"
      },
      {
        "authorId": "1795578",
        "name": "T. Ho"
      }
    ],
    "abstract": "Machine learning is a popular topic in data analysis and modeling. Many different machine learning algorithms have been developed and implemented in a variety of programming languages over the past 20 years. In this article, we first provide an overview of machine learning and clarify its difference from statistical inference. Then, we review Scikit-learn, a machine learning package in the Python programming language that is widely used in data science. The Scikit-learn package includes implementations of a comprehensive list of machine learning methods under unified data and modeling procedure conventions, making it a convenient toolkit for educational and behavior statisticians."
  },
  {
    "paperId": "5ec6039389d448f24183084b503cf1ac899f45fc",
    "title": "What Is Machine Learning: a Primer for the Epidemiologist.",
    "venue": "American Journal of Epidemiology",
    "year": 2019,
    "citationCount": 406,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1093/aje/kwz189?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/aje/kwz189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2247418",
        "name": "Qifang Bi"
      },
      {
        "authorId": "2442518",
        "name": "K. Goodman"
      },
      {
        "authorId": "66547188",
        "name": "J. Kaminsky"
      },
      {
        "authorId": "3020850",
        "name": "J. Lessler"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4f2b9cb774489c1a600c224c75edb8da07a24064",
    "title": "Machine-learning reprogrammable metasurface imager",
    "venue": "Nature Communications",
    "year": 2019,
    "citationCount": 489,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41467-019-09103-2.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6403242, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "6013040",
        "name": "Lianlin Li"
      },
      {
        "authorId": "38749395",
        "name": "Hengxin Ruan"
      },
      {
        "authorId": null,
        "name": "Che Liu"
      },
      {
        "authorId": "93648258",
        "name": "Ying Li"
      },
      {
        "authorId": "17686104",
        "name": "Ya Shuang"
      },
      {
        "authorId": "2186738926",
        "name": "A. Alú"
      },
      {
        "authorId": "144274551",
        "name": "C. Qiu"
      },
      {
        "authorId": "1911485",
        "name": "T. Cui"
      }
    ],
    "abstract": "Conventional microwave imagers usually require either time-consuming data acquisition, or complicated reconstruction algorithms for data post-processing, making them largely ineffective for complex in-situ sensing and monitoring. Here, we experimentally report a real-time digital-metasurface imager that can be trained in-situ to generate the radiation patterns required by machine-learning optimized measurement modes. This imager is electronically reprogrammed in real time to access the optimized solution for an entire data set, realizing storage and transfer of full-resolution raw data in dynamically varying scenes. High-accuracy image coding and recognition are demonstrated in situ for various image sets, including hand-written digits and through-wall body gestures, using a single physical hardware imager, reprogrammed in real time. Our electronically controlled metasurface imager opens new venues for intelligent surveillance, fast data acquisition and processing, imaging at various frequencies, and beyond. Conventional imagers require time-consuming data acquisition, or complicated reconstruction algorithms for data post-processing. Here, the authors demonstrate a real-time digital-metasurface imager that can be trained in-situ to show high accuracy image coding and recognition for various image sets."
  },
  {
    "paperId": "37f239603ce77e8f10be255be0a2cff7070122ad",
    "title": "Enhancing gravitational-wave science with machine learning",
    "venue": "Machine Learning: Science and Technology",
    "year": 2020,
    "citationCount": 166,
    "openAccessPdf": {
      "url": "https://doi.org/10.1088/2632-2153/abb93a",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.03745, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "114728464",
        "name": "E. Cuoco"
      },
      {
        "authorId": "152265306",
        "name": "J. Powell"
      },
      {
        "authorId": "3180530",
        "name": "M. Cavaglià"
      },
      {
        "authorId": "134237646",
        "name": "K. Ackley"
      },
      {
        "authorId": "41186371",
        "name": "M. Bejger"
      },
      {
        "authorId": "103378230",
        "name": "C. Chatterjee"
      },
      {
        "authorId": "1380955296",
        "name": "M. Coughlin"
      },
      {
        "authorId": "39507823",
        "name": "S. Coughlin"
      },
      {
        "authorId": "1380288971",
        "name": "P. Easter"
      },
      {
        "authorId": "114667899",
        "name": "R. Essick"
      },
      {
        "authorId": "82620197",
        "name": "H. Gabbard"
      },
      {
        "authorId": "143733079",
        "name": "Timothy D. Gebhard"
      },
      {
        "authorId": "49870703",
        "name": "Shaon Ghosh"
      },
      {
        "authorId": "1381205122",
        "name": "L. Haegel"
      },
      {
        "authorId": "51918071",
        "name": "A. Iess"
      },
      {
        "authorId": "94813340",
        "name": "D. Keitel"
      },
      {
        "authorId": "40412024",
        "name": "Z. Márka"
      },
      {
        "authorId": "50184636",
        "name": "S. Márka"
      },
      {
        "authorId": "2360561138",
        "name": "Filip Morawski"
      },
      {
        "authorId": "2116108017",
        "name": "Tri Nguyen"
      },
      {
        "authorId": "121389315",
        "name": "R. Ormiston"
      },
      {
        "authorId": "6095473",
        "name": "M. Pürrer"
      },
      {
        "authorId": "69036661",
        "name": "M. Razzano"
      },
      {
        "authorId": "47023388",
        "name": "K. Staats"
      },
      {
        "authorId": "3051130",
        "name": "G. Vajente"
      },
      {
        "authorId": "2152726806",
        "name": "Daniel Williams"
      }
    ],
    "abstract": "Machine learning has emerged as a popular and powerful approach for solving problems in astrophysics. We review applications of machine learning techniques for the analysis of ground-based gravitational-wave (GW) detector data. Examples include techniques for improving the sensitivity of Advanced Laser Interferometer GW Observatory and Advanced Virgo GW searches, methods for fast measurements of the astrophysical parameters of GW sources, and algorithms for reduction and characterization of non-astrophysical detector noise. These applications demonstrate how machine learning techniques may be harnessed to enhance the science that is possible with current and future GW detectors."
  },
  {
    "paperId": "5d500ff62baeac5a27ea7512a833e2a25dcb2354",
    "title": "Machine Learning for Survival Analysis",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 382,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3214306?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3214306, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "66313970",
        "name": "Ping Wang"
      },
      {
        "authorId": "2152885669",
        "name": "Yan Li"
      },
      {
        "authorId": "144417522",
        "name": "Chandan K. Reddy"
      }
    ],
    "abstract": "Survival analysis is a subfield of statistics where the goal is to analyze and model data where the outcome is the time until an event of interest occurs. One of the main challenges in this context is the presence of instances whose event outcomes become unobservable after a certain time point or when some instances do not experience any event during the monitoring period. This so-called censoring can be handled most effectively using survival analysis techniques. Traditionally, statistical approaches have been widely developed in the literature to overcome the issue of censoring. In addition, many machine learning algorithms have been adapted to deal with such censored data and tackle other challenging problems that arise in real-world data. In this survey, we provide a comprehensive and structured review of the statistical methods typically used and the machine learning techniques developed for survival analysis, along with a detailed taxonomy of the existing methods. We also discuss several topics that are closely related to survival analysis and describe several successful applications in a variety of real-world application domains. We hope that this article will give readers a more comprehensive understanding of recent advances in survival analysis and offer some guidelines for applying these approaches to solve new problems arising in applications involving censored data."
  },
  {
    "paperId": "adfc508b9b3d4fc3903aa383a290dc68fb8bbe5a",
    "title": "Implementing Machine Learning in Health Care - Addressing Ethical Challenges.",
    "venue": "New England Journal of Medicine",
    "year": 2018,
    "citationCount": 1041,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc5962261?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1056/NEJMp1714229?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1056/NEJMp1714229, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "16015502",
        "name": "Danton S. Char"
      },
      {
        "authorId": "143665076",
        "name": "N. Shah"
      },
      {
        "authorId": "8439459",
        "name": "D. Magnus"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "daf468f001c3a5c6f9e667417becb94fa83efb2f",
    "title": "Exploiting machine learning for end-to-end drug discovery and development",
    "venue": "Nature Materials",
    "year": 2019,
    "citationCount": 427,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6594828",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41563-019-0338-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41563-019-0338-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1887610",
        "name": "S. Ekins"
      },
      {
        "authorId": "39778181",
        "name": "A. C. Puhl"
      },
      {
        "authorId": "67164018",
        "name": "Kimberley M. Zorn"
      },
      {
        "authorId": "50556284",
        "name": "T. Lane"
      },
      {
        "authorId": "8903363",
        "name": "Daniel P. Russo"
      },
      {
        "authorId": "143722544",
        "name": "Jennifer J Klein"
      },
      {
        "authorId": "2053197",
        "name": "A. Hickey"
      },
      {
        "authorId": "143961624",
        "name": "A. Clark"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "39361b3507c9f8b0a97780568b645f80a208d78a",
    "title": "Machine Learning and Deep Learning Methods for Cybersecurity",
    "venue": "IEEE Access",
    "year": 2018,
    "citationCount": 876,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/access.2018.2836950",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2018.2836950?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2018.2836950, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2067672128",
        "name": "Yang Xin"
      },
      {
        "authorId": "2069277364",
        "name": "Lingshuang Kong"
      },
      {
        "authorId": "2118357790",
        "name": "Zhi Liu"
      },
      {
        "authorId": "49069825",
        "name": "Yuling Chen"
      },
      {
        "authorId": "121704135",
        "name": "Yanmiao Li"
      },
      {
        "authorId": "96519515",
        "name": "Hongliang Zhu"
      },
      {
        "authorId": "49594896",
        "name": "Mingcheng Gao"
      },
      {
        "authorId": "2149274",
        "name": "Haixia Hou"
      },
      {
        "authorId": "2201459853",
        "name": "Chunhua Wang"
      }
    ],
    "abstract": "With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions."
  },
  {
    "paperId": "3784b73a1f392160523400ec0309191c0a96d86f",
    "title": "MLlib: Machine Learning in Apache Spark",
    "venue": "Journal of machine learning research",
    "year": 2015,
    "citationCount": 1821,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1505.06807, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39309572",
        "name": "Xiangrui Meng"
      },
      {
        "authorId": "2086593199",
        "name": "Joseph K. Bradley"
      },
      {
        "authorId": "2065287033",
        "name": "B. Yavuz"
      },
      {
        "authorId": "144752747",
        "name": "Evan R. Sparks"
      },
      {
        "authorId": "2697906",
        "name": "S. Venkataraman"
      },
      {
        "authorId": "2536434",
        "name": "Davies Liu"
      },
      {
        "authorId": "2114973651",
        "name": "Jeremy Freeman"
      },
      {
        "authorId": "2064759911",
        "name": "D. Tsai"
      },
      {
        "authorId": "2089931559",
        "name": "Manish Amde"
      },
      {
        "authorId": "2060860697",
        "name": "Sean Owen"
      },
      {
        "authorId": "40413768",
        "name": "Doris Xin"
      },
      {
        "authorId": "2066641",
        "name": "Reynold Xin"
      },
      {
        "authorId": "143666627",
        "name": "M. Franklin"
      },
      {
        "authorId": "5985064",
        "name": "R. Zadeh"
      },
      {
        "authorId": "143834867",
        "name": "M. Zaharia"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      }
    ],
    "abstract": "Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed."
  },
  {
    "paperId": "32c709cf5d6ba1b5a729b4871c3129bb1bf578bf",
    "title": "Quantum machine learning in high energy physics",
    "venue": "Machine Learning: Science and Technology",
    "year": 2020,
    "citationCount": 142,
    "openAccessPdf": {
      "url": "https://iopscience.iop.org/article/10.1088/2632-2153/abc17d/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.08582, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47368669",
        "name": "W. Guan"
      },
      {
        "authorId": "51116496",
        "name": "G. Perdue"
      },
      {
        "authorId": "52133091",
        "name": "Arthur Pesah"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "94071871",
        "name": "K. Terashi"
      },
      {
        "authorId": "3425469",
        "name": "S. Vallecorsa"
      },
      {
        "authorId": "52630992",
        "name": "J. Vlimant"
      }
    ],
    "abstract": "Machine learning has been used in high energy physics (HEP) for a long time, primarily at the analysis level with supervised classification. Quantum computing was postulated in the early 1980s as way to perform computations that would not be tractable with a classical computer. With the advent of noisy intermediate-scale quantum computing devices, more quantum algorithms are being developed with the aim at exploiting the capacity of the hardware for machine learning applications. An interesting question is whether there are ways to apply quantum machine learning to HEP. This paper reviews the first generation of ideas that use quantum machine learning on problems in HEP and provide an outlook on future applications."
  },
  {
    "paperId": "c61134ada9f0e3f3373d635c31a8b3caa37f9977",
    "title": "Genetic algorithms and Machine Learning",
    "venue": "Machine-mediated learning",
    "year": 1988,
    "citationCount": 3355,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF00113892?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF00113892, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1715339",
        "name": "D. Goldberg"
      },
      {
        "authorId": "144404817",
        "name": "J. Holland"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fa9906b466bbbff3a8c206b499cd34323a91d1b2",
    "title": "Points of Significance: Statistics versus machine learning",
    "venue": "Nature Methods",
    "year": 2018,
    "citationCount": 988,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/nmeth.4642.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/nmeth.4642?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/nmeth.4642, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1700231",
        "name": "D. Bzdok"
      },
      {
        "authorId": "145019044",
        "name": "Naomi Altman"
      },
      {
        "authorId": "2802123",
        "name": "M. Krzywinski"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "161ce338538f94b0b9be51ae2336db0aa4b012e5",
    "title": "Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data",
    "venue": "JAMA Internal Medicine",
    "year": 2018,
    "citationCount": 1051,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc6347576?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1001/jamainternmed.2018.3763?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jamainternmed.2018.3763, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5086547",
        "name": "M. Gianfrancesco"
      },
      {
        "authorId": "2364709",
        "name": "Suzanne Tamang"
      },
      {
        "authorId": "5441960",
        "name": "J. Yazdany"
      },
      {
        "authorId": "5589030",
        "name": "G. Schmajuk"
      }
    ],
    "abstract": "A promise of machine learning in health care is the avoidance of biases in diagnosis and treatment; a computer algorithm could objectively synthesize and interpret the data in the medical record. Integration of machine learning with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. Machine learning algorithms, however, may also be subject to biases. The biases include those related to missing data and patients not identified by algorithms, sample size and underestimation, and misclassification and measurement error. There is concern that biases and deficiencies in the data used by machine learning algorithms may contribute to socioeconomic disparities in health care. This Special Communication outlines the potential biases that may be introduced into machine learning–based clinical decision support tools that use electronic health record data and proposes potential solutions to the problems of overreliance on automation, algorithms based on biased data, and algorithms that do not provide information that is clinically meaningful. Existing health care disparities should not be amplified by thoughtless or excessive reliance on machines."
  },
  {
    "paperId": "2e6c570d277b0b4edd48e2054d5cede4c6bbb50f",
    "title": "Machine learning in acoustics: Theory and applications.",
    "venue": "Journal of the Acoustical Society of America",
    "year": 2019,
    "citationCount": 427,
    "openAccessPdf": {
      "url": "https://asa.scitation.org/doi/pdf/10.1121/1.5133944",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.04418, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48293266",
        "name": "Michael J. Bianco"
      },
      {
        "authorId": "1929240",
        "name": "P. Gerstoft"
      },
      {
        "authorId": "50690309",
        "name": "James Traer"
      },
      {
        "authorId": "15018343",
        "name": "Emma Ozanich"
      },
      {
        "authorId": "35154087",
        "name": "M. Roch"
      },
      {
        "authorId": "1774548",
        "name": "S. Gannot"
      },
      {
        "authorId": "2262533",
        "name": "Charles-Alban Deledalle"
      }
    ],
    "abstract": "Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning (ML), including deep learning, in the field of acoustics. ML is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, ML is data-driven. Given sufficient training data, ML can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, ML can discover models describing complex acoustic phenomena such as human speech and reverberation. ML in acoustics is rapidly developing with compelling results and significant future promise. We first introduce ML, then highlight ML developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes."
  },
  {
    "paperId": "eed9fa4483cab37eacd59db0fac4b1441431ee85",
    "title": "Tensor Decomposition for Signal Processing and Machine Learning",
    "venue": "IEEE Transactions on Signal Processing",
    "year": 2016,
    "citationCount": 1470,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/tsp.2017.2690524",
      "status": "HYBRID",
      "license": "publisher-specific, author manuscript",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1607.01668, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "73776482",
        "name": "N. Sidiropoulos"
      },
      {
        "authorId": "2217213",
        "name": "L. D. Lathauwer"
      },
      {
        "authorId": "144406546",
        "name": "Xiao Fu"
      },
      {
        "authorId": "2349460",
        "name": "Kejun Huang"
      },
      {
        "authorId": "3000659",
        "name": "E. Papalexakis"
      },
      {
        "authorId": "1702392",
        "name": "C. Faloutsos"
      }
    ],
    "abstract": "Tensors or <italic>multiway arrays</italic> are functions of three or more indices <inline-formula> <tex-math notation=\"LaTeX\">$(i,j,k,\\ldots)$</tex-math></inline-formula>—similar to matrices (two-way arrays), which are functions of two indices <inline-formula><tex-math notation=\"LaTeX\">$(r,c)$</tex-math></inline-formula> for (row, column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining, and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth <italic>and depth</italic> that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some background in applied optimization is useful but not strictly required. The material covered includes tensor rank and rank decomposition; basic tensor factorization models and their relationships and properties (including fairly good coverage of identifiability); broad coverage of algorithms ranging from alternating optimization to stochastic gradient; statistical performance analysis; and applications ranging from source separation to collaborative filtering, mixture and topic modeling, classification, and multilinear subspace learning."
  },
  {
    "paperId": "033f25ad905ef2ed32a8331cf38b83953ff15922",
    "title": "A Review of Relational Machine Learning for Knowledge Graphs",
    "venue": "Proceedings of the IEEE",
    "year": 2015,
    "citationCount": 1646,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/jproc.2015.2483592",
      "status": "HYBRID",
      "license": "publisher-specific, author manuscript",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1503.00759, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1729762",
        "name": "Maximilian Nickel"
      },
      {
        "authorId": "1702318",
        "name": "K. Murphy"
      },
      {
        "authorId": "1700754",
        "name": "Volker Tresp"
      },
      {
        "authorId": "1718798",
        "name": "E. Gabrilovich"
      }
    ],
    "abstract": "Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's knowledge vault project as an example of such combination."
  },
  {
    "paperId": "5327bb691a1c63791a06de2d3f0478e47785add5",
    "title": "Predicting Diabetes Mellitus With Machine Learning Techniques",
    "venue": "Frontiers in Genetics",
    "year": 2018,
    "citationCount": 703,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fgene.2018.00515/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6232260, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144268946",
        "name": "Q. Zou"
      },
      {
        "authorId": "26953868",
        "name": "Kaiyang Qu"
      },
      {
        "authorId": "2112602289",
        "name": "Ya-ling Luo"
      },
      {
        "authorId": "2053677281",
        "name": "Dehui Yin"
      },
      {
        "authorId": "144250293",
        "name": "Y. Ju"
      },
      {
        "authorId": "144256490",
        "name": "Hua Tang"
      }
    ],
    "abstract": "Diabetes mellitus is a chronic disease characterized by hyperglycemia. It may cause many complications. According to the growing morbidity in recent years, in 2040, the world’s diabetic patients will reach 642 million, which means that one of the ten adults in the future is suffering from diabetes. There is no doubt that this alarming figure needs great attention. With the rapid development of machine learning, machine learning has been applied to many aspects of medical health. In this study, we used decision tree, random forest and neural network to predict diabetes mellitus. The dataset is the hospital physical examination data in Luzhou, China. It contains 14 attributes. In this study, five-fold cross validation was used to examine the models. In order to verity the universal applicability of the methods, we chose some methods that have the better performance to conduct independent test experiments. We randomly selected 68994 healthy people and diabetic patients’ data, respectively as training set. Due to the data unbalance, we randomly extracted 5 times data. And the result is the average of these five experiments. In this study, we used principal component analysis (PCA) and minimum redundancy maximum relevance (mRMR) to reduce the dimensionality. The results showed that prediction with random forest could reach the highest accuracy (ACC = 0.8084) when all the attributes were used."
  },
  {
    "paperId": "d73149832c5dc18c8a74b2cc0924eceb51be2e60",
    "title": "Hands-On Machine Learning with R",
    "venue": "",
    "year": 2019,
    "citationCount": 426,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1201/9780367816377?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/9780367816377, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46216076",
        "name": "Bradley C. Boehmke"
      },
      {
        "authorId": "35664117",
        "name": "Brandon M. Greenwell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8f04029d1d83f41eaebf5a216ebecf2a61ff6dc0",
    "title": "Selection of Relevant Features and Examples in Machine Learning",
    "venue": "Artificial Intelligence",
    "year": 1997,
    "citationCount": 3591,
    "openAccessPdf": {
      "url": "http://yaroslavvb.com/papers/blum-selection.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0004-3702(97)00063-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0004-3702(97)00063-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1690967",
        "name": "Avrim Blum"
      },
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "adade3149b2a6177296de352f003471eefa958b8",
    "title": "The Impact of Machine Learning on Economics",
    "venue": "The Economics of Artificial Intelligence",
    "year": 2018,
    "citationCount": 460,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.7208/chicago/9780226613475.003.0021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7208/chicago/9780226613475.003.0021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2631417",
        "name": "S. Athey"
      }
    ],
    "abstract": "This paper provides an assessment of the early contributions of machine learning to economics, as well as predictions about its future contributions. It begins by brieﬂy overviewing some themes from the literature on machine learning, and then draws some contrasts with traditional approaches to estimating the impact of counterfactual policies in economics. Next, we review some of the initial “oﬀ-the-shelf” applications of machine learning to economics, including applications in analyzing text and images. We then describe new types of questions that have been posed surrounding the application of machine learning to policy problems, including “prediction policy problems,” as well as considerations of fairness and manipulability. Next, we brieﬂy review of some of the emerging econometric literature combining machine learning and causal inference. Finally, we overview a set of predictions about the future impact of machine learning on economics."
  },
  {
    "paperId": "598563b8320e6760b828cf08e2adc41c7027d0fe",
    "title": "Automated Machine Learning: Methods, Systems, Challenges",
    "venue": "The Springer Series on Challenges in Machine Learning",
    "year": 2019,
    "citationCount": 425,
    "openAccessPdf": {
      "url": "https://doi.org/10.1007/978-3-030-29135-8",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-05318-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-05318-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2263076826",
        "name": "Frank Hutter"
      },
      {
        "authorId": "2330340874",
        "name": "Lars Kotthoff"
      },
      {
        "authorId": "2388744066",
        "name": "Joaquin Vanschoren"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7c8858eba8571d86abd90252e734a11e3a6dd73f",
    "title": "An Introduction to MCMC for Machine Learning",
    "venue": "Machine-mediated learning",
    "year": 2004,
    "citationCount": 2723,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023%2FA%3A1020281327116.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1020281327116?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1020281327116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49630843",
        "name": "C. Andrieu"
      },
      {
        "authorId": "1737568",
        "name": "Nando de Freitas"
      },
      {
        "authorId": "1701800",
        "name": "A. Doucet"
      },
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "88a97c8ef539589c55a6fe869c243792e470d6a3",
    "title": "Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective",
    "venue": "International Symposium on High-Performance Computer Architecture",
    "year": 2018,
    "citationCount": 589,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/HPCA.2018.00059?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/HPCA.2018.00059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1775500",
        "name": "K. Hazelwood"
      },
      {
        "authorId": "145583374",
        "name": "Sarah Bird"
      },
      {
        "authorId": "1896817",
        "name": "D. Brooks"
      },
      {
        "authorId": "2127604",
        "name": "Soumith Chintala"
      },
      {
        "authorId": "40863835",
        "name": "Utku Diril"
      },
      {
        "authorId": "40858378",
        "name": "Dmytro Dzhulgakov"
      },
      {
        "authorId": "2133743548",
        "name": "Mohamed Fawzy"
      },
      {
        "authorId": "33920592",
        "name": "Bill Jia"
      },
      {
        "authorId": "39978391",
        "name": "Yangqing Jia"
      },
      {
        "authorId": "10774798",
        "name": "Aditya Kalro"
      },
      {
        "authorId": "2057766961",
        "name": "James Law"
      },
      {
        "authorId": "2110234018",
        "name": "Kevin Lee"
      },
      {
        "authorId": "2159321510",
        "name": "Jason Lu"
      },
      {
        "authorId": "34837514",
        "name": "P. Noordhuis"
      },
      {
        "authorId": "1711231",
        "name": "M. Smelyanskiy"
      },
      {
        "authorId": "2068237821",
        "name": "Liang Xiong"
      },
      {
        "authorId": "2108429236",
        "name": "Xiaodong Wang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b7621b358485eb3e34a874b97d1ecd6b5d5ac70b",
    "title": "Machine learning methods for solar radiation forecasting: A review",
    "venue": "",
    "year": 2017,
    "citationCount": 1419,
    "openAccessPdf": {
      "url": "https://zenodo.org/records/889123/files/Machine%20Learning%20methods%20for%20solar%20radiation%20forecasting.%20A%20review.pdf",
      "status": "GREEN",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.RENENE.2016.12.095?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.RENENE.2016.12.095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2013408",
        "name": "Cyril Voyant"
      },
      {
        "authorId": "2523574",
        "name": "G. Notton"
      },
      {
        "authorId": "2606543",
        "name": "S. Kalogirou"
      },
      {
        "authorId": "41174026",
        "name": "M. Nivet"
      },
      {
        "authorId": "46325092",
        "name": "C. Paoli"
      },
      {
        "authorId": "121644432",
        "name": "F. Motte"
      },
      {
        "authorId": "31122309",
        "name": "A. Fouilloy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "60e801e3dfc9812e294ed9de6d579e0293d61643",
    "title": "Probabilistic machine learning and artificial intelligence",
    "venue": "Nature",
    "year": 2015,
    "citationCount": 1895,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/nature14541?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/nature14541, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1744700",
        "name": "Zoubin Ghahramani"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "730fba26faa7f91dc6742a0c3521eb439670a825",
    "title": "Machine-learning-guided directed evolution for protein engineering",
    "venue": "Nature Methods",
    "year": 2018,
    "citationCount": 846,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41592-019-0496-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41592-019-0496-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47271615",
        "name": "Kevin Kaichuang Yang"
      },
      {
        "authorId": "51125091",
        "name": "Zachary Wu"
      },
      {
        "authorId": "2795724",
        "name": "F. Arnold"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "49d1f40312af25d01da721e33f4a8be8cea29551",
    "title": "Data mining - practical machine learning tools and techniques, Second Edition",
    "venue": "The Morgan Kaufmann series in data management systems",
    "year": 2005,
    "citationCount": 2581,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "9419406",
        "name": "I. Witten"
      },
      {
        "authorId": "1767318",
        "name": "E. Frank"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0",
    "title": "Extreme learning machine: a new learning scheme of feedforward neural networks",
    "venue": "2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)",
    "year": 2004,
    "citationCount": 4114,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.2004.1380068?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.2004.1380068, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "50736254",
        "name": "Q. Zhu"
      },
      {
        "authorId": "1683268",
        "name": "C. Siew"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "33d9d4593d44792e17a045e5f3407f0fe7a40dd1",
    "title": "Machine learning of accurate energy-conserving molecular force fields",
    "venue": "Science Advances",
    "year": 2016,
    "citationCount": 1164,
    "openAccessPdf": {
      "url": "https://advances.sciencemag.org/content/advances/3/5/e1603015.full.pdf",
      "status": "GOLD",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.04678, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7631063",
        "name": "Stefan Chmiela"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      },
      {
        "authorId": "10667063",
        "name": "H. Sauceda"
      },
      {
        "authorId": "5667638",
        "name": "I. Poltavsky"
      },
      {
        "authorId": "33075217",
        "name": "Kristof T. Schütt"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": "The law of energy conservation is used to develop an efficient machine learning approach to construct accurate force fields. Using conservation of energy—a fundamental property of closed classical and quantum mechanical systems—we develop an efficient gradient-domain machine learning (GDML) approach to construct accurate molecular force fields using a restricted number of samples from ab initio molecular dynamics (AIMD) trajectories. The GDML implementation is able to reproduce global potential energy surfaces of intermediate-sized molecules with an accuracy of 0.3 kcal mol−1 for energies and 1 kcal mol−1 Å̊−1 for atomic forces using only 1000 conformational geometries for training. We demonstrate this accuracy for AIMD trajectories of molecules, including benzene, toluene, naphthalene, ethanol, uracil, and aspirin. The challenge of constructing conservative force fields is accomplished in our work by learning in a Hilbert space of vector-valued functions that obey the law of energy conservation. The GDML approach enables quantitative molecular dynamics simulations for molecules at a fraction of cost of explicit AIMD calculations, thereby allowing the construction of efficient force fields with the accuracy and transferability of high-level ab initio methods."
  },
  {
    "paperId": "82a5a84528a7ca0409f75e2211a3b33a217e9bac",
    "title": "Ensuring Fairness in Machine Learning to Advance Health Equity",
    "venue": "Annals of Internal Medicine",
    "year": 2018,
    "citationCount": 763,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc6594166?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.7326/M18-1990?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7326/M18-1990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8638650",
        "name": "A. Rajkomar"
      },
      {
        "authorId": "40356669",
        "name": "Michaela Hardt"
      },
      {
        "authorId": "145310670",
        "name": "M. Howell"
      },
      {
        "authorId": "2084098271",
        "name": "Greg S. Corrado"
      },
      {
        "authorId": "2186184",
        "name": "M. Chin"
      }
    ],
    "abstract": "Machine learning can identify the statistical patterns of data generated by tens of thousands of physicians and billions of patients to train computers to perform specific tasks with sometimes superhuman ability, such as detecting diabetic eye disease better than retinal specialists (1). However, historical data also capture patterns of health care disparities, and machine-learning models trained on these data may perpetuate these inequities. This concern is not just academic. In a model used to predict future crime on the basis of historical arrest records, African American defendants who did not reoffend were classified as high risk at a substantially higher rate than white defendants who did not reoffend (2, 3). Similar biases have been observed in predictive policing (4) and identifying which calls to a child protective services agency required an in-person investigation (5, 6). The implications for health care led the American Medical Association to pass policy recommendations to promote development of thoughtfully designed, high-quality, clinically validated health care AI [artificial or augmented intelligence, such as machine learning] that . . . identifies and takes steps to address bias and avoids introducing or exacerbating health care disparities including when testing or deploying new AI tools on vulnerable populations (7). We argue that health care organizations and policymakers should go beyond the American Medical Association's position of doing no harm and instead proactively design and use machine-learning systems to advance health equity. Whereas much health disparities work has focused on discriminatory decision making and implicit biases by clinicians, policymakers, organizational leaders, and researchers are increasingly focusing on the ill health effects of structural racism and classismhow systems are shaped in ways that harm the health of disempowered, marginalized populations (8). For example, the United States has a shameful history of purposive decisions by government and private businesses to segregate housing. Zoning laws, discrimination in mortgage lending, prejudicial practices by real estate agents, and the ghettoization of public housing all contributed to the concentration of urban African Americans in inferior housing that has led to poor health (9, 10). Even when the goal of decision makers is not outright discrimination against disadvantaged groups, actions may lead to inequities. For example, if the goal of a machine-learning system is to maximize efficiency, that might come at the expense of disadvantaged populations. As a society, we value health equity. For example, the Healthy People 2020 vision statement aims for a society in which all people live long, healthy lives, and one of the mission's goals is to achieve health equity, eliminate disparities, and improve the health of all groups (11). The 4 classic principles of Western clinical medical ethics are justice, autonomy, beneficence, and nonmaleficence. However, health equity will not be attained unless we purposely design our health and social systems, which increasingly will be infused with machine learning (12), to achieve this goal. To ensure fairness in machine learning, we recommend a participatory process that involves key stakeholders, including frequently marginalized populations, and considers distributive justice within specific clinical and organizational contexts. Different technical approaches can configure the mathematical properties of machine-learning models to render predictions that are equitable in various ways. The existence of mathematical levers must be supplemented with criteria for when and why they should be usedeach tool comes with tradeoffs that require ethical reasoning to decide what is best for a given application. We propose incorporating fairness into the design, deployment, and evaluation of machine-learning models. We discuss 2 clinical applications in which machine learning might harm protected groups by being inaccurate, diverting resources, or worsening outcomes, especially if the models are built without consideration for these patients. We then describe the mechanisms by which a model's design, data, and deployment may lead to disparities; explain how different approaches to distributive justice in machine learning can advance health equity; and explore what contexts are more appropriate for different equity approaches in machine learning. Case Study 1: Intensive Care Unit Monitoring A common area of predictive modeling research focuses on creating a monitoring systemfor example, to warn a rapid response team about inpatients at high risk for deterioration (1315), requiring their transfer to an intensive care unit within 6 hours. How might such a system inadvertently result in harm to a protected group? In this thought experiment, we consider African Americans as a protected group. To build the model, our hypothetical researchers collected historical records of patients who had clinical deterioration and those who did not. The model acts like a diagnostic test of risk for intensive care unit transfer. However, if too few African American patients were included in the training datathe data used to construct the modelthe model might be inaccurate for them. For example, it might have a lower sensitivity and miss more patients at risk for deterioration. African American patients might be harmed if clinical teams started relying on alerts to identify at-risk patients without realizing that the prediction system underdetects patients in that group (automation bias) (16). If the model had a lower positive predictive value for African Americans, it might also disproportionately harm them through dismissal biasa generalization of alert fatigue in which clinicians may learn to discount or dismiss alerts for African Americans because they are more likely to be false-positive (17). Case Study 2: Reducing Length of Stay Imagine that a hospital created a model with clinical and social variables to predict which inpatients might be discharged earliest so that it could direct limited case management resources to them to prevent delays. If residence in ZIP codes of socioeconomically depressed or predominantly African American neighborhoods predicted greater lengths of stay (18), this model might disproportionately allocate case management resources to patients from richer, predominantly white neighborhoods and away from African Americans in poorer ones. What Is Machine Learning? Traditionally, computer systems map inputs to outputs according to manually specified ifthen rules. With increasingly complex tasks, such as language translation, manually specifying rules becomes infeasible, and instead the mapping (or model) is learned by the system given only input examples represented through a set of features together with their desired output, referred to as labels. The quality of a model is assessed by computing evaluation metrics on data not used to build the model, such as sensitivity, specificity, or the c-statistic, which measures the ability of a model to distinguish patients with a condition from those without it (19, 20). Once the model's quality is deemed satisfactory, it can be deployed to make predictions on new examples for which the label is unknown when the prediction is made. The quality of the models on retrospective data must be followed with tests of clinical effectiveness, safety, and comparison with current practice, which may require clinical trials (21). Traditionally, statistical models for prediction, such as the pooled-cohort equation (22), have used few variables to predict clinical outcomes, such as cardiovascular risk (23). Modern machine-learning techniques, however, can consider many more features. For example, a recent model to predict hospital readmissions examined hundreds of thousands of pieces of information, including the free text of clinical notes (24). Complex data and models can drive more personalized and accurate predictions but may also make algorithms hard to understand and trust (25). What Can Cause a Machine-Learning System to Be Unfair? The Glossary lists key biases in the design, data, and deployment of a machine-learning model that may perpetuate or exacerbate health care disparities if left unchecked. The Figure reveals how the various biases relate to one another and how the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Biases may arise during the design of a model. For example, if the label is marred by health care disparities, such as predicting the onset of clinical depression in environments where protected groups have been systematically misdiagnosed, then the model will learn to perpetuate this disparity. This represents a generalization of test-referral bias (26) that we refer to as label bias. Moreover, the data on which the model is developed may be biased. Data on patients in the protected group might be distributed differently from those in the nonprotected group because of biological or nonbiological variation (9, 27). For example, the data may not contain enough examples from a group to properly tailor the predictions to them (minority bias) (28), or the data set of the protected group may be less informative because features are missing not at random as a result of more fragmented care (29, 30). Glossary Figure. Conceptual framework of how various biases relate to one another. During model development, differences in the distribution of features used to predict a label between the protected and nonprotected groups may bias a model to be less accurate for protected groups. Moreover, the data used to develop a model may not generalize to the data used during model deployment (trainingserving skew). Biases in model design and data affect patient outcomes through the model's interaction with clinicians and patients. The immediate effect of these differences is that the model may "
  },
  {
    "paperId": "4f2baff3195b6fc43a38e3e869496dab9fe9dbc3",
    "title": "Delayed Impact of Fair Machine Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 498,
    "openAccessPdf": {
      "url": "https://www.ijcai.org/proceedings/2019/0862.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.04383, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1748108610",
        "name": "Lydia T. Liu"
      },
      {
        "authorId": "1491339790",
        "name": "Sarah Dean"
      },
      {
        "authorId": "144322309",
        "name": "Esther Rolf"
      },
      {
        "authorId": "3385674",
        "name": "Max Simchowitz"
      },
      {
        "authorId": "1775622",
        "name": "Moritz Hardt"
      }
    ],
    "abstract": "Static classification has been the predominant focus of the study of fairness in machine learning. While most models do not consider how decisions change populations over time, it is conventional wisdom that fairness criteria promote the long-term well-being of groups they aim to protect. This work studies the interaction of static fairness criteria with temporal indicators of well-being. We show a simple one-step feedback model in which common criteria do not generally promote improvement over time, and may in fact cause harm. Our results highlight the importance of temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs."
  },
  {
    "paperId": "29524f145db94cab2336da99f157e869d805dead",
    "title": "SoK: Security and Privacy in Machine Learning",
    "venue": "European Symposium on Security and Privacy",
    "year": 2018,
    "citationCount": 556,
    "openAccessPdf": {
      "url": "https://ink.library.smu.edu.sg/sis_research/4790",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/EuroSP.2018.00035?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/EuroSP.2018.00035, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367796356",
        "name": "Nicolas Papernot"
      },
      {
        "authorId": "144061974",
        "name": "P. Mcdaniel"
      },
      {
        "authorId": "2370629",
        "name": "Arunesh Sinha"
      },
      {
        "authorId": "1796536",
        "name": "Michael P. Wellman"
      }
    ],
    "abstract": "Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive—new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, à la PAC theory, will foster a science of security and privacy in ML."
  },
  {
    "paperId": "29409efa04ac99ccf01d2a011d21d5d14e870000",
    "title": "Artificial intelligence to deep learning: machine intelligence approach for drug discovery",
    "venue": "Molecular diversity",
    "year": 2021,
    "citationCount": 873,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s11030-021-10217-3.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8040371, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1409846740",
        "name": "Rohan Gupta"
      },
      {
        "authorId": "153610437",
        "name": "Devesh Srivastava"
      },
      {
        "authorId": "2059118408",
        "name": "Mehar Sahu"
      },
      {
        "authorId": "2072850683",
        "name": "Swati Tiwari"
      },
      {
        "authorId": "2288195",
        "name": "R. K. Ambasta"
      },
      {
        "authorId": "38183916",
        "name": "Pravir Kumar"
      }
    ],
    "abstract": "Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind. The primary concern associated with drug design and development is time consumption and production cost. Further, inefficiency, inaccurate target delivery, and inappropriate dosage are other hurdles that inhibit the process of drug delivery and development. With advancements in technology, computer-aided drug design integrating artificial intelligence algorithms can eliminate the challenges and hurdles of traditional drug design and development. Artificial intelligence is referred to as superset comprising machine learning, whereas machine learning comprises supervised learning, unsupervised learning, and reinforcement learning. Further, deep learning, a subset of machine learning, has been extensively implemented in drug design and development. The artificial neural network, deep neural network, support vector machines, classification and regression, generative adversarial networks, symbolic learning, and meta-learning are examples of the algorithms applied to the drug design and discovery process. Artificial intelligence has been applied to different areas of drug design and development process, such as from peptide synthesis to molecule design, virtual screening to molecular docking, quantitative structure–activity relationship to drug repositioning, protein misfolding to protein–protein interactions, and molecular pathway identification to polypharmacology. Artificial intelligence principles have been applied to the classification of active and inactive, monitoring drug release, pre-clinical and clinical development, primary and secondary drug screening, biomarker development, pharmaceutical manufacturing, bioactivity identification and physiochemical properties, prediction of toxicity, and identification of mode of action."
  },
  {
    "paperId": "64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
    "title": "Tunability: Importance of Hyperparameters of Machine Learning Algorithms",
    "venue": "Journal of machine learning research",
    "year": 2018,
    "citationCount": 699,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.09596, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47670226",
        "name": "Philipp Probst"
      },
      {
        "authorId": "1751504",
        "name": "A. Boulesteix"
      },
      {
        "authorId": "1686924",
        "name": "B. Bischl"
      }
    ],
    "abstract": "Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define data-based defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to chose adequate hyperparameter spaces for tuning."
  },
  {
    "paperId": "d5125164c7fec457d1442cce807a3436841715d0",
    "title": "Machine Learning Approaches for Clinical Psychology and Psychiatry.",
    "venue": "Annual Review of Clinical Psychology",
    "year": 2018,
    "citationCount": 728,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-clinpsy-032816-045037?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-clinpsy-032816-045037, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5672681",
        "name": "Dominic Dwyer"
      },
      {
        "authorId": "2660554",
        "name": "P. Falkai"
      },
      {
        "authorId": "3214043",
        "name": "N. Koutsouleris"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "54b2c43d93d1f525213da5ddc70db5d27c1120f4",
    "title": "Auto-sklearn: Efficient and Robust Automated Machine Learning",
    "venue": "Automated Machine Learning",
    "year": 2019,
    "citationCount": 335,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_6.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-05318-5_6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-05318-5_6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2868444",
        "name": "Matthias Feurer"
      },
      {
        "authorId": "145227684",
        "name": "Aaron Klein"
      },
      {
        "authorId": "2607675",
        "name": "Katharina Eggensperger"
      },
      {
        "authorId": "2060551",
        "name": "Jost Tobias Springenberg"
      },
      {
        "authorId": "2058090778",
        "name": "Manuel Blum"
      },
      {
        "authorId": "144661829",
        "name": "F. Hutter"
      }
    ],
    "abstract": "The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on the Python machine learning package scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub Auto-sklearn, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won six out of ten phases of the first ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of Auto-sklearn."
  },
  {
    "paperId": "a10bc90b3c97a4abe86c73cfb2a8490a9b44373f",
    "title": "A General-Purpose Machine Learning Framework for Predicting Properties of Inorganic Materials",
    "venue": "",
    "year": 2016,
    "citationCount": 1375,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/npjcompumats201628.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.09551, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47766095",
        "name": "Logan T. Ward"
      },
      {
        "authorId": "144186018",
        "name": "Ankit Agrawal"
      },
      {
        "authorId": "143975793",
        "name": "A. Choudhary"
      },
      {
        "authorId": "2088553",
        "name": "C. Wolverton"
      }
    ],
    "abstract": "A very active area of materials research is to devise methods that use machine learning to automatically extract predictive models from existing materials data. While prior examples have demonstrated successful models for some applications, many more applications exist where machine learning can make a strong impact. To enable faster development of machine-learning-based models for such applications, we have created a framework capable of being applied to a broad range of materials data. Our method works by using a chemically diverse list of attributes, which we demonstrate are suitable for describing a wide variety of properties, and a novel method for partitioning the data set into groups of similar materials in order to boost the predictive accuracy. In this manuscript, we demonstrate how this new method can be used to predict diverse properties of crystalline and amorphous materials, such as band gap energy and glass-forming ability."
  },
  {
    "paperId": "ea7887fadc666d6faf92e569d4a10d994ee91297",
    "title": "iml: An R package for Interpretable Machine Learning",
    "venue": "Journal of Open Source Software",
    "year": 2018,
    "citationCount": 485,
    "openAccessPdf": {
      "url": "https://joss.theoj.org/papers/10.21105/joss.00786.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.21105/JOSS.00786?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21105/JOSS.00786, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50621691",
        "name": "Christoph Molnar"
      },
      {
        "authorId": "8662947",
        "name": "Giuseppe Casalicchio"
      },
      {
        "authorId": "1686924",
        "name": "B. Bischl"
      }
    ],
    "abstract": "Complex, non-parametric models, which are typically used in machine learning, have proven to be successful in many prediction tasks. But these models usually operate as black boxes: While they are good at predicting, they are often not interpretable. Many inherently interpretable models have been suggested, which come at the cost of losing predictive power. Another option is to apply interpretability methods to a black box model after model training. Given the velocity of research on new machine learning models, it is preferable to have model-agnostic tools which can be applied to a random forest as well as to a neural network. Tools for model-agnostic interpretability methods should improve the adoption of machine learning."
  },
  {
    "paperId": "0f5476c9629f8093e8ba8c6a41868415c6a7f2f1",
    "title": "Stealing Hyperparameters in Machine Learning",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2018,
    "citationCount": 487,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418595.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.05351, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1789625",
        "name": "Binghui Wang"
      },
      {
        "authorId": "144516687",
        "name": "N. Gong"
      }
    ],
    "abstract": "Hyperparameters are critical in machine learning, as different hyperparameters often result in models with significantly different performance. Hyperparameters may be deemed confidential because of their commercial value and the confidentiality of the proprietary algorithms that the learner uses to learn them. In this work, we propose attacks on stealing the hyperparameters that are learned by a learner. We call our attacks hyperparameter stealing attacks. Our attacks are applicable to a variety of popular machine learning algorithms such as ridge regression, logistic regression, support vector machine, and neural network. We evaluate the effectiveness of our attacks both theoretically and empirically. For instance, we evaluate our attacks on Amazon Machine Learning. Our results demonstrate that our attacks can accurately steal hyperparameters. We also study countermeasures. Our results highlight the need for new defenses against our hyperparameter stealing attacks for certain machine learning algorithms."
  },
  {
    "paperId": "3a83d8595e6727269c876fcebd23ee9ddd524b76",
    "title": "A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2018,
    "citationCount": 750,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1811.03402",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.03402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "30840932",
        "name": "Yuji Roh"
      },
      {
        "authorId": "2539412",
        "name": "Geon Heo"
      },
      {
        "authorId": "3288247",
        "name": "Steven Euijong Whang"
      }
    ],
    "abstract": "Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research."
  },
  {
    "paperId": "7d065e649e3bfc7d6d36166f50eab37b8404eae0",
    "title": "Interpretable Machine Learning in Healthcare",
    "venue": "IEEE International Conference on Healthcare Informatics",
    "year": 2018,
    "citationCount": 627,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3233547.3233667?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3233547.3233667, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145919340",
        "name": "M. Ahmad"
      },
      {
        "authorId": "1752398",
        "name": "A. Teredesai"
      },
      {
        "authorId": "36979326",
        "name": "C. Eckert"
      }
    ],
    "abstract": "This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare."
  },
  {
    "paperId": "70f6937b6253db8209d8fd6a4115e766946f04c5",
    "title": "eDoctor: machine learning and the future of medicine",
    "venue": "Journal of Internal Medicine",
    "year": 2018,
    "citationCount": 673,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/joim.12822",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1111/joim.12822?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/joim.12822, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "26612400",
        "name": "G. Handelman"
      },
      {
        "authorId": "6129704",
        "name": "H. Kok"
      },
      {
        "authorId": "35333607",
        "name": "R. Chandra"
      },
      {
        "authorId": "3144725",
        "name": "A. H. Razavi"
      },
      {
        "authorId": "153692329",
        "name": "M. Lee"
      },
      {
        "authorId": "145625751",
        "name": "H. Asadi"
      }
    ],
    "abstract": "Machine learning (ML) is a burgeoning field of medicine with huge resources being applied to fuse computer science and statistics to medical problems. Proponents of ML extol its ability to deal with large, complex and disparate data, often found within medicine and feel that ML is the future for biomedical research, personalized medicine, computer‐aided diagnosis to significantly advance global health care. However, the concepts of ML are unfamiliar to many medical professionals and there is untapped potential in the use of ML as a research tool. In this article, we provide an overview of the theory behind ML, explore the common ML algorithms used in medicine including their pitfalls and discuss the potential future of ML in medicine."
  },
  {
    "paperId": "a38b3183a6aef62eed68946a416e31d5aa90da59",
    "title": "Machine learning in medicine: Addressing ethical challenges",
    "venue": "PLoS Medicine",
    "year": 2018,
    "citationCount": 576,
    "openAccessPdf": {
      "url": "https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.1002689&type=printable",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6219763, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145104974",
        "name": "E. Vayena"
      },
      {
        "authorId": "6475221",
        "name": "A. Blasimme"
      },
      {
        "authorId": "2253082083",
        "name": "I. Cohen"
      }
    ],
    "abstract": "Effy Vayena and colleagues argue that machine learning in medicine must offer data protection, algorithmic transparency, and accountability to earn the trust of patients and clinicians."
  },
  {
    "paperId": "a0390b8d4a82daa1d24bba341b317aa710e4ce4d",
    "title": "Super-resolution reconstruction of turbulent flows with machine learning",
    "venue": "Journal of Fluid Mechanics",
    "year": 2018,
    "citationCount": 665,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1811.11328",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.11328, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "102460658",
        "name": "Kai Fukami"
      },
      {
        "authorId": "14873147",
        "name": "K. Fukagata"
      },
      {
        "authorId": "2780687",
        "name": "K. Taira"
      }
    ],
    "abstract": "We use machine learning to perform super-resolution analysis of grossly under-resolved turbulent flow field data to reconstruct the high-resolution flow field. Two machine learning models are developed, namely, the convolutional neural network (CNN) and the hybrid downsampled skip-connection/multi-scale (DSC/MS) models. These machine learning models are applied to a two-dimensional cylinder wake as a preliminary test and show remarkable ability to reconstruct laminar flow from low-resolution flow field data. We further assess the performance of these models for two-dimensional homogeneous turbulence. The CNN and DSC/MS models are found to reconstruct turbulent flows from extremely coarse flow field images with remarkable accuracy. For the turbulent flow problem, the machine-leaning-based super-resolution analysis can greatly enhance the spatial resolution with as little as 50 training snapshot data, holding great potential to reveal subgrid-scale physics of complex turbulent flows. With the growing availability of flow field data from high-fidelity simulations and experiments, the present approach motivates the development of effective super-resolution models for a variety of fluid flows."
  },
  {
    "paperId": "5fdc2223709079ba5c0f78661cdf66cec2173258",
    "title": "Current Applications and Future Impact of Machine Learning in Radiology.",
    "venue": "Radiology",
    "year": 2018,
    "citationCount": 664,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc6542626?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1148/radiol.2018171820?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1148/radiol.2018171820, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2381045406",
        "name": "M. M. •. Garry Choy"
      },
      {
        "authorId": "2381045638",
        "name": "MD Mph Omid Khalilzadeh"
      },
      {
        "authorId": "2381048240",
        "name": "MD • Mark Michalski"
      },
      {
        "authorId": "2286627655",
        "name": "PhD • Synho Do"
      },
      {
        "authorId": "2381045256",
        "name": "M. M. •. Anthony E. Samir"
      },
      {
        "authorId": "2381051588",
        "name": "PhD Oleg S. Pianykh"
      },
      {
        "authorId": "2381050117",
        "name": "MD • • J. Raymond Geis"
      },
      {
        "authorId": "2381045852",
        "name": "M. M. •. Pari V. Pandharipande"
      },
      {
        "authorId": "2381047198",
        "name": "MD • James A. Brink"
      },
      {
        "authorId": "2290366283",
        "name": "D. P. Keith J. Dreyer"
      }
    ],
    "abstract": "Recent advances and future perspectives of machine learning techniques offer promising applications in medical imaging. Machine learning has the potential to improve different steps of the radiology workflow including order scheduling and triage, clinical decision support systems, detection and interpretation of findings, postprocessing and dose estimation, examination quality control, and radiology reporting. In this article, the authors review examples of current applications of machine learning and artificial intelligence techniques in diagnostic radiology. In addition, the future impact and natural extension of these techniques in radiology practice are discussed."
  },
  {
    "paperId": "b2e0b79e6f180af2e0e559f2b1faba66b2bd578a",
    "title": "Accelerating the Machine Learning Lifecycle with MLflow",
    "venue": "IEEE Data Engineering Bulletin",
    "year": 2018,
    "citationCount": 420,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "143834867",
        "name": "M. Zaharia"
      },
      {
        "authorId": "2111074632",
        "name": "A. Chen"
      },
      {
        "authorId": "39885771",
        "name": "A. Davidson"
      },
      {
        "authorId": "38565890",
        "name": "A. Ghodsi"
      },
      {
        "authorId": "3352005",
        "name": "S. Hong"
      },
      {
        "authorId": "2371549",
        "name": "A. Konwinski"
      },
      {
        "authorId": "88307932",
        "name": "Siddharth Murching"
      },
      {
        "authorId": "2766877",
        "name": "Tomas Nykodym"
      },
      {
        "authorId": "1873118",
        "name": "Paul Ogilvie"
      },
      {
        "authorId": "87380811",
        "name": "Mani Parkhe"
      },
      {
        "authorId": "2054585376",
        "name": "Fen Xie"
      },
      {
        "authorId": "52145600",
        "name": "Corey Zumar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6d67ddd0855c60ada2fb4151f0f944feffdaf357",
    "title": "Machine Learning from Theory to Algorithms: An Overview",
    "venue": "Journal of Physics: Conference Series",
    "year": 2018,
    "citationCount": 577,
    "openAccessPdf": {
      "url": "https://doi.org/10.1088/1742-6596/1142/1/012012",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/1142/1/012012?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/1142/1/012012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3363367",
        "name": "J. Alzubi"
      },
      {
        "authorId": "3286242",
        "name": "A. Nayyar"
      },
      {
        "authorId": "2116451265",
        "name": "Akshi Kumar"
      }
    ],
    "abstract": "The current SMAC (Social, Mobile, Analytic, Cloud) technology trend paves the way to a future in which intelligent machines, networked processes and big data are brought together. This virtual world has generated vast amount of data which is accelerating the adoption of machine learning solutions & practices. Machine Learning enables computers to imitate and adapt human-like behaviour. Using machine learning, each interaction, each action performed, becomes something the system can learn and use as experience for the next time. This work is an overview of this data analytics method which enables computers to learn and do what comes naturally to humans, i.e. learn from experience. It includes the preliminaries of machine learning, the definition, nomenclature and applications’ describing it’s what, how and why. The technology roadmap of machine learning is discussed to understand and verify its potential as a market & industry practice. The primary intent of this work is to give insight into why machine learning is the future."
  },
  {
    "paperId": "4135da4cc0ef70917e45ae4436e7a6411077325c",
    "title": "A Review of Machine Learning and Deep Learning Applications",
    "venue": "International Conference on Computing Communication Control and automation",
    "year": 2018,
    "citationCount": 491,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCUBEA.2018.8697857?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCUBEA.2018.8697857, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "108021414",
        "name": "Pramila Shinde"
      },
      {
        "authorId": "47973421",
        "name": "Seema Shah"
      }
    ],
    "abstract": "Machine learning is one of the fields in the modern computing world. A plenty of research has been undertaken to make machines intelligent. Learning is a natural human behavior which has been made an essential aspect of the machines as well. There are various techniques devised for the same. Traditional machine learning algorithms have been applied in many application areas. Researchers have put many efforts to improve the accuracy of that machinelearning algorithms. Another dimension was given thought which leads to deep learning concept. Deep learning is a subset of machine learning. So far few applications of deep learning have been explored. This is definitely going to cater to solving issues in several new application domains, sub-domains using deep learning. A review of these past and future application domains, sub-domains, and applications of machine learning and deep learning are illustrated in this paper."
  },
  {
    "paperId": "033c08ca48aaed2d5ab0a17d668d410538678ed8",
    "title": "Evasion Attacks against Machine Learning at Test Time",
    "venue": "ECML/PKDD",
    "year": 2013,
    "citationCount": 2238,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1708.06131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1684175",
        "name": "B. Biggio"
      },
      {
        "authorId": "2338858",
        "name": "Igino Corona"
      },
      {
        "authorId": "3248803",
        "name": "Davide Maiorca"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "2118348",
        "name": "Nedim Srndic"
      },
      {
        "authorId": "1754215",
        "name": "P. Laskov"
      },
      {
        "authorId": "1779484",
        "name": "G. Giacinto"
      },
      {
        "authorId": "1710171",
        "name": "F. Roli"
      }
    ],
    "abstract": "In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis."
  },
  {
    "paperId": "95274ca3be569765960464d24f898c6fe025bac9",
    "title": "Machine learning applications in cancer prognosis and prediction",
    "venue": "Computational and Structural Biotechnology Journal",
    "year": 2014,
    "citationCount": 2747,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.csbj.2014.11.005",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4348437, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1950395",
        "name": "Konstantina D. Kourou"
      },
      {
        "authorId": "1716899",
        "name": "T. Exarchos"
      },
      {
        "authorId": "2311834339",
        "name": "K. Exarchos"
      },
      {
        "authorId": "4575621",
        "name": "M. Karamouzis"
      },
      {
        "authorId": "1692818",
        "name": "D. Fotiadis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8285e1b5536ce11d55462ae757f61c75ec6773c6",
    "title": "The Frontiers of Fairness in Machine Learning",
    "venue": "arXiv.org",
    "year": 2018,
    "citationCount": 432,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.08810, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2359380327",
        "name": "Alexandra Chouldechova"
      },
      {
        "authorId": "1682008",
        "name": "Aaron Roth"
      }
    ],
    "abstract": "The last few years have seen an explosion of academic and popular interest in algorithmic fairness. Despite this interest and the volume and velocity of work that has been produced recently, the fundamental science of fairness in machine learning is still in a nascent state. In March 2018, we convened a group of experts as part of a CCC visioning workshop to assess the state of the field, and distill the most promising research directions going forward. This report summarizes the findings of that workshop. Along the way, it surveys recent theoretical work in the field and points towards promising directions for research."
  },
  {
    "paperId": "ffb9404d53b5cfcecf8fc7dbf85257c560f135a4",
    "title": "Machine learning in materials science",
    "venue": "InfoMat",
    "year": 2019,
    "citationCount": 619,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/inf2.12028",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/inf2.12028?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/inf2.12028, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2141564635",
        "name": "Jing Wei"
      },
      {
        "authorId": "2048654183",
        "name": "Xuan Chu"
      },
      {
        "authorId": "93425239",
        "name": "Xiangyu Sun"
      },
      {
        "authorId": "2113451966",
        "name": "Kun Xu"
      },
      {
        "authorId": "48470691",
        "name": "H. Deng"
      },
      {
        "authorId": "1940653397",
        "name": "Jigen Chen"
      },
      {
        "authorId": "6095903",
        "name": "Zhongming Wei"
      },
      {
        "authorId": "47805251",
        "name": "M. Lei"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1ed33896e82cc3810b349cdffc2039f0b8edd82e",
    "title": "Deep learning and its applications to machine health monitoring",
    "venue": "Mechanical systems and signal processing",
    "year": 2019,
    "citationCount": 2121,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.YMSSP.2018.05.050?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.YMSSP.2018.05.050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49832912",
        "name": "Rui Zhao"
      },
      {
        "authorId": "35374692",
        "name": "Ruqiang Yan"
      },
      {
        "authorId": "48354147",
        "name": "Zhenghua Chen"
      },
      {
        "authorId": "144067957",
        "name": "K. Mao"
      },
      {
        "authorId": "48319740",
        "name": "Peng Wang"
      },
      {
        "authorId": "1700762",
        "name": "R. Gao"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8fd8fe76b3fc76adb47b1f1597e2e182a8280225",
    "title": "Survey on SDN based network intrusion detection system using machine learning approaches",
    "venue": "Peer-to-Peer Networking and Applications",
    "year": 2018,
    "citationCount": 429,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s12083-017-0630-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s12083-017-0630-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9729107",
        "name": "N. Sultana"
      },
      {
        "authorId": "9219862",
        "name": "N. Chilamkurti"
      },
      {
        "authorId": "145439284",
        "name": "Wei Peng"
      },
      {
        "authorId": "51132514",
        "name": "Rabei Alhadad"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e689e16f439c3677c2b09c53b6e80238bc0153aa",
    "title": "Machine Learning Algorithms",
    "venue": "Optimization Techniques and Applications with Examples",
    "year": 2018,
    "citationCount": 456,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4842-3633-8_5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4842-3633-8_5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2485823",
        "name": "Vishnu S Pendyala"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fad1bd501aa769f7701c1016f8a4d1473ca77601",
    "title": "Machine Learning, Neural and Statistical Classification",
    "venue": "",
    "year": 2009,
    "citationCount": 2897,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1080/00401706.1995.10484383?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/00401706.1995.10484383, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145878706",
        "name": "D. Michie"
      },
      {
        "authorId": "48616434",
        "name": "D. Spiegelhalter"
      },
      {
        "authorId": "2115490664",
        "name": "Charles C. Taylor"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "66ce6a5b7f3e888f4ab75054bb9cf0271bb6f012",
    "title": "A strategy to apply machine learning to small datasets in materials science",
    "venue": "npj Computational Materials",
    "year": 2018,
    "citationCount": 607,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41524-018-0081-z.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41524-018-0081-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41524-018-0081-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153391511",
        "name": "Ying Zhang"
      },
      {
        "authorId": "2059987839",
        "name": "Chen Ling"
      }
    ],
    "abstract": "There is growing interest in applying machine learning techniques in the research of materials science. However, although it is recognized that materials datasets are typically smaller and sometimes more diverse compared to other fields, the influence of availability of materials data on training machine learning models has not yet been studied, which prevents the possibility to establish accurate predictive rules using small materials datasets. Here we analyzed the fundamental interplay between the availability of materials data and the predictive capability of machine learning models. Instead of affecting the model precision directly, the effect of data size is mediated by the degree of freedom (DoF) of model, resulting in the phenomenon of association between precision and DoF. The appearance of precision–DoF association signals the issue of underfitting and is characterized by large bias of prediction, which consequently restricts the accurate prediction in unknown domains. We proposed to incorporate the crude estimation of property in the feature space to establish ML models using small sized materials data, which increases the accuracy of prediction without the cost of higher DoF. In three case studies of predicting the band gap of binary semiconductors, lattice thermal conductivity, and elastic properties of zeolites, the integration of crude estimation effectively boosted the predictive capability of machine learning models to state-of-art levels, demonstrating the generality of the proposed strategy to construct accurate machine learning models using small materials dataset.MACHINE LEARNING: Dealing with small datasetsMachine learning can be useful for materials prediction if crude estimations of the outcome are integrated in the code. Machine learning has been attracting tremendous attention lately due to its predictive power; evidence suggests it is directly proportional to the size of the available datasets. Machine learning can be useful in predicting new materials and novel properties, but materials sets tend to be smaller and more diverse than other fields. Ying Zhang and Chen Ling from the Toyota Research Institute of North America report that these small datasets affect the freedom of the algorithms and thus limit their predictive capabilities. In order to counterbalance the effect, they suggest introducing in the code crude estimations of the targeted property, obtained by other means."
  },
  {
    "paperId": "1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c",
    "title": "The Marginal Value of Adaptive Gradient Methods in Machine Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 1090,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1705.08292, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144102853",
        "name": "Ashia C. Wilson"
      },
      {
        "authorId": "40458654",
        "name": "R. Roelofs"
      },
      {
        "authorId": "144872294",
        "name": "Mitchell Stern"
      },
      {
        "authorId": "1706280",
        "name": "N. Srebro"
      },
      {
        "authorId": "9229182",
        "name": "B. Recht"
      }
    ],
    "abstract": "Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks."
  },
  {
    "paperId": "f4c3315684cfd474c3d13ae4954de0dead5e81a3",
    "title": "Machine learning in cardiovascular medicine: are we there yet?",
    "venue": "Heart",
    "year": 2018,
    "citationCount": 412,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1136/heartjnl-2017-311198?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/heartjnl-2017-311198, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47189518",
        "name": "K. Shameer"
      },
      {
        "authorId": "10776200",
        "name": "Kipp W. Johnson"
      },
      {
        "authorId": "116603382",
        "name": "Benjamin S. Glicksberg"
      },
      {
        "authorId": "13964487",
        "name": "J. Dudley"
      },
      {
        "authorId": "2274738",
        "name": "P. Sengupta"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "441c31274f4535a4a50892c1ad6e19eacfd17f8c",
    "title": "Perspective: Machine learning potentials for atomistic simulations.",
    "venue": "Journal of Chemical Physics",
    "year": 2016,
    "citationCount": 1198,
    "openAccessPdf": {
      "url": "https://aip.scitation.org/doi/pdf/10.1063/1.4966192",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1063/1.4966192?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1063/1.4966192, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144136091",
        "name": "J. Behler"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a8797f1d253c75669d96e6fcceda2be3f8534e1d",
    "title": "Support Vector Machine Active Learning with Applications to Text Classification",
    "venue": "Journal of machine learning research",
    "year": 2000,
    "citationCount": 3492,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2058177533",
        "name": "Simon Tong"
      },
      {
        "authorId": "1736370",
        "name": "D. Koller"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3bc4c90a7bbc7badd47b78043cdf540144557efc",
    "title": "Machine Learning in Banking Risk Management: A Literature Review",
    "venue": "Risks",
    "year": 2019,
    "citationCount": 329,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2227-9091/7/1/29/pdf?version=1552043105",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/RISKS7010029?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/RISKS7010029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "65758874",
        "name": "M. Leo"
      },
      {
        "authorId": "2109864289",
        "name": "Suneel Sharma"
      },
      {
        "authorId": "31112068",
        "name": "K. Maddulety"
      }
    ],
    "abstract": "There is an increasing influence of machine learning in business applications, with many solutions already implemented and many more being explored. Since the global financial crisis, risk management in banks has gained more prominence, and there has been a constant focus around how risks are being detected, measured, reported and managed. Considerable research in academia and industry has focused on the developments in banking and risk management and the current and emerging challenges. This paper, through a review of the available literature seeks to analyse and evaluate machine-learning techniques that have been researched in the context of banking risk management, and to identify areas or problems in risk management that have been inadequately explored and are potential areas for further research. The review has shown that the application of machine learning in the management of banking risks such as credit risk, market risk, operational risk and liquidity risk has been explored; however, it doesn’t appear commensurate with the current industry level of focus on both risk management and machine learning. A large number of areas remain in bank risk management that could significantly benefit from the study of how machine learning can be applied to address specific problems."
  },
  {
    "paperId": "960ba564e9e598d864dff38d2f3d0bad1b319ead",
    "title": "A Survey of Machine Learning for Big Code and Naturalness",
    "venue": "ACM Computing Surveys",
    "year": 2017,
    "citationCount": 915,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3212695",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1709.06182, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3216345",
        "name": "Miltiadis Allamanis"
      },
      {
        "authorId": "1757975",
        "name": "Earl T. Barr"
      },
      {
        "authorId": "1730296",
        "name": "Premkumar T. Devanbu"
      },
      {
        "authorId": "37210858",
        "name": "Charles Sutton"
      }
    ],
    "abstract": "Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities."
  },
  {
    "paperId": "db8c3cfaae04a14c1209d62953029b6fa53e23c7",
    "title": "Challenges in representation learning: A report on three machine learning contests",
    "venue": "Neural Networks",
    "year": 2013,
    "citationCount": 1793,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1307.0414.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1307.0414, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "1761978",
        "name": "D. Erhan"
      },
      {
        "authorId": "153921980",
        "name": "P. Carrier"
      },
      {
        "authorId": "1760871",
        "name": "Aaron C. Courville"
      },
      {
        "authorId": "153583218",
        "name": "Mehdi Mirza"
      },
      {
        "authorId": "3033919",
        "name": "Benjamin Hamner"
      },
      {
        "authorId": "3155742",
        "name": "William J. Cukierski"
      },
      {
        "authorId": "34312504",
        "name": "Yichuan Tang"
      },
      {
        "authorId": "2060512985",
        "name": "David Thaler"
      },
      {
        "authorId": "2115475379",
        "name": "Dong-Hyun Lee"
      },
      {
        "authorId": "34872128",
        "name": "Yingbo Zhou"
      },
      {
        "authorId": "1764124",
        "name": "Chetan Ramaiah"
      },
      {
        "authorId": "39825530",
        "name": "Fangxiang Feng"
      },
      {
        "authorId": "2462591",
        "name": "Ruifan Li"
      },
      {
        "authorId": "38542466",
        "name": "Xiaojie Wang"
      },
      {
        "authorId": "19998730",
        "name": "Dimitris Athanasakis"
      },
      {
        "authorId": "1404459229",
        "name": "J. Shawe-Taylor"
      },
      {
        "authorId": "2449832",
        "name": "Maxim Milakov"
      },
      {
        "authorId": "2116009470",
        "name": "John Park"
      },
      {
        "authorId": "1817759",
        "name": "Radu Tudor Ionescu"
      },
      {
        "authorId": "49006356",
        "name": "M. Popescu"
      },
      {
        "authorId": "2599036",
        "name": "C. Grozea"
      },
      {
        "authorId": "32837403",
        "name": "J. Bergstra"
      },
      {
        "authorId": "2208516000",
        "name": "Jingjing Xie"
      },
      {
        "authorId": "1743912",
        "name": "Lukasz Romaszko"
      },
      {
        "authorId": "2113742925",
        "name": "Bing Xu"
      },
      {
        "authorId": "2118514062",
        "name": "Chuang Zhang"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f4c15e38073f22a600c84be9f5f799809f99712a",
    "title": "The Challenge of Machine Learning in Space Weather: Nowcasting and Forecasting",
    "venue": "Space Weather",
    "year": 2019,
    "citationCount": 293,
    "openAccessPdf": {
      "url": "https://ir.cwi.nl/pub/29285/29285.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.05192, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3142448",
        "name": "E. Camporeale"
      }
    ],
    "abstract": "The numerous recent breakthroughs in machine learning make imperative to carefully ponder how the scientific community can benefit from a technology that, although not necessarily new, is today living its golden age. This Grand Challenge review paper is focused on the present and future role of machine learning in Space Weather. The purpose is twofold. On one hand, we will discuss previous works that use machine learning for Space Weather forecasting, focusing in particular on the few areas that have seen most activity: the forecasting of geomagnetic indices, of relativistic electrons at geosynchronous orbits, of solar flares occurrence, of coronal mass ejection propagation time, and of solar wind speed. On the other hand, this paper serves as a gentle introduction to the field of machine learning tailored to the Space Weather community and as a pointer to a number of open challenges that we believe the community should undertake in the next decade. The recurring themes throughout the review are the need to shift our forecasting paradigm to a probabilistic approach focused on the reliable assessment of uncertainties, and the combination of physics‐based and machine learning approaches, known as gray box."
  },
  {
    "paperId": "4fb1202c313d6c221c51fc264e7f2a57b8bc4f1a",
    "title": "Machine learning and soil sciences: a review aided by machine learning tools",
    "venue": "The Soil",
    "year": 2019,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "https://soil.copernicus.org/articles/6/35/2020/soil-6-35-2020.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.5194/soil-2019-57?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5194/soil-2019-57, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2212261",
        "name": "J. Padarian"
      },
      {
        "authorId": "2526638",
        "name": "B. Minasny"
      },
      {
        "authorId": "2786192",
        "name": "A. McBratney"
      }
    ],
    "abstract": "Abstract. The application of machine learning (ML) techniques in various fields of science has increased rapidly, especially in the last 10 years. The increasing availability of soil data that can be efficiently acquired remotely and proximally, and freely available open-source algorithms, have led to an accelerated adoption of ML techniques to analyse soil data. Given the large number of publications, it is an impossible task to manually review all papers on the application of ML in soil science without narrowing down a narrative of ML application in a specific research question. This paper aims to provide a comprehensive review of the application of ML techniques in soil science aided by a ML algorithm (latent Dirichlet allocation) to find patterns in a large collection of text corpora. The objective is to gain insight into publications of ML applications in soil science and to discuss the research gaps in this topic. We found that (a) there is an increasing usage of ML methods in soil sciences, mostly concentrated in developed countries,\n(b) the reviewed publications can be grouped into 12 topics, namely remote sensing, soil organic carbon, water, contamination, methods (ensembles), erosion and parent material, methods (NN, neural networks, SVM, support vector machines), spectroscopy, modelling (classes), crops, physical, and modelling (continuous),\nand (c) advanced ML methods usually perform better than simpler approaches thanks to their capability to capture non-linear relationships.\nFrom these findings, we found research gaps, in particular, about the precautions that should be taken (parsimony) to avoid overfitting, and that the interpretability of the ML models is an important aspect to consider when applying advanced ML methods in order to improve our knowledge and understanding of soil. We foresee that a large number of studies will focus on the latter topic.\n"
  },
  {
    "paperId": "5b77625b30ab2fa8abf5c152831a6985a61516ee",
    "title": "Can machine-learning improve cardiovascular risk prediction using routine clinical data?",
    "venue": "PLoS ONE",
    "year": 2017,
    "citationCount": 1062,
    "openAccessPdf": {
      "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0174944&type=printable",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5380334, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8955394",
        "name": "S. Weng"
      },
      {
        "authorId": "2090454",
        "name": "J. Reps"
      },
      {
        "authorId": "3428487",
        "name": "J. Kai"
      },
      {
        "authorId": "145890843",
        "name": "J. Garibaldi"
      },
      {
        "authorId": "4757323",
        "name": "N. Qureshi"
      }
    ],
    "abstract": "Background Current approaches to predict cardiovascular risk fail to identify many people who would benefit from preventive treatment, while others receive unnecessary intervention. Machine-learning offers opportunity to improve accuracy by exploiting complex interactions between risk factors. We assessed whether machine-learning can improve cardiovascular risk prediction. Methods Prospective cohort study using routine clinical data of 378,256 patients from UK family practices, free from cardiovascular disease at outset. Four machine-learning algorithms (random forest, logistic regression, gradient boosting machines, neural networks) were compared to an established algorithm (American College of Cardiology guidelines) to predict first cardiovascular event over 10-years. Predictive accuracy was assessed by area under the ‘receiver operating curve’ (AUC); and sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) to predict 7.5% cardiovascular risk (threshold for initiating statins). Findings 24,970 incident cardiovascular events (6.6%) occurred. Compared to the established risk prediction algorithm (AUC 0.728, 95% CI 0.723–0.735), machine-learning algorithms improved prediction: random forest +1.7% (AUC 0.745, 95% CI 0.739–0.750), logistic regression +3.2% (AUC 0.760, 95% CI 0.755–0.766), gradient boosting +3.3% (AUC 0.761, 95% CI 0.755–0.766), neural networks +3.6% (AUC 0.764, 95% CI 0.759–0.769). The highest achieving (neural networks) algorithm predicted 4,998/7,404 cases (sensitivity 67.5%, PPV 18.4%) and 53,458/75,585 non-cases (specificity 70.7%, NPV 95.7%), correctly predicting 355 (+7.6%) more patients who developed cardiovascular disease compared to the established algorithm. Conclusions Machine-learning significantly improves accuracy of cardiovascular risk prediction, increasing the number of patients identified who could benefit from preventive treatment, while avoiding unnecessary treatment of others."
  },
  {
    "paperId": "bb0bec2f6836b97af51f280eb77895e7170f47c9",
    "title": "Machine learning at the energy and intensity frontiers of particle physics",
    "venue": "Nature",
    "year": 2018,
    "citationCount": 415,
    "openAccessPdf": {
      "url": "https://www.osti.gov/biblio/1469751",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41586-018-0361-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41586-018-0361-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40189320",
        "name": "A. Radovic"
      },
      {
        "authorId": "143615527",
        "name": "Mike Williams"
      },
      {
        "authorId": "3200334",
        "name": "D. Rousseau"
      },
      {
        "authorId": "11413078",
        "name": "M. Kagan"
      },
      {
        "authorId": "2434951",
        "name": "D. Bonacorsi"
      },
      {
        "authorId": "72835228",
        "name": "A. Himmel"
      },
      {
        "authorId": "145435602",
        "name": "A. Aurisano"
      },
      {
        "authorId": "102645858",
        "name": "K. Terao"
      },
      {
        "authorId": "2304452495",
        "name": "T. Wongjirad"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "dd41d656e21c30dd761bee2eba303d1aa014d120",
    "title": "Machine Learning Paradigms for Next-Generation Wireless Networks",
    "venue": "IEEE wireless communications",
    "year": 2017,
    "citationCount": 963,
    "openAccessPdf": {
      "url": "https://eprints.soton.ac.uk/403861/1/WirelessMag_Hanzo-rev1.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MWC.2016.1500356WC?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MWC.2016.1500356WC, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1750017",
        "name": "Chunxiao Jiang"
      },
      {
        "authorId": "50024622",
        "name": "Haijun Zhang"
      },
      {
        "authorId": "145659296",
        "name": "Yong Ren"
      },
      {
        "authorId": "145169163",
        "name": "Zhu Han"
      },
      {
        "authorId": "66073306",
        "name": "Kwang-Cheng Chen"
      },
      {
        "authorId": "1730180",
        "name": "L. Hanzo"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "741b11606c2fb3167c756b3d8fd2d39e060b11f9",
    "title": "Machine Learning for Medical Imaging.",
    "venue": "Radiographics",
    "year": 2017,
    "citationCount": 947,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5375621",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1148/rg.2017160130?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1148/rg.2017160130, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144917634",
        "name": "B. Erickson"
      },
      {
        "authorId": "1986491",
        "name": "P. Korfiatis"
      },
      {
        "authorId": "2015410",
        "name": "Z. Akkus"
      },
      {
        "authorId": "4729578",
        "name": "T. Kline"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e3f8c8253767b6fe0891025cdf772cd286337921",
    "title": "A Proposal on Machine Learning via Dynamical Systems",
    "venue": "Communications in Mathematics and Statistics",
    "year": 2017,
    "citationCount": 824,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40304-017-0103-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40304-017-0103-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2255989653",
        "name": "Weinan E"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9873d43696165b50fab955d27b9dde838c0a0152",
    "title": "Machine learning applications in genetics and genomics",
    "venue": "Nature reviews genetics",
    "year": 2015,
    "citationCount": 1634,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5204302",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/nrg3920?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/nrg3920, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2342524",
        "name": "Maxwell W. Libbrecht"
      },
      {
        "authorId": "144458655",
        "name": "William Stafford Noble"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7b13474bf99b8fd20ee67cef5d76a9b298932ac4",
    "title": "Machine learning in chemoinformatics and drug discovery.",
    "venue": "Drug Discovery Today",
    "year": 2018,
    "citationCount": 720,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.drudis.2018.05.010",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.drudis.2018.05.010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.drudis.2018.05.010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2316213",
        "name": "Yu-Chen Lo"
      },
      {
        "authorId": "5662611",
        "name": "Stefano E. Rensi"
      },
      {
        "authorId": "4965649",
        "name": "Wen Torng"
      },
      {
        "authorId": "144446128",
        "name": "R. Altman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3f22c9462f8e588ce4210a304133e2265f41d913",
    "title": "Artificial Intelligence and Machine Learning in Pathology: The Present Landscape of Supervised Methods",
    "venue": "Academic Pathology",
    "year": 2019,
    "citationCount": 286,
    "openAccessPdf": {
      "url": "https://journals.sagepub.com/doi/pdf/10.1177/2374289519873088",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6727099, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "31682040",
        "name": "H. Rashidi"
      },
      {
        "authorId": "144026292",
        "name": "N. Tran"
      },
      {
        "authorId": "83007327",
        "name": "E. Betts"
      },
      {
        "authorId": "5788528",
        "name": "L. Howell"
      },
      {
        "authorId": "2072877937",
        "name": "Ralph Green"
      }
    ],
    "abstract": "Increased interest in the opportunities provided by artificial intelligence and machine learning has spawned a new field of health-care research. The new tools under development are targeting many aspects of medical practice, including changes to the practice of pathology and laboratory medicine. Optimal design in these powerful tools requires cross-disciplinary literacy, including basic knowledge and understanding of critical concepts that have traditionally been unfamiliar to pathologists and laboratorians. This review provides definitions and basic knowledge of machine learning categories (supervised, unsupervised, and reinforcement learning), introduces the underlying concept of the bias-variance trade-off as an important foundation in supervised machine learning, and discusses approaches to the supervised machine learning study design along with an overview and description of common supervised machine learning algorithms (linear regression, logistic regression, Naive Bayes, k-nearest neighbor, support vector machine, random forest, convolutional neural networks)."
  },
  {
    "paperId": "50684b147b752a07c313cb73d864f7b21bd8b703",
    "title": "Scaling Distributed Machine Learning with the Parameter Server",
    "venue": "USENIX Symposium on Operating Systems Design and Implementation",
    "year": 2014,
    "citationCount": 1856,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2124778071",
        "name": "Mu Li"
      },
      {
        "authorId": "34752743",
        "name": "D. Andersen"
      },
      {
        "authorId": "2115992237",
        "name": "J. Park"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      },
      {
        "authorId": "50731654",
        "name": "Amr Ahmed"
      },
      {
        "authorId": "1679460",
        "name": "V. Josifovski"
      },
      {
        "authorId": "2117316446",
        "name": "James Long"
      },
      {
        "authorId": "2915064",
        "name": "E. Shekita"
      },
      {
        "authorId": "6231754",
        "name": "Bor-Yiing Su"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fdd025e077a36166b10120b448d0c4e4009824a9",
    "title": "Model-Agnostic Interpretability of Machine Learning",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 902,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.05386, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "78846919",
        "name": "Marco Tulio Ribeiro"
      },
      {
        "authorId": "34650964",
        "name": "Sameer Singh"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      }
    ],
    "abstract": "Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges."
  },
  {
    "paperId": "36d6e7ccf43166107153700d99a87af58684ebc0",
    "title": "Machine learning and complex biological data",
    "venue": "Genome Biology",
    "year": 2019,
    "citationCount": 275,
    "openAccessPdf": {
      "url": "https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-019-1689-0",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6469083, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7521190",
        "name": "Chunming Xu"
      },
      {
        "authorId": "2495697",
        "name": "S. Jackson"
      }
    ],
    "abstract": "Machine learning has demonstrated potential in analyzing large, complex biological data. In practice, however, biological information is required in addition to machine learning for successful application."
  },
  {
    "paperId": "be1496e9620089b377ef631692478f5034ee95b8",
    "title": "Machine learning applications in epilepsy",
    "venue": "Epilepsia",
    "year": 2019,
    "citationCount": 284,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9897263",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1111/epi.16333?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/epi.16333, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48487599",
        "name": "B. Abbasi"
      },
      {
        "authorId": "2423726",
        "name": "D. Goldenholz"
      }
    ],
    "abstract": "Machine learning leverages statistical and computer science principles to develop algorithms capable of improving performance through interpretation of data rather than through explicit instructions. Alongside widespread use in image recognition, language processing, and data mining, machine learning techniques have received increasing attention in medical applications, ranging from automated imaging analysis to disease forecasting. This review examines the parallel progress made in epilepsy, highlighting applications in automated seizure detection from electroencephalography (EEG), video, and kinetic data, automated imaging analysis and pre‐surgical planning, prediction of medication response, and prediction of medical and surgical outcomes using a wide variety of data sources. A brief overview of commonly used machine learning approaches, as well as challenges in further application of machine learning techniques in epilepsy, is also presented. With increasing computational capabilities, availability of effective machine learning algorithms, and accumulation of larger datasets, clinicians and researchers will increasingly benefit from familiarity with these techniques and the significant progress already made in their application in epilepsy."
  },
  {
    "paperId": "2a944564c2466883ec14a6f6ef461f0e34d21b38",
    "title": "Fairness in Machine Learning: Lessons from Political Philosophy",
    "venue": "FAT",
    "year": 2017,
    "citationCount": 788,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1712.03586, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144147883",
        "name": "Reuben Binns"
      }
    ],
    "abstract": "What does it mean for a machine learning model to be `fair', in terms which can be operationalised? Should fairness consist of ensuring everyone has an equal probability of obtaining some benefit, or should we aim instead to minimise the harms to the least advantaged? Can the relevant ideal be determined by reference to some alternative state of affairs in which a particular social pattern of discrimination does not exist? Various definitions proposed in recent literature make different assumptions about what terms like discrimination and fairness mean and how they can be defined in mathematical terms. Questions of discrimination, egalitarianism and justice are of significant interest to moral and political philosophers, who have expended significant efforts in formalising and defending these central concepts. It is therefore unsurprising that attempts to formalise `fairness' in machine learning contain echoes of these old philosophical debates. This paper draws on existing work in moral and political philosophy in order to elucidate emerging debates about fair machine learning."
  },
  {
    "paperId": "765d93759b7888fa1f7b2f3576809ad558c60caf",
    "title": "Machine-learning-assisted materials discovery using failed experiments",
    "venue": "Nature",
    "year": 2016,
    "citationCount": 1356,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/nature17439?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/nature17439, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3430287",
        "name": "Paul Raccuglia"
      },
      {
        "authorId": "5219966",
        "name": "Katherine C. Elbert"
      },
      {
        "authorId": "2058592864",
        "name": "Philip Adler"
      },
      {
        "authorId": "38601860",
        "name": "Casey Falk"
      },
      {
        "authorId": "9616758",
        "name": "Malia B. Wenny"
      },
      {
        "authorId": "48742335",
        "name": "Aurelio Mollo"
      },
      {
        "authorId": "1885911",
        "name": "M. Zeller"
      },
      {
        "authorId": "34597147",
        "name": "Sorelle A. Friedler"
      },
      {
        "authorId": "49916345",
        "name": "Joshua Schrier"
      },
      {
        "authorId": "5787497",
        "name": "A. Norquist"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1eb131a34fbb508a9dd8b646950c65901d6f1a5b",
    "title": "Hidden Technical Debt in Machine Learning Systems",
    "venue": "Neural Information Processing Systems",
    "year": 2015,
    "citationCount": 1207,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1733143",
        "name": "D. Sculley"
      },
      {
        "authorId": "144510728",
        "name": "Gary Holt"
      },
      {
        "authorId": "145973657",
        "name": "D. Golovin"
      },
      {
        "authorId": "143698521",
        "name": "Eugene Davydov"
      },
      {
        "authorId": "2054375101",
        "name": "Todd Phillips"
      },
      {
        "authorId": "49236095",
        "name": "D. Ebner"
      },
      {
        "authorId": "2055477158",
        "name": "Vinay Chaudhary"
      },
      {
        "authorId": "2114084357",
        "name": "Michael Young"
      },
      {
        "authorId": "40169157",
        "name": "Jean-François Crespo"
      },
      {
        "authorId": "47019745",
        "name": "Dan Dennison"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b3928729e3501c5b304211092b6406c7d1d555a3",
    "title": "Machine Learning Techniques for Biomedical Image Segmentation: An Overview of Technical Aspects and Introduction to State-of-Art Applications",
    "venue": "Medical Physics (Lancaster)",
    "year": 2019,
    "citationCount": 252,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338207",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.02521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2065447089",
        "name": "Hyunseok Seo"
      },
      {
        "authorId": "3242040",
        "name": "M. B. Khuzani"
      },
      {
        "authorId": "32040356",
        "name": "V. Vasudevan"
      },
      {
        "authorId": "1688082",
        "name": "Charles Huang"
      },
      {
        "authorId": "2081764",
        "name": "Hongyi Ren"
      },
      {
        "authorId": "2198145",
        "name": "Ruoxiu Xiao"
      },
      {
        "authorId": "2059151",
        "name": "Xiao Jia"
      },
      {
        "authorId": "144218954",
        "name": "Lei Xing"
      }
    ],
    "abstract": "In recent years, significant progress has been made in developing more accurate and efficient machine learning algorithms for segmentation of medical and natural images. In this review article, we highlight the imperative role of machine learning algorithms in enabling efficient and accurate segmentation in the field of medical imaging. We specifically focus on several key studies pertaining to the application of machine learning methods to biomedical image segmentation. We review classical machine learning algorithms such as Markov random fields, k-means clustering, random forest, etc. Although such classical learning models are often less accurate compared to the deep-learning techniques, they are often more sample efficient and have a less complex structure. We also review different deep-learning architectures, such as the artificial neural networks (ANNs), the convolutional neural networks (CNNs), and the recurrent neural networks (RNNs), and present the segmentation results attained by those learning models that were published in the past 3 yr. We highlight the successes and limitations of each machine learning paradigm. In addition, we discuss several challenges related to the training of different machine learning models, and we present some heuristics to address those challenges."
  },
  {
    "paperId": "db4d0e45560ceda35b6212036513bd4ab59ce99d",
    "title": "SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient",
    "venue": "International Conference on Machine Learning",
    "year": 2017,
    "citationCount": 660,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.00102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144274166",
        "name": "Lam M. Nguyen"
      },
      {
        "authorId": "2146651544",
        "name": "Jie Liu"
      },
      {
        "authorId": "2005127",
        "name": "K. Scheinberg"
      },
      {
        "authorId": "144696183",
        "name": "Martin Takác"
      }
    ],
    "abstract": "In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems. Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients. The linear convergence rate of SARAH is proven under strong convexity assumption. We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess. Numerical experiments demonstrate the efficiency of our algorithm."
  },
  {
    "paperId": "bab1753d993c0c028a0fa729569b8c1528af4fe8",
    "title": "TensorFlow.js: Machine Learning for the Web and Beyond",
    "venue": "USENIX workshop on Tackling computer systems problems with machine learning techniques",
    "year": 2019,
    "citationCount": 180,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1901.05350, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2842148",
        "name": "D. Smilkov"
      },
      {
        "authorId": "144203200",
        "name": "Nikhil Thorat"
      },
      {
        "authorId": "2867282",
        "name": "Yannick Assogba"
      },
      {
        "authorId": "2061016887",
        "name": "Ann Yuan"
      },
      {
        "authorId": "66420904",
        "name": "Nick Kreeger"
      },
      {
        "authorId": "144909203",
        "name": "Ping Yu"
      },
      {
        "authorId": "2145459759",
        "name": "Kangyi Zhang"
      },
      {
        "authorId": "49406880",
        "name": "Shanqing Cai"
      },
      {
        "authorId": "2055012116",
        "name": "Eric Nielsen"
      },
      {
        "authorId": "46773550",
        "name": "David Soergel"
      },
      {
        "authorId": "1747918",
        "name": "S. Bileschi"
      },
      {
        "authorId": "49427600",
        "name": "Michael Terry"
      },
      {
        "authorId": "2053019791",
        "name": "Charles Nicholson"
      },
      {
        "authorId": "2118973495",
        "name": "Sandeep N. Gupta"
      },
      {
        "authorId": "39876485",
        "name": "S. Sirajuddin"
      },
      {
        "authorId": "1733143",
        "name": "D. Sculley"
      },
      {
        "authorId": "3089272",
        "name": "R. Monga"
      },
      {
        "authorId": "32131713",
        "name": "G. Corrado"
      },
      {
        "authorId": "1765169",
        "name": "F. Viégas"
      },
      {
        "authorId": "145233583",
        "name": "M. Wattenberg"
      }
    ],
    "abstract": "TensorFlow.js is a library for building and executing machine learning algorithms in JavaScript. TensorFlow.js models run in a web browser and in the Node.js environment. The library is part of the TensorFlow ecosystem, providing a set of APIs that are compatible with those in Python, allowing models to be ported between the Python and JavaScript ecosystems. TensorFlow.js has empowered a new set of developers from the extensive JavaScript community to build and deploy machine learning models and enabled new classes of on-device computation. This paper describes the design, API, and implementation of TensorFlow.js, and highlights some of the impactful use cases."
  },
  {
    "paperId": "63b1f74bb56d2a1eed5cc61426975f244afc70d0",
    "title": "Machine learning for composite materials",
    "venue": "MRS Communications",
    "year": 2019,
    "citationCount": 246,
    "openAccessPdf": {
      "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F54F60AC0048291BA47E0B671733ED15/S2159685919000326a.pdf/div-class-title-machine-learning-for-composite-materials-div.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1557/mrc.2019.32?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1557/mrc.2019.32, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153246325",
        "name": "Chun-Teh Chen"
      },
      {
        "authorId": "11329466",
        "name": "Grace X. Gu"
      }
    ],
    "abstract": "Machine learning (ML) has been perceived as a promising tool for the design and discovery of novel materials for a broad range of applications. In this prospective paper, we summarize recent progress in the applications of ML to composite materials modeling and design. An overview of how different types of ML algorithms can be applied to accelerate composite research is presented. This framework is envisioned to revolutionize approaches to design and optimize composites for the next generation of materials with unprecedented properties."
  },
  {
    "paperId": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd",
    "title": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning",
    "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
    "year": 2014,
    "citationCount": 1611,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2541940.2541967?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2541940.2541967, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144049725",
        "name": "Tianshi Chen"
      },
      {
        "authorId": "1678776",
        "name": "Zidong Du"
      },
      {
        "authorId": "145550877",
        "name": "Ninghui Sun"
      },
      {
        "authorId": "2110368816",
        "name": "Jia Wang"
      },
      {
        "authorId": "7514065",
        "name": "Chengyong Wu"
      },
      {
        "authorId": "7377735",
        "name": "Yunji Chen"
      },
      {
        "authorId": "1731764",
        "name": "O. Temam"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c7ce37d51ba01e17c9291f1dbf2ca8223b948b7f",
    "title": "Machine learning for Internet of Things data analysis: A survey",
    "venue": "Digit. Commun. Networks",
    "year": 2017,
    "citationCount": 933,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.dcan.2017.10.002",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.06305, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35838436",
        "name": "Mohammad Saeid Mahdavinejad"
      },
      {
        "authorId": "143976214",
        "name": "M. Rezvan"
      },
      {
        "authorId": "39393520",
        "name": "M. Barekatain"
      },
      {
        "authorId": "49277935",
        "name": "Peyman Adibi"
      },
      {
        "authorId": "1740880",
        "name": "P. Barnaghi"
      },
      {
        "authorId": "144463965",
        "name": "A. Sheth"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9d46dc975aeed3f96bddb144079b50238f746ecd",
    "title": "Machine learning in manufacturing: advantages, challenges, and applications",
    "venue": "",
    "year": 2016,
    "citationCount": 1100,
    "openAccessPdf": {
      "url": "https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/21693277.2016.1192517?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/21693277.2016.1192517, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2511781",
        "name": "Thorsten Wuest"
      },
      {
        "authorId": "2051446256",
        "name": "Daniel Weimer"
      },
      {
        "authorId": "1852549",
        "name": "C. Irgens"
      },
      {
        "authorId": "144199043",
        "name": "K. Thoben"
      }
    ],
    "abstract": "The nature of manufacturing systems faces ever more complex, dynamic and at times even chaotic behaviors. In order to being able to satisfy the demand for high-quality products in an efficient manner, it is essential to utilize all means available. One area, which saw fast pace developments in terms of not only promising results but also usability, is machine learning. Promising an answer to many of the old and new challenges of manufacturing, machine learning is widely discussed by researchers and practitioners alike. However, the field is very broad and even confusing which presents a challenge and a barrier hindering wide application. Here, this paper contributes in presenting an overview of available machine learning techniques and structuring this rather complicated area. A special focus is laid on the potential benefit, and examples of successful applications in a manufacturing environment."
  },
  {
    "paperId": "959c9dbfceda3825787f75f63fd7c87f332dc271",
    "title": "Machine Learning-Based Sentiment Analysis for Twitter Accounts",
    "venue": "",
    "year": 2018,
    "citationCount": 384,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2297-8747/23/1/11/pdf?version=1521536262",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/MCA23010011?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/MCA23010011, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152757679",
        "name": "A. Hasan"
      },
      {
        "authorId": "2069268061",
        "name": "Sana Moin"
      },
      {
        "authorId": "145867316",
        "name": "Ahmad Karim"
      },
      {
        "authorId": "1758091",
        "name": "Shahaboddin Shamshirband"
      }
    ],
    "abstract": "Growth in the area of opinion mining and sentiment analysis has been rapid and aims to explore the opinions or text present on different platforms of social media through machine-learning techniques with sentiment, subjectivity analysis or polarity calculations. Despite the use of various machine-learning techniques and tools for sentiment analysis during elections, there is a dire need for a state-of-the-art approach. To deal with these challenges, the contribution of this paper includes the adoption of a hybrid approach that involves a sentiment analyzer that includes machine learning. Moreover, this paper also provides a comparison of techniques of sentiment analysis in the analysis of political views by applying supervised machine-learning algorithms such as Naive Bayes and support vector machines (SVM)."
  },
  {
    "paperId": "3d6f1561f0bb29add7cbe56fac9040039a69eb92",
    "title": "A survey on evolutionary machine learning",
    "venue": "Journal of the Royal Society of New Zealand",
    "year": 2019,
    "citationCount": 202,
    "openAccessPdf": {
      "url": "https://figshare.com/articles/journal_contribution/A_Survey_on_Evolutionary_Machine_Learning/12493928/1/files/27353930.pdf",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/03036758.2019.1609052?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/03036758.2019.1609052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1403017303",
        "name": "Harith Al-Sahaf"
      },
      {
        "authorId": "151479922",
        "name": "Ying Bi"
      },
      {
        "authorId": "2115813273",
        "name": "Qi Chen"
      },
      {
        "authorId": "144320047",
        "name": "Andrew Lensen"
      },
      {
        "authorId": "144789032",
        "name": "Yi Mei"
      },
      {
        "authorId": "2145378606",
        "name": "Yanan Sun"
      },
      {
        "authorId": "145856310",
        "name": "Binh Tran"
      },
      {
        "authorId": "144395433",
        "name": "Bing Xue"
      },
      {
        "authorId": "145269712",
        "name": "Mengjie Zhang"
      }
    ],
    "abstract": "ABSTRACT Artificial intelligence (AI) emphasises the creation of intelligent machines/systems that function like humans. AI has been applied to many real-world applications. Machine learning is a branch of AI based on the idea that systems can learn from data, identify hidden patterns, and make decisions with little/minimal human intervention. Evolutionary computation is an umbrella of population-based intelligent/learning algorithms inspired by nature, where New Zealand has a good international reputation. This paper provides a review on evolutionary machine learning, i.e. evolutionary computation techniques for major machine learning tasks such as classification, regression and clustering, and emerging topics including combinatorial optimisation, computer vision, deep learning, transfer learning, and ensemble learning. The paper also provides a brief review of evolutionary learning applications, such as supply chain and manufacturing for milk/dairy, wine and seafood industries, which are important to New Zealand. Finally, the paper presents current issues with future perspectives in evolutionary machine learning."
  },
  {
    "paperId": "0fa45cfa88ee9ac93cb01ec159ad8713d0e32d93",
    "title": "Data Mining: Practical Machine Learning Tools and Techniques, 3/E",
    "venue": "",
    "year": 2014,
    "citationCount": 1269,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "9419406",
        "name": "I. Witten"
      },
      {
        "authorId": "1767318",
        "name": "E. Frank"
      },
      {
        "authorId": "118860642",
        "name": "M. Hall"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1c3752586e7d746b13eb5b2784ac9fe53756b7fd",
    "title": "Attractor reconstruction by machine learning.",
    "venue": "Chaos",
    "year": 2018,
    "citationCount": 368,
    "openAccessPdf": {
      "url": "https://aip.scitation.org/doi/10.1063/1.5039508",
      "status": "HYBRID",
      "license": "publisher-specific, author manuscript",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1805.03362, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34949672",
        "name": "Zhixin Lu"
      },
      {
        "authorId": "1868698",
        "name": "B. Hunt"
      },
      {
        "authorId": "144596753",
        "name": "E. Ott"
      }
    ],
    "abstract": "A machine-learning approach called \"reservoir computing\" has been used successfully for short-term prediction and attractor reconstruction of chaotic dynamical systems from time series data. We present a theoretical framework that describes conditions under which reservoir computing can create an empirical model capable of skillful short-term forecasts and accurate long-term ergodic behavior. We illustrate this theory through numerical experiments. We also argue that the theory applies to certain other machine learning methods for time series prediction."
  },
  {
    "paperId": "5939ac3b5a9d64d8371ee179751351d7698637df",
    "title": "Using Machine Learning to Advance Personality Assessment and Theory",
    "venue": "Personality and Social Psychology Review",
    "year": 2019,
    "citationCount": 190,
    "openAccessPdf": {
      "url": "https://www.zora.uzh.ch/id/eprint/205990/1/Bleidorn_%26_Hopwood_%28in_press%29.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1177/1088868318772990?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/1088868318772990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5199283",
        "name": "W. Bleidorn"
      },
      {
        "authorId": "2066036",
        "name": "C. Hopwood"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2d57b38ff6fa651cc932a29f0c7ca72e9f7a8cf9",
    "title": "Data Validation for Machine Learning",
    "venue": "USENIX workshop on Tackling computer systems problems with machine learning techniques",
    "year": 2019,
    "citationCount": 323,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1798895",
        "name": "Eric Breck"
      },
      {
        "authorId": "1763100",
        "name": "N. Polyzotis"
      },
      {
        "authorId": "144762442",
        "name": "Sudip Roy"
      },
      {
        "authorId": "3288247",
        "name": "Steven Euijong Whang"
      },
      {
        "authorId": "8195063",
        "name": "Martin A. Zinkevich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c9887b9e16380884f2ba6568669883884163551a",
    "title": "Machine learning for image based species identification",
    "venue": "Methods in Ecology and Evolution",
    "year": 2018,
    "citationCount": 365,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/2041-210X.13075",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1111/2041-210X.13075?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/2041-210X.13075, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50602098",
        "name": "Jana Wäldchen"
      },
      {
        "authorId": "35215848",
        "name": "Patrick Mäder"
      }
    ],
    "abstract": "Accurate species identification is the basis for all aspects of taxonomic research and is an essential component of workflows in biological research. Biologists are asking for more efficient methods to meet the identification demand. Smart mobile devices, digital cameras as well as the mass digitisation of natural history collections led to an explosion of openly available image data depicting living organisms. This rapid increase in biological image data in combination with modern machine learning methods, such as deep learning, offers tremendous opportunities for automated species identification. In this paper, we focus on deep learning neural networks as a technology that enabled breakthroughs in automated species identification in the last 2 years. In order to stimulate more work in this direction, we provide a brief overview of machine learning frameworks applicable to the species identification problem. We review selected deep learning approaches for image based species identification and introduce publicly available applications. Eventually, this article aims to provide insights into the current state‐of‐the‐art in automated identification and to serve as a starting point for researchers willing to apply novel machine learning techniques in their biological studies. While modern machine learning approaches only slowly pave their way into the field of species identification, we argue that we are going to see a proliferation of these techniques being applied to the problem in the future. Artificial intelligence systems will provide alternative tools for taxonomic identification in the near future."
  },
  {
    "paperId": "cd71e73e7377b3acdc09bf5732fce65414548100",
    "title": "Ten quick tips for machine learning in computational biology",
    "venue": "BioData Mining",
    "year": 2017,
    "citationCount": 747,
    "openAccessPdf": {
      "url": "https://biodatamining.biomedcentral.com/track/pdf/10.1186/s13040-017-0155-3",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5721660, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1702328",
        "name": "D. Chicco"
      }
    ],
    "abstract": "Machine learning has become a pivotal tool for many projects in computational biology, bioinformatics, and health informatics. Nevertheless, beginners and biomedical researchers often do not have enough experience to run a data mining project effectively, and therefore can follow incorrect practices, that may lead to common mistakes or over-optimistic results. With this review, we present ten quick tips to take advantage of machine learning in any computational biology context, by avoiding some common errors that we observed hundreds of times in multiple bioinformatics projects. We believe our ten suggestions can strongly help any machine learning practitioner to carry on a successful project in computational biology and related sciences."
  },
  {
    "paperId": "a7f8b8e6124901c1e22e940092e87b5b93776ab3",
    "title": "Machine Learning With Big Data: Challenges and Approaches",
    "venue": "IEEE Access",
    "year": 2017,
    "citationCount": 781,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/access.2017.2696365",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2017.2696365?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2017.2696365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1401702869",
        "name": "Alexandra L’Heureux"
      },
      {
        "authorId": "2257293214",
        "name": "Katarina Grolinger"
      },
      {
        "authorId": "3193379",
        "name": "H. ElYamany"
      },
      {
        "authorId": "1711826",
        "name": "Miriam A. M. Capretz"
      }
    ],
    "abstract": "The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data."
  },
  {
    "paperId": "f615bd164110160e160c98f59d7bfcc931a3cdc1",
    "title": "Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution",
    "venue": "Web Search and Data Mining",
    "year": 2018,
    "citationCount": 343,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1801.04016",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1801.04016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145430701",
        "name": "J. Pearl"
      }
    ],
    "abstract": "Current machine learning systems operate, almost exclusively, in a statistical, or model-blind mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal inference."
  },
  {
    "paperId": "38753ed76cca05bcdb95a1ce8bb8743ff3ae52b8",
    "title": "Review: machine learning techniques applied to cybersecurity",
    "venue": "International Journal of Machine Learning and Cybernetics",
    "year": 2019,
    "citationCount": 160,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-018-00906-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-018-00906-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1394457268",
        "name": "J. Martínez Torres"
      },
      {
        "authorId": "1557402968",
        "name": "Carla Iglesias Comesaña"
      },
      {
        "authorId": "115479287",
        "name": "P. J. García–Nieto"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1ce15f4a83706b877e86f29549920651a888b144",
    "title": "Data Mining and Analytics in the Process Industry: The Role of Machine Learning",
    "venue": "IEEE Access",
    "year": 2017,
    "citationCount": 721,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/access.2017.2756872",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2017.2756872?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2017.2756872, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145619185",
        "name": "Zhiqiang Ge"
      },
      {
        "authorId": "2554622",
        "name": "Zhihuan Song"
      },
      {
        "authorId": "144558270",
        "name": "S. Ding"
      },
      {
        "authorId": "144466701",
        "name": "Biao Huang"
      }
    ],
    "abstract": "Data mining and analytics have played an important role in knowledge discovery and decision making/supports in the process industry over the past several decades. As a computational engine to data mining and analytics, machine learning serves as basic tools for information extraction, data pattern recognition and predictions. From the perspective of machine learning, this paper provides a review on existing data mining and analytics applications in the process industry over the past several decades. The state-of-the-art of data mining and analytics are reviewed through eight unsupervised learning and ten supervised learning algorithms, as well as the application status of semi-supervised learning algorithms. Several perspectives are highlighted and discussed for future researches on data mining and analytics in the process industry."
  },
  {
    "paperId": "c0eb2d5d65ecc27cb00501bffdcc55167c61cfe0",
    "title": "What can machine learning do? Workforce implications",
    "venue": "Science",
    "year": 2017,
    "citationCount": 793,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aap8062?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aap8062, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2841157",
        "name": "Erik Brynjolfsson"
      },
      {
        "authorId": "144135485",
        "name": "Tom M. Mitchell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "86d7ef18644c45f9417239907daeba1b61dc8185",
    "title": "Machine Learning and Data Mining Methods in Diabetes Research",
    "venue": "Computational and Structural Biotechnology Journal",
    "year": 2017,
    "citationCount": 1127,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.csbj.2016.12.005",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5257026, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2386640",
        "name": "Ioannis Kavakiotis"
      },
      {
        "authorId": "3459938",
        "name": "O. Tsave"
      },
      {
        "authorId": "3459934",
        "name": "A. Salifoglou"
      },
      {
        "authorId": "144338063",
        "name": "N. Maglaveras"
      },
      {
        "authorId": "1697941",
        "name": "I. Vlahavas"
      },
      {
        "authorId": "1935587",
        "name": "I. Chouvarda"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "73811a7f8b89de1b8bdad6bb938e58059a9076d3",
    "title": "Introduction to machine learning: k-nearest neighbors.",
    "venue": "Annals of Translational Medicine",
    "year": 2016,
    "citationCount": 936,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc4916348?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.21037/atm.2016.03.37?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21037/atm.2016.03.37, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7969555",
        "name": "Wentao Bao"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5ba3f64789fb54bee10a891bc21222964d83c687",
    "title": "A Review of Challenges and Opportunities in Machine Learning for Health.",
    "venue": "AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science",
    "year": 2018,
    "citationCount": 311,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1806.00388, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2804918",
        "name": "M. Ghassemi"
      },
      {
        "authorId": "2113888405",
        "name": "Tristan Naumann"
      },
      {
        "authorId": "145610328",
        "name": "Peter F. Schulam"
      },
      {
        "authorId": "1507094362",
        "name": "A. Beam"
      },
      {
        "authorId": "34574044",
        "name": "I. Chen"
      },
      {
        "authorId": "2615814",
        "name": "R. Ranganath"
      }
    ],
    "abstract": "Modern electronic health records (EHRs) provide data to answer clinically meaningful questions. The growing data in EHRs makes healthcare ripe for the use of machine learning. However, learning in a clinical setting presents unique challenges that complicate the use of common machine learning methodologies. For example, diseases in EHRs are poorly labeled, conditions can encompass multiple underlying endotypes, and healthy individuals are underrepresented. This article serves as a primer to illuminate these challenges and highlights opportunities for members of the machine learning community to contribute to healthcare."
  },
  {
    "paperId": "192f45d07d16c47e8194e1e3d00ec8c8b05f128c",
    "title": "Materials discovery and design using machine learning",
    "venue": "",
    "year": 2017,
    "citationCount": 1060,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.jmat.2017.08.002",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.JMAT.2017.08.002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.JMAT.2017.08.002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2119033820",
        "name": "Yue Liu"
      },
      {
        "authorId": "3491940",
        "name": "Tianlu Zhao"
      },
      {
        "authorId": "39847803",
        "name": "Wangwei Ju"
      },
      {
        "authorId": "48806968",
        "name": "S. Shi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "079b2cfe950a96d5a43a3febc983d151fb533b53",
    "title": "Machine learning on big data: Opportunities and challenges",
    "venue": "Neurocomputing",
    "year": 2017,
    "citationCount": 968,
    "openAccessPdf": {
      "url": "https://www.sciencedirect.com/science/article/am/pii/S0925231217300577",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neucom.2017.01.026?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neucom.2017.01.026, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1691036",
        "name": "Lina Zhou"
      },
      {
        "authorId": "2239443126",
        "name": "Shimei Pan"
      },
      {
        "authorId": "46583503",
        "name": "Jianwu Wang"
      },
      {
        "authorId": "1747034",
        "name": "A. Vasilakos"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "02e2e79a77d8aabc1af1900ac80ceebac20abde4",
    "title": "Explanation and Justification in Machine Learning : A Survey Or",
    "venue": "",
    "year": 2017,
    "citationCount": 539,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "20402453",
        "name": "Or Biran"
      },
      {
        "authorId": "2244926",
        "name": "Courtenay V. Cotton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "43d1fe40167c5f2ed010c8e06c8e008c774fd22b",
    "title": "Non-convex Optimization for Machine Learning",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2017,
    "citationCount": 501,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1712.07897",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1712.07897, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48964143",
        "name": "Prateek Jain"
      },
      {
        "authorId": "39746893",
        "name": "Purushottam Kar"
      }
    ],
    "abstract": "A vast majority of machine learning algorithms train their models and perform inference by solving optimization problems. In order to capture the learning and prediction problems accurately, structural constraints such as sparsity or low rank are frequently imposed or else the objective itself is designed to be a non-convex function. This is especially true of algorithms that operate in high-dimensional spaces or that train non-linear models such as tensor models and deep networks.  The freedom to express the learning problem as a non-convex optimization problem gives immense modeling power to the algorithm designer, but often such problems are NP-hard to solve.  A popular workaround to this has been to relax non-convex problems to convex ones and use traditional methods to solve the (convex) relaxed optimization problems. However this approach may be lossy and nevertheless presents significant challenges for large scale optimization.  On the other hand, direct approaches to non-convex optimization have met with resounding success in several domains and remain the methods of choice for the practitioner, as they frequently outperform relaxation-based techniques - popular heuristics include projected gradient descent and alternating minimization. However, these are often poorly understood in terms of their convergence and other properties.  This monograph presents a selection of recent advances that bridge a long-standing gap in our understanding of these heuristics. We hope that an insight into the inner workings of these methods will allow the reader to appreciate the unique marriage of task structure and generative models that allow these heuristic techniques to (provably) succeed. The monograph will lead the reader through several widely used non-convex optimization techniques, as well as applications thereof. The goal of this monograph is to both, introduce the rich literature in this area, as well as equip the reader with the tools and techniques needed to analyze these simple procedures for non-convex problems."
  },
  {
    "paperId": "5c4dbf5b17e2729c570174f9099f35c247d1a889",
    "title": "enchmark for molecular machine learning †",
    "venue": "",
    "year": 2017,
    "citationCount": 521,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "9957625",
        "name": "Zhenqin Wu"
      },
      {
        "authorId": "2378027",
        "name": "Bharath Ramsundar"
      },
      {
        "authorId": "5932099",
        "name": "Evan N. Feinberg"
      },
      {
        "authorId": "145986494",
        "name": "Joseph Gomes"
      },
      {
        "authorId": "2347660128",
        "name": "Caleb Geniesse"
      },
      {
        "authorId": "5929246",
        "name": "Aneesh S. Pappu"
      },
      {
        "authorId": "2290983225",
        "name": "Karl Leswingd"
      },
      {
        "authorId": "1806271",
        "name": "V. Pande"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "611544418ca53cdad254df444addc7814abcfddc",
    "title": "An introduction to statistical learning with applications in R",
    "venue": "Statistical Theory and Related Fields",
    "year": 2021,
    "citationCount": 4238,
    "openAccessPdf": {
      "url": "https://www.tandfonline.com/doi/pdf/10.1080/24754269.2021.1980261?needAccess=true",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/24754269.2021.1980261?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/24754269.2021.1980261, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "151004165",
        "name": "Fariha Sohil"
      },
      {
        "authorId": "2134162313",
        "name": "Muhammad Umair Sohali"
      },
      {
        "authorId": "1840524",
        "name": "J. Shabbir"
      }
    ],
    "abstract": "The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts. Every chapter includes worked examples and exercises to test understanding. Programming tutorials are offered on the book's web site. This textbook considers statistical learning applications when interest centers on the conditional distribution of a response variable, given a set of predictors, and in the absence of a credible model that can be specified before the data analysis begins. Consistent with modern data analytics, it emphasizes that a proper statistical learning data analysis depends in an integrated fashion on sound data collection, intelligent data management, appropriate statistical procedures, and an"
  },
  {
    "paperId": "184d770ef86cf302836bc8873ea9c03acc454bf1",
    "title": "TPOT: A Tree-based Pipeline Optimization Tool for Automating Machine Learning",
    "venue": "AutoML@ICML",
    "year": 2016,
    "citationCount": 656,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_8.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-05318-5_8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-05318-5_8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3297552",
        "name": "Randal S. Olson"
      },
      {
        "authorId": "152512193",
        "name": "J. Moore"
      }
    ],
    "abstract": "As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks—all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain."
  },
  {
    "paperId": "4ab891e6044695abb31c72048f654b3b205c60bb",
    "title": "Survey of Machine Learning Algorithms for Disease Diagnostic",
    "venue": "",
    "year": 2017,
    "citationCount": 580,
    "openAccessPdf": {
      "url": "http://www.scirp.org/journal/PaperDownload.aspx?paperID=73781",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.4236/JILSA.2017.91001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4236/JILSA.2017.91001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "30721756",
        "name": "M. Fatima"
      },
      {
        "authorId": "144225210",
        "name": "Maruf Pasha"
      }
    ],
    "abstract": "In medical imaging, Computer Aided Diagnosis (CAD) is a rapidly growing dynamic area of research. In recent years, significant attempts are made for the enhancement of computer aided diagnosis applications because errors in medical diagnostic systems can result in seriously misleading medical treatments. Machine learning is important in Computer Aided Diagnosis. After using an easy equation, objects such as organs may not be indicated accurately. So, pattern recognition fundamentally involves learning from examples. In the field of bio-medical, pattern recognition and machine learning promise the improved accuracy of perception and diagnosis of disease. They also promote the objectivity of decision-making process. For the analysis of high-dimensional and multimodal bio-medical data, machine learning offers a worthy approach for making classy and automatic algorithms. This survey paper provides the comparative analysis of different machine learning algorithms for diagnosis of different diseases such as heart disease, diabetes disease, liver disease, dengue disease and hepatitis disease. It brings attention towards the suite of machine learning algorithms and tools that are used for the analysis of diseases and decision-making process accordingly."
  },
  {
    "paperId": "8dd5b04e5f89f9bf26d93eef995bbc58e3d1de87",
    "title": "Machine Learning in Enzyme Engineering",
    "venue": "ACS Catalysis",
    "year": 2019,
    "citationCount": 322,
    "openAccessPdf": {
      "url": "https://pubs.acs.org/doi/pdf/10.1021/acscatal.9b04321",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1021/acscatal.9b04321?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acscatal.9b04321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40550171",
        "name": "S. Mazurenko"
      },
      {
        "authorId": "3105282",
        "name": "Z. Prokop"
      },
      {
        "authorId": "3069214",
        "name": "J. Damborský"
      }
    ],
    "abstract": "Enzyme engineering plays a central role in developing efficient biocatalysts for biotechnology, biomedicine, and life sciences. Apart from classical rational design and directed evolution approache..."
  },
  {
    "paperId": "6724a5386dd7401d234f2d8b8715cb175fbe15bd",
    "title": "Unintended consequences of machine learning in medicine?",
    "venue": "F1000Research",
    "year": 2017,
    "citationCount": 504,
    "openAccessPdf": {
      "url": "https://f1000research.com/articles/6-1707/v1/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5701440, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144883837",
        "name": "L. McDonald"
      },
      {
        "authorId": "5406728",
        "name": "S. Ramagopalan"
      },
      {
        "authorId": "2053776777",
        "name": "A. Cox"
      },
      {
        "authorId": "46356580",
        "name": "M. Oğuz"
      }
    ],
    "abstract": "Machine learning (ML) has the potential to significantly aid medical practice. However, a recent article highlighted some negative consequences that may arise from using ML decision support in medicine. We argue here that whilst the concerns raised by the authors may be appropriate, they are not specific to ML, and thus the article may lead to an adverse perception about this technique in particular. Whilst ML is not without its limitations like any methodology, a balanced view is needed in order to not hamper its use in potentially enabling better patient care."
  },
  {
    "paperId": "f4bfd0add23a9a8e06f5b1ac6780e713dc9d4eff",
    "title": "Machine learning in catalysis",
    "venue": "Nature Catalysis",
    "year": 2018,
    "citationCount": 354,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41929-018-0056-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41929-018-0056-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "4495786",
        "name": "J. Kitchin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "46d71d947231f86e1f9d4581e61212385debbe14",
    "title": "OpenML: networked science in machine learning",
    "venue": "SKDD",
    "year": 2014,
    "citationCount": 1419,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1407.7722",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1407.7722, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1717534",
        "name": "J. Vanschoren"
      },
      {
        "authorId": "1764155",
        "name": "J. N. V. Rijn"
      },
      {
        "authorId": "1686924",
        "name": "B. Bischl"
      },
      {
        "authorId": "66444903",
        "name": "Luís Torgo"
      }
    ],
    "abstract": "Many sciences have made significant breakthroughs by adopting online tools that help organize, structure and mine information that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, individual scientists, as well as students and practitioners."
  },
  {
    "paperId": "4157ed3db4c656854e69931cb6089b64b08784b9",
    "title": "DaDianNao: A Machine-Learning Supercomputer",
    "venue": "Micro",
    "year": 2014,
    "citationCount": 1399,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MICRO.2014.58?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MICRO.2014.58, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7377735",
        "name": "Yunji Chen"
      },
      {
        "authorId": "2068286576",
        "name": "Tao Luo"
      },
      {
        "authorId": "39419985",
        "name": "Shaoli Liu"
      },
      {
        "authorId": "2145407329",
        "name": "Shijin Zhang"
      },
      {
        "authorId": "37167270",
        "name": "Liqiang He"
      },
      {
        "authorId": "2110368816",
        "name": "Jia Wang"
      },
      {
        "authorId": "3353457",
        "name": "Ling Li"
      },
      {
        "authorId": "144049725",
        "name": "Tianshi Chen"
      },
      {
        "authorId": "1719934",
        "name": "Zhiwei Xu"
      },
      {
        "authorId": "145550877",
        "name": "Ninghui Sun"
      },
      {
        "authorId": "1731764",
        "name": "O. Temam"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "262c0e54370dfc03a7ad53d79930568d18dd448c",
    "title": "Speeding Up Distributed Machine Learning Using Codes",
    "venue": "IEEE Transactions on Information Theory",
    "year": 2015,
    "citationCount": 884,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/tit.2017.2736066",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1512.02673, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "27911143",
        "name": "Kangwook Lee"
      },
      {
        "authorId": "2347284",
        "name": "Maximilian Lam"
      },
      {
        "authorId": "2686521",
        "name": "Ramtin Pedarsani"
      },
      {
        "authorId": "1740595",
        "name": "Dimitris Papailiopoulos"
      },
      {
        "authorId": "144161012",
        "name": "K. Ramchandran"
      }
    ],
    "abstract": "Codes are widely used in many engineering applications to offer <italic>robustness</italic> against <italic>noise</italic>. In large-scale systems, there are several types of noise that can affect the performance of distributed machine learning algorithms—straggler nodes, system failures, or communication bottlenecks—but there has been little interaction cutting across codes, machine learning, and distributed systems. In this paper, we provide theoretical insights on how <italic>coded</italic> solutions can achieve significant gains compared with uncoded ones. We focus on two of the most basic building blocks of distributed learning algorithms: <italic>matrix multiplication</italic> and <italic>data shuffling</italic>. For matrix multiplication, we use codes to alleviate the effect of stragglers and show that if the number of homogeneous workers is <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>, and the runtime of each subtask has an exponential tail, coded computation can speed up distributed matrix multiplication by a factor of <inline-formula> <tex-math notation=\"LaTeX\">$\\log n$ </tex-math></inline-formula>. For data shuffling, we use codes to reduce communication bottlenecks, exploiting the excess in storage. We show that when a constant fraction <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula> of the data matrix can be cached at each worker, and <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> is the number of workers, <italic>coded shuffling</italic> reduces the communication cost by a factor of <inline-formula> <tex-math notation=\"LaTeX\">$\\left({\\alpha + \\frac {1}{n}}\\right)\\gamma (n)$ </tex-math></inline-formula> compared with uncoded shuffling, where <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma (n)$ </tex-math></inline-formula> is the ratio of the cost of unicasting <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> messages to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users to multicasting a common message (of the same size) to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users. For instance, <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma (n) \\simeq n$ </tex-math></inline-formula> if multicasting a message to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users is as cheap as unicasting a message to one user. We also provide experimental results, corroborating our theoretical gains of the coded algorithms."
  },
  {
    "paperId": "448d13aae6ed21411d28887c550663973893f70c",
    "title": "Machine Learning in Healthcare: A Review",
    "venue": "2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "year": 2018,
    "citationCount": 272,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICECA.2018.8474918?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICECA.2018.8474918, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9339569",
        "name": "K. Shailaja"
      },
      {
        "authorId": "51451321",
        "name": "B. Seetharamulu"
      },
      {
        "authorId": "144959450",
        "name": "M. Jabbar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c87a4433c57ddabd50f32ca2c2d2197244692106",
    "title": "mlr: Machine Learning in R",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 651,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1686924",
        "name": "B. Bischl"
      },
      {
        "authorId": "143962282",
        "name": "Michel Lang"
      },
      {
        "authorId": "1722782",
        "name": "Lars Kotthoff"
      },
      {
        "authorId": "1763314",
        "name": "J. Schiffner"
      },
      {
        "authorId": "145444740",
        "name": "Jakob Richter"
      },
      {
        "authorId": "2083245997",
        "name": "Erich Studerus"
      },
      {
        "authorId": "8662947",
        "name": "Giuseppe Casalicchio"
      },
      {
        "authorId": "2076956892",
        "name": "Zachary M. Jones"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cef530e1a4b270262e1d17327711d4c59a7d99a5",
    "title": "A review on extreme learning machine",
    "venue": "Multimedia tools and applications",
    "year": 2021,
    "citationCount": 406,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s11042-021-11007-7.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11042-021-11007-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11042-021-11007-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2152769626",
        "name": "Jian Wang"
      },
      {
        "authorId": "3008614",
        "name": "Siyuan Lu"
      },
      {
        "authorId": "2121366199",
        "name": "Shui-hua Wang"
      },
      {
        "authorId": "7550152",
        "name": "Yudong Zhang"
      }
    ],
    "abstract": "Extreme learning machine (ELM) is a training algorithm for single hidden layer feedforward neural network (SLFN), which converges much faster than traditional methods and yields promising performance. In this paper, we hope to present a comprehensive review on ELM. Firstly, we will focus on the theoretical analysis including universal approximation theory and generalization. Then, the various improvements are listed, which help ELM works better in terms of stability, efficiency, and accuracy. Because of its outstanding performance, ELM has been successfully applied in many real-time learning tasks for classification, clustering, and regression. Besides, we report the applications of ELM in medical imaging: MRI, CT, and mammogram. The controversies of ELM were also discussed in this paper. We aim to report these advances and find some future perspectives."
  },
  {
    "paperId": "7aaede70f5efcb1542a80707c1f0f8b01955a7d2",
    "title": "Oblivious Multi-Party Machine Learning on Trusted Processors",
    "venue": "USENIX Security Symposium",
    "year": 2016,
    "citationCount": 571,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144849964",
        "name": "O. Ohrimenko"
      },
      {
        "authorId": "145124099",
        "name": "Felix Schuster"
      },
      {
        "authorId": "25650985",
        "name": "C. Fournet"
      },
      {
        "authorId": "37655483",
        "name": "Aastha Mehta"
      },
      {
        "authorId": "2388416",
        "name": "Sebastian Nowozin"
      },
      {
        "authorId": "1796965",
        "name": "K. Vaswani"
      },
      {
        "authorId": "144638568",
        "name": "Manuel Costa"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "227e0591634cef50d0bcfc73fe6c5b34a2256e5f",
    "title": "Radio Machine Learning Dataset Generation with GNU Radio",
    "venue": "",
    "year": 2016,
    "citationCount": 572,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1388350203",
        "name": "Tim O'Shea"
      },
      {
        "authorId": "145028728",
        "name": "Nathan E. West"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "56703e0ccba03378962f5006f299cd98d48198f9",
    "title": "Smart Machining Process Using Machine Learning: A Review and Perspective on Machining Industry",
    "venue": "International Journal of Precision Engineering and Manufacturing - Green Technology",
    "year": 2018,
    "citationCount": 249,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40684-018-0057-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40684-018-0057-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47182192",
        "name": "Dong-Hyeon Kim"
      },
      {
        "authorId": "46760092",
        "name": "T. J. Y. Kim"
      },
      {
        "authorId": "2108072972",
        "name": "Xinlin Wang"
      },
      {
        "authorId": "123446787",
        "name": "Mincheol Kim"
      },
      {
        "authorId": "13640537",
        "name": "Ying-Jun Quan"
      },
      {
        "authorId": "49321942",
        "name": "Jin Woo Oh"
      },
      {
        "authorId": "6464425",
        "name": "S. Min"
      },
      {
        "authorId": "2277348",
        "name": "Hyungjung Kim"
      },
      {
        "authorId": "80598184",
        "name": "B. Bhandari"
      },
      {
        "authorId": "2064802297",
        "name": "Insoon Yang"
      },
      {
        "authorId": "6578920",
        "name": "Sung-hoon Ahn"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c",
    "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 7039,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.08144, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48607963",
        "name": "Yonghui Wu"
      },
      {
        "authorId": "144927151",
        "name": "M. Schuster"
      },
      {
        "authorId": "2545358",
        "name": "Z. Chen"
      },
      {
        "authorId": "2827616",
        "name": "Quoc V. Le"
      },
      {
        "authorId": "144739074",
        "name": "Mohammad Norouzi"
      },
      {
        "authorId": "3153147",
        "name": "Wolfgang Macherey"
      },
      {
        "authorId": "2048712",
        "name": "M. Krikun"
      },
      {
        "authorId": "145144022",
        "name": "Yuan Cao"
      },
      {
        "authorId": "145312180",
        "name": "Qin Gao"
      },
      {
        "authorId": "113439369",
        "name": "Klaus Macherey"
      },
      {
        "authorId": "2367620",
        "name": "J. Klingner"
      },
      {
        "authorId": "145825976",
        "name": "Apurva Shah"
      },
      {
        "authorId": "145657834",
        "name": "Melvin Johnson"
      },
      {
        "authorId": "2109059862",
        "name": "Xiaobing Liu"
      },
      {
        "authorId": "40527594",
        "name": "Lukasz Kaiser"
      },
      {
        "authorId": "2776283",
        "name": "Stephan Gouws"
      },
      {
        "authorId": "2739610",
        "name": "Yoshikiyo Kato"
      },
      {
        "authorId": "1765329",
        "name": "Taku Kudo"
      },
      {
        "authorId": "1754386",
        "name": "H. Kazawa"
      },
      {
        "authorId": "144077726",
        "name": "K. Stevens"
      },
      {
        "authorId": "1753079661",
        "name": "George Kurian"
      },
      {
        "authorId": "2056800684",
        "name": "Nishant Patil"
      },
      {
        "authorId": "49337181",
        "name": "Wei Wang"
      },
      {
        "authorId": "39660914",
        "name": "C. Young"
      },
      {
        "authorId": "2119125158",
        "name": "Jason R. Smith"
      },
      {
        "authorId": "2909504",
        "name": "Jason Riesa"
      },
      {
        "authorId": "29951847",
        "name": "Alex Rudnick"
      },
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      },
      {
        "authorId": "32131713",
        "name": "G. Corrado"
      },
      {
        "authorId": "48342565",
        "name": "Macduff Hughes"
      },
      {
        "authorId": "49959210",
        "name": "J. Dean"
      }
    ],
    "abstract": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system."
  },
  {
    "paperId": "91f7848ea9045f29345467552496db97b037ae01",
    "title": "Machine Learning and Materials Informatics: Recent Applications and Prospects",
    "venue": "",
    "year": 2017,
    "citationCount": 719,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1707.07294, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "4063724",
        "name": "R. Ramprasad"
      },
      {
        "authorId": "143832304",
        "name": "Rohit Batra"
      },
      {
        "authorId": "49542803",
        "name": "G. Pilania"
      },
      {
        "authorId": "2340090139",
        "name": "A. Mannodi‐Kanakkithodi"
      },
      {
        "authorId": "1690355",
        "name": "Chiho Kim"
      }
    ],
    "abstract": "Propelled partly by the Materials Genome Initiative, and partly by the algorithmic developments and the resounding successes of data-driven efforts in other domains, informatics strategies are beginning to take shape within materials science. These approaches lead to surrogate machine learning models that enable rapid predictions based purely on past data rather than by direct experimentation or by computations/simulations in which fundamental equations are explicitly solved. Data-centric informatics methods are becoming useful to determine material properties that are hard to measure or compute using traditional methods--due to the cost, time or effort involved--but for which reliable data either already exists or can be generated for at least a subset of the critical cases. Predictions are typically interpolative, involving fingerprinting a material numerically first, and then following a mapping (established via a learning algorithm) between the fingerprint and the property of interest. Fingerprints may be of many types and scales, as dictated by the application domain and needs. Predictions may also be extrapolative--extending into new materials spaces--provided prediction uncertainties are properly taken into account. This article attempts to provide an overview of some of the recent successful data-driven \"materials informatics\" strategies undertaken in the last decade, and identifies some challenges the community is facing and those that should be overcome in the near future."
  },
  {
    "paperId": "702786aebfce591499d4a635539453f936afb3d9",
    "title": "A survey on application of machine learning for Internet of Things",
    "venue": "International Journal of Machine Learning and Cybernetics",
    "year": 2018,
    "citationCount": 227,
    "openAccessPdf": {
      "url": "http://hdl.handle.net/10397/78310",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-018-0834-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-018-0834-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1678696",
        "name": "Laizhong Cui"
      },
      {
        "authorId": "123362946",
        "name": "Shu Yang"
      },
      {
        "authorId": "144765278",
        "name": "Fei Chen"
      },
      {
        "authorId": "2055356098",
        "name": "Zhongxing Ming"
      },
      {
        "authorId": "2054645275",
        "name": "N. Lu"
      },
      {
        "authorId": "2114046891",
        "name": "Jing Qin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0a71787d52d88678f59d717b0c1f585347043378",
    "title": "Python machine learning : machine learning and deep learning with Python, scikit-learn, and TensorFlow",
    "venue": "",
    "year": 2017,
    "citationCount": 500,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2562040",
        "name": "S. Raschka"
      },
      {
        "authorId": "2067221484",
        "name": "Vahid Mirjalili"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e",
    "title": "Faster and Better: A Machine Learning Approach to Corner Detection",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2008,
    "citationCount": 1974,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/0810.2434",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/0810.2434, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1721991",
        "name": "E. Rosten"
      },
      {
        "authorId": "145881323",
        "name": "R. Porter"
      },
      {
        "authorId": "144418842",
        "name": "T. Drummond"
      }
    ],
    "abstract": "The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is important because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection and, using machine learning, we derive a feature detector from this which can fully process live PAL video using less than 5 percent of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115 percent, SIFT 195 percent). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that, despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and of very high quality."
  },
  {
    "paperId": "24e6c5bfe9bb0751e5708b501d04e860011b2953",
    "title": "Applications of Support Vector Machine (SVM) Learning in Cancer Genomics.",
    "venue": "Cancer Genomics & Proteomics",
    "year": 2018,
    "citationCount": 1342,
    "openAccessPdf": {
      "url": "http://cgp.iiarjournals.org/content/15/1/41.full.pdf",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.21873/CGP.20063?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21873/CGP.20063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47156522",
        "name": "Shujun Huang"
      },
      {
        "authorId": "27122362",
        "name": "Nianguang Cai"
      },
      {
        "authorId": "47479574",
        "name": "Pedro Penzuti Pacheco"
      },
      {
        "authorId": "32286482",
        "name": "Shavira Narrandes"
      },
      {
        "authorId": null,
        "name": "Yang Wang"
      },
      {
        "authorId": "50232365",
        "name": "Wayne W. Xu"
      }
    ],
    "abstract": "Machine learning with maximization (support) of separating margin (vector), called support vector machine (SVM) learning, is a powerful classification tool that has been used for cancer genomic classification or subtyping. Today, as advancements in high-throughput technologies lead to production of large amounts of genomic and epigenomic data, the classification feature of SVMs is expanding its use in cancer genomics, leading to the discovery of new biomarkers, new drug targets, and a better understanding of cancer driver genes. Herein we reviewed the recent progress of SVMs in cancer genomic studies. We intend to comprehend the strength of the SVM learning and its future perspective in cancer genomic applications."
  },
  {
    "paperId": "07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b",
    "title": "Advances and Open Problems in Federated Learning",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2019,
    "citationCount": 7227,
    "openAccessPdf": {
      "url": "https://wrap.warwick.ac.uk/170168/1/WRAP-Advances-and-open-problems-in-federated-learning-Cormode-2022.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.04977, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3115341",
        "name": "P. Kairouz"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "15519668",
        "name": "Brendan Avent"
      },
      {
        "authorId": "1702915",
        "name": "A. Bellet"
      },
      {
        "authorId": "1702172",
        "name": "M. Bennis"
      },
      {
        "authorId": "10754103",
        "name": "A. Bhagoji"
      },
      {
        "authorId": "2039588",
        "name": "Keith Bonawitz"
      },
      {
        "authorId": "143676545",
        "name": "Zachary B. Charles"
      },
      {
        "authorId": "1709589",
        "name": "Graham Cormode"
      },
      {
        "authorId": "49326047",
        "name": "Rachel Cummings"
      },
      {
        "authorId": "1410457573",
        "name": "Rafael G. L. D'Oliveira"
      },
      {
        "authorId": "40464010",
        "name": "S. E. Rouayheb"
      },
      {
        "authorId": "2116660698",
        "name": "David Evans"
      },
      {
        "authorId": "33685819",
        "name": "Josh Gardner"
      },
      {
        "authorId": "40449749",
        "name": "Zachary Garrett"
      },
      {
        "authorId": "145511365",
        "name": "Adrià Gascón"
      },
      {
        "authorId": "2529354",
        "name": "Badih Ghazi"
      },
      {
        "authorId": "1974678",
        "name": "Phillip B. Gibbons"
      },
      {
        "authorId": "1708469",
        "name": "M. Gruteser"
      },
      {
        "authorId": "1753355",
        "name": "Zaïd Harchaoui"
      },
      {
        "authorId": "31927890",
        "name": "Chaoyang He"
      },
      {
        "authorId": "51222147",
        "name": "Lie He"
      },
      {
        "authorId": "3382735",
        "name": "Zhouyuan Huo"
      },
      {
        "authorId": "2044655623",
        "name": "Ben Hutchinson"
      },
      {
        "authorId": "39756252",
        "name": "Justin Hsu"
      },
      {
        "authorId": "2456863",
        "name": "Martin Jaggi"
      },
      {
        "authorId": "47197693",
        "name": "T. Javidi"
      },
      {
        "authorId": "144225970",
        "name": "Gauri Joshi"
      },
      {
        "authorId": "10398264",
        "name": "M. Khodak"
      },
      {
        "authorId": "32139366",
        "name": "Jakub Konecný"
      },
      {
        "authorId": "2823893",
        "name": "A. Korolova"
      },
      {
        "authorId": "3018662",
        "name": "F. Koushanfar"
      },
      {
        "authorId": "143812875",
        "name": "Oluwasanmi Koyejo"
      },
      {
        "authorId": "1792616",
        "name": "Tancrède Lepoint"
      },
      {
        "authorId": "1614034792",
        "name": "Yang Liu"
      },
      {
        "authorId": "143615345",
        "name": "Prateek Mittal"
      },
      {
        "authorId": "81080659",
        "name": "M. Mohri"
      },
      {
        "authorId": "1718786",
        "name": "R. Nock"
      },
      {
        "authorId": "2064241030",
        "name": "A. Özgür"
      },
      {
        "authorId": "1801719",
        "name": "R. Pagh"
      },
      {
        "authorId": "1702744",
        "name": "Mariana Raykova"
      },
      {
        "authorId": "2072589474",
        "name": "Hang Qi"
      },
      {
        "authorId": "1878835",
        "name": "Daniel Ramage"
      },
      {
        "authorId": "145711633",
        "name": "R. Raskar"
      },
      {
        "authorId": "143711382",
        "name": "D. Song"
      },
      {
        "authorId": "2118727912",
        "name": "Weikang Song"
      },
      {
        "authorId": "2127057",
        "name": "Sebastian U. Stich"
      },
      {
        "authorId": "8908922",
        "name": "Ziteng Sun"
      },
      {
        "authorId": "9486035",
        "name": "A. Suresh"
      },
      {
        "authorId": "2444919",
        "name": "Florian Tramèr"
      },
      {
        "authorId": "2927870",
        "name": "Praneeth Vepakomma"
      },
      {
        "authorId": "30880777",
        "name": "Jianyu Wang"
      },
      {
        "authorId": "2291135512",
        "name": "Li Xiong"
      },
      {
        "authorId": "144897102",
        "name": "Zheng Xu"
      },
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      },
      {
        "authorId": "1815972",
        "name": "Felix X. Yu"
      },
      {
        "authorId": "2110984588",
        "name": "Han Yu"
      },
      {
        "authorId": "49113001",
        "name": "Sen Zhao"
      }
    ],
    "abstract": "Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges."
  },
  {
    "paperId": "27245e65a27bde90b5b0bb25d157bb75a0ad8b5a",
    "title": "A survey of machine learning for big data processing",
    "venue": "EURASIP Journal on Advances in Signal Processing",
    "year": 2016,
    "citationCount": 810,
    "openAccessPdf": {
      "url": "https://asp-eurasipjournals.springeropen.com/track/pdf/10.1186/s13634-016-0355-x",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1186/s13634-016-0355-x?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s13634-016-0355-x, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3181960",
        "name": "Junfei Qiu"
      },
      {
        "authorId": "145447232",
        "name": "Qi-hui Wu"
      },
      {
        "authorId": "1788703",
        "name": "Guoru Ding"
      },
      {
        "authorId": "1409931639",
        "name": "Yuhua Xu"
      },
      {
        "authorId": "145340634",
        "name": "S. Feng"
      }
    ],
    "abstract": "There is no doubt that big data are now rapidly expanding in all science and engineering domains. While the potential of these massive data is undoubtedly significant, fully making sense of them requires new ways of thinking and novel learning techniques to address the various challenges. In this paper, we present a literature survey of the latest advances in researches on machine learning for big data processing. First, we review the machine learning techniques and highlight some promising learning methods in recent studies, such as representation learning, deep learning, distributed and parallel learning, transfer learning, active learning, and kernel-based learning. Next, we focus on the analysis and discussions about the challenges and possible solutions of machine learning for big data. Following that, we investigate the close connections of machine learning with signal processing techniques for big data processing. Finally, we outline several open issues and research trends."
  },
  {
    "paperId": "fd0611608567d9a278e2f030c9b19544f8fae035",
    "title": "Neural Networks for Machine Learning",
    "venue": "",
    "year": 2017,
    "citationCount": 523,
    "openAccessPdf": {
      "url": "https://ir.lib.vntu.edu.ua//bitstream/123456789/24788/2/52857.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/9781139051699.031?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/9781139051699.031, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2285784540",
        "name": "Richard F. Lyon"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e1f9ef01ab55d53349096a58d76fd0cfa7bb051d",
    "title": "Quantum machine learning: a classical perspective",
    "venue": "Proceedings of the Royal Society A",
    "year": 2017,
    "citationCount": 482,
    "openAccessPdf": {
      "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2017.0551",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1707.08561, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "7666146",
        "name": "C. Ciliberto"
      },
      {
        "authorId": "1839746",
        "name": "M. Herbster"
      },
      {
        "authorId": "46403120",
        "name": "Alessandro Davide Ialongo"
      },
      {
        "authorId": "1704699",
        "name": "M. Pontil"
      },
      {
        "authorId": "8478411",
        "name": "Andrea Rocchetto"
      },
      {
        "authorId": "47831052",
        "name": "S. Severini"
      },
      {
        "authorId": "3438240",
        "name": "Leonard Wossnig"
      }
    ],
    "abstract": "Recently, increased computational power and data availability, as well as algorithmic advances, have led machine learning (ML) techniques to impressive results in regression, classification, data generation and reinforcement learning tasks. Despite these successes, the proximity to the physical limits of chip fabrication alongside the increasing size of datasets is motivating a growing number of researchers to explore the possibility of harnessing the power of quantum computation to speed up classical ML algorithms. Here we review the literature in quantum ML and discuss perspectives for a mixed readership of classical ML and quantum computation experts. Particular emphasis will be placed on clarifying the limitations of quantum algorithms, how they compare with their best classical counterparts and why quantum resources are expected to provide advantages for learning problems. Learning in the presence of noise and certain computationally hard problems in ML are identified as promising directions for the field. Practical questions, such as how to upload classical data into quantum form, will also be addressed."
  },
  {
    "paperId": "e7cd99f99092593d6ffa0e8f274bc06ba188d461",
    "title": "Machine Learning",
    "venue": "A First Course in Artificial Intelligence",
    "year": 2021,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2174/9781681088532121010005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2174/9781681088532121010005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e",
    "title": "Neural Discrete Representation Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 6109,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1711.00937, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3422336",
        "name": "Aäron van den Oord"
      },
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      },
      {
        "authorId": "2645384",
        "name": "K. Kavukcuoglu"
      }
    ],
    "abstract": "Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of \"posterior collapse\" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations."
  },
  {
    "paperId": "22a67be81ab3b778a1f39a6182cbab37e07d26ee",
    "title": "Diversity in Machine Learning",
    "venue": "IEEE Access",
    "year": 2018,
    "citationCount": 226,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08717641.pdf",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1807.01477, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2605832",
        "name": "Z. Gong"
      },
      {
        "authorId": "143741620",
        "name": "P. Zhong"
      },
      {
        "authorId": "2283543181",
        "name": "Weidong Hu"
      }
    ],
    "abstract": "Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a totally good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though diversity plays an important role in the machine learning process, there is no systematical analysis of the diversification in the machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work. Our analysis provides a deeper understanding of the diversity technology in machine learning tasks and hence can help design and learn more effective models for real-world applications."
  },
  {
    "paperId": "22a67be81ab3b778a1f39a6182cbab37e07d26ee",
    "title": "Diversity in Machine Learning",
    "venue": "IEEE Access",
    "year": 2018,
    "citationCount": 226,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08717641.pdf",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1807.01477, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2605832",
        "name": "Z. Gong"
      },
      {
        "authorId": "143741620",
        "name": "P. Zhong"
      },
      {
        "authorId": "2283543181",
        "name": "Weidong Hu"
      }
    ],
    "abstract": "Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a totally good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though diversity plays an important role in the machine learning process, there is no systematical analysis of the diversification in the machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work. Our analysis provides a deeper understanding of the diversity technology in machine learning tasks and hence can help design and learn more effective models for real-world applications."
  },
  {
    "paperId": "97ad5e35cf07c74c36cf1af629021412d2c2afa6",
    "title": "Machine Learning",
    "venue": "Quantum Machine Learning: An Applied Approach",
    "year": 2021,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4842-7098-1_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4842-7098-1_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "83123035",
        "name": "Santanu Ganguly"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "44479cc5266788c3bafcc0b12ef0758827741fe3",
    "title": "Guidelines for Developing and Reporting Machine Learning Predictive Models in Biomedical Research: A Multidisciplinary View",
    "venue": "Journal of Medical Internet Research",
    "year": 2016,
    "citationCount": 798,
    "openAccessPdf": {
      "url": "https://doi.org/10.2196/jmir.5870",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5238707, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145951567",
        "name": "Wei Luo"
      },
      {
        "authorId": "145890410",
        "name": "Dinh Phung"
      },
      {
        "authorId": "6254479",
        "name": "T. Tran"
      },
      {
        "authorId": "119971153",
        "name": "Sunil Gupta"
      },
      {
        "authorId": "2285720075",
        "name": "Santu Rana"
      },
      {
        "authorId": "145467385",
        "name": "C. Karmakar"
      },
      {
        "authorId": "49512795",
        "name": "A. Shilton"
      },
      {
        "authorId": "1726789",
        "name": "J. Yearwood"
      },
      {
        "authorId": "2160177",
        "name": "N. Dimitrova"
      },
      {
        "authorId": "1719940",
        "name": "T. Ho"
      },
      {
        "authorId": "143761093",
        "name": "S. Venkatesh"
      },
      {
        "authorId": "2274601",
        "name": "M. Berk"
      }
    ],
    "abstract": "Background As more and more researchers are turning to big data for new opportunities of biomedical discoveries, machine learning models, as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of machine learning methods, they are prone to misuse. Because of the flexibility in specifying machine learning models, the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs. Objective To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence. Methods A multidisciplinary panel of machine learning experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method. Results The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models. Conclusions A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with machine learning methods, in the biomedical research community."
  },
  {
    "paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
    "title": "Matching Networks for One Shot Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2016,
    "citationCount": 7914,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.04080, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      },
      {
        "authorId": "1723876",
        "name": "C. Blundell"
      },
      {
        "authorId": "2542999",
        "name": "T. Lillicrap"
      },
      {
        "authorId": "2645384",
        "name": "K. Kavukcuoglu"
      },
      {
        "authorId": "1688276",
        "name": "D. Wierstra"
      }
    ],
    "abstract": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank."
  },
  {
    "paperId": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
    "title": "Deep Learning with Differential Privacy",
    "venue": "Conference on Computer and Communications Security",
    "year": 2016,
    "citationCount": 6774,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1607.00133",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1607.00133, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2057642721",
        "name": "Martín Abadi"
      },
      {
        "authorId": "1396184193",
        "name": "Andy Chu"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "145591745",
        "name": "Ilya Mironov"
      },
      {
        "authorId": "35210462",
        "name": "Kunal Talwar"
      },
      {
        "authorId": "2152832173",
        "name": "Li Zhang"
      }
    ],
    "abstract": "Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality."
  },
  {
    "paperId": "53b55682222692323a3a0d546d9e1a3de29454f0",
    "title": "A review of supervised machine learning algorithms",
    "venue": "International Conference on Computing for Sustainable Global Development",
    "year": 2016,
    "citationCount": 595,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2116287748",
        "name": "Amanpreet Singh"
      },
      {
        "authorId": "2675918",
        "name": "Narina Thakur"
      },
      {
        "authorId": "2109261490",
        "name": "Aakanksha Sharma"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "09755f549468209199565f8037061281080c968f",
    "title": "Interactive machine learning for health informatics: when do we need the human-in-the-loop?",
    "venue": "Brain Informatics",
    "year": 2016,
    "citationCount": 786,
    "openAccessPdf": {
      "url": "https://braininformatics.springeropen.com/counter/pdf/10.1007/s40708-016-0042-6",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4883171, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1749801",
        "name": "Andreas Holzinger"
      }
    ],
    "abstract": "Machine learning (ML) is the fastest growing field in computer science, and health informatics is among the greatest challenges. The goal of ML is to develop algorithms which can learn and improve over time and can be used for predictions. Most ML researchers concentrate on automatic machine learning (aML), where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from big data with many training sets. However, in the health domain, sometimes we are confronted with a small number of data sets or rare events, where aML-approaches suffer of insufficient training samples. Here interactive machine learning (iML) may be of help, having its roots in reinforcement learning, preference learning, and active learning. The term iML is not yet well used, so we define it as “algorithms that can interact with agents and can optimize their learning behavior through these interactions, where the agents can also be human.” This “human-in-the-loop” can be beneficial in solving computationally hard problems, e.g., subspace clustering, protein folding, or k-anonymization of health data, where human expertise can help to reduce an exponential search space through heuristic selection of samples. Therefore, what would otherwise be an NP-hard problem, reduces greatly in complexity through the input and the assistance of a human agent involved in the learning phase."
  },
  {
    "paperId": "05d20fda297c9afb347214bd1693bd049674e0c6",
    "title": "Machine Learning for the Geosciences: Challenges and Opportunities",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2017,
    "citationCount": 462,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1711.04708",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1711.04708, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2548167",
        "name": "A. Karpatne"
      },
      {
        "authorId": "1405321572",
        "name": "I. Ebert‐Uphoff"
      },
      {
        "authorId": "1753019",
        "name": "S. Ravela"
      },
      {
        "authorId": "30160005",
        "name": "H. Babaie"
      },
      {
        "authorId": "2107978833",
        "name": "Vipin Kumar"
      }
    ],
    "abstract": "Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML)—that has been widely successful in commercial domains—offers immense potential to contribute to problems in geosciences. However, geoscience applications introduce novel challenges for ML due to combinations of geoscience properties encountered in every problem, requiring novel research in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their common properties. We then describe some of the common categories of geoscience problems where machine learning can play a role, discussing the challenges faced by existing ML methods and opportunities for novel ML research. We conclude by discussing some of the cross-cutting research themes in machine learning that are applicable across several geoscience problems, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines."
  },
  {
    "paperId": "2e5ee400be272be9c64c40f19ea91efb11046202",
    "title": "Bypassing the Kohn-Sham equations with machine learning",
    "venue": "Nature Communications",
    "year": 2016,
    "citationCount": 624,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41467-017-00839-3.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.02815, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3468686",
        "name": "Felix Brockherde"
      },
      {
        "authorId": "47024906",
        "name": "Leslie Vogt"
      },
      {
        "authorId": "2156055534",
        "name": "Li Li"
      },
      {
        "authorId": "2616915",
        "name": "M. Tuckerman"
      },
      {
        "authorId": "2544144",
        "name": "K. Burke"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": "Last year, at least 30,000 scientific papers used the Kohn–Sham scheme of density functional theory to solve electronic structure problems in a wide variety of scientific fields. Machine learning holds the promise of learning the energy functional via examples, bypassing the need to solve the Kohn–Sham equations. This should yield substantial savings in computer time, allowing larger systems and/or longer time-scales to be tackled, but attempts to machine-learn this functional have been limited by the need to find its derivative. The present work overcomes this difficulty by directly learning the density-potential and energy-density maps for test systems and various molecules. We perform the first molecular dynamics simulation with a machine-learned density functional on malonaldehyde and are able to capture the intramolecular proton transfer process. Learning density models now allows the construction of accurate density functionals for realistic molecular systems. Machine learning allows electronic structure calculations to access larger system sizes and, in dynamical simulations, longer time scales. Here, the authors perform such a simulation using a machine-learned density functional that avoids direct solution of the Kohn-Sham equations."
  },
  {
    "paperId": "49bdeb07b045dd77f0bfe2b44436608770235a23",
    "title": "Federated Learning: Challenges, Methods, and Future Directions",
    "venue": "IEEE Signal Processing Magazine",
    "year": 2019,
    "citationCount": 5216,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1908.07873",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1908.07873, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145530218",
        "name": "Tian Li"
      },
      {
        "authorId": "2894821",
        "name": "Anit Kumar Sahu"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      },
      {
        "authorId": "145260024",
        "name": "Virginia Smith"
      }
    ],
    "abstract": "Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities."
  },
  {
    "paperId": "3af7252f7e3ca8e9bc8f45e6cbf567b10ecb5d95",
    "title": "Machine learning models and bankruptcy prediction",
    "venue": "Expert systems with applications",
    "year": 2017,
    "citationCount": 711,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.eswa.2017.04.006?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.eswa.2017.04.006, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143613746",
        "name": "Flavio Barboza"
      },
      {
        "authorId": "3473696",
        "name": "H. Kimura"
      },
      {
        "authorId": "2568606",
        "name": "E. Altman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "32e29041fa352a9df0889f42807ed6141bc0b5ff",
    "title": "Machine learning in geosciences and remote sensing",
    "venue": "",
    "year": 2016,
    "citationCount": 912,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/j.gsf.2015.07.003",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.GSF.2015.07.003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.GSF.2015.07.003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46965265",
        "name": "David John Lary"
      },
      {
        "authorId": "8422959",
        "name": "A. Alavi"
      },
      {
        "authorId": "1764455",
        "name": "A. H. Gandomi"
      },
      {
        "authorId": "2228270660",
        "name": "A. Walker"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c5c3fa019574988c479474c32f34debecd12e8d1",
    "title": "Procedural Content Generation via Machine Learning (PCGML)",
    "venue": "IEEE Transactions on Games",
    "year": 2017,
    "citationCount": 421,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1702.00539",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1702.00539, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3375548",
        "name": "A. Summerville"
      },
      {
        "authorId": "29929346",
        "name": "Sam Snodgrass"
      },
      {
        "authorId": "144599741",
        "name": "Matthew J. Guzdial"
      },
      {
        "authorId": "1757823",
        "name": "Christoffer Holmgård"
      },
      {
        "authorId": "48630276",
        "name": "Amy K. Hoover"
      },
      {
        "authorId": "2232368",
        "name": "Aaron Isaksen"
      },
      {
        "authorId": "3431050",
        "name": "Andy Nealen"
      },
      {
        "authorId": "1810053",
        "name": "J. Togelius"
      }
    ],
    "abstract": "This survey explores procedural content generation via machine learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content, such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content, such as sprites and sound effects. In addition to using PCG for autonomous generation, cocreativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the generated content. Multiple PCGML methods are covered, including neural networks: long short-term memory networks, autoencoders, and deep convolutional networks; Markov models: $n$-grams and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in PCGML, including learning from small data sets, lack of training data, multilayered learning, style-transfer, parameter tuning, and PCG as a game mechanic."
  },
  {
    "paperId": "92ace17730c2173e642934d64f96d359697b7a93",
    "title": "Bayesian reasoning and machine learning",
    "venue": "",
    "year": 2012,
    "citationCount": 1600,
    "openAccessPdf": {
      "url": "http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/270212.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9780511804779.017?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9780511804779.017, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145617808",
        "name": "D. Barber"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f5c7d0998b4cf8de9b5b171e3593427724ec4600",
    "title": "Lifelong Machine Learning, Second Edition",
    "venue": "Lifelong Machine Learning",
    "year": 2018,
    "citationCount": 154,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-031-01581-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-031-01581-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2111630932",
        "name": "Zhiyuan Chen"
      },
      {
        "authorId": "145321667",
        "name": "B. Liu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1cd21e0af5489947a65c72b1030015b6ce1462d6",
    "title": "Machine Learning for Survival Analysis: A Survey",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 383,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1708.04649, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144442051",
        "name": "Ping Wang"
      },
      {
        "authorId": "2152885669",
        "name": "Yan Li"
      },
      {
        "authorId": "144417522",
        "name": "Chandan K. Reddy"
      }
    ],
    "abstract": "Accurately predicting the time of occurrence of an event of interest is a critical problem in longitudinal data analysis. One of the main challenges in this context is the presence of instances whose event outcomes become unobservable after a certain time point or when some instances do not experience any event during the monitoring period. Such a phenomenon is called censoring which can be effectively handled using survival analysis techniques. Traditionally, statistical approaches have been widely developed in the literature to overcome this censoring issue. In addition, many machine learning algorithms are adapted to effectively handle survival data and tackle other challenging problems that arise in real-world data. In this survey, we provide a comprehensive and structured review of the representative statistical methods along with the machine learning techniques used in survival analysis and provide a detailed taxonomy of the existing methods. We also discuss several topics that are closely related to survival analysis and illustrate several successful applications in various real-world application domains. We hope that this paper will provide a more thorough understanding of the recent advances in survival analysis and offer some guidelines on applying these approaches to solve new problems that arise in applications with censored data."
  },
  {
    "paperId": "be08c04637a5f0ba13bfb52c670dbeb227dcb4cc",
    "title": "PMLB: a large benchmark suite for machine learning evaluation and comparison",
    "venue": "BioData Mining",
    "year": 2017,
    "citationCount": 412,
    "openAccessPdf": {
      "url": "https://biodatamining.biomedcentral.com/track/pdf/10.1186/s13040-017-0154-4",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.00512, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3297552",
        "name": "Randal S. Olson"
      },
      {
        "authorId": "2910714",
        "name": "W. L. Cava"
      },
      {
        "authorId": "3156986",
        "name": "P. Orzechowski"
      },
      {
        "authorId": "1800213",
        "name": "R. Urbanowicz"
      },
      {
        "authorId": "152512193",
        "name": "J. Moore"
      }
    ],
    "abstract": "The selection, development, or comparison of machine learning methods in data mining can be a difficult task based on the target problem and goals of a particular study. Numerous publicly available real-world and simulated benchmark datasets have emerged from different sources, but their organization and adoption as standards have been inconsistent. As such, selecting and curating specific benchmarks remains an unnecessary burden on machine learning practitioners and data scientists. The present study introduces an accessible, curated, and developing public benchmark resource to facilitate identification of the strengths and weaknesses of different machine learning methodologies. We compare meta-features among the current set of benchmark datasets in this resource to characterize the diversity of available data. Finally, we apply a number of established machine learning methods to the entire benchmark suite and analyze how datasets and algorithms cluster in terms of performance. From this study, we find that existing benchmarks lack the diversity to properly benchmark machine learning algorithms, and there are several gaps in benchmarking problems that still need to be considered. This work represents another important step towards understanding the limitations of popular benchmarking suites and developing a resource that connects existing benchmarking standards to more diverse and efficient standards in the future."
  },
  {
    "paperId": "18d026ec5d0eebd17ee2c762da89540c0b3d7bde",
    "title": "A Comprehensive Survey on Transfer Learning",
    "venue": "Proceedings of the IEEE",
    "year": 2019,
    "citationCount": 5189,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1911.02685",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.02685, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1799525",
        "name": "Fuzhen Zhuang"
      },
      {
        "authorId": "51052604",
        "name": "Zhiyuan Qi"
      },
      {
        "authorId": "108237152",
        "name": "Keyu Duan"
      },
      {
        "authorId": "120791559",
        "name": "Dongbo Xi"
      },
      {
        "authorId": "1864765978",
        "name": "Yongchun Zhu"
      },
      {
        "authorId": "1968806",
        "name": "Hengshu Zhu"
      },
      {
        "authorId": "144467554",
        "name": "Hui Xiong"
      },
      {
        "authorId": "144131273",
        "name": "Qing He"
      }
    ],
    "abstract": "Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target-domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning research studies, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey article reviews more than 40 representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over 20 representative transfer learning models are used for experiments. The models are performed on three different data sets, that is, Amazon Reviews, Reuters-21578, and Office-31, and the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice."
  },
  {
    "paperId": "b191fc4294f6f067067e4e152bd4efc8bbb87afd",
    "title": "Unintended Consequences of Machine Learning in Medicine",
    "venue": "Journal of the American Medical Association (JAMA)",
    "year": 2017,
    "citationCount": 375,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1001/jama.2017.7797?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jama.2017.7797, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3037324",
        "name": "F. Cabitza"
      },
      {
        "authorId": "15665454",
        "name": "Raffaele Rasoini"
      },
      {
        "authorId": "1981465",
        "name": "G. Gensini"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c3a159d6a85be68af4c985c281718bc5801ada19",
    "title": "Lifelong Machine Learning",
    "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
    "year": 2016,
    "citationCount": 477,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/bfm:978-3-031-01581-6/1?pdf=chapter%20toc",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-031-01575-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-031-01575-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2258804408",
        "name": "Zhiyuan Chen"
      },
      {
        "authorId": "2237128270",
        "name": "Bing Liu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9ec1cb983d6d475bf0fc2879ea1a7e31201d8c37",
    "title": "Python Machine Learning",
    "venue": "",
    "year": 2015,
    "citationCount": 646,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "45ac43993bb43fa9aa046ed4377f2277a3736eeb",
    "title": "Lifelong machine learning: a paradigm for continuous learning",
    "venue": "Frontiers of Computer Science",
    "year": 2017,
    "citationCount": 332,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11704-016-6903-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11704-016-6903-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2111630932",
        "name": "Zhiyuan Chen"
      },
      {
        "authorId": "145321667",
        "name": "B. Liu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1202d5a0da9790ae5d8a5d67125e83c82d33faf9",
    "title": "Encyclopedia of Machine Learning and Data Mining",
    "venue": "Encyclopedia of Machine Learning and Data Mining",
    "year": 2017,
    "citationCount": 443,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4899-7687-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4899-7687-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1804253",
        "name": "Claude Sammut"
      },
      {
        "authorId": "114031010",
        "name": "Geoffrey I. Webb"
      },
      {
        "authorId": "3323364",
        "name": "Z. Abdallah"
      },
      {
        "authorId": "2167690625",
        "name": "Charu C. Aggarwal"
      },
      {
        "authorId": "2242697481",
        "name": "Ibm T J Watson"
      },
      {
        "authorId": "2287034670",
        "name": "Biliana Alexandrova-Kabadjova Banco de M´exico"
      },
      {
        "authorId": "2272512842",
        "name": "México City"
      },
      {
        "authorId": "2259318845",
        "name": "México"
      },
      {
        "authorId": "2282746509",
        "name": "Peter Auer"
      },
      {
        "authorId": "1756566",
        "name": "J. Bagnell"
      },
      {
        "authorId": "2168175874",
        "name": "Michael Bain"
      },
      {
        "authorId": "1730590",
        "name": "A. Barto"
      },
      {
        "authorId": "3025197",
        "name": "R. Baxter"
      },
      {
        "authorId": "2239233539",
        "name": "Bettina Berendt"
      },
      {
        "authorId": "2261641699",
        "name": "K. Leuven"
      },
      {
        "authorId": "70176856",
        "name": "Leuven"
      },
      {
        "authorId": "2238250027",
        "name": "Belgium"
      },
      {
        "authorId": "2245322521",
        "name": "Hendrik Blockeel"
      },
      {
        "authorId": "33488138",
        "name": "S. Bohn"
      },
      {
        "authorId": "2148612914",
        "name": "Gavin Brown"
      },
      {
        "authorId": "2378197",
        "name": "D. Brzezinski"
      },
      {
        "authorId": "2265927244",
        "name": "M. D. Buhmann"
      },
      {
        "authorId": "2287027349",
        "name": "Gail A. Carpenter"
      },
      {
        "authorId": "1491250253",
        "name": "Philip K. Chan"
      },
      {
        "authorId": "2286859252",
        "name": "Zhiyuan Chen"
      },
      {
        "authorId": "2286239076",
        "name": "Peter Christen"
      },
      {
        "authorId": "2064558872",
        "name": "David Cohn"
      },
      {
        "authorId": "2237634925",
        "name": "David Corne"
      },
      {
        "authorId": "1742472",
        "name": "Susan Craw"
      },
      {
        "authorId": "2265966220",
        "name": "Artur Czumaj"
      },
      {
        "authorId": "2237633772",
        "name": "Gerald DeJong"
      },
      {
        "authorId": "2287034927",
        "name": "Chris Drummond"
      },
      {
        "authorId": "2287229912",
        "name": "Lan Du"
      },
      {
        "authorId": "2057050",
        "name": "Y. Engel"
      },
      {
        "authorId": "1758714",
        "name": "S. Fahlman"
      },
      {
        "authorId": "2249181461",
        "name": "P. Flach"
      },
      {
        "authorId": "1679287",
        "name": "P. Flener"
      },
      {
        "authorId": "2287029336",
        "name": "Thomas G¨artner"
      },
      {
        "authorId": "70429824",
        "name": "Fraunhofer Iais"
      },
      {
        "authorId": "67204470",
        "name": "Schloss Birlinghoven"
      },
      {
        "authorId": "2287024563",
        "name": "Alma Lilia Garc ´ ıa-Almanza"
      },
      {
        "authorId": "1785678",
        "name": "G. C. Garriga"
      },
      {
        "authorId": "1746034",
        "name": "L. Getoor"
      },
      {
        "authorId": "1398517004",
        "name": "C. Giraud-Carrier"
      },
      {
        "authorId": "2111759058",
        "name": "Jiawei Han"
      },
      {
        "authorId": "1799538",
        "name": "B. Hengst"
      },
      {
        "authorId": "2287034803",
        "name": "Geoffrey Hinton"
      },
      {
        "authorId": "2287067110",
        "name": "Tam´as Horv´ath"
      },
      {
        "authorId": "2286784801",
        "name": "Marcus Hutter"
      },
      {
        "authorId": "2057970162",
        "name": "Tommy R. Jensen"
      },
      {
        "authorId": "2807119",
        "name": "A. Kakas"
      },
      {
        "authorId": "2240569",
        "name": "Anne Kao"
      },
      {
        "authorId": "69057684",
        "name": "S. Kaski"
      },
      {
        "authorId": "1698581",
        "name": "C. Kavka"
      },
      {
        "authorId": "152198664",
        "name": "J. Kennedy"
      },
      {
        "authorId": "2257169155",
        "name": "Joshua Knowles"
      },
      {
        "authorId": "2287034807",
        "name": "Aleksander KoŁcz"
      },
      {
        "authorId": "2287024276",
        "name": "Microsoft One"
      },
      {
        "authorId": "2287003597",
        "name": "Microsoft Way"
      },
      {
        "authorId": "1730706",
        "name": "K. Korb"
      },
      {
        "authorId": "35248610",
        "name": "Petra Kralj Novak"
      },
      {
        "authorId": "2263994650",
        "name": "Stefan Kramer"
      },
      {
        "authorId": "1784072",
        "name": "M. Lagoudakis"
      },
      {
        "authorId": "2273859824",
        "name": "John Langford"
      },
      {
        "authorId": "2287067805",
        "name": "Pier Luca"
      },
      {
        "authorId": "2287026585",
        "name": "Lanzi Politecnico"
      },
      {
        "authorId": "2241350368",
        "name": "Milano Italy di Milano"
      },
      {
        "authorId": "2287034205",
        "name": "Gregor Leban"
      },
      {
        "authorId": "2287766729",
        "name": "Hang Li"
      },
      {
        "authorId": "2059988796",
        "name": "Charles X. Ling"
      },
      {
        "authorId": "2250570453",
        "name": "Bing Liu"
      },
      {
        "authorId": "2287545684",
        "name": "Huan Liu"
      },
      {
        "authorId": "2286895313",
        "name": "John Lloyd"
      },
      {
        "authorId": "2287004123",
        "name": "Seraf´ın Mart´ınez-Jaramillo"
      },
      {
        "authorId": "48650879",
        "name": "E. Martin"
      },
      {
        "authorId": "1749003",
        "name": "S. Matwin"
      },
      {
        "authorId": "104838085",
        "name": "J. McAuley"
      },
      {
        "authorId": "2286907558",
        "name": "Franziska Meier"
      },
      {
        "authorId": "2241623758",
        "name": "Risto Miikkulainen"
      },
      {
        "authorId": "50414219",
        "name": "Jun Morimoto"
      },
      {
        "authorId": "50854821",
        "name": "P. Munro"
      },
      {
        "authorId": "2067947117",
        "name": "Andrew Y. Ng"
      },
      {
        "authorId": "1702481",
        "name": "Siegfried Nijssen"
      },
      {
        "authorId": "2270151804",
        "name": "William Stafford Noble"
      },
      {
        "authorId": "144942719",
        "name": "J. Patrick"
      },
      {
        "authorId": "2016017069",
        "name": "J. Peters"
      },
      {
        "authorId": "2263188304",
        "name": "Francesco Petruccione"
      },
      {
        "authorId": "1738196",
        "name": "Cecilia M. Procopiuc"
      },
      {
        "authorId": "37814588",
        "name": "M. Puterman"
      },
      {
        "authorId": "1740042",
        "name": "L. D. Raedt"
      },
      {
        "authorId": "2053887441",
        "name": "M. Reid"
      },
      {
        "authorId": "2060586276",
        "name": "Joerg Sander"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "2093249009",
        "name": "Stephen Scott"
      },
      {
        "authorId": "2239008237",
        "name": "Victor S. Sheng"
      },
      {
        "authorId": "71058328",
        "name": "J. S. Shirabad"
      },
      {
        "authorId": "2852732",
        "name": "T. Shultz"
      },
      {
        "authorId": "145049659",
        "name": "Ricardo Silva"
      },
      {
        "authorId": "1707878",
        "name": "M. Sipper"
      },
      {
        "authorId": "2286222263",
        "name": "William D. Smart"
      },
      {
        "authorId": "145726060",
        "name": "Carlos Soares"
      },
      {
        "authorId": "1409204115",
        "name": "Liaad-Inesc Porto"
      },
      {
        "authorId": "2263382573",
        "name": "Myra Spiliopoulou"
      },
      {
        "authorId": "2286265819",
        "name": "Thomas"
      },
      {
        "authorId": "2286102932",
        "name": "Jerzy Stefanowski"
      },
      {
        "authorId": "2052614922",
        "name": "F. Stephan"
      },
      {
        "authorId": "2057783847",
        "name": "Peter Stone"
      },
      {
        "authorId": "1990806",
        "name": "Alexander L. Strehl"
      },
      {
        "authorId": "2286693686",
        "name": "Prasad Tadepalli"
      },
      {
        "authorId": "1700133",
        "name": "Jo-Anne Ting"
      },
      {
        "authorId": "2195972",
        "name": "P. Utgoff"
      },
      {
        "authorId": "2242158893",
        "name": "Ricardo Vilalta"
      },
      {
        "authorId": "6541629",
        "name": "K. Wagstaff"
      },
      {
        "authorId": "2286977473",
        "name": "Suhang Wang"
      },
      {
        "authorId": "144773003",
        "name": "R. P. Wiegand"
      },
      {
        "authorId": "1766844",
        "name": "Eric Wiewiora"
      },
      {
        "authorId": "2257223405",
        "name": "William E. Winkler"
      },
      {
        "authorId": "40009100",
        "name": "Anthony Wirth"
      },
      {
        "authorId": "2582677",
        "name": "Michael Witbrock"
      },
      {
        "authorId": "49027178",
        "name": "David Wolpert"
      },
      {
        "authorId": "2237719681",
        "name": "Stefan Wrobel"
      },
      {
        "authorId": "2109186533",
        "name": "Jason Wu"
      },
      {
        "authorId": "2115511050",
        "name": "Zhao Xu"
      },
      {
        "authorId": "2259068335",
        "name": "Sankt Augustin"
      },
      {
        "authorId": "2285143608",
        "name": "Germany"
      },
      {
        "authorId": "1409943049",
        "name": "Sungwook Yoon"
      },
      {
        "authorId": "2287034201",
        "name": "MapR"
      },
      {
        "authorId": "2287117259",
        "name": "Min-Ling Zhang"
      },
      {
        "authorId": "2286792823",
        "name": "Max Zimmermann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7",
    "title": "Machine Learning methods for Quantitative Radiomic Biomarkers",
    "venue": "Scientific Reports",
    "year": 2015,
    "citationCount": 901,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/srep13087.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4538374, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40470674",
        "name": "C. Parmar"
      },
      {
        "authorId": "49405431",
        "name": "P. Grossmann"
      },
      {
        "authorId": "48938629",
        "name": "J. Bussink"
      },
      {
        "authorId": "1693233",
        "name": "P. Lambin"
      },
      {
        "authorId": "143849569",
        "name": "H. Aerts"
      }
    ],
    "abstract": "Radiomics extracts and mines large number of medical imaging features quantifying tumor phenotypic characteristics. Highly accurate and reliable machine-learning approaches can drive the success of radiomic applications in clinical care. In this radiomic study, fourteen feature selection methods and twelve classification methods were examined in terms of their performance and stability for predicting overall survival. A total of 440 radiomic features were extracted from pre-treatment computed tomography (CT) images of 464 lung cancer patients. To ensure the unbiased evaluation of different machine-learning methods, publicly available implementations along with reported parameter configurations were used. Furthermore, we used two independent radiomic cohorts for training (n = 310 patients) and validation (n = 154 patients). We identified that Wilcoxon test based feature selection method WLCX (stability = 0.84 ± 0.05, AUC = 0.65 ± 0.02) and a classification method random forest RF (RSD = 3.52%, AUC = 0.66 ± 0.03) had highest prognostic performance with high stability against data perturbation. Our variability analysis indicated that the choice of classification method is the most dominant source of performance variation (34.21% of total variance). Identification of optimal machine-learning methods for radiomic applications is a crucial step towards stable and clinically relevant radiomic biomarkers, providing a non-invasive way of quantifying and monitoring tumor-phenotypic characteristics in clinical practice."
  },
  {
    "paperId": "95615c6bce2123f12e39c3d9eb293ebb759501aa",
    "title": "Machine learning, social learning and the governance of self-driving cars",
    "venue": "Social Studies of Science",
    "year": 2017,
    "citationCount": 306,
    "openAccessPdf": {
      "url": "https://discovery.ucl.ac.uk/10038434/1/Stilgoe_Machine%20learning%2C%20social%20learning%20and%20the%20governance%20of%20self-driving%20cars_AAM.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1177/0306312717741687?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0306312717741687, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3416633",
        "name": "J. Stilgoe"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2878d9936f494ed7d0c8aec47e9bcc5e51609f9a",
    "title": "Extreme Learning Machine for Multilayer Perceptron",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2016,
    "citationCount": 1293,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2015.2424995?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2015.2424995, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2967405",
        "name": "Jiexiong Tang"
      },
      {
        "authorId": "7175017",
        "name": "Chenwei Deng"
      },
      {
        "authorId": "145678691",
        "name": "G. Huang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ccf73e723d8308f28a98cb435dfb585581f59e2c",
    "title": "Genetic Algorithms in Search, Optimization & Machine Learning",
    "venue": "",
    "year": 1989,
    "citationCount": 2669,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2060983236",
        "name": "D. E. Goldberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "84bb60b83f82ad847e19d96403ad0011abfc888f",
    "title": "The Boosting Approach to Machine Learning An Overview",
    "venue": "",
    "year": 2003,
    "citationCount": 2244,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-0-387-21579-2_9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-0-387-21579-2_9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1716301",
        "name": "R. Schapire"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b1059d25d092e0e872a1d2db01b24c73eb869ad9",
    "title": "Machine Learning for Neural Decoding",
    "venue": "eNeuro",
    "year": 2017,
    "citationCount": 272,
    "openAccessPdf": {
      "url": "https://www.eneuro.org/content/eneuro/7/4/ENEURO.0506-19.2020.full.pdf",
      "status": "GOLD",
      "license": "CCBYNCSA",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1708.00909, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2937772",
        "name": "Joshua I. Glaser"
      },
      {
        "authorId": "38308858",
        "name": "Raeed H. Chowdhury"
      },
      {
        "authorId": "5228640",
        "name": "M. Perich"
      },
      {
        "authorId": "32776555",
        "name": "L. Miller"
      },
      {
        "authorId": "3282030",
        "name": "Konrad Paul Kording"
      }
    ],
    "abstract": "Abstract Despite rapid advances in machine learning tools, the majority of neural decoding approaches still use traditional methods. Modern machine learning tools, which are versatile and easy to use, have the potential to significantly improve decoding performance. This tutorial describes how to effectively apply these algorithms for typical decoding problems. We provide descriptions, best practices, and code for applying common machine learning methods, including neural networks and gradient boosting. We also provide detailed comparisons of the performance of various methods at the task of decoding spiking activity in motor cortex, somatosensory cortex, and hippocampus. Modern methods, particularly neural networks and ensembles, significantly outperform traditional approaches, such as Wiener and Kalman filters. Improving the performance of neural decoding algorithms allows neuroscientists to better understand the information contained in a neural population and can help to advance engineering applications such as brain–machine interfaces. Our code package is available at github.com/kordinglab/neural_decoding."
  },
  {
    "paperId": "961d0f3d0c852055a202ef315b02cd69863098e9",
    "title": "Artificial intelligence, machine learning and deep learning",
    "venue": "International Conference on ICT and Knowledge Engineering",
    "year": 2017,
    "citationCount": 269,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTKE.2017.8259629?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTKE.2017.8259629, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "31807503",
        "name": "Pariwat Ongsulee"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "31e12b8d558a7515f3a1e3337551f5f30e466cde",
    "title": "Unified representation of molecules and crystals for machine learning",
    "venue": "Machine Learning: Science and Technology",
    "year": 2017,
    "citationCount": 245,
    "openAccessPdf": {
      "url": "https://kops.uni-konstanz.de/bitstreams/ef286cd2-85ab-4686-a98b-ee2492d6c898/download",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1704.06439, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "94267262",
        "name": "Haoyan Huo"
      },
      {
        "authorId": "48041657",
        "name": "M. Rupp"
      }
    ],
    "abstract": "Accurate simulations of atomistic systems from first principles are limited by computational cost. In high-throughput settings, machine learning can reduce these costs significantly by accurately interpolating between reference calculations. For this, kernel learning approaches crucially require a representation that accommodates arbitrary atomistic systems. We introduce a many-body tensor representation that is invariant to translations, rotations, and nuclear permutations of same elements, unique, differentiable, can represent molecules and crystals, and is fast to compute. Empirical evidence for competitive energy and force prediction errors is presented for changes in molecular structure, crystal chemistry, and molecular dynamics using kernel regression and symmetric gradient-domain machine learning as models. Applicability is demonstrated for phase diagrams of Pt-group/transition-metal binary systems."
  },
  {
    "paperId": "7db5aa6ab4c15d56d4604502f7f08b6ad9de816f",
    "title": "Machine Learning",
    "venue": "Machine Learning and Big Data",
    "year": 2020,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781119654834.ch7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781119654834.ch7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2082828270",
        "name": "Elham Ghanbari"
      },
      {
        "authorId": "144728970",
        "name": "S. Najafzadeh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a1e1763709ff399ce015fc5a46e29af195821c20",
    "title": "Machine Learning",
    "venue": "Fundamentals of Artificial Intelligence",
    "year": 2020,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-81-322-3972-7_13?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-81-322-3972-7_13, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2285605727",
        "name": "Benno Stein"
      },
      {
        "authorId": "2287476718",
        "name": "Theo Lettmann"
      },
      {
        "authorId": "2287483143",
        "name": "Michael Völske"
      },
      {
        "authorId": "2277904570",
        "name": "Martin Potthast"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "60991366c7964a408d40b4d94caec51dde8cff8c",
    "title": "Machine Learning",
    "venue": "Data Science",
    "year": 2020,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "https://doi.org/10.1002/9781119544180.ch5",
      "status": "GOLD",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781119544180.ch5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781119544180.ch5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2161274689",
        "name": "Miri Master"
      },
      {
        "authorId": "16014350",
        "name": "L. Belanche"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2678e213cec548d278879ceaf01582ee8913cc3f",
    "title": "Classification Techniques in Machine Learning: Applications and Issues",
    "venue": "",
    "year": 2017,
    "citationCount": 252,
    "openAccessPdf": {
      "url": "https://doi.org/10.6000/1927-5129.2017.13.76",
      "status": "HYBRID",
      "license": "CCBYSA",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.6000/1927-5129.2017.13.76?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.6000/1927-5129.2017.13.76, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46225914",
        "name": "Aized Amin Soofi"
      },
      {
        "authorId": "144674832",
        "name": "Arshad Awan"
      }
    ],
    "abstract": "Classification is a data mining (machine learning) technique used to predict group membership for data instances. There are several classification techniques that can be used for classification purpose. In this paper, we present the basic classification techniques. Later we discuss some major types of classification method including Bayesian networks, decision tree induction, k-nearest neighbor classifier and Support Vector Machines (SVM) with their strengths, weaknesses, potential applications and issues with their available solution. The goal of this study is to provide a comprehensive review of different classification techniques in machine learning. This work will be helpful for both academia and new comers in the field of machine learning to further strengthen the basis of classification methods."
  },
  {
    "paperId": "9e6060316394393c226b5c86ce51b06c4c75bee1",
    "title": "Machine Learning Classification over Encrypted Data",
    "venue": "Network and Distributed System Security Symposium",
    "year": 2015,
    "citationCount": 744,
    "openAccessPdf": {
      "url": "http://eprint.iacr.org/2014/331.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.14722/NDSS.2015.23241?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14722/NDSS.2015.23241, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39940567",
        "name": "Raphael Bost"
      },
      {
        "authorId": "144963510",
        "name": "Raluca A. Popa"
      },
      {
        "authorId": "2058019574",
        "name": "Stephen Tu"
      },
      {
        "authorId": "1706681",
        "name": "S. Goldwasser"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a5c0309b9895066ebd08acfe326b01ce2fdefdd4",
    "title": "Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges",
    "venue": "European Heart Journal",
    "year": 2016,
    "citationCount": 441,
    "openAccessPdf": {
      "url": "https://academic.oup.com/eurheartj/article-pdf/38/23/1805/24120384/ehw302.pdf",
      "status": "HYBRID",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5837244, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35352396",
        "name": "B. Goldstein"
      },
      {
        "authorId": "86968656",
        "name": "A. Navar"
      },
      {
        "authorId": "145554444",
        "name": "R. Carter"
      }
    ],
    "abstract": "Abstract Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning."
  },
  {
    "paperId": "ad0d1149875291d9b1177bc47e53e09237beeca0",
    "title": "Quantum-enhanced machine learning",
    "venue": "Physical Review Letters",
    "year": 2016,
    "citationCount": 417,
    "openAccessPdf": {
      "url": "http://link.aps.org/pdf/10.1103/PhysRevLett.117.130501",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1610.08251, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2878563",
        "name": "V. Dunjko"
      },
      {
        "authorId": "2110747638",
        "name": "Jacob M. Taylor"
      },
      {
        "authorId": "32534184",
        "name": "H. Briegel"
      }
    ],
    "abstract": "The emerging field of quantum machine learning has the potential to substantially aid in the problems and scope of artificial intelligence. This is only enhanced by recent successes in the field of classical machine learning. In this work we propose an approach for the systematic treatment of machine learning, from the perspective of quantum information. Our approach is general and covers all three main branches of machine learning: supervised, unsupervised, and reinforcement learning. While quantum improvements in supervised and unsupervised learning have been reported, reinforcement learning has received much less attention. Within our approach, we tackle the problem of quantum enhancements in reinforcement learning as well, and propose a systematic scheme for providing improvements. As an example, we show that quadratic improvements in learning efficiency, and exponential improvements in performance over limited time periods, can be obtained for a broad class of learning problems."
  },
  {
    "paperId": "f38513dc4350cfb987a8f0b774fc361c4d910a17",
    "title": "Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies",
    "venue": "",
    "year": 2015,
    "citationCount": 662,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "34967075",
        "name": "John D. Kelleher"
      },
      {
        "authorId": "7616304",
        "name": "Brian Mac Namee"
      },
      {
        "authorId": "1409191033",
        "name": "Aoife D'Arcy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a15067563a18378dac71a206c6cc2e2d8c871301",
    "title": "Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning",
    "venue": "International Conference on Machine Learning",
    "year": 1999,
    "citationCount": 2032,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "118860642",
        "name": "M. Hall"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3804ca5590a0829c5d56e84d860a2b2a456e3757",
    "title": "Principles of Explanatory Debugging to Personalize Interactive Machine Learning",
    "venue": "International Conference on Intelligent User Interfaces",
    "year": 2015,
    "citationCount": 625,
    "openAccessPdf": {
      "url": "https://openaccess.city.ac.uk/id/eprint/13819/1/paper326.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2678025.2701399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2678025.2701399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1847827",
        "name": "Todd Kulesza"
      },
      {
        "authorId": "1737204",
        "name": "M. Burnett"
      },
      {
        "authorId": "37535697",
        "name": "Weng-Keen Wong"
      },
      {
        "authorId": "2121662",
        "name": "S. Stumpf"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c396ba3ce3c58591b8ee282e65ab5a6d610e16ed",
    "title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 187,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1707.06742, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2812486",
        "name": "Patrice Y. Simard"
      },
      {
        "authorId": "1719124",
        "name": "Saleema Amershi"
      },
      {
        "authorId": "1724065",
        "name": "D. M. Chickering"
      },
      {
        "authorId": "21134435",
        "name": "Alicia Edelman Pelton"
      },
      {
        "authorId": "39715299",
        "name": "S. Ghorashi"
      },
      {
        "authorId": "50004012",
        "name": "Christopher Meek"
      },
      {
        "authorId": "2057749310",
        "name": "Gonzalo A. Ramos"
      },
      {
        "authorId": "38972741",
        "name": "Jina Suh"
      },
      {
        "authorId": "39963433",
        "name": "J. Verwey"
      },
      {
        "authorId": "2109019287",
        "name": "Mo Wang"
      },
      {
        "authorId": "2372116",
        "name": "J. Wernsing"
      }
    ],
    "abstract": "The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. \nWhile machine learning focuses on creating new algorithms and improving the accuracy of \"learners\", the machine teaching discipline focuses on the efficacy of the \"teachers\". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. \nIn this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models."
  },
  {
    "paperId": "85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175",
    "title": "An introduction to quantum machine learning",
    "venue": "Contemporary physics (Print)",
    "year": 2014,
    "citationCount": 1205,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1409.3097.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1409.3097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "2498866",
        "name": "I. Sinayskiy"
      },
      {
        "authorId": "2258749",
        "name": "Francesco Petruccione"
      }
    ],
    "abstract": "Machine learning algorithms learn a desired input-output relation from examples in order to interpret new inputs. This is important for tasks such as image and speech recognition or strategy optimisation, with growing applications in the IT industry. In the last couple of years, researchers investigated if quantum computing can help to improve classical machine learning algorithms. Ideas range from running computationally costly algorithms or their subroutines efficiently on a quantum computer to the translation of stochastic methods into the language of quantum theory. This contribution gives a systematic overview of the emerging field of quantum machine learning. It presents the approaches as well as technical details in an accessible way, and discusses the potential of a future theory of quantum learning."
  },
  {
    "paperId": "8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92",
    "title": "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2010,
    "citationCount": 1715,
    "openAccessPdf": {
      "url": "http://www.icir.org/robin/papers/oakland10-ml.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/SP.2010.25?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SP.2010.25, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1690799",
        "name": "Robin Sommer"
      },
      {
        "authorId": "1744800",
        "name": "V. Paxson"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a",
    "title": "A review of automatic selection methods for machine learning algorithms and hyper-parameter values",
    "venue": "Network Modeling Analysis in Health Informatics and Bioinformatics",
    "year": 2016,
    "citationCount": 324,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13721-016-0125-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13721-016-0125-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144050855",
        "name": "G. Luo"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "aaa76e15235d937d093a7063c0be86ed84494dee",
    "title": "Machine Learning: A Bayesian and Optimization Perspective",
    "venue": "",
    "year": 2015,
    "citationCount": 560,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "534362486b5ae4b839f124af3413032c95c0483e",
    "title": "Instance spaces for machine learning classification",
    "venue": "Machine-mediated learning",
    "year": 2017,
    "citationCount": 135,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-017-5629-5.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-017-5629-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-017-5629-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143813954",
        "name": "Mario Andrés Muñoz"
      },
      {
        "authorId": "36310954",
        "name": "Laura Villanova"
      },
      {
        "authorId": "49218752",
        "name": "Davaatseren Baatar"
      },
      {
        "authorId": "1398371449",
        "name": "K. Smith‐Miles"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9f86366feecbcfdf6c5be165fcf38c679164cc89",
    "title": "Machine Learning and the Profession of Medicine.",
    "venue": "Journal of the American Medical Association (JAMA)",
    "year": 2016,
    "citationCount": 366,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1001/jama.2015.18421?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jama.2015.18421, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "6120000",
        "name": "Alison M Darcy"
      },
      {
        "authorId": "7172935",
        "name": "A. Louie"
      },
      {
        "authorId": "34934943",
        "name": "L. Roberts"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7fcb90f68529cbfab49f471b54719ded7528d0ef",
    "title": "Federated Learning: Strategies for Improving Communication Efficiency",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 5045,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1610.05492, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32139366",
        "name": "Jakub Konecný"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "1815972",
        "name": "Felix X. Yu"
      },
      {
        "authorId": "2662221",
        "name": "Peter Richtárik"
      },
      {
        "authorId": "9486035",
        "name": "A. Suresh"
      },
      {
        "authorId": "36577444",
        "name": "D. Bacon"
      }
    ],
    "abstract": "Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude."
  },
  {
    "paperId": "f3ed7343727361a25e77fdef315850bdaf29d20e",
    "title": "Second-Order Stochastic Optimization for Machine Learning in Linear Time",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 260,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3332636",
        "name": "Naman Agarwal"
      },
      {
        "authorId": "3378789",
        "name": "Brian Bullins"
      },
      {
        "authorId": "34840427",
        "name": "Elad Hazan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb",
    "title": "Deep Learning",
    "venue": "",
    "year": 2015,
    "citationCount": 39347,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1688882",
        "name": "Yann LeCun"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
    "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2015,
    "citationCount": 10393,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1506.02142, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2681954",
        "name": "Y. Gal"
      },
      {
        "authorId": "1744700",
        "name": "Zoubin Ghahramani"
      }
    ],
    "abstract": "Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning."
  },
  {
    "paperId": "139b2afafdaccba02c983d2f40f257db64860320",
    "title": "Machine Learning Topological States",
    "venue": "",
    "year": 2016,
    "citationCount": 240,
    "openAccessPdf": {
      "url": "https://link.aps.org/accepted/10.1103/PhysRevB.96.195145",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.09060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "5204254",
        "name": "D. Deng"
      },
      {
        "authorId": "2144414251",
        "name": "Xiaopeng Li"
      },
      {
        "authorId": "2108285127",
        "name": "Xiaopeng Li"
      },
      {
        "authorId": "2888542",
        "name": "S. Sarma"
      }
    ],
    "abstract": "Machine learning, the core of artificial intelligence and data science, is a very active field, with vast applications throughout science and technology. Recently, machine learning techniques have been adopted to tackle intricate quantum many-body problems and phase transitions. In this work, the authors construct exact mappings from exotic quantum states to machine learning network models. This work shows for the first time that the restricted Boltzmann machine can be used to study both symmetry-protected topological phases and intrinsic topological order. The exact results are expected to provide a substantial boost to the field of machine learning of phases of matter."
  },
  {
    "paperId": "19a28325b68346f7715e17a97eb71db1b2b3c1af",
    "title": "Machine Learning for Predictive Maintenance: A Multiple Classifier Approach",
    "venue": "IEEE Transactions on Industrial Informatics",
    "year": 2015,
    "citationCount": 651,
    "openAccessPdf": {
      "url": "https://pure.qub.ac.uk/files/17844756/machine.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TII.2014.2349359?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TII.2014.2349359, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3126083",
        "name": "Gian Antonio Susto"
      },
      {
        "authorId": "2979820",
        "name": "A. Schirru"
      },
      {
        "authorId": "2383035",
        "name": "S. Pampuri"
      },
      {
        "authorId": "48147378",
        "name": "S. McLoone"
      },
      {
        "authorId": "1744705",
        "name": "A. Beghi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c62043a7d2537bbf40a84b9913957452a47fdb83",
    "title": "Dataset Shift in Machine Learning",
    "venue": "",
    "year": 2009,
    "citationCount": 2097,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/MITPRESS/9780262170055.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/MITPRESS/9780262170055.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1409068337",
        "name": "Joaquin Quionero-Candela"
      },
      {
        "authorId": "67154907",
        "name": "Masashi Sugiyama"
      },
      {
        "authorId": "2071649",
        "name": "A. Schwaighofer"
      },
      {
        "authorId": "145306271",
        "name": "Neil D. Lawrence"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1b481d6f30a1bdabb896c1b4ccb0567ec6749d54",
    "title": "Comprehensive Review On Supervised Machine Learning Algorithms",
    "venue": "2017 International Conference on Machine Learning and Data Science (MLDS)",
    "year": 2017,
    "citationCount": 140,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MLDS.2017.11?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MLDS.2017.11, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3577861",
        "name": "Rishabh Choudhary"
      },
      {
        "authorId": "31346552",
        "name": "Hemant Kumar Gianey"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
    "title": "Determinantal Point Processes for Machine Learning",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2012,
    "citationCount": 1203,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1207.6083",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1207.6083, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145500336",
        "name": "Alex Kulesza"
      },
      {
        "authorId": "1685978",
        "name": "B. Taskar"
      }
    ],
    "abstract": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. While they have been studied extensively by mathematicians, giving rise to a deep and beautiful theory, DPPs are relatively new in machine learning. Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories. It presents the general mathematical background to DPPs along with a range of modeling extensions, efficient algorithms, and theoretical results that aim to enable practical modeling and learning."
  },
  {
    "paperId": "df2a7756382540e92895f10703cec32d50c4f316",
    "title": "Fast and accurate modeling of molecular atomization energies with machine learning.",
    "venue": "Physical Review Letters",
    "year": 2011,
    "citationCount": 1676,
    "openAccessPdf": {
      "url": "https://link.aps.org/accepted/10.1103/PhysRevLett.108.058301",
      "status": "HYBRID",
      "license": "publisher-specific, author manuscript",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1109.2618, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48041657",
        "name": "M. Rupp"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "7847508",
        "name": "O. A. von Lilienfeld"
      }
    ],
    "abstract": "We introduce a machine learning model to predict atomization energies of a diverse set of organic molecules, based on nuclear charges and atomic positions only. The problem of solving the molecular Schrödinger equation is mapped onto a nonlinear statistical regression problem of reduced complexity. Regression models are trained on and compared to atomization energies computed with hybrid density-functional theory. Cross validation over more than seven thousand organic molecules yields a mean absolute error of ∼10  kcal/mol. Applicability is demonstrated for the prediction of molecular atomization potential energy curves."
  },
  {
    "paperId": "d37fc9e9c4fedc32865b08661e7fb950df1f8fbe",
    "title": "Kernel methods in machine learning",
    "venue": "",
    "year": 2007,
    "citationCount": 2139,
    "openAccessPdf": {
      "url": "https://projecteuclid.org/journals/annals-of-statistics/volume-36/issue-3/Kernel-methods-in-machine-learning/10.1214/009053607000000677.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/math/0701907, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      }
    ],
    "abstract": "We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data."
  },
  {
    "paperId": "3449b65008b27f6e60a73d80c1fd990f0481126b",
    "title": "Torch7: A Matlab-like Environment for Machine Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2011,
    "citationCount": 1589,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2939803",
        "name": "R. Collobert"
      },
      {
        "authorId": "2645384",
        "name": "K. Kavukcuoglu"
      },
      {
        "authorId": "2256269",
        "name": "C. Farabet"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "de9180ecc8b645aff238be05f645d50fa34a808f",
    "title": "Learning Curves in Machine Learning",
    "venue": "Encyclopedia of Machine Learning and Data Mining",
    "year": 2017,
    "citationCount": 75,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4899-7687-1_452?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4899-7687-1_452, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1933403",
        "name": "Claudia Perlich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bf2827963894ed234db7d5a0d9474e1046531ad8",
    "title": "Ensemble Methods in Machine Learning",
    "venue": "",
    "year": 2007,
    "citationCount": 2083,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "93aa298b40bb3ec23c25239089284fdf61ded917",
    "title": "Support vector machine learning for interdependent and structured output spaces",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 1478,
    "openAccessPdf": {
      "url": "https://www.cs.cornell.edu/people/tj/publications/tsochantaridis_etal_04a.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015341?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015341, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1765700",
        "name": "Ioannis Tsochantaridis"
      },
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      },
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      },
      {
        "authorId": "1783941",
        "name": "Y. Altun"
      }
    ],
    "abstract": "Learning general functional dependencies is one of the main goals in machine learning. Recent progress in kernel-based methods has focused on designing flexible and powerful input representations. This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces. We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs. The resulting optimization problem is solved efficiently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem. We demonstrate the versatility and effectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment."
  },
  {
    "paperId": "5888c776e38f39efb9b96d0ba2713981008a86b1",
    "title": "Structural Health Monitoring: A Machine Learning Perspective",
    "venue": "",
    "year": 2012,
    "citationCount": 1415,
    "openAccessPdf": {
      "url": "http://ela.kpi.ua/bitstream/123456789/21467/1/2016_2825.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781118443118?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781118443118, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3151407",
        "name": "C. Farrar"
      },
      {
        "authorId": "144789804",
        "name": "K. Worden"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6",
    "title": "Transfer Learning for Low-Resource Neural Machine Translation",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2016,
    "citationCount": 884,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/D16-1163.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1604.02201, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2368067",
        "name": "Barret Zoph"
      },
      {
        "authorId": "2808366",
        "name": "Deniz Yuret"
      },
      {
        "authorId": "143823227",
        "name": "Jonathan May"
      },
      {
        "authorId": "152971314",
        "name": "Kevin Knight"
      }
    ],
    "abstract": "The encoder-decoder framework for neural machine translation (NMT) has been shown effective in large data scenarios, but is much less effective for low-resource languages. We present a transfer learning method that significantly improves Bleu scores across a range of low-resource languages. Our key idea is to first train a high-resource language pair (the parent model), then transfer some of the learned parameters to the low-resource pair (the child model) to initialize and constrain training. Using our transfer learning method we improve baseline NMT models by an average of 5.6 Bleu on four low-resource language pairs. Ensembling and unknown word replacement add another 2 Bleu which brings the NMT performance on low-resource machine translation close to a strong syntax based machine translation (SBMT) system, exceeding its performance on one language pair. Additionally, using the transfer learning model for re-scoring, we can improve the SBMT system by an average of 1.3 Bleu, improving the state-of-the-art on low-resource machine translation."
  },
  {
    "paperId": "825ca26af5a2a510dbc1a7b97587212bc98ae968",
    "title": "Power to the People: The Role of Humans in Interactive Machine Learning",
    "venue": "The AI Magazine",
    "year": 2014,
    "citationCount": 1052,
    "openAccessPdf": {
      "url": "https://aaai.org/ojs/index.php/aimagazine/article/download/2513/2456",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1609/AIMAG.V35I4.2513?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/AIMAG.V35I4.2513, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1719124",
        "name": "Saleema Amershi"
      },
      {
        "authorId": "35096370",
        "name": "M. Cakmak"
      },
      {
        "authorId": "144288136",
        "name": "W. B. Knox"
      },
      {
        "authorId": "1847827",
        "name": "Todd Kulesza"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "23b559b5ab27f2fca6f56c0a7b6478bcf69db509",
    "title": "Dual Learning for Machine Translation",
    "venue": "Neural Information Processing Systems",
    "year": 2016,
    "citationCount": 877,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.00179, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1391126980",
        "name": "Di He"
      },
      {
        "authorId": "2794096",
        "name": "Yingce Xia"
      },
      {
        "authorId": "143826491",
        "name": "Tao Qin"
      },
      {
        "authorId": "24952249",
        "name": "Liwei Wang"
      },
      {
        "authorId": "1708598",
        "name": "Nenghai Yu"
      },
      {
        "authorId": "2110264337",
        "name": "Tie-Yan Liu"
      },
      {
        "authorId": "1712167",
        "name": "Wei-Ying Ma"
      }
    ],
    "abstract": "While neural machine translation (NMT) is making good progress in the past two years, tens of millions of bilingual sentence pairs are needed for its training. However, human labeling is very costly. To tackle this training data bottleneck, we develop a dual-learning mechanism, which can enable an NMT system to automatically learn from unlabeled data through a dual-learning game. This mechanism is inspired by the following observation: any machine translation task has a dual task, e.g., English-to-French translation (primal) versus French-to-English translation (dual); the primal and dual tasks can form a closed loop, and generate informative feedback signals to train the translation models, even if without the involvement of a human labeler. In the dual-learning mechanism, we use one agent to represent the model for the primal task and the other agent to represent the model for the dual task, then ask them to teach each other through a reinforcement learning process. Based on the feedback signals generated during this process (e.g., the language-model likelihood of the output of a model, and the reconstruction error of the original sentence after the primal and dual translations), we can iteratively update the two models until convergence (e.g., using the policy gradient methods). We call the corresponding approach to neural machine translation dual-NMT. Experiments show that dual-NMT works very well on English ↔ French translation; especially, by learning from monolingual data (with 10% bilingual data for warm start), it achieves a comparable accuracy to NMT trained from the full bilingual data for the French-to-English translation task."
  },
  {
    "paperId": "f743833c22961537791171ef1d3fb42db8f357a3",
    "title": "Machine Learning Methods for Attack Detection in the Smart Grid",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2015,
    "citationCount": 520,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1503.06468",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1503.06468, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2159942",
        "name": "M. Ozay"
      },
      {
        "authorId": "2549673",
        "name": "I. Esnaola"
      },
      {
        "authorId": "2228966286",
        "name": "Fatos Tunay"
      },
      {
        "authorId": "70633342",
        "name": "Yarman Vural"
      },
      {
        "authorId": "1697413",
        "name": "S. Kulkarni"
      },
      {
        "authorId": "2256635120",
        "name": "H. Vincent Poor"
      }
    ],
    "abstract": "Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework."
  },
  {
    "paperId": "33ed3d9a505131daf631ca5fa1307e3aafdd3343",
    "title": "Learning skillful medium-range global weather forecasting",
    "venue": "Science",
    "year": 2023,
    "citationCount": 1073,
    "openAccessPdf": {
      "url": "https://www.science.org/doi/pdf/10.1126/science.adi2336?download=true",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.adi2336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.adi2336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2266459752",
        "name": "Remi Lam"
      },
      {
        "authorId": "2266397148",
        "name": "Alvaro Sanchez-Gonzalez"
      },
      {
        "authorId": "2266396481",
        "name": "Matthew Willson"
      },
      {
        "authorId": "5721359",
        "name": "Peter Wirnsberger"
      },
      {
        "authorId": "2065413220",
        "name": "Meire Fortunato"
      },
      {
        "authorId": "2266458515",
        "name": "Ferran Alet"
      },
      {
        "authorId": "2938043",
        "name": "Suman V. Ravuri"
      },
      {
        "authorId": "23988602",
        "name": "T. Ewalds"
      },
      {
        "authorId": "1397576010",
        "name": "Z. Eaton-Rosen"
      },
      {
        "authorId": "2267195372",
        "name": "Weihua Hu"
      },
      {
        "authorId": "2198276136",
        "name": "Alexander Merose"
      },
      {
        "authorId": "2257229905",
        "name": "Stephan Hoyer"
      },
      {
        "authorId": "2198276080",
        "name": "George Holland"
      },
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      },
      {
        "authorId": "2114860628",
        "name": "Jacklynn Stott"
      },
      {
        "authorId": "1863250",
        "name": "A. Pritzel"
      },
      {
        "authorId": "1701708450",
        "name": "Shakir Mohamed"
      },
      {
        "authorId": "2265542669",
        "name": "Peter Battaglia"
      }
    ],
    "abstract": "Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. Editor’s summary The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting."
  },
  {
    "paperId": "bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6",
    "title": "A survey of feature selection and feature extraction techniques in machine learning",
    "venue": "Sai",
    "year": 2014,
    "citationCount": 995,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/SAI.2014.6918213?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SAI.2014.6918213, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2257398",
        "name": "Samina Khalid"
      },
      {
        "authorId": "33075067",
        "name": "Tehmina Khalil"
      },
      {
        "authorId": "49538771",
        "name": "Shamila Nasreen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6c16cf47f2b872e7b2ad06facb5d491857650514",
    "title": "C4.5: Programs for Machine Learning (書評)",
    "venue": "",
    "year": 1995,
    "citationCount": 2007,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2095718110",
        "name": "金田 重郎"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c",
    "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
    "venue": "International Conference on Machine Learning",
    "year": 2015,
    "citationCount": 8473,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1503.03585, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1407546424",
        "name": "Jascha Narain Sohl-Dickstein"
      },
      {
        "authorId": "2144479710",
        "name": "Eric A. Weiss"
      },
      {
        "authorId": "2333223",
        "name": "Niru Maheswaranathan"
      },
      {
        "authorId": "25769960",
        "name": "S. Ganguli"
      }
    ],
    "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm."
  },
  {
    "paperId": "cc242e85615d38ab166295753823180ec9099951",
    "title": "Scikit-learn: Machine Learning Without Learning the Machinery",
    "venue": "GETMBL",
    "year": 2015,
    "citationCount": 471,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2786984.2786995?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2786984.2786995, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3025780",
        "name": "G. Varoquaux"
      },
      {
        "authorId": "2286302",
        "name": "L. Buitinck"
      },
      {
        "authorId": "1881041",
        "name": "Gilles Louppe"
      },
      {
        "authorId": "2958756",
        "name": "O. Grisel"
      },
      {
        "authorId": "2570016",
        "name": "Fabian Pedregosa"
      },
      {
        "authorId": "2086994888",
        "name": "A. Mueller"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0173ca962e4ab3d084c89568345e06f67d3d7efc",
    "title": "Hyperparameter Search in Machine Learning",
    "venue": "arXiv.org",
    "year": 2015,
    "citationCount": 459,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1502.02127, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48461464",
        "name": "M. Claesen"
      },
      {
        "authorId": "143750713",
        "name": "B. Moor"
      }
    ],
    "abstract": "We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential."
  },
  {
    "paperId": "3bff76c25f7c416834655ba664553b14eb67a11c",
    "title": "Sparse Bayesian Learning and the Relevance Vector Machine",
    "venue": "Journal of machine learning research",
    "year": 2001,
    "citationCount": 2265,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2831141",
        "name": "Michael E. Tipping"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7f8c7783a92d4c2f388902fffb3b378921f9e8ad",
    "title": "Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications",
    "venue": "IEEE Communications Surveys and Tutorials",
    "year": 2014,
    "citationCount": 857,
    "openAccessPdf": {
      "url": "https://ink.library.smu.edu.sg/sis_research/2963",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1405.4463, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34714099",
        "name": "Mohammad Abu Alsheikh"
      },
      {
        "authorId": "2047908196",
        "name": "Shaowei Lin"
      },
      {
        "authorId": "1713586",
        "name": "D. Niyato"
      },
      {
        "authorId": "145858985",
        "name": "H. Tan"
      }
    ],
    "abstract": "Wireless sensor networks (WSNs) monitor dynamic environments that change rapidly over time. This dynamic behavior is either caused by external factors or initiated by the system designers themselves. To adapt to such conditions, sensor networks often adopt machine learning techniques to eliminate the need for unnecessary redesign. Machine learning also inspires many practical solutions that maximize resource utilization and prolong the lifespan of the network. In this paper, we present an extensive literature review over the period 2002-2013 of machine learning methods that were used to address common issues in WSNs. The advantages and disadvantages of each proposed algorithm are evaluated against the corresponding problem. We also provide a comparative guide to aid WSN designers in developing suitable machine learning solutions for their specific application challenges."
  },
  {
    "paperId": "1592fe924114866c1ac559bae33ea789930daa98",
    "title": "Gaussian Processes for Machine Learning",
    "venue": "Adaptive computation and machine learning",
    "year": 2005,
    "citationCount": 1655,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/mitpress/3206.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/mitpress/3206.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2247411478",
        "name": "Carl E. Rasmussen"
      },
      {
        "authorId": "2248834664",
        "name": "Christopher K. I. Williams"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7da323e7103245eeaed32367c46abe3f4913df86",
    "title": "A survey of techniques for internet traffic classification using machine learning",
    "venue": "IEEE Communications Surveys and Tutorials",
    "year": 2008,
    "citationCount": 1683,
    "openAccessPdf": {
      "url": "https://researchbank.swinburne.edu.au/file/4dd80a73-aaee-4a78-929d-b42124b30192/1/PDF (Published version).pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/SURV.2008.080406?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SURV.2008.080406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1716282",
        "name": "Thuy T. T. Nguyen"
      },
      {
        "authorId": "145027304",
        "name": "G. Armitage"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30",
    "title": "MLaaS: Machine Learning as a Service",
    "venue": "International Conference on Machine Learning and Applications",
    "year": 2015,
    "citationCount": 400,
    "openAccessPdf": {
      "url": "http://publish.uwo.ca/%7Ekgroling/papers/MLaaS.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMLA.2015.152?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMLA.2015.152, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2067582822",
        "name": "Mauro Ribeiro"
      },
      {
        "authorId": "2222599",
        "name": "Katarina Grolinger"
      },
      {
        "authorId": "1711826",
        "name": "Miriam A. M. Capretz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b6cf9167aeb2782651156de5e22cad82ee69a225",
    "title": "UCI Repository of Machine Learning Databases",
    "venue": "",
    "year": 1996,
    "citationCount": 2192,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3335246",
        "name": "C. Merz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "61017ac0c108f68c987a1fe3e4c2b6223ddd6f31",
    "title": "Machine learning classifiers and fMRI: A tutorial overview",
    "venue": "NeuroImage",
    "year": 2009,
    "citationCount": 1709,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc2892746?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neuroimage.2008.11.007?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neuroimage.2008.11.007, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144637670",
        "name": "Francisco Pereira"
      },
      {
        "authorId": "40975594",
        "name": "Tom Michael Mitchell"
      },
      {
        "authorId": "46378362",
        "name": "M. Botvinick"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0cb51ba29590c24b5cbdabd1fd608b0a728d28af",
    "title": "Machine Learning",
    "venue": "Industrial Applications of Machine Learning",
    "year": 2018,
    "citationCount": 2,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1201/9781351128384-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/9781351128384-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144999310",
        "name": "P. Larrañaga"
      },
      {
        "authorId": "2064423697",
        "name": "D. Atienza"
      },
      {
        "authorId": "1410223664",
        "name": "J. Diaz-Rozo"
      },
      {
        "authorId": "72399671",
        "name": "A. Ogbechie"
      },
      {
        "authorId": "1405432430",
        "name": "Carlos Puerto-Santana"
      },
      {
        "authorId": "1687365",
        "name": "C. Bielza"
      }
    ],
    "abstract": ": The difficulty of detecting non-technical losses by electric energy concessionaires has been a great and constant challenge. Inspecting consumer units located in rural areas demands excessive time and expenses on the part of concessionaires, due to the distance from urban centers and the difficulty of access, without there being a previous technical indication of the occurrence of Non-Technical Losses. This work aims to present a methodology for estimating electricity consumption for rice crops that use flood irrigation, in the city of Uruguaiana, Rio Grande do Sul, implementing classification using artificial intelligence techniques (clustering, k-means and random forest)"
  },
  {
    "paperId": "a749fccbcfc0382f26789ce0b9a03fa98b9e608c",
    "title": "Programs for Machine Learning. Part I",
    "venue": "Information and Control",
    "year": 1962,
    "citationCount": 2259,
    "openAccessPdf": {
      "url": "https://doi.org/10.1016/s0019-9958(62)90649-6",
      "status": "HYBRID",
      "license": "elsevier-specific: oa user license",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0019-9958(62)90649-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0019-9958(62)90649-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "4688223",
        "name": "A. Hormann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e",
    "title": "MACHINE LEARNING An Artificial Intelligence Approach",
    "venue": "",
    "year": 2009,
    "citationCount": 1869,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2421006",
        "name": "R. Michalski"
      },
      {
        "authorId": "2285118814",
        "name": "Tom M Mitchell"
      },
      {
        "authorId": "1695106",
        "name": "Jack Mostow"
      },
      {
        "authorId": "2285270221",
        "name": "Bernard Nudel"
      },
      {
        "authorId": "2285156580",
        "name": "Michael Rychener"
      },
      {
        "authorId": "2285146061",
        "name": "Ross Quinlan"
      },
      {
        "authorId": "2285271872",
        "name": "Herbert Simon"
      },
      {
        "authorId": "2258056458",
        "name": "Derek Sleeman"
      },
      {
        "authorId": "2061198516",
        "name": "Robert Stepp"
      },
      {
        "authorId": "2195972",
        "name": "P. Utgoff"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ed875931b55fd413bff6e04ab58d594647065eac",
    "title": "Encyclopedia of Machine Learning",
    "venue": "Encyclopedia of Machine Learning",
    "year": 2011,
    "citationCount": 1374,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-0-387-30164-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-0-387-30164-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1804253",
        "name": "Claude Sammut"
      },
      {
        "authorId": "1726660",
        "name": "Geoffrey I. Webb"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "04f4085c0126ba29453a582cd1e62e05c8e15c82",
    "title": "Automating the Construction of Internet Portals with Machine Learning",
    "venue": "Information retrieval (Boston)",
    "year": 2000,
    "citationCount": 1531,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1009953814988?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1009953814988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143753639",
        "name": "A. McCallum"
      },
      {
        "authorId": "145172877",
        "name": "K. Nigam"
      },
      {
        "authorId": "35211659",
        "name": "Jason D. M. Rennie"
      },
      {
        "authorId": "2544946",
        "name": "K. Seymore"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cc944c3a1b51ff3112840cb147c32c14433b1279",
    "title": "Systematic Poisoning Attacks on and Defenses for Machine Learning in Healthcare",
    "venue": "IEEE journal of biomedical and health informatics",
    "year": 2015,
    "citationCount": 320,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/JBHI.2014.2344095?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JBHI.2014.2344095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1703366",
        "name": "Mehran Mozaffari Kermani"
      },
      {
        "authorId": "1398781979",
        "name": "S. Sur-Kolay"
      },
      {
        "authorId": "145291370",
        "name": "A. Raghunathan"
      },
      {
        "authorId": "144874163",
        "name": "N. Jha"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "da71c787c20a4ca14528e3c87edbb1432ee78135",
    "title": "Machine Learning",
    "venue": "Wiley StatsRef: Statistics Reference Online",
    "year": 2018,
    "citationCount": 1,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781118445112.stat08098?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781118445112.stat08098, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1951155",
        "name": "M. Fattore"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1684ae5e1e4ddb26a0b16cf452cd2ddfe2b8d258",
    "title": "Machine Learning",
    "venue": "Encyclopedia of Social Network Analysis and Mining. 2nd Ed.",
    "year": 2018,
    "citationCount": 0,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4939-7131-2_100620?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4939-7131-2_100620, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1768120",
        "name": "Tony Jebara"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "01f702f8b1f9d1314587015f1f038af4d5735e77",
    "title": "Opposition-Based Learning: A New Scheme for Machine Intelligence",
    "venue": "International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",
    "year": 2005,
    "citationCount": 1981,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/CIMCA.2005.1631345?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CIMCA.2005.1631345, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9315255",
        "name": "H. Tizhoosh"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9cf9ba251aa8a41be50a8342839b1813cfc30370",
    "title": "API design for machine learning software: experiences from the scikit-learn project",
    "venue": "arXiv.org",
    "year": 2013,
    "citationCount": 1064,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1309.0238, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2286302",
        "name": "L. Buitinck"
      },
      {
        "authorId": "2064496649",
        "name": "G. Louppe"
      },
      {
        "authorId": "2292398682",
        "name": "Mathieu Blondel"
      },
      {
        "authorId": "2310335993",
        "name": "F. Pedregosa"
      },
      {
        "authorId": null,
        "name": "Andreas Mueller"
      },
      {
        "authorId": "2958756",
        "name": "O. Grisel"
      },
      {
        "authorId": "2264431013",
        "name": "Vlad Niculae"
      },
      {
        "authorId": "2780213",
        "name": "P. Prettenhofer"
      },
      {
        "authorId": "2394635438",
        "name": "Alexandre Gramfort"
      },
      {
        "authorId": "40122174",
        "name": "Jaques Grobler"
      },
      {
        "authorId": "2394636232",
        "name": "Robert Layton"
      },
      {
        "authorId": "2394636205",
        "name": "Jacob VanderPlas"
      },
      {
        "authorId": "2394632361",
        "name": "Arnaud Joly"
      },
      {
        "authorId": "2394635368",
        "name": "Brian Holt"
      },
      {
        "authorId": "3025780",
        "name": "G. Varoquaux"
      }
    ],
    "abstract": "Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library."
  },
  {
    "paperId": "04ca5de59edbdd49a9c0502c58331524d220bc8c",
    "title": "Communication Efficient Distributed Machine Learning with the Parameter Server",
    "venue": "Neural Information Processing Systems",
    "year": 2014,
    "citationCount": 669,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2124778071",
        "name": "Mu Li"
      },
      {
        "authorId": "34752743",
        "name": "D. Andersen"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      },
      {
        "authorId": "144782042",
        "name": "Kai Yu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6eabf6e67c29778265bc9fef3b58b2756c739c83",
    "title": "Machine Learning for Aerial Image Labeling",
    "venue": "",
    "year": 2013,
    "citationCount": 817,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      },
      {
        "authorId": "3255983",
        "name": "Volodymyr Mnih"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b2114228411d367cfa6ca091008291f250a2c490",
    "title": "Deep learning and process understanding for data-driven Earth system science",
    "venue": "Nature",
    "year": 2019,
    "citationCount": 3605,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41586-019-0912-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41586-019-0912-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2530948",
        "name": "M. Reichstein"
      },
      {
        "authorId": "1397959153",
        "name": "Gustau Camps-Valls"
      },
      {
        "authorId": "121696502",
        "name": "B. Stevens"
      },
      {
        "authorId": "95799904",
        "name": "M. Jung"
      },
      {
        "authorId": "1728382",
        "name": "Joachim Denzler"
      },
      {
        "authorId": "116377499",
        "name": "N. Carvalhais"
      },
      {
        "authorId": "1764912",
        "name": "Prabhat"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1b04936c2599e59b120f743fbb30df2eed3fd782",
    "title": "Shortcut learning in deep neural networks",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 2353,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2004.07780",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2004.07780, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1949747",
        "name": "Robert Geirhos"
      },
      {
        "authorId": "51919565",
        "name": "J. Jacobsen"
      },
      {
        "authorId": "40899528",
        "name": "Claudio Michaelis"
      },
      {
        "authorId": "1804104",
        "name": "R. Zemel"
      },
      {
        "authorId": "40634590",
        "name": "Wieland Brendel"
      },
      {
        "authorId": "1731199",
        "name": "M. Bethge"
      },
      {
        "authorId": "1924112",
        "name": "Felix Wichmann"
      }
    ],
    "abstract": "Deep learning has triggered the current rise of artificial intelligence and is the workhorse of today’s machine intelligence. Numerous success stories have rapidly spread all over science, industry and society, but its limitations have only recently come into focus. In this Perspective we seek to distil how many of deep learning’s failures can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in comparative psychology, education and linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike. Based on these observations, we develop a set of recommendations for model interpretation and benchmarking, highlighting recent advances in machine learning to improve robustness and transferability from the lab to real-world applications. Deep learning has resulted in impressive achievements, but under what circumstances does it fail, and why? The authors propose that its failures are a consequence of shortcut learning, a common characteristic across biological and artificial systems in which strategies that appear to have solved a problem fail unexpectedly under different circumstances."
  },
  {
    "paperId": "b245c5d36702eaae0ff374fad92848024bc99534",
    "title": "The future of digital health with federated learning",
    "venue": "npj Digital Medicine",
    "year": 2020,
    "citationCount": 2154,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41746-020-00323-1.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.08119, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3180607",
        "name": "Nicola Rieke"
      },
      {
        "authorId": "2058725702",
        "name": "Jonny Hancox"
      },
      {
        "authorId": "47112939",
        "name": "Wenqi Li"
      },
      {
        "authorId": "1877512",
        "name": "F. Milletarì"
      },
      {
        "authorId": "144531567",
        "name": "H. Roth"
      },
      {
        "authorId": "3098247",
        "name": "Shadi Albarqouni"
      },
      {
        "authorId": "3199900",
        "name": "S. Bakas"
      },
      {
        "authorId": "145817877",
        "name": "M. Galtier"
      },
      {
        "authorId": "1699344",
        "name": "B. Landman"
      },
      {
        "authorId": "2139962185",
        "name": "K. Maier-Hein"
      },
      {
        "authorId": "143951081",
        "name": "S. Ourselin"
      },
      {
        "authorId": "51496137",
        "name": "Micah J. Sheller"
      },
      {
        "authorId": "2052151390",
        "name": "Ronald M. Summers"
      },
      {
        "authorId": "145994651",
        "name": "Andrew Trask"
      },
      {
        "authorId": "3262394",
        "name": "Daguang Xu"
      },
      {
        "authorId": "1816169",
        "name": "Maximilian Baust"
      },
      {
        "authorId": "145244249",
        "name": "M. Cardoso"
      }
    ],
    "abstract": "Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed."
  },
  {
    "paperId": "b3683f5b5bfa6533b2c0eacd653e19ac1ec33d57",
    "title": "Distributed GraphLab: A Framework for Machine Learning in the Cloud",
    "venue": "Proceedings of the VLDB Endowment",
    "year": 2012,
    "citationCount": 1081,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1204.6078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1680638",
        "name": "Yucheng Low"
      },
      {
        "authorId": "2119113835",
        "name": "Joseph Gonzalez"
      },
      {
        "authorId": "1717990",
        "name": "Aapo Kyrola"
      },
      {
        "authorId": "1741745",
        "name": "Danny Bickson"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      },
      {
        "authorId": "1695576",
        "name": "Joseph M Hellerstein"
      }
    ],
    "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. \n \nWe develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations."
  },
  {
    "paperId": "79cf9462a583e1889781868cbf8c31e43b36dd2f",
    "title": "Towards Federated Learning at Scale: System Design",
    "venue": "USENIX workshop on Tackling computer systems problems with machine learning techniques",
    "year": 2019,
    "citationCount": 2893,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1902.01046, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2039588",
        "name": "Keith Bonawitz"
      },
      {
        "authorId": "153086296",
        "name": "Hubert Eichner"
      },
      {
        "authorId": "1718871",
        "name": "W. Grieskamp"
      },
      {
        "authorId": "68973739",
        "name": "Dzmitry Huba"
      },
      {
        "authorId": "67147139",
        "name": "A. Ingerman"
      },
      {
        "authorId": "2072422622",
        "name": "Vladimir Ivanov"
      },
      {
        "authorId": "3104292",
        "name": "Chloé Kiddon"
      },
      {
        "authorId": "32139366",
        "name": "Jakub Konecný"
      },
      {
        "authorId": "49436220",
        "name": "S. Mazzocchi"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "2592207",
        "name": "Timon Van Overveldt"
      },
      {
        "authorId": "2131407",
        "name": "David Petrou"
      },
      {
        "authorId": "1878835",
        "name": "Daniel Ramage"
      },
      {
        "authorId": "68972407",
        "name": "Jason Roselander"
      }
    ],
    "abstract": "Federated Learning is a distributed machine learning approach which enables model training on a large corpus of decentralized data. We have built a scalable production system for Federated Learning in the domain of mobile devices, based on TensorFlow. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, and touch upon the open problems and future directions."
  },
  {
    "paperId": "ce615ae61d67db8537e981a0a08da7f0f2ff1cee",
    "title": "Understanding Machine Learning: From Theory to Algorithms",
    "venue": "",
    "year": 2014,
    "citationCount": 426,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1389955537",
        "name": "Shai Shalev-Shwartz"
      },
      {
        "authorId": "1409749316",
        "name": "S. Ben-David"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9b0aa51901f05278928bdfcb4e9826a429a81293",
    "title": "Quantum algorithms for supervised and unsupervised machine learning",
    "venue": "",
    "year": 2013,
    "citationCount": 831,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1307.0411, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145762777",
        "name": "S. Lloyd"
      },
      {
        "authorId": "145233982",
        "name": "M. Mohseni"
      },
      {
        "authorId": "3157522",
        "name": "P. Rebentrost"
      }
    ],
    "abstract": "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms."
  },
  {
    "paperId": "db6ad6ded1cfa26fdc7437f27fb823ec533e96fe",
    "title": "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions",
    "venue": "SN Computer Science",
    "year": 2021,
    "citationCount": 1953,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s42979-021-00815-1.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8372231, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3456687",
        "name": "Iqbal H. Sarker"
      }
    ],
    "abstract": "Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of today’s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics, cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals."
  },
  {
    "paperId": "0e779fd59353a7f1f5b559b9d65fa4bfe367890c",
    "title": "Geometric Deep Learning: Going beyond Euclidean data",
    "venue": "IEEE Signal Processing Magazine",
    "year": 2016,
    "citationCount": 3566,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1611.08097",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.08097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1732570",
        "name": "M. Bronstein"
      },
      {
        "authorId": "143627859",
        "name": "Joan Bruna"
      },
      {
        "authorId": "1688882",
        "name": "Yann LeCun"
      },
      {
        "authorId": "3149531",
        "name": "Arthur Szlam"
      },
      {
        "authorId": "1697397",
        "name": "P. Vandergheynst"
      }
    ],
    "abstract": "Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them."
  },
  {
    "paperId": "e3948c28d605e0d90e88e160556cfc14fbba57c8",
    "title": "Incremental and Decremental Support Vector Machine Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2000,
    "citationCount": 1416,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2702388",
        "name": "G. Cauwenberghs"
      },
      {
        "authorId": "1685292",
        "name": "T. Poggio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39",
    "title": "Quantum Machine Learning: What Quantum Computing Means to Data Mining",
    "venue": "",
    "year": 2014,
    "citationCount": 401,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1756871",
        "name": "P. Wittek"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b4adef6c659ab62943ce1e68db4d9409d2ce3878",
    "title": "Machine learning methods in chemoinformatics",
    "venue": "Wiley Interdisciplinary Reviews. Computational Molecular Science",
    "year": 2014,
    "citationCount": 397,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcms.1183",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4180928, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35405821",
        "name": "John B. O. Mitchell"
      }
    ],
    "abstract": "Machine learning algorithms are generally developed in computer science or adjacent disciplines and find their way into chemical modeling by a process of diffusion. Though particular machine learning methods are popular in chemoinformatics and quantitative structure–activity relationships (QSAR), many others exist in the technical literature. This discussion is methods‐based and focused on some algorithms that chemoinformatics researchers frequently use. It makes no claim to be exhaustive. We concentrate on methods for supervised learning, predicting the unknown property values of a test set of instances, usually molecules, based on the known values for a training set. Particularly relevant approaches include Artificial Neural Networks, Random Forest, Support Vector Machine, k‐Nearest Neighbors and naïve Bayes classifiers. WIREs Comput Mol Sci 2014, 4:468–481."
  },
  {
    "paperId": "c99179ca3784e3465fd9ed049d7f34b50d39393e",
    "title": "Ensemble learning: A survey",
    "venue": "WIREs Data Mining Knowl. Discov.",
    "year": 2018,
    "citationCount": 2702,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1249",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/widm.1249?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/widm.1249, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2066733832",
        "name": "Omer Sagi"
      },
      {
        "authorId": "1732091",
        "name": "L. Rokach"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6d431f835c06afdea45dff6b24486bf301ebdef0",
    "title": "An Overview of Multi-Task Learning in Deep Neural Networks",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 3013,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1706.05098, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2884561",
        "name": "Sebastian Ruder"
      }
    ],
    "abstract": "Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks."
  },
  {
    "paperId": "1d122a074c936fcfd95faf44608e377a9d1799c8",
    "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2017,
    "citationCount": 2866,
    "openAccessPdf": {
      "url": "https://www.ijcai.org/proceedings/2017/0239.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.04247, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3339005",
        "name": "Huifeng Guo"
      },
      {
        "authorId": "2824766",
        "name": "Ruiming Tang"
      },
      {
        "authorId": "144782498",
        "name": "Yunming Ye"
      },
      {
        "authorId": "7718952",
        "name": "Zhenguo Li"
      },
      {
        "authorId": "1996703",
        "name": "Xiuqiang He"
      }
    ],
    "abstract": "Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide & Deep model from Google, DeepFM has a shared input to its \"wide\" and \"deep\" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data."
  },
  {
    "paperId": "9eca724e2b8e7a20fa1b05b8a9398f86a24b86d6",
    "title": "The master algorithm: how the quest for the ultimate learning machine will remake our world",
    "venue": "",
    "year": 2015,
    "citationCount": 508,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "31294642",
        "name": "W. Hasperué"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0d41dd8c5a1a1d78575bd4f4ca5d7af3d471839a",
    "title": "Multiagent Systems: A Survey from a Machine Learning Perspective",
    "venue": "Auton. Robots",
    "year": 2000,
    "citationCount": 1448,
    "openAccessPdf": {
      "url": "http://www-2.cs.cmu.edu/~mmv/papers/MASsurvey.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1008942012299?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1008942012299, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144848112",
        "name": "P. Stone"
      },
      {
        "authorId": "1956361",
        "name": "M. Veloso"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "06a81f63fc4ccfcf02934647a7c17454b91853b0",
    "title": "Machine Learning - The Art and Science of Algorithms that Make Sense of Data",
    "venue": "",
    "year": 2012,
    "citationCount": 952,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144474086",
        "name": "P. Flach"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ea58af907495e97c93997119db4a59fab5cd3683",
    "title": "Deep Machine Learning - A New Frontier in Artificial Intelligence Research [Research Frontier]",
    "venue": "IEEE Computational Intelligence Magazine",
    "year": 2010,
    "citationCount": 1175,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MCI.2010.938364?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MCI.2010.938364, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1804314",
        "name": "I. Arel"
      },
      {
        "authorId": "2483864",
        "name": "Derek C. Rose"
      },
      {
        "authorId": "1970334",
        "name": "T. Karnowski"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d82f27f4a8dcee6cbab41ff954cc6c2b7709a693",
    "title": "Mastering Machine Learning With scikit-learn",
    "venue": "",
    "year": 2014,
    "citationCount": 252,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "69904096",
        "name": "Gavin Hackeling"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4efe53a9653d1481e50382a2c95bce6eb4f6de9d",
    "title": "Kernel Methods and Machine Learning",
    "venue": "",
    "year": 2014,
    "citationCount": 232,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9781139176224.013?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9781139176224.013, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144410963",
        "name": "S. Kung"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "38aff6df1accc456f6cda7d16d4b9ecf418ef21e",
    "title": "Map-Reduce for Machine Learning on Multicore",
    "venue": "Neural Information Processing Systems",
    "year": 2006,
    "citationCount": 1276,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2551676",
        "name": "Cheng-Tao Chu"
      },
      {
        "authorId": "2109828167",
        "name": "Sang Kyun Kim"
      },
      {
        "authorId": "47904256",
        "name": "Yi-An Lin"
      },
      {
        "authorId": "2117163611",
        "name": "YuanYuan Yu"
      },
      {
        "authorId": "1720184",
        "name": "Gary R. Bradski"
      },
      {
        "authorId": "34699434",
        "name": "A. Ng"
      },
      {
        "authorId": "1746638",
        "name": "K. Olukotun"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ca011427853d34ce4ec9ccafde8a70c9eacc3e21",
    "title": "Deep Learning for Computer Vision: A Brief Review",
    "venue": "Computational Intelligence and Neuroscience",
    "year": 2018,
    "citationCount": 3054,
    "openAccessPdf": {
      "url": "http://downloads.hindawi.com/journals/cin/2018/7068349.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5816885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2594647",
        "name": "A. Voulodimos"
      },
      {
        "authorId": "120205775",
        "name": "N. Doulamis"
      },
      {
        "authorId": "1746705",
        "name": "A. Doulamis"
      },
      {
        "authorId": "1806369",
        "name": "Eftychios E. Protopapadakis"
      }
    ],
    "abstract": "Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein."
  },
  {
    "paperId": "92a314bf9ae817836389cc97af5a9f42c561a772",
    "title": "Accelerating materials property predictions using machine learning",
    "venue": "Scientific Reports",
    "year": 2013,
    "citationCount": 697,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/srep02810.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3786293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49542803",
        "name": "G. Pilania"
      },
      {
        "authorId": "2108707708",
        "name": "Chenchen Wang"
      },
      {
        "authorId": "2144282447",
        "name": "Xun Jiang"
      },
      {
        "authorId": "143856869",
        "name": "S. Rajasekaran"
      },
      {
        "authorId": "83280215",
        "name": "R. Ramprasad"
      }
    ],
    "abstract": "The materials discovery process can be significantly expedited and simplified if we can learn effectively from available knowledge and data. In the present contribution, we show that efficient and accurate prediction of a diverse set of properties of material systems is possible by employing machine (or statistical) learning methods trained on quantum mechanical computations in combination with the notions of chemical similarity. Using a family of one-dimensional chain systems, we present a general formalism that allows us to discover decision rules that establish a mapping between easily accessible attributes of a system and its properties. It is shown that fingerprints based on either chemo-structural (compositional and configurational information) or the electronic charge density distribution can be used to make ultra-fast, yet accurate, property predictions. Harnessing such learning paradigms extends recent efforts to systematically explore and mine vast chemical spaces and can significantly accelerate the discovery of new application-specific materials."
  },
  {
    "paperId": "36dd3331060e5e6157d9558563b95253308709cb",
    "title": "Machine learning: a review of classification and combining techniques",
    "venue": "Artificial Intelligence Review",
    "year": 2006,
    "citationCount": 1375,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-007-9052-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-007-9052-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1697867",
        "name": "S. Kotsiantis"
      },
      {
        "authorId": "3194855",
        "name": "I. Zaharakis"
      },
      {
        "authorId": "1725504",
        "name": "P. Pintelas"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fa25610fb8586c2b50a3654edc5bb42fa7fc4729",
    "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction",
    "venue": "",
    "year": 2004,
    "citationCount": 18921,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1198/jasa.2004.s339?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1198/jasa.2004.s339, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144108246",
        "name": "D. Ruppert"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "184ac0766262312ba76bbdece4e7ffad0aa8180b",
    "title": "Representation Learning: A Review and New Perspectives",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2012,
    "citationCount": 13113,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1206.5538",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1206.5538, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "1760871",
        "name": "Aaron C. Courville"
      },
      {
        "authorId": "145467703",
        "name": "Pascal Vincent"
      }
    ],
    "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning."
  },
  {
    "paperId": "c0f7fcc2e03be4395625b6757b17b8834632b952",
    "title": "Ensemble Machine Learning: Methods and Applications",
    "venue": "",
    "year": 2012,
    "citationCount": 847,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2109292021",
        "name": "Cha Zhang"
      },
      {
        "authorId": "2363386",
        "name": "Yunqian Ma"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ea0425270d0dc496b31108572e706df7e40bce85",
    "title": "Machine Learning in Medical Imaging",
    "venue": "Machine Vision and Applications",
    "year": 2012,
    "citationCount": 853,
    "openAccessPdf": {
      "url": "https://doi.org/10.1155/2012/123727",
      "status": "CLOSED",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3303553, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2118855751",
        "name": "Kenji Suzuki"
      },
      {
        "authorId": "144855557",
        "name": "Pingkun Yan"
      },
      {
        "authorId": "2148955499",
        "name": "Fei Wang"
      },
      {
        "authorId": "144986260",
        "name": "D. Shen"
      }
    ],
    "abstract": "Medical imaging is becoming indispensable for patients' healthcare. Machine learning plays an essential role in the medical imaging field, including computer-aided diagnosis, image segmentation, image registration, image fusion, image-guided therapy, image annotation, and image database retrieval. With advances in medical imaging, new imaging modalities and methodologies such as cone-beam/multislice CT, 3D ultrasound imaging, tomosynthesis, diffusion-weighted magnetic resonance imaging (MRI), positron-emission tomography (PET)/CT, electrical impedance tomography, and diffuse optical tomography, new machine-learning algorithms/applications are demanded in the medical imaging field. Because of large variations and complexityit is generally difficult to derive analytic solutions or simple equations to represent objects such as lesions and anatomy in medical images. Therefore, tasks in medical imaging require “learning from examples” for accurate representation of data and prior knowledge. Because of its essential needs, machine learning in medical imaging is one of the most promising, growing fields. \n \nThe main aim of this special issue is to help advance the scientific research within the broad field of machine learning in medical imaging. The special issue was planned in conjunction with the International Workshop on Machine Learning in Medical Imaging (MLMI 2010) [1], which was the first workshop on this topic, held at the 13th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2010) in September, 2010, in Beijing, China. This special issue is one in a series of special issues of journals on this topic [2]; it focuses on major trends and challenges in this area, and it presents work aimed at identifying new cutting-edge techniques and their use in medical imaging. \n \nThe quality level of the submissions for this special issue was very high. A total of 17 papers were submitted to this issue in response to the call for papers. Based on a rigorous review process, 10 papers (59%) were accepted for publication in the special issue. The special issue starts by a review of studies on a class of machine-learning techniques, called pixel/voxel-based machine learning, in medical imaging by K. Suzuki. A series of medical imaging applications of machine-learning techniques are presented. A large variety of applications are well represented here, including organ modeling by D. Wang et al. and X. Qiao and Y.-W. Chen, brain function estimation by V. Michel et al., image reconstruction by H. Shouno et al., lesion classification by P. Wighton et al., modality classification by X.-H. Han and Y.-W. Chen, lesion segmentation by M. Zortea et al., organ segmentation by S. Alzubi et al., and visualization of molecular signals by F. Mattoli et al. Also, the issue covers various biomedical imaging modalities, including MRI by D. Wang et al., CT by X. Qiao and Y.-W. Chen and H. Shouno et al., functional MRI by V. Michel et al., dermoscopy by P. Wighton et al. and M. Zortea et al., scintigraphy by X.-H. Han and Y.-W. Chen, ultrasound imaging by X.-H. Han and Y.-W. Chen, radiography by X.-H. Han and Y.-W. Chen, MR angiography by S. Alzubi et al., and microscopy by F. Mattoli et al. as well as a variety of organs, including the kidneys by D. Wang et al., liver by X. Qiao and Y.-W. Chen, brain by V. Michel et al. and F. Mattoli et al., chest by S. Alzubi et al., skin by P. Wighton et al. and M. Zortea et al., and heart by F. Mattoli et al. Various machine-learning techniques were developed/used to solve the respective problems, including structured dictionary learning by D. Wang et al., generalized N-dimensional principal component analysis by X. Qiao et al., multiclass sparse Bayesian regression by V. Michel et al., Bayesian hyperparameter inference by H. Shouno et al., supervised learning of probabilistic models based on maximum aposteriori estimation and conditional random fields by P. Wighton et al., joint kernel equal contribution in support vector classification by X.-H. Han and Y.-W. Chen, and iterative hybrid classification by M. Zortea et al. \n \nWe are grateful to all authors for their excellent contributions to this special issue and to all reviewers for their reviews and constructive suggestions. We hope that this special issue will inspire further ideas for creative research, advance the field of machine learning in medical imaging, and facilitate the translation of the research from bench to bedside. \n \n \nKenji Suzuki \n \nPingkun Yan \n \nFei Wang \n \nDinggang Shen"
  },
  {
    "paperId": "8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795",
    "title": "Machine Unlearning",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2019,
    "citationCount": 1118,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.03817, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1452678444",
        "name": "Lucas Bourtoule"
      },
      {
        "authorId": "143754359",
        "name": "Varun Chandrasekaran"
      },
      {
        "authorId": "1415982317",
        "name": "Christopher A. Choquette-Choo"
      },
      {
        "authorId": "120074583",
        "name": "Hengrui Jia"
      },
      {
        "authorId": "1452679273",
        "name": "Adelin Travers"
      },
      {
        "authorId": "23696685",
        "name": "Baiwu Zhang"
      },
      {
        "authorId": "47412202",
        "name": "D. Lie"
      },
      {
        "authorId": "1967156",
        "name": "Nicolas Papernot"
      }
    ],
    "abstract": "Once users have shared their data online, it is generally difficult for them to revoke access and ask for the data to be deleted. Machine learning (ML) exacerbates this problem because any model trained with said data may have memorized it, putting users at risk of a successful privacy attack exposing their information. Yet, having models unlearn is notoriously difficult.We introduce SISA training, a framework that expedites the unlearning process by strategically limiting the influence of a data point in the training procedure. While our framework is applicable to any learning algorithm, it is designed to achieve the largest improvements for stateful algorithms like stochastic gradient descent for deep neural networks. SISA training reduces the computational overhead associated with unlearning, even in the worst-case setting where unlearning requests are made uniformly across the training set. In some cases, the service provider may have a prior on the distribution of unlearning requests that will be issued by users. We may take this prior into account to partition and order data accordingly, and further decrease overhead from unlearning.Our evaluation spans several datasets from different domains, with corresponding motivations for unlearning. Under no distributional assumptions, for simple learning tasks, we observe that SISA training improves time to unlearn points from the Purchase dataset by 4.63×, and 2.45× for the SVHN dataset, over retraining from scratch. SISA training also provides a speed-up of 1.36× in retraining for complex learning tasks such as ImageNet classification; aided by transfer learning, this results in a small degradation in accuracy. Our work contributes to practical data governance in machine unlearning."
  },
  {
    "paperId": "8a0f17e0ee66ad5f50cd35932747e6a806ef03cf",
    "title": "Applications of Machine Learning in Cancer Prediction and Prognosis",
    "venue": "Cancer Informatics",
    "year": 2006,
    "citationCount": 1223,
    "openAccessPdf": {
      "url": "https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030",
      "status": "GOLD",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC2675494, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34468738",
        "name": "Joseph A. Cruz"
      },
      {
        "authorId": "2066145",
        "name": "D. Wishart"
      }
    ],
    "abstract": "Machine learning is a branch of artificial intelligence that employs a variety of statistical, probabilistic and optimization techniques that allows computers to “learn” from past examples and to detect hard-to-discern patterns from large, noisy or complex data sets. This capability is particularly well-suited to medical applications, especially those that depend on complex proteomic and genomic measurements. As a result, machine learning is frequently used in cancer diagnosis and detection. More recently machine learning has been applied to cancer prognosis and prediction. This latter approach is particularly interesting as it is part of a growing trend towards personalized, predictive medicine. In assembling this review we conducted a broad survey of the different types of machine learning methods being used, the types of data being integrated and the performance of these methods in cancer prediction and prognosis. A number of trends are noted, including a growing dependence on protein biomarkers and microarray data, a strong bias towards applications in prostate and breast cancer, and a heavy reliance on “older” technologies such artificial neural networks (ANNs) instead of more recently developed or more easily interpretable machine learning methods. A number of published studies also appear to lack an appropriate level of validation or testing. Among the better designed and validated studies it is clear that machine learning methods can be used to substantially (15–25%) improve the accuracy of predicting cancer susceptibility, recurrence and mortality. At a more fundamental level, it is also evident that machine learning is also helping to improve our basic understanding of cancer development and progression."
  },
  {
    "paperId": "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972",
    "title": "A Survey on Transfer Learning",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2010,
    "citationCount": 22183,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TKDE.2009.191?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TKDE.2009.191, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1746914",
        "name": "Sinno Jialin Pan"
      },
      {
        "authorId": "152290618",
        "name": "Qiang Yang"
      }
    ],
    "abstract": "A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research."
  },
  {
    "paperId": "3803ea42e1fc773db3b1d0fa05f41b5ebf0a61d1",
    "title": "Toward Causal Representation Learning",
    "venue": "Proceedings of the IEEE",
    "year": 2021,
    "citationCount": 1138,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/5/9420072/09363924.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/JPROC.2021.3058954?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JPROC.2021.3058954, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2231240655",
        "name": "Bernhard Schölkopf"
      },
      {
        "authorId": "9557137",
        "name": "Francesco Locatello"
      },
      {
        "authorId": "153125952",
        "name": "Stefan Bauer"
      },
      {
        "authorId": "145604319",
        "name": "Nan Rosemary Ke"
      },
      {
        "authorId": "2583391",
        "name": "Nal Kalchbrenner"
      },
      {
        "authorId": "1996705",
        "name": "Anirudh Goyal"
      },
      {
        "authorId": "1865800402",
        "name": "Y. Bengio"
      }
    ],
    "abstract": "The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities."
  },
  {
    "paperId": "3448e3c55cf3b1f25aab4719eb094a95dbe7f05e",
    "title": "A survey on semi-supervised learning",
    "venue": "Machine-mediated learning",
    "year": 2019,
    "citationCount": 2228,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-019-05855-6.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-019-05855-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-019-05855-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1410913947",
        "name": "Jesper E. van Engelen"
      },
      {
        "authorId": "2470869",
        "name": "H. Hoos"
      }
    ],
    "abstract": "Semi-supervised learning is the branch of machine learning concerned with using labelled as well as unlabelled data to perform certain learning tasks. Conceptually situated between supervised and unsupervised learning, it permits harnessing the large amounts of unlabelled data available in many use cases in combination with typically smaller sets of labelled data. In recent years, research in this area has followed the general trends observed in machine learning, with much attention directed at neural network-based models and generative learning. The literature on the topic has also expanded in volume and scope, now encompassing a broad spectrum of theory, algorithms and applications. However, no recent surveys exist to collect and organize this knowledge, impeding the ability of researchers and engineers alike to utilize it. Filling this void, we present an up-to-date overview of semi-supervised learning methods, covering earlier work as well as more recent advances. We focus primarily on semi-supervised classification, where the large majority of semi-supervised learning research takes place. Our survey aims to provide researchers and practitioners new to the field as well as more advanced readers with a solid understanding of the main approaches and algorithms developed over the past two decades, with an emphasis on the most prominent and currently relevant work. Furthermore, we propose a new taxonomy of semi-supervised classification algorithms, which sheds light on the different conceptual and methodological approaches for incorporating unlabelled data into the training process. Lastly, we show how the fundamental assumptions underlying most semi-supervised learning algorithms are closely connected to each other, and how they relate to the well-known semi-supervised clustering assumption."
  },
  {
    "paperId": "63861fbeb7ec41986b85965b9780b428d919919e",
    "title": "Support vector machine active learning for image retrieval",
    "venue": "MULTIMEDIA '01",
    "year": 2001,
    "citationCount": 1551,
    "openAccessPdf": {
      "url": "http://vc.cs.nthu.edu.tw/home/paper/codfiles/hcliang/200706051516/p107-tong.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/500141.500159?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/500141.500159, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2058177533",
        "name": "Simon Tong"
      },
      {
        "authorId": "33794424",
        "name": "E. Chang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "481dd25896ac531707870c9b8c179cce20013401",
    "title": "Towards Personalized Federated Learning",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2021,
    "citationCount": 1062,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2103.00710",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2103.00710, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2051715391",
        "name": "A. Tan"
      },
      {
        "authorId": "2110984588",
        "name": "Han Yu"
      },
      {
        "authorId": "101457473",
        "name": "Li-zhen Cui"
      },
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      }
    ],
    "abstract": "In parallel with the rapid adoption of artificial intelligence (AI) empowered by advances in AI research, there has been growing awareness and concerns of data privacy. Recent significant developments in the data regulation landscape have prompted a seismic shift in interest toward privacy-preserving AI. This has contributed to the popularity of Federated Learning (FL), the leading paradigm for the training of machine learning models on data silos in a privacy-preserving manner. In this survey, we explore the domain of personalized FL (PFL) to address the fundamental challenges of FL on heterogeneous data, a universal characteristic inherent in all real-world datasets. We analyze the key motivations for PFL and present a unique taxonomy of PFL techniques categorized according to the key challenges and personalization strategies in PFL. We highlight their key ideas, challenges, opportunities, and envision promising future trajectories of research toward a new PFL architectural design, realistic PFL benchmarking, and trustworthy PFL approaches."
  },
  {
    "paperId": "0dfcec3139b2b52a3b6a144f323f89dd37de1fa4",
    "title": "Supervised learning with quantum-enhanced feature spaces",
    "venue": "Nature",
    "year": 2018,
    "citationCount": 2116,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1804.11326, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3305298",
        "name": "Vojtěch Havlíček"
      },
      {
        "authorId": "143780361",
        "name": "A. Córcoles"
      },
      {
        "authorId": "1882551",
        "name": "K. Temme"
      },
      {
        "authorId": "3172601",
        "name": "A. Harrow"
      },
      {
        "authorId": "5817392",
        "name": "A. Kandala"
      },
      {
        "authorId": "37400490",
        "name": "J. Chow"
      },
      {
        "authorId": "34654804",
        "name": "J. Gambetta"
      }
    ],
    "abstract": "Machine learning and quantum computing are two technologies that each have the potential to alter how computation is performed to address previously untenable problems. Kernel methods for machine learning are ubiquitous in pattern recognition, with support vector machines (SVMs) being the best known method for classification problems. However, there are limitations to the successful solution to such classification problems when the feature space becomes large, and the kernel functions become computationally expensive to estimate. A core element in the computational speed-ups enabled by quantum algorithms is the exploitation of an exponentially large quantum state space through controllable entanglement and interference. Here we propose and experimentally implement two quantum algorithms on a superconducting processor. A key component in both methods is the use of the quantum state space as feature space. The use of a quantum-enhanced feature space that is only efficiently accessible on a quantum computer provides a possible path to quantum advantage. The algorithms solve a problem of supervised learning: the construction of a classifier. One method, the quantum variational classifier, uses a variational quantum circuit1,2 to classify the data in a way similar to the method of conventional SVMs. The other method, a quantum kernel estimator, estimates the kernel function on the quantum computer and optimizes a classical SVM. The two methods provide tools for exploring the applications of noisy intermediate-scale quantum computers3 to machine learning. Two classification algorithms that use the quantum state space to produce feature maps are demonstrated on a superconducting processor, enabling the solution of problems when the feature space is large and the kernel functions are computationally expensive to estimate."
  },
  {
    "paperId": "0d39cc42f2186dac99898121bbc8bb2b965ba93d",
    "title": "Assessment and Validation of Machine Learning Methods for Predicting Molecular Atomization Energies.",
    "venue": "Journal of Chemical Theory and Computation",
    "year": 2013,
    "citationCount": 549,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1021/ct400195d?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/ct400195d, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39960184",
        "name": "K. Hansen"
      },
      {
        "authorId": "144535526",
        "name": "G. Montavon"
      },
      {
        "authorId": "3022604",
        "name": "Franziska Biegler"
      },
      {
        "authorId": "3050606",
        "name": "S. Fazli"
      },
      {
        "authorId": "48041657",
        "name": "M. Rupp"
      },
      {
        "authorId": "2286219690",
        "name": "Matthias Schefﬂer"
      },
      {
        "authorId": "11615881",
        "name": "O. V. Lilienfeld"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "2242066384",
        "name": "Acs Paragon"
      },
      {
        "authorId": "2242066378",
        "name": "Plus Environment"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
    "title": "Supplementary for: Deep learning with convolutional neural networks for EEG decoding and visualization",
    "venue": "",
    "year": 2017,
    "citationCount": 2797,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "9948572",
        "name": "R. Schirrmeister"
      },
      {
        "authorId": "2060551",
        "name": "Jost Tobias Springenberg"
      },
      {
        "authorId": "1704186",
        "name": "L. Fiederer"
      },
      {
        "authorId": "9936842",
        "name": "M. Glasstetter"
      },
      {
        "authorId": "2607675",
        "name": "Katharina Eggensperger"
      },
      {
        "authorId": "2345823",
        "name": "M. Tangermann"
      },
      {
        "authorId": "144661829",
        "name": "F. Hutter"
      },
      {
        "authorId": "2106871731",
        "name": "Wolfram Burgard"
      },
      {
        "authorId": "145928182",
        "name": "T. Ball"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1ee7be29ce297de6d79a438d26037595967f5b17",
    "title": "Ensemble Machine Learning",
    "venue": "",
    "year": 2012,
    "citationCount": 855,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4419-9326-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4419-9326-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2109292021",
        "name": "Cha Zhang"
      },
      {
        "authorId": "2363386",
        "name": "Yunqian Ma"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7cda32aeefdd3cabd76871b8ee06bd1a1ea2ba10",
    "title": "Revisiting the Nystrom Method for Improved Large-scale Machine Learning",
    "venue": "Journal of machine learning research",
    "year": 2013,
    "citationCount": 427,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1303.1849, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9545803",
        "name": "Alex Gittens"
      },
      {
        "authorId": "143884206",
        "name": "Michael W. Mahoney"
      }
    ],
    "abstract": "We reconsider randomized algorithms for the low-rank approximation of SPSD matrices such as Laplacian and kernel matrices that arise in data analysis and machine learning applications. Our main results consist of an empirical evaluation of the performance quality and running time of sampling and projection methods on a diverse suite of SPSD matrices. Our results highlight complementary aspects of sampling versus projection methods, and they point to differences between uniform and nonuniform sampling methods based on leverage scores. We complement our empirical results with a suite of worst-case theoretical bounds for both random sampling and random projection methods. These bounds are qualitatively superior to existing bounds--e.g., improved additive-error bounds for spectral and Frobenius norm error and relative-error bounds for trace norm error."
  },
  {
    "paperId": "3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
    "title": "Deep Learning with Python",
    "venue": "",
    "year": 2017,
    "citationCount": 2663,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2285163580",
        "name": "François Chollet"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5ff135450ae462855df27f44ad76872de5f1d1ea",
    "title": "Machine Learning for the Detection of Oil Spills in Satellite Radar Images",
    "venue": "Machine-mediated learning",
    "year": 1998,
    "citationCount": 1304,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1007452223027.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1007452223027?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1007452223027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713687",
        "name": "M. Kubát"
      },
      {
        "authorId": "1796214",
        "name": "R. Holte"
      },
      {
        "authorId": "1749003",
        "name": "S. Matwin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "622428f5122ad12a40229e1768ecb929fd747ee7",
    "title": "Multimodal Learning With Transformers: A Survey",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2022,
    "citationCount": 788,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/34/4359286/10123038.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2206.06488, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2087575115",
        "name": "P. Xu"
      },
      {
        "authorId": "2310779361",
        "name": "Xiatian Zhu"
      },
      {
        "authorId": "31799453",
        "name": "D. Clifton"
      }
    ],
    "abstract": "Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal Big Data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community."
  },
  {
    "paperId": "78989616eeeac55b202e3e4205225e7135054185",
    "title": "An Introduction to Deep Learning for the Physical Layer",
    "venue": "IEEE Transactions on Cognitive Communications and Networking",
    "year": 2017,
    "citationCount": 2345,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1702.00832",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1702.00832, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1388350203",
        "name": "Tim O'Shea"
      },
      {
        "authorId": "1749686",
        "name": "J. Hoydis"
      }
    ],
    "abstract": "We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation."
  },
  {
    "paperId": "ea86b804a5f4536d9646e4ac26898a43e35c6bc4",
    "title": "Machine Learning - An Algorithmic Perspective",
    "venue": "Chapman and Hall / CRC machine learning and pattern recognition series",
    "year": 2009,
    "citationCount": 1122,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2112255",
        "name": "S. Marsland"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1023f93870ff700c2ce936348a250deae8bd11cf",
    "title": "A Survey of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects",
    "venue": "IEEE Access",
    "year": 2022,
    "citationCount": 704,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09893798.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2022.3207287?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2022.3207287, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1395936685",
        "name": "Ibomoiye Domor Mienye"
      },
      {
        "authorId": "35110250",
        "name": "Yanxia Sun"
      }
    ],
    "abstract": "Ensemble learning techniques have achieved state-of-the-art performance in diverse machine learning applications by combining the predictions from two or more base models. This paper presents a concise overview of ensemble learning, covering the three main ensemble methods: bagging, boosting, and stacking, their early development to the recent state-of-the-art algorithms. The study focuses on the widely used ensemble algorithms, including random forest, adaptive boosting (AdaBoost), gradient boosting, extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical boosting (CatBoost). An attempt is made to concisely cover their mathematical and algorithmic representations, which is lacking in the existing literature and would be beneficial to machine learning researchers and practitioners."
  },
  {
    "paperId": "bc745811e231d1b4e37d2c56cbd2d67e37ba9032",
    "title": "Machine Learning Paradigms for Speech Recognition: An Overview",
    "venue": "IEEE Transactions on Audio, Speech, and Language Processing",
    "year": 2013,
    "citationCount": 397,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TASL.2013.2244083?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TASL.2013.2244083, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144718788",
        "name": "L. Deng"
      },
      {
        "authorId": "2108787178",
        "name": "Xiao Li"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8ccdee6826cbc97256bd4d082ebfa8cdfd2c727f",
    "title": "Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations",
    "venue": "Science",
    "year": 2020,
    "citationCount": 1727,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc7219083?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aaw4741?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aaw4741, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145401977",
        "name": "M. Raissi"
      },
      {
        "authorId": "37412357",
        "name": "A. Yazdani"
      },
      {
        "authorId": "1720124",
        "name": "G. Karniadakis"
      }
    ],
    "abstract": "Machine-learning fluid flow Quantifying fluid flow is relevant to disciplines ranging from geophysics to medicine. Flow can be experimentally visualized using, for example, smoke or contrast agents, but extracting velocity and pressure fields from this information is tricky. Raissi et al. developed a machine-learning approach to tackle this problem. Their method exploits the knowledge of Navier-Stokes equations, which govern the dynamics of fluid flow in many scientifically relevant situations. The authors illustrate their approach using examples such as blood flow in an aneurysm. Science, this issue p. 1026 A machine learning approach exploiting the knowledge of Navier-Stokes equations can extract detailed fluid flow information. For centuries, flow visualization has been the art of making fluid motion visible in physical and biological systems. Although such flow patterns can be, in principle, described by the Navier-Stokes equations, extracting the velocity and pressure fields directly from the images is challenging. We addressed this problem by developing hidden fluid mechanics (HFM), a physics-informed deep-learning framework capable of encoding the Navier-Stokes equations into the neural networks while being agnostic to the geometry or the initial and boundary conditions. We demonstrate HFM for several physical and biomedical problems by extracting quantitative information for which direct measurements may not be possible. HFM is robust to low resolution and substantial noise in the observation data, which is important for potential applications."
  },
  {
    "paperId": "4187caa4d0d329f47e18377a6cd31ef3f580cfcc",
    "title": "GraphLab: A New Framework For Parallel Machine Learning",
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "year": 2010,
    "citationCount": 922,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1006.4990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1680638",
        "name": "Yucheng Low"
      },
      {
        "authorId": "49988044",
        "name": "Joseph E. Gonzalez"
      },
      {
        "authorId": "1717990",
        "name": "Aapo Kyrola"
      },
      {
        "authorId": "1741745",
        "name": "Danny Bickson"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      },
      {
        "authorId": "1695576",
        "name": "Joseph M Hellerstein"
      }
    ],
    "abstract": "Designing and implementing efficient, provably correct parallel machine learning (ML) algorithms is challenging. Existing high-level parallel abstractions like MapReduce are insufficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. By targeting common patterns in ML, we developed GraphLab, which improves upon abstractions like MapReduce by compactly expressing asynchronous iterative algorithms with sparse computational dependencies while ensuring data consistency and achieving a high degree of parallel performance. We demonstrate the expressiveness of the GraphLab framework by designing and implementing parallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and Compressed Sensing. We show that using GraphLab we can achieve excellent parallel performance on large scale real-world problems."
  },
  {
    "paperId": "5776d0fea69d826519ee3649f620e8755a490efe",
    "title": "Lifelong Machine Learning Systems: Beyond Learning Algorithms",
    "venue": "AAAI Spring Symposium: Lifelong Machine Learning",
    "year": 2013,
    "citationCount": 377,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "49601276",
        "name": "Daniel L. Silver"
      },
      {
        "authorId": "152290618",
        "name": "Qiang Yang"
      },
      {
        "authorId": "2048948347",
        "name": "Lianghao Li"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "01e1fa7924b3eb76b73f1828c93805f3ba028bae",
    "title": "MLbase: A Distributed Machine-learning System",
    "venue": "Conference on Innovative Data Systems Research",
    "year": 2013,
    "citationCount": 378,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1746961",
        "name": "Tim Kraska"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      },
      {
        "authorId": "1734693",
        "name": "John C. Duchi"
      },
      {
        "authorId": "50331526",
        "name": "Rean Griffith"
      },
      {
        "authorId": "143666627",
        "name": "M. Franklin"
      },
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7ad66cba3b7e3abae7ef33122588512a146f7f77",
    "title": "A Survey on Multi-Task Learning",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2017,
    "citationCount": 2598,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1707.08114",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1707.08114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46867608",
        "name": "Yu Zhang"
      },
      {
        "authorId": "152290618",
        "name": "Qiang Yang"
      }
    ],
    "abstract": "Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications and theoretical analyses. For algorithmic modeling, we give a definition of MTL and then classify different MTL algorithms into five categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works in this paper. Finally, we present theoretical analyses and discuss several future directions for MTL."
  },
  {
    "paperId": "2bf7c350a8280e7c593d46a60127f99b21517121",
    "title": "On the Variance of the Adaptive Learning Rate and Beyond",
    "venue": "International Conference on Learning Representations",
    "year": 2019,
    "citationCount": 2088,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1908.03265, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46458310",
        "name": "Liyuan Liu"
      },
      {
        "authorId": "5795999",
        "name": "Haoming Jiang"
      },
      {
        "authorId": "50462546",
        "name": "Pengcheng He"
      },
      {
        "authorId": "2109136147",
        "name": "Weizhu Chen"
      },
      {
        "authorId": "46522098",
        "name": "Xiaodong Liu"
      },
      {
        "authorId": "1800422",
        "name": "Jianfeng Gao"
      },
      {
        "authorId": "153034701",
        "name": "Jiawei Han"
      }
    ],
    "abstract": "The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Here, we study its mechanism in details. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. We further propose RAdam, a new variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. All implementations are available at: this https URL."
  },
  {
    "paperId": "02ccfc9b550d381b5df4365a2ae48bb5f7f7578e",
    "title": "Noise2Noise: Learning Image Restoration without Clean Data",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 1808,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.04189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49244945",
        "name": "J. Lehtinen"
      },
      {
        "authorId": "1762967",
        "name": "Jacob Munkberg"
      },
      {
        "authorId": "2266452",
        "name": "J. Hasselgren"
      },
      {
        "authorId": "36436218",
        "name": "S. Laine"
      },
      {
        "authorId": "2976930",
        "name": "Tero Karras"
      },
      {
        "authorId": "1907688",
        "name": "M. Aittala"
      },
      {
        "authorId": "1761103",
        "name": "Timo Aila"
      }
    ],
    "abstract": "We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: under certain common circumstances, it is possible to learn to restore signals without ever observing clean ones, at performance close or equal to training using clean exemplars. We show applications in photographic noise removal, denoising of synthetic Monte Carlo images, and reconstruction of MRI scans from undersampled inputs, all based on only observing corrupted data."
  },
  {
    "paperId": "e3d772986d176057aca2f5e3eb783da53b559134",
    "title": "Unsupervised Machine Translation Using Monolingual Corpora Only",
    "venue": "International Conference on Learning Representations",
    "year": 2017,
    "citationCount": 1123,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1711.00043, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1830914",
        "name": "Guillaume Lample"
      },
      {
        "authorId": "8905591",
        "name": "Ludovic Denoyer"
      },
      {
        "authorId": "1706809",
        "name": "Marc'Aurelio Ranzato"
      }
    ],
    "abstract": "Machine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts to extend these successes to low-resource language pairs, yet requiring tens of thousands of parallel sentences. In this work, we take this research direction to the extreme and investigate whether it is possible to learn to translate even without any parallel data. We propose a model that takes sentences from monolingual corpora in two different languages and maps them into the same latent space. By learning to reconstruct in both languages from this shared feature space, the model effectively learns to translate without using any labeled data. We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French datasets, without using even a single parallel sentence at training time."
  },
  {
    "paperId": "b90d44f59fcb74c71d3e31f67a3f09efab187a4e",
    "title": "Machine learning in cell biology – teaching computers to recognize phenotypes",
    "venue": "Journal of Cell Science",
    "year": 2013,
    "citationCount": 320,
    "openAccessPdf": {
      "url": "https://doi.org/10.1242/jcs.123604",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1242/jcs.123604?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1242/jcs.123604, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2059204219",
        "name": "Christoph Sommer"
      },
      {
        "authorId": "5811106",
        "name": "D. Gerlich"
      }
    ],
    "abstract": "Summary Recent advances in microscope automation provide new opportunities for high-throughput cell biology, such as image-based screening. High-complex image analysis tasks often make the implementation of static and predefined processing rules a cumbersome effort. Machine-learning methods, instead, seek to use intrinsic data structure, as well as the expert annotations of biologists to infer models that can be used to solve versatile data analysis tasks. Here, we explain how machine-learning methods work and what needs to be considered for their successful application in cell biology. We outline how microscopy images can be converted into a data representation suitable for machine learning, and then introduce various state-of-the-art machine-learning algorithms, highlighting recent applications in image-based screening. Our Commentary aims to provide the biologist with a guide to the application of machine learning to microscopy assays and we therefore include extensive discussion on how to optimize experimental workflow as well as the data analysis pipeline."
  },
  {
    "paperId": "260077710ef86047c582bbe505feca36962ca406",
    "title": "Distributed GraphLab: A Framework for Machine Learning in the Cloud",
    "venue": "Very Large Data Bases Conference",
    "year": 2012,
    "citationCount": 687,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1680638",
        "name": "Yucheng Low"
      },
      {
        "authorId": "49988044",
        "name": "Joseph E. Gonzalez"
      },
      {
        "authorId": "1717990",
        "name": "Aapo Kyrola"
      },
      {
        "authorId": "1741745",
        "name": "Danny Bickson"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      },
      {
        "authorId": "1695576",
        "name": "Joseph M Hellerstein"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6ffe8872748d183d792c1b45aa5e4eb3b2116741",
    "title": "The immune system, adaptation, and machine learning",
    "venue": "",
    "year": 1986,
    "citationCount": 1418,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/0167-2789(81)90072-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/0167-2789(81)90072-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145394227",
        "name": "J. Farmer"
      },
      {
        "authorId": "2078655",
        "name": "N. Packard"
      },
      {
        "authorId": "1832489",
        "name": "A. Perelson"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e7e25fd534e9e024da329aea546484938df305a5",
    "title": "Gaussian Processes for Machine Learning (GPML) Toolbox",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 1057,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1756006.1953029?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1756006.1953029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3472959",
        "name": "C. Rasmussen"
      },
      {
        "authorId": "1748758",
        "name": "H. Nickisch"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ecf6c42d84351f34e1625a6a2e4cc6526da45c74",
    "title": "Representation Learning on Graphs: Methods and Applications",
    "venue": "IEEE Data Engineering Bulletin",
    "year": 2017,
    "citationCount": 2061,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1709.05584, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49437682",
        "name": "William L. Hamilton"
      },
      {
        "authorId": "83539859",
        "name": "Rex Ying"
      },
      {
        "authorId": "1702139",
        "name": "J. Leskovec"
      }
    ],
    "abstract": "Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work."
  },
  {
    "paperId": "4e55e4f5352d843bcf71a046b211dc72d0da1e1c",
    "title": "Human Decisions and Machine Predictions",
    "venue": "Quarterly Journal of Economics",
    "year": 2017,
    "citationCount": 1100,
    "openAccessPdf": {
      "url": "https://www.nber.org/system/files/working_papers/w23180/w23180.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1093/qje/qjx032?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/qje/qjx032, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3371403",
        "name": "J. Kleinberg"
      },
      {
        "authorId": "1892673",
        "name": "Himabindu Lakkaraju"
      },
      {
        "authorId": "1702139",
        "name": "J. Leskovec"
      },
      {
        "authorId": "50197963",
        "name": "J. Ludwig"
      },
      {
        "authorId": "2062143",
        "name": "S. Mullainathan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "afd0859a858481d2f36109f68090aebd77456b7f",
    "title": "The security of machine learning",
    "venue": "Machine-mediated learning",
    "year": 2010,
    "citationCount": 905,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf",
      "status": "HYBRID",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-010-5188-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-010-5188-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145140480",
        "name": "M. Barreno"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "1687701",
        "name": "A. Joseph"
      },
      {
        "authorId": "46245628",
        "name": "Doug J. Tygar"
      }
    ],
    "abstract": "Machine learning’s ability to rapidly evolve to changing and complex situations has helped it become a fundamental tool for computer security. That adaptability is also a vulnerability: attackers can exploit machine learning systems. We present a taxonomy identifying and analyzing attacks against machine learning systems. We show how these classes influence the costs for the attacker and defender, and we give a formal structure defining their interaction. We use our framework to survey and analyze the literature of attacks against machine learning systems. We also illustrate our taxonomy by showing how it can guide attacks against SpamBayes, a popular statistical spam filter. Finally, we discuss how our taxonomy suggests new lines of defenses."
  },
  {
    "paperId": "0ecf8c56300c20622f317e1e6cefdeeb85c513e2",
    "title": "Improving propensity score weighting using machine learning",
    "venue": "Statistics in Medicine",
    "year": 2010,
    "citationCount": 892,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc2807890?pdf=render",
      "status": "GREEN",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/sim.3782?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/sim.3782, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "16170202",
        "name": "Brian K. Lee"
      },
      {
        "authorId": "3020850",
        "name": "J. Lessler"
      },
      {
        "authorId": "145130892",
        "name": "E. Stuart"
      }
    ],
    "abstract": "Machine learning techniques such as classification and regression trees (CART) have been suggested as promising alternatives to logistic regression for the estimation of propensity scores. The authors examined the performance of various CART‐based propensity score models using simulated data. Hypothetical studies of varying sample sizes (n=500, 1000, 2000) with a binary exposure, continuous outcome, and 10 covariates were simulated under seven scenarios differing by degree of non‐linear and non‐additive associations between covariates and the exposure. Propensity score weights were estimated using logistic regression (all main effects), CART, pruned CART, and the ensemble methods of bagged CART, random forests, and boosted CART. Performance metrics included covariate balance, standard error, per cent absolute bias, and 95 per cent confidence interval (CI) coverage. All methods displayed generally acceptable performance under conditions of either non‐linearity or non‐additivity alone. However, under conditions of both moderate non‐additivity and moderate non‐linearity, logistic regression had subpar performance, whereas ensemble methods provided substantially better bias reduction and more consistent 95 per cent CI coverage. The results suggest that ensemble methods, especially boosted CART, may be useful for propensity score weighting. Copyright © 2009 John Wiley & Sons, Ltd."
  },
  {
    "paperId": "55635aac4cd439a00356f83dad52bd8d7b0ea87e",
    "title": "A Survey on Curriculum Learning",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2021,
    "citationCount": 784,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2010.13166",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPAMI.2021.3069908?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPAMI.2021.3069908, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153687490",
        "name": "Xin Wang"
      },
      {
        "authorId": "51310474",
        "name": "Yudong Chen"
      },
      {
        "authorId": "145583986",
        "name": "Wenwu Zhu"
      }
    ],
    "abstract": "Curriculum learning (CL) is a training strategy that trains a machine learning model from easier data to harder data, which imitates the meaningful learning order in human curricula. As an easy-to-use plug-in, the CL strategy has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision and natural language processing etc. In this survey article, we comprehensively review CL from various aspects including motivations, definitions, theories, and applications. We discuss works on curriculum learning within a general CL framework, elaborating on how to design a manually predefined curriculum or an automatic curriculum. In particular, we summarize existing CL designs based on the general framework of <italic>Difficulty Measurer <inline-formula><tex-math notation=\"LaTeX\">$+$</tex-math><alternatives><mml:math><mml:mo>+</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3069908.gif\"/></alternatives></inline-formula> Training Scheduler</italic> and further categorize the methodologies for automatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RL Teacher, and Other Automatic CL. We also analyze principles to select different CL designs that may benefit practical applications. Finally, we present our insights on the relationships connecting CL and other machine learning concepts including transfer learning, meta-learning, continual learning and active learning, etc., then point out challenges in CL as well as potential future research directions deserving further investigations."
  },
  {
    "paperId": "f295b3e251f4cc2bb5e866330ba74b582b978aa5",
    "title": "Biological underpinnings for lifelong learning machines",
    "venue": "Nature Machine Intelligence",
    "year": 2022,
    "citationCount": 240,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-022-00452-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-022-00452-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3327477",
        "name": "D. Kudithipudi"
      },
      {
        "authorId": "1404247210",
        "name": "Mario Aguilar-Simon"
      },
      {
        "authorId": "50608764",
        "name": "Jonathan Babb"
      },
      {
        "authorId": "143968639",
        "name": "M. Bazhenov"
      },
      {
        "authorId": "6032938",
        "name": "Douglas Blackiston"
      },
      {
        "authorId": "7373730",
        "name": "J. Bongard"
      },
      {
        "authorId": "2387335605",
        "name": "Andrew P. Brna"
      },
      {
        "authorId": "1410335556",
        "name": "Suraj Chakravarthi Raja"
      },
      {
        "authorId": "2800259",
        "name": "Nick Cheney"
      },
      {
        "authorId": "2552141",
        "name": "J. Clune"
      },
      {
        "authorId": "108501856",
        "name": "A. Daram"
      },
      {
        "authorId": "1773023",
        "name": "Stefano Fusi"
      },
      {
        "authorId": "3365578",
        "name": "Peter Helfer"
      },
      {
        "authorId": "2075087398",
        "name": "Leslie M. Kay"
      },
      {
        "authorId": "2806710",
        "name": "Nicholas A. Ketz"
      },
      {
        "authorId": "145276578",
        "name": "Z. Kira"
      },
      {
        "authorId": "2062432",
        "name": "Soheil Kolouri"
      },
      {
        "authorId": "1753673",
        "name": "J. Krichmar"
      },
      {
        "authorId": "3450084",
        "name": "Sam Kriegman"
      },
      {
        "authorId": "2070083553",
        "name": "Michael Levin"
      },
      {
        "authorId": "7021018",
        "name": "Sandeep Madireddy"
      },
      {
        "authorId": "3349068",
        "name": "Santosh Manicka"
      },
      {
        "authorId": "7830131",
        "name": "Ali Marjaninejad"
      },
      {
        "authorId": "2065323374",
        "name": "Bruce L. McNaughton"
      },
      {
        "authorId": "1686788",
        "name": "R. Miikkulainen"
      },
      {
        "authorId": "2740466",
        "name": "Zaneta Navratilova"
      },
      {
        "authorId": "46195801",
        "name": "Tej Pandit"
      },
      {
        "authorId": "2053684900",
        "name": "Alice Parker"
      },
      {
        "authorId": "2888448",
        "name": "Praveen K. Pilly"
      },
      {
        "authorId": "1745664",
        "name": "S. Risi"
      },
      {
        "authorId": "50504368",
        "name": "T. Sejnowski"
      },
      {
        "authorId": "2818113",
        "name": "Andrea Soltoggio"
      },
      {
        "authorId": "3491820",
        "name": "Nicholas Soures"
      },
      {
        "authorId": "1739838",
        "name": "A. Tolias"
      },
      {
        "authorId": "1410371602",
        "name": "Darío Urbina-Meléndez"
      },
      {
        "authorId": "1399358279",
        "name": "F. Valero-Cuevas"
      },
      {
        "authorId": "118439707",
        "name": "Gido M. van de Ven"
      },
      {
        "authorId": "1717958",
        "name": "J. Vogelstein"
      },
      {
        "authorId": "2359965593",
        "name": "Felix Wang"
      },
      {
        "authorId": "2067827787",
        "name": "Ron Weiss"
      },
      {
        "authorId": "1403764279",
        "name": "A. Yanguas-Gil"
      },
      {
        "authorId": "26565367",
        "name": "Xinyun Zou"
      },
      {
        "authorId": "2797623",
        "name": "H. Siegelmann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "adc61e21eafecfbf6ebecc570f9f913659a2bfb2",
    "title": "Deep Learning--based Text Classification",
    "venue": "ACM Computing Surveys",
    "year": 2020,
    "citationCount": 1191,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2004.03705, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2164604",
        "name": "Shervin Minaee"
      },
      {
        "authorId": "49943757",
        "name": "E. Cambria"
      },
      {
        "authorId": "48441311",
        "name": "Jianfeng Gao"
      }
    ],
    "abstract": "Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions."
  },
  {
    "paperId": "a19a69cdb137e83ba4b8d5c99d187b9f44bbc2d3",
    "title": "Learning scikit-learn: Machine Learning in Python",
    "venue": "",
    "year": 2013,
    "citationCount": 260,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2091354115",
        "name": "Ral Garreta"
      },
      {
        "authorId": "2171196",
        "name": "Guillermo Moncecchi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5fb8ba2e3967e079c57aa703bf216c168ea8104f",
    "title": "Model-based machine learning",
    "venue": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "year": 2013,
    "citationCount": 231,
    "openAccessPdf": {
      "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2012.0222",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3538442, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1792884",
        "name": "Charles M. Bishop"
      }
    ],
    "abstract": "Several decades of research in the field of machine learning have resulted in a multitude of different algorithms for solving a broad range of problems. To tackle a new application, a researcher typically tries to map their problem onto one of these existing methods, often influenced by their familiarity with specific algorithms and by the availability of corresponding software implementations. In this study, we describe an alternative methodology for applying machine learning, in which a bespoke solution is formulated for each new application. The solution is expressed through a compact modelling language, and the corresponding custom machine learning code is then generated automatically. This model-based approach offers several major advantages, including the opportunity to create highly tailored models for specific scenarios, as well as rapid prototyping and comparison of a range of alternative models. Furthermore, newcomers to the field of machine learning do not have to learn about the huge range of traditional methods, but instead can focus their attention on understanding a single modelling environment. In this study, we show how probabilistic graphical models, coupled with efficient inference algorithms, provide a very flexible foundation for model-based machine learning, and we outline a large-scale commercial application of this framework involving tens of millions of users. We also describe the concept of probabilistic programming as a powerful software environment for model-based machine learning, and we discuss a specific probabilistic programming language called Infer.NET, which has been widely used in practical applications."
  },
  {
    "paperId": "ea11efe27e029e391ea52609468353f98d9f946b",
    "title": "Machine learning on Big Data",
    "venue": "IEEE International Conference on Data Engineering",
    "year": 2013,
    "citationCount": 226,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2463676.2465338?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2463676.2465338, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3269316",
        "name": "Tyson Condie"
      },
      {
        "authorId": "3040175",
        "name": "Paul Mineiro"
      },
      {
        "authorId": "1763100",
        "name": "N. Polyzotis"
      },
      {
        "authorId": "2965406",
        "name": "Markus Weimer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "43dcda631f8a0d39949ba3f9e3e22101db4daba0",
    "title": "A Machine Learning Framework for Programming by Example",
    "venue": "International Conference on Machine Learning",
    "year": 2013,
    "citationCount": 163,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2844480",
        "name": "A. Menon"
      },
      {
        "authorId": "1740329",
        "name": "O. Tamuz"
      },
      {
        "authorId": "2108314",
        "name": "Sumit Gulwani"
      },
      {
        "authorId": "2665014",
        "name": "B. Lampson"
      },
      {
        "authorId": "2186481",
        "name": "A. Kalai"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6aa8f8ae07a57a2025d6adc27a0bc53f6a7ee385",
    "title": "Machine learning for targeted display advertising: transfer learning in action",
    "venue": "Machine-mediated learning",
    "year": 2013,
    "citationCount": 179,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-013-5375-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-013-5375-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1933403",
        "name": "Claudia Perlich"
      },
      {
        "authorId": "3242748",
        "name": "Brian Dalessandro"
      },
      {
        "authorId": "2468485",
        "name": "Troy Raeder"
      },
      {
        "authorId": "2147050",
        "name": "Ori Stitelman"
      },
      {
        "authorId": "1752722",
        "name": "F. Provost"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e2e0e226f1f74ff65c0de3e5ad565bcd8b9710da",
    "title": "Adaptive Federated Learning in Resource Constrained Edge Computing Systems",
    "venue": "IEEE Journal on Selected Areas in Communications",
    "year": 2018,
    "citationCount": 1875,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1804.05271",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1804.05271, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50695457",
        "name": "Shiqiang Wang"
      },
      {
        "authorId": "40917131",
        "name": "Tiffany Tuor"
      },
      {
        "authorId": "2522394",
        "name": "Theodoros Salonidis"
      },
      {
        "authorId": "145353889",
        "name": "K. Leung"
      },
      {
        "authorId": "1702283",
        "name": "C. Makaya"
      },
      {
        "authorId": "145299837",
        "name": "T. He"
      },
      {
        "authorId": "46998035",
        "name": "K. Chan"
      }
    ],
    "abstract": "Emerging technologies and applications including Internet of Things, social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent-based approaches. We analyze the convergence bound of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best tradeoff between local update and global parameter aggregation to minimize the loss function under a given resource budget. The performance of the proposed algorithm is evaluated via extensive experiments with real datasets, both on a networked prototype system and in a larger-scale simulated environment. The experimentation results show that our proposed approach performs near to the optimum with various machine learning models and different data distributions."
  },
  {
    "paperId": "2968a1ec5479b89384886bdd6cc6cc76056c5318",
    "title": "A survey of transfer learning",
    "venue": "Journal of Big Data",
    "year": 2016,
    "citationCount": 3107,
    "openAccessPdf": {
      "url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-016-0043-6",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1186/s40537-016-0043-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s40537-016-0043-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35541327",
        "name": "Karl R. Weiss"
      },
      {
        "authorId": "1725285",
        "name": "T. Khoshgoftaar"
      },
      {
        "authorId": "39472430",
        "name": "Dingding Wang"
      }
    ],
    "abstract": "Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments."
  },
  {
    "paperId": "d05d86db86a4ac0d95e6dcd951b42a9651939793",
    "title": "Deep Learning Approach for Intelligent Intrusion Detection System",
    "venue": "IEEE Access",
    "year": 2019,
    "citationCount": 1278,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08681044.pdf",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2895334?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2895334, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51162051",
        "name": "R. Vinayakumar"
      },
      {
        "authorId": "2474250",
        "name": "M. Alazab"
      },
      {
        "authorId": "2285465435",
        "name": "I. K. P. S. Senior Member"
      },
      {
        "authorId": "2916235",
        "name": "P. Poornachandran"
      },
      {
        "authorId": "1399133087",
        "name": "Ameer Al-Nemrat"
      },
      {
        "authorId": "145710905",
        "name": "S. Venkatraman"
      }
    ],
    "abstract": "Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01–0.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks."
  },
  {
    "paperId": "da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
    "title": "Deep Bayesian Active Learning with Image Data",
    "venue": "International Conference on Machine Learning",
    "year": 2017,
    "citationCount": 1856,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.02910, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2681954",
        "name": "Y. Gal"
      },
      {
        "authorId": "18014232",
        "name": "Riashat Islam"
      },
      {
        "authorId": "1744700",
        "name": "Zoubin Ghahramani"
      }
    ],
    "abstract": "Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task)."
  },
  {
    "paperId": "8ed390c98912ab8d27a398ab583d358c5a41fee9",
    "title": "Machine learning for science and society",
    "venue": "Machine-mediated learning",
    "year": 2013,
    "citationCount": 116,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5425-9.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-013-5425-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-013-5425-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48395540",
        "name": "C. Rudin"
      },
      {
        "authorId": "6541629",
        "name": "K. Wagstaff"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c088a41395a9f08d719be8479dc11ddecf047530",
    "title": "Density Ratio Estimation in Machine Learning",
    "venue": "",
    "year": 2012,
    "citationCount": 628,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9781139035613?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9781139035613, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "67154907",
        "name": "Masashi Sugiyama"
      },
      {
        "authorId": "2026193813",
        "name": "Taiji Suzuki"
      },
      {
        "authorId": "1897617",
        "name": "T. Kanamori"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8729441d734782c3ed532a7d2d9611b438c0a09a",
    "title": "ADADELTA: An Adaptive Learning Rate Method",
    "venue": "arXiv.org",
    "year": 2012,
    "citationCount": 6774,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1212.5701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48799969",
        "name": "Matthew D. Zeiler"
      }
    ],
    "abstract": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment."
  },
  {
    "paperId": "7ab0f0da686cd4094fd96f5a30e0b6072525fd09",
    "title": "Deep Learning in Medical Image Analysis.",
    "venue": "Annual Review of Biomedical Engineering",
    "year": 2017,
    "citationCount": 2632,
    "openAccessPdf": {
      "url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-071516-044442",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-bioeng-071516-044442?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-bioeng-071516-044442, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144986260",
        "name": "D. Shen"
      },
      {
        "authorId": "46531894",
        "name": "Guorong Wu"
      },
      {
        "authorId": "143802908",
        "name": "Heung-Il Suk"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
    "title": "A State-of-the-Art Survey on Deep Learning Theory and Architectures",
    "venue": "Electronics",
    "year": 2019,
    "citationCount": 1370,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2079-9292/8/3/292/pdf?version=1552274432",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/ELECTRONICS8030292?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/ELECTRONICS8030292, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1932404",
        "name": "Md. Zahangir Alom"
      },
      {
        "authorId": "1799779",
        "name": "T. Taha"
      },
      {
        "authorId": "2498059",
        "name": "C. Yakopcic"
      },
      {
        "authorId": "40893684",
        "name": "Stefan Westberg"
      },
      {
        "authorId": "2325550",
        "name": "P. Sidike"
      },
      {
        "authorId": "100898809",
        "name": "Mst Shamima Nasrin"
      },
      {
        "authorId": "2152302063",
        "name": "Mahmudul Hasan"
      },
      {
        "authorId": "2298684229",
        "name": "Brian C. Van Essen"
      },
      {
        "authorId": "144948131",
        "name": "A. Awwal"
      },
      {
        "authorId": "2401900",
        "name": "V. Asari"
      }
    ],
    "abstract": "In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models."
  },
  {
    "paperId": "4d931ea98be69882f547ec6c1b42b78c3e13c36d",
    "title": "Quantum circuit learning",
    "venue": "Physical Review A",
    "year": 2018,
    "citationCount": 1413,
    "openAccessPdf": {
      "url": "https://ir.library.osaka-u.ac.jp/repo/ouka/all/77645/PhysRevA_98_03_032309.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.00745, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "89418147",
        "name": "K. Mitarai"
      },
      {
        "authorId": "31729454",
        "name": "M. Negoro"
      },
      {
        "authorId": "2460970",
        "name": "M. Kitagawa"
      },
      {
        "authorId": "144950743",
        "name": "K. Fujii"
      }
    ],
    "abstract": "We propose a classical-quantum hybrid algorithm for machine learning on near-term quantum processors, which we call quantum circuit learning. A quantum circuit driven by our framework learns a given task by tuning parameters implemented on it. The iterative optimization of the parameters allows us to circumvent the high-depth circuit. Theoretical investigation shows that a quantum circuit can approximate nonlinear functions, which is further confirmed by numerical simulations. Hybridizing a low-depth quantum circuit and a classical computer for machine learning, the proposed framework paves the way toward applications of near-term quantum devices for quantum machine learning."
  },
  {
    "paperId": "3c8bf504ddc7db1829466b6e9da5251025dd48f1",
    "title": "Automatic analysis of malware behavior using machine learning",
    "venue": "Journal of computing and security",
    "year": 2011,
    "citationCount": 741,
    "openAccessPdf": {
      "url": "http://www.eecs.tu-berlin.de/fileadmin/f4/TechReports/2009/tr-2009-18.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.3233/JCS-2010-0410?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/JCS-2010-0410, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144825749",
        "name": "Konrad Rieck"
      },
      {
        "authorId": "2032673",
        "name": "Philipp Trinius"
      },
      {
        "authorId": "2043274",
        "name": "Carsten Willems"
      },
      {
        "authorId": "144227650",
        "name": "Thorsten Holz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f",
    "title": "Scaling Neural Machine Translation",
    "venue": "Conference on Machine Translation",
    "year": 2018,
    "citationCount": 634,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/W18-6301.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1806.00187, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40511414",
        "name": "Myle Ott"
      },
      {
        "authorId": "2068070",
        "name": "Sergey Edunov"
      },
      {
        "authorId": "2529182",
        "name": "David Grangier"
      },
      {
        "authorId": "2325985",
        "name": "Michael Auli"
      }
    ],
    "abstract": "Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. On WMT’14 English-German translation, we match the accuracy of Vaswani et al. (2017) in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT’14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs."
  },
  {
    "paperId": "93d6752f11d5db3687cc9f895f219b1bed7e1023",
    "title": "A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2019,
    "citationCount": 1213,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1907.09693",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1907.09693, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "92621060",
        "name": "Q. Li"
      },
      {
        "authorId": "39003902",
        "name": "Zeyi Wen"
      },
      {
        "authorId": "47039498",
        "name": "Zhaomin Wu"
      },
      {
        "authorId": "143824511",
        "name": "Bingsheng He"
      }
    ],
    "abstract": "As data privacy increasingly becomes a critical societal concern, federated learning has been a hot research topic in enabling the collaborative training of machine learning models among different organizations under the privacy restrictions. As researchers try to support more machine learning models with different privacy-preserving approaches, there is a requirement in developing systems and infrastructures to ease the development of various federated learning algorithms. Similar to deep learning systems such as PyTorch and TensorFlow that boost the development of deep learning, federated learning systems (FLSs) are equivalently important, and face challenges from various aspects such as effectiveness, efficiency, and privacy. In this survey, we conduct a comprehensive review on federated learning systems. To understand the key design system components and guide future research, we introduce the definition of federated learning systems and analyze the system components. Moreover, we provide a thorough categorization for federated learning systems according to six different aspects, including data distribution, machine learning model, privacy mechanism, communication architecture, scale of federation and motivation of federation. The categorization can help the design of federated learning systems as shown in our case studies. By systematically summarizing the existing federated learning systems, we present the design factors, case studies, and future research opportunities."
  },
  {
    "paperId": "e1b41796b752d6fb6032bbad2f8998302209d79b",
    "title": "A survey on ensemble learning",
    "venue": "Frontiers of Computer Science",
    "year": 2019,
    "citationCount": 1618,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11704-019-8208-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11704-019-8208-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152147830",
        "name": "Xibin Dong"
      },
      {
        "authorId": "144861834",
        "name": "Zhiwen Yu"
      },
      {
        "authorId": "47415977",
        "name": "Wenming Cao"
      },
      {
        "authorId": "39596382",
        "name": "Yifan Shi"
      },
      {
        "authorId": "144598359",
        "name": "Qianli Ma"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "91a613ed06c4654f38f5c2e7fe6ebffeec53d887",
    "title": "Weighted extreme learning machine for imbalance learning",
    "venue": "Neurocomputing",
    "year": 2013,
    "citationCount": 714,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neucom.2012.08.010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neucom.2012.08.010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2459175",
        "name": "Weiwei Zong"
      },
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "2109360525",
        "name": "Yiqiang Chen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "276194e96ebd620b5cff35a9168bdda39a0be57b",
    "title": "Federated Multi-Task Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 1978,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1705.10467, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145260024",
        "name": "Virginia Smith"
      },
      {
        "authorId": "2054892",
        "name": "Chao-Kai Chiang"
      },
      {
        "authorId": "2095979",
        "name": "Maziar Sanjabi"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      }
    ],
    "abstract": "Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets."
  },
  {
    "paperId": "85e4dbcff0b63773db298562ae3fff258eea195f",
    "title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2011,
    "citationCount": 3509,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2277391914",
        "name": "Stephen P. Boyd"
      },
      {
        "authorId": "46822591",
        "name": "Neal Parikh"
      },
      {
        "authorId": "2277280019",
        "name": "Eric Chu"
      },
      {
        "authorId": "2277389952",
        "name": "Borja Peleato"
      },
      {
        "authorId": "2394943402",
        "name": "Jonathan Eckstein"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
    "title": "Deep learning for sentiment analysis: A survey",
    "venue": "WIREs Data Mining Knowl. Discov.",
    "year": 2018,
    "citationCount": 1752,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1253",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1801.07883, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50081327",
        "name": "Lei Zhang"
      },
      {
        "authorId": "1717480",
        "name": "Shuai Wang"
      },
      {
        "authorId": "145321667",
        "name": "B. Liu"
      }
    ],
    "abstract": "Deep learning has emerged as a powerful machine learning technique that learns multiple layers of representations or features of the data and produces state‐of‐the‐art prediction results. Along with the success of deep learning in many application domains, deep learning is also used in sentiment analysis in recent years. This paper gives an overview of deep learning and then provides a comprehensive survey of its current applications in sentiment analysis."
  },
  {
    "paperId": "c2a7afbb5609a723f8eea91bfde4b02579b048d6",
    "title": "Unsupervised Neural Machine Translation",
    "venue": "International Conference on Learning Representations",
    "year": 2017,
    "citationCount": 790,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1710.11041, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2347956",
        "name": "Mikel Artetxe"
      },
      {
        "authorId": "3255091",
        "name": "Gorka Labaka"
      },
      {
        "authorId": "1733049",
        "name": "Eneko Agirre"
      },
      {
        "authorId": "1979489",
        "name": "Kyunghyun Cho"
      }
    ],
    "abstract": "In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project."
  },
  {
    "paperId": "be9811f7e6019d5cd59ff97829a44bb5577bab00",
    "title": "Machine Learning in Action",
    "venue": "",
    "year": 2012,
    "citationCount": 566,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2066048097",
        "name": "P. B. Harrington"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d",
    "title": "Tensor2Tensor for Neural Machine Translation",
    "venue": "Conference of the Association for Machine Translation in the Americas",
    "year": 2018,
    "citationCount": 542,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.07416, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40348417",
        "name": "Ashish Vaswani"
      },
      {
        "authorId": "1751569",
        "name": "Samy Bengio"
      },
      {
        "authorId": "2445241",
        "name": "E. Brevdo"
      },
      {
        "authorId": "1565641737",
        "name": "François Chollet"
      },
      {
        "authorId": "19177000",
        "name": "Aidan N. Gomez"
      },
      {
        "authorId": "2776283",
        "name": "Stephan Gouws"
      },
      {
        "authorId": "145024664",
        "name": "Llion Jones"
      },
      {
        "authorId": "40527594",
        "name": "Lukasz Kaiser"
      },
      {
        "authorId": "2583391",
        "name": "Nal Kalchbrenner"
      },
      {
        "authorId": "3877127",
        "name": "Niki Parmar"
      },
      {
        "authorId": "35474601",
        "name": "Ryan Sepassi"
      },
      {
        "authorId": "1846258",
        "name": "Noam Shazeer"
      },
      {
        "authorId": "39328010",
        "name": "Jakob Uszkoreit"
      }
    ],
    "abstract": "Tensor2Tensor is a library for deep learning models that is well-suited for neural machine translation and includes the reference implementation of the state-of-the-art Transformer model."
  },
  {
    "paperId": "ce70030c9d4e2ce2280cc15f50da42ea755d37d3",
    "title": "Neural Networks and Learning Machines",
    "venue": "",
    "year": 2010,
    "citationCount": 5400,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1735300",
        "name": "S. Haykin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "727f14e94f33f7bf9d1fa9d3d4649cc828a30ba6",
    "title": "Intrusion detection by machine learning: A review",
    "venue": "Expert systems with applications",
    "year": 2009,
    "citationCount": 1006,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.eswa.2009.05.029?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.eswa.2009.05.029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1707262",
        "name": "Chih-Fong Tsai"
      },
      {
        "authorId": "121748233",
        "name": "Yu-Feng Hsu"
      },
      {
        "authorId": "2116504193",
        "name": "Chia-Ying Lin"
      },
      {
        "authorId": "1682393",
        "name": "Wei-Yang Lin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cd49acefc8d51e324aa562e5337e1c2aff067053",
    "title": "An Overview of Multi-task Learning",
    "venue": "",
    "year": 2018,
    "citationCount": 1756,
    "openAccessPdf": {
      "url": "https://academic.oup.com/nsr/article-pdf/5/1/30/24164435/nwx105.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1093/NSR/NWX105?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/NSR/NWX105, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46867608",
        "name": "Yu Zhang"
      },
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      }
    ],
    "abstract": "As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented."
  },
  {
    "paperId": "b87c0cf95208caacb025bf87d9ba451a87aacaca",
    "title": "Machine Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks",
    "venue": "IEEE transactions on industrial electronics (1982. Print)",
    "year": 2018,
    "citationCount": 691,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TIE.2017.2733438?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TIE.2017.2733438, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49832912",
        "name": "Rui Zhao"
      },
      {
        "authorId": "2047932486",
        "name": "Dongzhe Wang"
      },
      {
        "authorId": "35374692",
        "name": "Ruqiang Yan"
      },
      {
        "authorId": "144067957",
        "name": "K. Mao"
      },
      {
        "authorId": "40592209",
        "name": "Fei Shen"
      },
      {
        "authorId": "49605588",
        "name": "Jinjiang Wang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "208cd4b25768f0096fb2e80e7690473da0e2a563",
    "title": "Meta-learning with differentiable closed-form solvers",
    "venue": "International Conference on Learning Representations",
    "year": 2018,
    "citationCount": 1009,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1805.08136, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2271057",
        "name": "Luca Bertinetto"
      },
      {
        "authorId": "143848064",
        "name": "João F. Henriques"
      },
      {
        "authorId": "143635540",
        "name": "Philip H. S. Torr"
      },
      {
        "authorId": "1687524",
        "name": "A. Vedaldi"
      }
    ],
    "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures. Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks."
  },
  {
    "paperId": "d2972fa779c91162f447d1e15540fba0df4cb547",
    "title": "Deploying an interactive machine learning system in an evidence-based practice center: abstrackr",
    "venue": "International Health Informatics Symposium",
    "year": 2012,
    "citationCount": 571,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2110363.2110464?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2110363.2110464, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1912476",
        "name": "Byron C. Wallace"
      },
      {
        "authorId": "50044599",
        "name": "Kevin Small"
      },
      {
        "authorId": "1729374",
        "name": "C. Brodley"
      },
      {
        "authorId": "143917291",
        "name": "J. Lau"
      },
      {
        "authorId": "2947796",
        "name": "T. Trikalinos"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0294bd2e6638c9a3619d4baaa63202a3c511dccc",
    "title": "SplitFed: When Federated Learning Meets Split Learning",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2020,
    "citationCount": 715,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/20825/20584",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2004.12088, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145890639",
        "name": "Chandra Thapa"
      },
      {
        "authorId": "2584232",
        "name": "Pathum Chamikara Mahawaga Arachchige"
      },
      {
        "authorId": "1811469",
        "name": "S. Çamtepe"
      }
    ],
    "abstract": "Federated learning (FL) and split learning (SL) are two popular distributed machine learning approaches. Both follow a model-to-data scenario; clients train and test machine learning models without sharing raw data. SL provides better model privacy than FL due to the machine learning model architecture split between clients and the server. Moreover, the split model makes SL a better option for resource-constrained environments. However, SL performs slower than FL due to the relay-based training across multiple clients. In this regard, this paper presents a novel approach, named splitfed learning (SFL), that amalgamates the two approaches eliminating their inherent drawbacks, along with a refined architectural configuration incorporating differential privacy and PixelDP to enhance data privacy and model robustness. Our analysis and empirical results demonstrate that (pure) SFL provides similar test accuracy and communication efficiency as SL while significantly decreasing its computation time per global epoch than in SL for multiple clients. Furthermore, as in SL, its communication efficiency over FL improves with the number of clients. Besides, the performance of SFL with privacy and robustness measures is further evaluated under extended experimental settings."
  },
  {
    "paperId": "9f1e9e56d80146766bc2316efbc54d8b770a23df",
    "title": "Deep Reinforcement Learning: An Overview",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 1704,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1701.07274, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2276894",
        "name": "Yuxi Li"
      }
    ],
    "abstract": "We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. \nPlease see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update."
  },
  {
    "paperId": "fc2057499fcc5dfe61316f1722db7837971a9c94",
    "title": "ML Confidential: Machine Learning on Encrypted Data",
    "venue": "International Conference on Information Security and Cryptology",
    "year": 2012,
    "citationCount": 493,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-37682-5_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-37682-5_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1686971",
        "name": "T. Graepel"
      },
      {
        "authorId": "2679550",
        "name": "K. Lauter"
      },
      {
        "authorId": "1813607",
        "name": "M. Naehrig"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "856d5dcba4772328b8fb784494e3d41d39669b0d",
    "title": "Machine Theory of Mind",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 532,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.07740, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3422052",
        "name": "Neil C. Rabinowitz"
      },
      {
        "authorId": "3054009",
        "name": "Frank Perbet"
      },
      {
        "authorId": "2107148568",
        "name": "H. F. Song"
      },
      {
        "authorId": "151505981",
        "name": "Chiyuan Zhang"
      },
      {
        "authorId": "143648071",
        "name": "S. Eslami"
      },
      {
        "authorId": "46378362",
        "name": "M. Botvinick"
      }
    ],
    "abstract": "Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We design a Theory of Mind neural network -- a ToMnet -- which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' behaviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer & Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system -- which autonomously learns how to model other agents in its world -- is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advancing the progress on interpretable AI."
  },
  {
    "paperId": "99a39ea1b9bf4e3afc422329c1d4d77446f060b8",
    "title": "Machine Learning Strategies for Time Series Forecasting",
    "venue": "European Business Intelligence Summer School",
    "year": 2012,
    "citationCount": 510,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-36318-4_3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-36318-4_3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1772497",
        "name": "Gianluca Bontempi"
      },
      {
        "authorId": "2397429",
        "name": "Souhaib Ben Taieb"
      },
      {
        "authorId": "7961631",
        "name": "Y. Borgne"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
    "title": "Reinforcement Learning: A Survey",
    "venue": "Journal of Artificial Intelligence Research",
    "year": 1996,
    "citationCount": 9513,
    "openAccessPdf": {
      "url": "https://www.jair.org/index.php/jair/article/download/10166/24110",
      "status": "GOLD",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/cs/9605103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1709512",
        "name": "L. Kaelbling"
      },
      {
        "authorId": "144885169",
        "name": "M. Littman"
      },
      {
        "authorId": "1760402",
        "name": "A. Moore"
      }
    ],
    "abstract": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning."
  },
  {
    "paperId": "a20bfec3c95aad003dcb45a21a220c19cca8bb66",
    "title": "A Machine Learning Approach to Coreference Resolution of Noun Phrases",
    "venue": "International Conference on Computational Logic",
    "year": 2001,
    "citationCount": 1136,
    "openAccessPdf": {
      "url": "https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://aclanthology.org/J01-4004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2248565",
        "name": "Wee Meng Soon"
      },
      {
        "authorId": "34789794",
        "name": "H. Ng"
      },
      {
        "authorId": "3216372",
        "name": "Chung Yong Lim"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "35aebe08b34e5cb0d012a16563e5c3f6fd17a906",
    "title": "Federated Learning with Personalization Layers",
    "venue": "arXiv.org",
    "year": 2019,
    "citationCount": 1042,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.00818, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1438307381",
        "name": "Manoj Ghuhan Arivazhagan"
      },
      {
        "authorId": "50429238",
        "name": "V. Aggarwal"
      },
      {
        "authorId": null,
        "name": "Aaditya Kumar Singh"
      },
      {
        "authorId": "37748424",
        "name": "Sunav Choudhary"
      }
    ],
    "abstract": "The emerging paradigm of federated learning strives to enable collaborative training of machine learning models on the network edge without centrally aggregating raw data and hence, improving data privacy. This sharply deviates from traditional machine learning and necessitates the design of algorithms robust to various sources of heterogeneity. Specifically, statistical heterogeneity of data across user devices can severely degrade the performance of standard federated averaging for traditional machine learning applications like personalization with deep learning. This paper pro-posesFedPer, a base + personalization layer approach for federated training of deep feedforward neural networks, which can combat the ill-effects of statistical heterogeneity. We demonstrate effectiveness ofFedPerfor non-identical data partitions ofCIFARdatasetsand on a personalized image aesthetics dataset from Flickr."
  },
  {
    "paperId": "a20bfec3c95aad003dcb45a21a220c19cca8bb66",
    "title": "A Machine Learning Approach to Coreference Resolution of Noun Phrases",
    "venue": "International Conference on Computational Logic",
    "year": 2001,
    "citationCount": 1136,
    "openAccessPdf": {
      "url": "https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://aclanthology.org/J01-4004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2248565",
        "name": "Wee Meng Soon"
      },
      {
        "authorId": "34789794",
        "name": "H. Ng"
      },
      {
        "authorId": "3216372",
        "name": "Chung Yong Lim"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "35aebe08b34e5cb0d012a16563e5c3f6fd17a906",
    "title": "Federated Learning with Personalization Layers",
    "venue": "arXiv.org",
    "year": 2019,
    "citationCount": 1042,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.00818, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1438307381",
        "name": "Manoj Ghuhan Arivazhagan"
      },
      {
        "authorId": "50429238",
        "name": "V. Aggarwal"
      },
      {
        "authorId": null,
        "name": "Aaditya Kumar Singh"
      },
      {
        "authorId": "37748424",
        "name": "Sunav Choudhary"
      }
    ],
    "abstract": "The emerging paradigm of federated learning strives to enable collaborative training of machine learning models on the network edge without centrally aggregating raw data and hence, improving data privacy. This sharply deviates from traditional machine learning and necessitates the design of algorithms robust to various sources of heterogeneity. Specifically, statistical heterogeneity of data across user devices can severely degrade the performance of standard federated averaging for traditional machine learning applications like personalization with deep learning. This paper pro-posesFedPer, a base + personalization layer approach for federated training of deep feedforward neural networks, which can combat the ill-effects of statistical heterogeneity. We demonstrate effectiveness ofFedPerfor non-identical data partitions ofCIFARdatasetsand on a personalized image aesthetics dataset from Flickr."
  },
  {
    "paperId": "222c68fc80b05064680ddc467243b620604fd11e",
    "title": "Machine learning and radiology",
    "venue": "Medical Image Anal.",
    "year": 2012,
    "citationCount": 634,
    "openAccessPdf": {
      "url": "https://europepmc.org/articles/pmc3372692?pdf=render",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.media.2012.02.005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.media.2012.02.005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49184570",
        "name": "Shijun Wang"
      },
      {
        "authorId": "2388128104",
        "name": "R. Summers"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4b61c25a86083c20730c9b12737ac6ac4178c364",
    "title": "An Introduction to Deep Reinforcement Learning",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2018,
    "citationCount": 1368,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1811.12560",
      "status": "GREEN",
      "license": "CCBYSA",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.12560, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2287512762",
        "name": "Vincent François-Lavet"
      },
      {
        "authorId": "40068904",
        "name": "Peter Henderson"
      },
      {
        "authorId": "18014232",
        "name": "Riashat Islam"
      },
      {
        "authorId": "1792298",
        "name": "Marc G. Bellemare"
      },
      {
        "authorId": "145134886",
        "name": "Joelle Pineau"
      }
    ],
    "abstract": "Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts."
  },
  {
    "paperId": "3904315e2eca50d0086e4b7273f7fd707c652230",
    "title": "Meta-Learning with Memory-Augmented Neural Networks",
    "venue": "International Conference on Machine Learning",
    "year": 2016,
    "citationCount": 1925,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "35030998",
        "name": "Adam Santoro"
      },
      {
        "authorId": "2258504",
        "name": "Sergey Bartunov"
      },
      {
        "authorId": "46378362",
        "name": "M. Botvinick"
      },
      {
        "authorId": "1688276",
        "name": "D. Wierstra"
      },
      {
        "authorId": "2542999",
        "name": "T. Lillicrap"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0148bbc80ea2f2526ab019a317639b4fb357f399",
    "title": "A Machine Learning Approach to Twitter User Classification",
    "venue": "International Conference on Web and Social Media",
    "year": 2011,
    "citationCount": 638,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/ICWSM/article/download/14139/13988",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/icwsm.v5i1.14139?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/icwsm.v5i1.14139, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145375801",
        "name": "M. Pennacchiotti"
      },
      {
        "authorId": "36445704",
        "name": "Ana-Maria Popescu"
      }
    ],
    "abstract": "\n \n This paper addresses the task of user classification in social media, with an application to Twitter. We automatically infer the values of user attributes such as political orientation or ethnicity by leveraging observable information such as the user behavior, network structure and the linguistic content of the user’s Twitter feed. We employ a machine learning approach which relies on a comprehensive set of features derived from such user information. We report encouraging experimental results on 3 tasks with different characteristics: political affiliation detection, ethnicity identification and detecting affinity for a particular business. Finally, our analysis shows that rich linguistic features prove consistently valuable across the 3 tasks and show great promise for additional user classification needs.\n \n"
  },
  {
    "paperId": "d837267b364b4dc97bb35facda235a19be5ed374",
    "title": "Machine Learning in Non-Stationary Environments - Introduction to Covariate Shift Adaptation",
    "venue": "Adaptive computation and machine learning",
    "year": 2012,
    "citationCount": 407,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1409749316",
        "name": "S. Ben-David"
      },
      {
        "authorId": "2704747",
        "name": "S. Bickel"
      },
      {
        "authorId": "2286831379",
        "name": "Karsten M. Borgwardt"
      },
      {
        "authorId": "2286826978",
        "name": "Michael Brückner"
      },
      {
        "authorId": "2286835051",
        "name": "David Corfield"
      },
      {
        "authorId": "2264110817",
        "name": "Amir Globerson"
      },
      {
        "authorId": "2252812544",
        "name": "Arthur Gretton"
      },
      {
        "authorId": "2362337076",
        "name": "L. Hansen"
      },
      {
        "authorId": "2286840444",
        "name": "Matthias Hein"
      },
      {
        "authorId": "2287115228",
        "name": "Jiayuan Huang"
      },
      {
        "authorId": "2286829862",
        "name": "Choon Hui"
      },
      {
        "authorId": "2286835016",
        "name": "Teo"
      },
      {
        "authorId": "1897617",
        "name": "T. Kanamori"
      },
      {
        "authorId": "2249992854",
        "name": "Klaus-Robert Müller"
      },
      {
        "authorId": "2285600176",
        "name": "Sam Roweis"
      },
      {
        "authorId": "2286834998",
        "name": "Neil Rubens"
      },
      {
        "authorId": "2286831448",
        "name": "Tobias Scheffer"
      },
      {
        "authorId": "2522463",
        "name": "M. Schmittfull"
      },
      {
        "authorId": "2286827126",
        "name": "Bernhard Schölkopf Hidetoshi Shimodaira"
      },
      {
        "authorId": "2250974573",
        "name": "A. Smola"
      },
      {
        "authorId": "1728216",
        "name": "A. Storkey"
      },
      {
        "authorId": "67154907",
        "name": "Masashi Sugiyama"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9d3e0fce253a4ae4a4456b2f24c03329a2b74621",
    "title": "Deep Learning for Health Informatics",
    "venue": "IEEE journal of biomedical and health informatics",
    "year": 2017,
    "citationCount": 1564,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/jbhi.2016.2636665",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/JBHI.2016.2636665?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JBHI.2016.2636665, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2347855602",
        "name": "Daniele Ravì"
      },
      {
        "authorId": "1905807",
        "name": "Charence Wong"
      },
      {
        "authorId": "2775904",
        "name": "F. Deligianni"
      },
      {
        "authorId": "3163767",
        "name": "M. Berthelot"
      },
      {
        "authorId": "1443783456",
        "name": "Javier Andreu-Perez"
      },
      {
        "authorId": "1745644",
        "name": "Benny P. L. Lo"
      },
      {
        "authorId": "144574968",
        "name": "Guang-Zhong Yang"
      }
    ],
    "abstract": "With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health."
  },
  {
    "paperId": "441fbfdcc77187c9f9c41166b5fd42de04de1427",
    "title": "Deep learning in remote sensing: a review",
    "venue": "arXiv.org",
    "year": 2017,
    "citationCount": 1702,
    "openAccessPdf": {
      "url": "https://cdr.lib.unc.edu/downloads/6969z593j",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1710.03959, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46875441",
        "name": "Xiaoxiang Zhu"
      },
      {
        "authorId": "2977931",
        "name": "D. Tuia"
      },
      {
        "authorId": "35041003",
        "name": "Lichao Mou"
      },
      {
        "authorId": "39943835",
        "name": "Gui-Song Xia"
      },
      {
        "authorId": "9802604",
        "name": "Liangpei Zhang"
      },
      {
        "authorId": "2152480620",
        "name": "Feng Xu"
      },
      {
        "authorId": "2033171",
        "name": "F. Fraundorfer"
      }
    ],
    "abstract": "Standing at the paradigm shift towards data-intensive science, machine learning techniques are becoming increasingly important. In particular, as a major breakthrough in the field, deep learning has proven as an extremely powerful tool in many fields. Shall we embrace deep learning as the key to all? Or, should we resist a 'black-box' solution? There are controversial opinions in the remote sensing community. In this article, we analyze the challenges of using deep learning for remote sensing data analysis, review the recent advances, and provide resources to make deep learning in remote sensing ridiculously simple to start with. More importantly, we advocate remote sensing scientists to bring their expertise into deep learning, and use it as an implicit general model to tackle unprecedented large-scale influential challenges, such as climate change and urbanization."
  },
  {
    "paperId": "5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7",
    "title": "Can machine learning be secure?",
    "venue": "ACM Asia Conference on Computer and Communications Security",
    "year": 2006,
    "citationCount": 981,
    "openAccessPdf": {
      "url": "http://www.cs.berkeley.edu/~adj/publications/paper-files/asiaccs06.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1128817.1128824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1128817.1128824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145140480",
        "name": "M. Barreno"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "145879573",
        "name": "Russell Sears"
      },
      {
        "authorId": "1687701",
        "name": "A. Joseph"
      },
      {
        "authorId": "1787610",
        "name": "J. D. Tygar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "818826f356444f3daa3447755bf63f171f39ec47",
    "title": "Active Learning Literature Survey",
    "venue": "",
    "year": 2009,
    "citationCount": 6380,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1717452",
        "name": "Burr Settles"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8de174ab5419b9d3127695405efd079808e956e8",
    "title": "Curriculum learning",
    "venue": "International Conference on Machine Learning",
    "year": 2009,
    "citationCount": 6320,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1553374.1553380?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1553374.1553380, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "2373952",
        "name": "J. Louradour"
      },
      {
        "authorId": "2939803",
        "name": "R. Collobert"
      },
      {
        "authorId": "145183709",
        "name": "J. Weston"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
    "title": "A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks",
    "venue": "IEEE Access",
    "year": 2017,
    "citationCount": 1481,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/access.2017.2762418",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2017.2762418?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2017.2762418, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "30796665",
        "name": "Chuanlong Yin"
      },
      {
        "authorId": "1733625",
        "name": "Yuefei Zhu"
      },
      {
        "authorId": "2191560",
        "name": "Jin-long Fei"
      },
      {
        "authorId": "50046030",
        "name": "Xin-Zheng He"
      }
    ],
    "abstract": "Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection."
  },
  {
    "paperId": "b57e6468740d9320f3f14c6079168b8e21366416",
    "title": "The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches",
    "venue": "arXiv.org",
    "year": 2018,
    "citationCount": 959,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.01164, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1932404",
        "name": "Md. Zahangir Alom"
      },
      {
        "authorId": "1799779",
        "name": "T. Taha"
      },
      {
        "authorId": "2498059",
        "name": "C. Yakopcic"
      },
      {
        "authorId": "40893684",
        "name": "Stefan Westberg"
      },
      {
        "authorId": "2325550",
        "name": "P. Sidike"
      },
      {
        "authorId": "100898809",
        "name": "Mst Shamima Nasrin"
      },
      {
        "authorId": "32977294",
        "name": "B. V. Essen"
      },
      {
        "authorId": "144948131",
        "name": "A. Awwal"
      },
      {
        "authorId": "2401900",
        "name": "V. Asari"
      }
    ],
    "abstract": "Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1]."
  },
  {
    "paperId": "7fe7e80bf59a112386211b38ef2ea0b71ae76345",
    "title": "Machine Learning that Matters",
    "venue": "International Conference on Machine Learning",
    "year": 2012,
    "citationCount": 323,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1206.4656, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "6541629",
        "name": "K. Wagstaff"
      }
    ],
    "abstract": "Much of current machine learning (ML) research has lost its connection to problems of import to the larger world of science and society. From this perspective, there exist glaring limitations in the data sets we investigate, the metrics we employ for evaluation, and the degree to which results are communicated back to their originating domains. What changes are needed to how we conduct research to increase the impact that ML has? We present six Impact Challenges to explicitly focus the field's energy and attention, and we discuss existing obstacles that must be addressed. We aim to inspire ongoing discussion and focus on ML that matters."
  },
  {
    "paperId": "e3eaf3c461114bc34675b0aa33e48ac0be003451",
    "title": "The random forest algorithm for statistical learning",
    "venue": "The Stata Journal",
    "year": 2020,
    "citationCount": 839,
    "openAccessPdf": {
      "url": "https://journals.sagepub.com/doi/pdf/10.1177/1536867X20909688",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1177/1536867X20909688?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/1536867X20909688, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1815604",
        "name": "Matthias Schonlau"
      },
      {
        "authorId": "151197773",
        "name": "Rosie Yuyan Zou"
      }
    ],
    "abstract": "Random forests (Breiman, 2001, Machine Learning 45: 5–32) is a statistical- or machine-learning algorithm for prediction. In this article, we introduce a corresponding new command, rforest. We overview the random forest algorithm and illustrate its use with two examples: The first example is a classification problem that predicts whether a credit card holder will default on his or her debt. The second example is a regression problem that predicts the logscaled number of shares of online news articles. We conclude with a discussion that summarizes key points demonstrated in the examples."
  },
  {
    "paperId": "4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c",
    "title": "Contrastive Representation Learning: A Framework and Review",
    "venue": "IEEE Access",
    "year": 2020,
    "citationCount": 815,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09226466.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.05113, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1994194269",
        "name": "Phúc H. Lê Khắc"
      },
      {
        "authorId": "30978009",
        "name": "G. Healy"
      },
      {
        "authorId": "1680223",
        "name": "A. Smeaton"
      }
    ],
    "abstract": "Contrastive Learning has recently received interest due to its success in self-supervised representation learning in the computer vision domain. However, the origins of Contrastive Learning date as far back as the 1990s and its development has spanned across many fields and domains including Metric Learning and natural language processing. In this paper, we provide a comprehensive literature review and we propose a general Contrastive Representation Learning framework that simplifies and unifies many different contrastive learning methods. We also provide a taxonomy for each of the components of contrastive learning in order to summarise it and distinguish it from other forms of machine learning. We then discuss the inductive biases which are present in any contrastive learning system and we analyse our framework under different views from various sub-fields of Machine Learning. Examples of how contrastive learning has been applied in computer vision, natural language processing, audio processing, and others, as well as in Reinforcement Learning are also presented. Finally, we discuss the challenges and some of the most promising future research directions ahead."
  },
  {
    "paperId": "48234756b7cf798bfeb47328f7c5d597fd4838c2",
    "title": "ADASYN: Adaptive synthetic sampling approach for imbalanced learning",
    "venue": "IEEE World Congress on Computational Intelligence",
    "year": 2008,
    "citationCount": 4393,
    "openAccessPdf": {
      "url": "http://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.2008.4633969?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.2008.4633969, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2198278",
        "name": "Haibo He"
      },
      {
        "authorId": "2115297828",
        "name": "Yang Bai"
      },
      {
        "authorId": "2111388466",
        "name": "E. A. Garcia"
      },
      {
        "authorId": "2116066317",
        "name": "Shutao Li"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d7009d10dd80d556ac28becad1e035c7cc2cde90",
    "title": "The MLIP package: moment tensor potentials with MPI and active learning",
    "venue": "Machine Learning: Science and Technology",
    "year": 2020,
    "citationCount": 540,
    "openAccessPdf": {
      "url": "https://iopscience.iop.org/article/10.1088/2632-2153/abc9fe/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2007.08555, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "102426056",
        "name": "I. Novikov"
      },
      {
        "authorId": "50974875",
        "name": "Konstantin Gubaev"
      },
      {
        "authorId": "51019270",
        "name": "E. Podryabinkin"
      },
      {
        "authorId": "2810901",
        "name": "A. Shapeev"
      }
    ],
    "abstract": "The subject of this paper is the technology (the ‘how’) of constructing machine-learning interatomic potentials, rather than science (the ‘what’ and ‘why’) of atomistic simulations using machine-learning potentials. Namely, we illustrate how to construct moment tensor potentials using active learning as implemented in the MLIP package, focusing on the efficient ways to automatically sample configurations for the training set, how expanding the training set changes the error of predictions, how to set up ab initio calculations in a cost-effective manner, etc. The MLIP package (short for Machine-Learning Interatomic Potentials) is available at https://mlip.skoltech.ru/download/."
  },
  {
    "paperId": "ce0b8b6fca7dc089548cc2e9aaac3bae82bb19da",
    "title": "Making machine learning models interpretable",
    "venue": "The European Symposium on Artificial Neural Networks",
    "year": 2012,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1723612",
        "name": "A. Vellido"
      },
      {
        "authorId": "84306443",
        "name": "J. Martín-Guerrero"
      },
      {
        "authorId": "145408620",
        "name": "P. Lisboa"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "890d19fd3b2913883624106f4ca5740c4885cf4a",
    "title": "Federated Learning",
    "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
    "year": 2019,
    "citationCount": 941,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2200/s00960ed2v01y201910aim043?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2200/s00960ed2v01y201910aim043, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153096457",
        "name": "Qiang Yang"
      },
      {
        "authorId": "1614034792",
        "name": "Yang Liu"
      },
      {
        "authorId": "2157394918",
        "name": "Yong Cheng"
      },
      {
        "authorId": "1505828520",
        "name": "Yan Kang"
      },
      {
        "authorId": "11573257",
        "name": "Tianjian Chen"
      },
      {
        "authorId": "2110984588",
        "name": "Han Yu"
      }
    ],
    "abstract": "How is it possible to allow multiple data owners to collaboratively train and use a shared prediction model while keeping all the local training data private? Traditional machine learning approaches need to combine all data at one location, typically a data center, which may very well violate the laws on user privacy and data confidentiality. Today, many parts of the world demand that technology companies treat user data carefully according to user-privacy laws. The European Union’s General Data Protection Regulation (GDPR) is a prime example. In this book, we describe how federated machine learning addresses this problem with novel solutions combining distributed machine learning, cryptography and security, and incentive mechanism design based on economic principles and game theory. We explain different types of privacypreserving machine learning solutions and their technological backgrounds, and highlight some representative practical use cases.We show how federated learning can become the foundation of next-generation machine learning that caters to technological and societal needs for responsible AI development and application."
  },
  {
    "paperId": "6ec7c724aa1d906e9e9f81c58497adddb22175b8",
    "title": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods",
    "venue": "",
    "year": 2000,
    "citationCount": 8388,
    "openAccessPdf": {
      "url": "http://www.gbv.de/dms/goettingen/512565724.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9780511801389.013?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9780511801389.013, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1685083",
        "name": "N. Cristianini"
      },
      {
        "authorId": "1404459229",
        "name": "J. Shawe-Taylor"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8b18dcb4ab41ccfb03ec079983d5d098e54dc5df",
    "title": "Neural Networks and Deep Learning",
    "venue": "Cambridge International Law Journal",
    "year": 2018,
    "citationCount": 822,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-319-94463-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-319-94463-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1682418",
        "name": "C. Aggarwal"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "29e6b12d3c6cd55e04bdfb9c22201f99578f4080",
    "title": "Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges",
    "venue": "IEEE Communications Surveys and Tutorials",
    "year": 2020,
    "citationCount": 684,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2009.13012",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2009.13012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2280048",
        "name": "L. U. Khan"
      },
      {
        "authorId": "145412074",
        "name": "W. Saad"
      },
      {
        "authorId": "145169163",
        "name": "Zhu Han"
      },
      {
        "authorId": "144158811",
        "name": "E. Hossain"
      },
      {
        "authorId": "143849708",
        "name": "C. Hong"
      }
    ],
    "abstract": "The Internet of Things (IoT) will be ripe for the deployment of novel machine learning algorithm for both network and application management. However, given the presence of massively distributed and private datasets, it is challenging to use classical centralized learning algorithms in the IoT. To overcome this challenge, federated learning can be a promising solution that enables on-device machine learning without the need to migrate the private end-user data to a central cloud. In federated learning, only learning model updates are transferred between end-devices and the aggregation server. Although federated learning can offer better privacy preservation than centralized machine learning, it has still privacy concerns. In this paper, first, we present the recent advances of federated learning towards enabling federated learning-powered IoT applications. A set of metrics such as sparsification, robustness, quantization, scalability, security, and privacy, is delineated in order to rigorously evaluate the recent advances. Second, we devise a taxonomy for federated learning over IoT networks. Finally, we present several open research challenges with their possible solutions."
  },
  {
    "paperId": "09c5931307cba3f80d3ecc14d02eecfa46463cfe",
    "title": "MLPACK: a scalable C++ machine learning library",
    "venue": "Journal of machine learning research",
    "year": 2012,
    "citationCount": 170,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1210.6293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34658148",
        "name": "Ryan R. Curtin"
      },
      {
        "authorId": "3264504",
        "name": "J. R. Cline"
      },
      {
        "authorId": "2101842823",
        "name": "N. P. Slagle"
      },
      {
        "authorId": "1769646",
        "name": "William B. March"
      },
      {
        "authorId": "2944292",
        "name": "Parikshit Ram"
      },
      {
        "authorId": "144447714",
        "name": "Nishant A. Mehta"
      },
      {
        "authorId": "1703070",
        "name": "Alexander G. Gray"
      }
    ],
    "abstract": "MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning library released in late 2011 offering both a simple, consistent API accessible to novice users and high performance and flexibility to expert users by leveraging modern features of C++. MLPACK provides cutting-edge algorithms whose benchmarks exhibit far better performance than other leading machine learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available at http://www.mlpack.org."
  },
  {
    "paperId": "58209c6db7b321ea7c75395b23ddb5100cd9bf81",
    "title": "Machine Learning for the New York City Power Grid",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2012,
    "citationCount": 252,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPAMI.2011.108?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPAMI.2011.108, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48395540",
        "name": "C. Rudin"
      },
      {
        "authorId": "1788375",
        "name": "D. Waltz"
      },
      {
        "authorId": "50035867",
        "name": "R. Anderson"
      },
      {
        "authorId": "21545954",
        "name": "A. Boulanger"
      },
      {
        "authorId": "1403192347",
        "name": "Ansaf Salleb-Aouissi"
      },
      {
        "authorId": "32350828",
        "name": "M. Chow"
      },
      {
        "authorId": "1720958",
        "name": "Haimonti Dutta"
      },
      {
        "authorId": "152889617",
        "name": "Philip Gross"
      },
      {
        "authorId": "40486307",
        "name": "Bert Huang"
      },
      {
        "authorId": "1779637",
        "name": "S. Ierome"
      }
    ],
    "abstract": "Power companies can benefit from the use of knowledge discovery methods and statistical machine learning for preventive maintenance. We introduce a general process for transforming historical electrical grid data into models that aim to predict the risk of failures for components and systems. These models can be used directly by power companies to assist with prioritization of maintenance and repair work. Specialized versions of this process are used to produce (1) feeder failure rankings, (2) cable, joint, terminator, and transformer rankings, (3) feeder Mean Time Between Failure (MTBF) estimates, and (4) manhole events vulnerability rankings. The process in its most general form can handle diverse, noisy, sources that are historical (static), semi-real-time, or real-time, incorporates state-of-the-art machine learning algorithms for prioritization (supervised ranking or MTBF), and includes an evaluation of results via cross-validation and blind test. Above and beyond the ranked lists and MTBF estimates are business management interfaces that allow the prediction capability to be integrated directly into corporate planning and decision support; such interfaces rely on several important properties of our general modeling approach: that machine learning features are meaningful to domain experts, that the processing of data is transparent, and that prediction results are accurate enough to support sound decision making. We discuss the challenges in working with historical electrical grid data that were not designed for predictive purposes. The “rawness” of these data contrasts with the accuracy of the statistical models that can be obtained from the process; these models are sufficiently accurate to assist in maintaining New York City's electrical grid."
  },
  {
    "paperId": "4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59",
    "title": "Deep learning for neural networks",
    "venue": "",
    "year": 2018,
    "citationCount": 1245,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2277226064",
        "name": "David Kauchak CS158 – Fall"
      },
      {
        "authorId": "2277230112",
        "name": "1. Admin"
      },
      {
        "authorId": "2277227965",
        "name": "Adam Coates"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "edb4643a71d734543fa4ae3cdf7a89177c5e9ebe",
    "title": "Introduction to machine learning for brain imaging",
    "venue": "NeuroImage",
    "year": 2011,
    "citationCount": 645,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neuroimage.2010.11.004?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neuroimage.2010.11.004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3294736",
        "name": "S. Lemm"
      },
      {
        "authorId": "3156886",
        "name": "B. Blankertz"
      },
      {
        "authorId": "2128904",
        "name": "T. Dickhaus"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3d73e21af71bde8dc7984bd72f7077fb691b2523",
    "title": "FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection",
    "venue": "Journal of machine learning research",
    "year": 2021,
    "citationCount": 269,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1614034792",
        "name": "Yang Liu"
      },
      {
        "authorId": "2072650627",
        "name": "Tao Fan"
      },
      {
        "authorId": "11573257",
        "name": "Tianjian Chen"
      },
      {
        "authorId": "144217477",
        "name": "Qian Xu"
      },
      {
        "authorId": "152290618",
        "name": "Qiang Yang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "791ca7f9f3eb5c0914880711f109e7372fb05959",
    "title": "Deep learning: new computational modelling techniques for genomics",
    "venue": "Nature reviews genetics",
    "year": 2019,
    "citationCount": 923,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41576-019-0122-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41576-019-0122-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "38086241",
        "name": "Gökçen Eraslan"
      },
      {
        "authorId": "52204747",
        "name": "Žiga Avsec"
      },
      {
        "authorId": "89030634",
        "name": "J. Gagneur"
      },
      {
        "authorId": "2958299",
        "name": "Fabian J Theis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d50c8fd5448e4149b470aeb92eefb270088adc44",
    "title": "Machine Learning Methods for Ecological Applications",
    "venue": "Springer US",
    "year": 2012,
    "citationCount": 222,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4615-5289-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4615-5289-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143841380",
        "name": "A. Fielding"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c58390a5563b672bf02f7fc3f8ca264babf3cc3d",
    "title": "Foundations of Machine Learning",
    "venue": "Adaptive computation and machine learning",
    "year": 2012,
    "citationCount": 162,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "81080659",
        "name": "M. Mohri"
      },
      {
        "authorId": "2435268",
        "name": "Afshin Rostamizadeh"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "44058a625cb64c311043145655645d8206e272c2",
    "title": "Scalable Private Learning with PATE",
    "venue": "International Conference on Learning Representations",
    "year": 2018,
    "citationCount": 661,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.08908, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367796356",
        "name": "Nicolas Papernot"
      },
      {
        "authorId": "144206374",
        "name": "Shuang Song"
      },
      {
        "authorId": "145591745",
        "name": "Ilya Mironov"
      },
      {
        "authorId": "1806005",
        "name": "A. Raghunathan"
      },
      {
        "authorId": "35210462",
        "name": "Kunal Talwar"
      },
      {
        "authorId": "1758110",
        "name": "Ú. Erlingsson"
      }
    ],
    "abstract": "The rapid adoption of machine learning has increased concerns about the privacy implications of machine learning models trained on sensitive data, such as medical records or other personal information. To address those concerns, one promising approach is Private Aggregation of Teacher Ensembles, or PATE, which transfers to a \"student\" model the knowledge of an ensemble of \"teacher\" models, with intuitive privacy provided by training teachers on disjoint data and strong privacy guaranteed by noisy aggregation of teachers' answers. However, PATE has so far been evaluated only on simple classification tasks like MNIST, leaving unclear its utility when applied to larger-scale learning tasks and real-world datasets. \nIn this work, we show how PATE can scale to learning tasks with large numbers of output classes and uncurated, imbalanced training data with errors. For this, we introduce new noisy aggregation mechanisms for teacher ensembles that are more selective and add less noise, and prove their tighter differential-privacy guarantees. Our new mechanisms build on two insights: the chance of teacher consensus is increased by using more concentrated noise and, lacking consensus, no answer need be given to a student. The consensus answers used are more likely to be correct, offer better intuitive privacy, and incur lower-differential privacy cost. Our evaluation shows our mechanisms improve on the original PATE on all measures, and scale to larger tasks with both high utility and very strong privacy ($\\varepsilon$ < 1.0)."
  },
  {
    "paperId": "7fc70d4cc5118fdbc8e8807979eae8b61948ff91",
    "title": "The elements of statistical learning: data mining, inference and prediction",
    "venue": "",
    "year": 2005,
    "citationCount": 4585,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF02985802?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF02985802, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145170400",
        "name": "James Franklin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852",
    "title": "Deep learning for cellular image analysis",
    "venue": "Nature Methods",
    "year": 2019,
    "citationCount": 969,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8759575",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41592-019-0403-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41592-019-0403-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2065614284",
        "name": "Erick Moen"
      },
      {
        "authorId": "91548448",
        "name": "Dylan Bannon"
      },
      {
        "authorId": "5864924",
        "name": "Takamasa Kudo"
      },
      {
        "authorId": "2054090660",
        "name": "William Graf"
      },
      {
        "authorId": "2835805",
        "name": "M. Covert"
      },
      {
        "authorId": "6838746",
        "name": "David Van Valen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4c4cfa036de5f136e7cfe6fed69f58e3b9d309a0",
    "title": "Transfer learning using VGG-16 with Deep Convolutional Neural Network for Classifying Images",
    "venue": "International Journal of Scientific and Research Publications (IJSRP)",
    "year": 2019,
    "citationCount": 614,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.29322/ijsrp.9.10.2019.p9420?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.29322/ijsrp.9.10.2019.p9420, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1453683405",
        "name": "Srikanth Tammina"
      }
    ],
    "abstract": "— Traditionally, data mining algorithms and machine learning algorithms are engineered to approach the problems in isolation. These algorithms are employed to train the model in separation on a specific feature space and same distribution. Depending on the business case, a model is trained by applying a machine learning algorithm for a specific task. A widespread assumption in the field of machine learning is that training data and test data must have identical feature spaces with the underlying distribution. On the contrary, in real world this assumption may not hold and thus models need to be rebuilt from the scratch if features and distribution changes. It is an arduous process to collect related training data and rebuild the models. In such cases, Transferring of Knowledge or transfer learning from disparate domains would be desirable. Transfer learning is a method of reusing a pre-trained model knowledge for another task. Transfer learning can be used for classification, regression and clustering problems. This paper uses one of the pre-trained models – VGG - 16 with Deep Convolutional Neural Network to classify images."
  },
  {
    "paperId": "90dd2cb51c396d283fe38701c8888a853e6d4fcf",
    "title": "Machine Learning in Non-Stationary Environments - Introduction to Covariate Shift Adaptation",
    "venue": "Adaptive computation and machine learning",
    "year": 2012,
    "citationCount": 125,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/mitpress/9780262017091.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/mitpress/9780262017091.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "67154907",
        "name": "Masashi Sugiyama"
      },
      {
        "authorId": "1716788",
        "name": "M. Kawanabe"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a206216c3f67605ac6e25b0178c3f156dc0f7ba0",
    "title": "WEKA: a machine learning workbench",
    "venue": "Proceedings of ANZIIS '94 - Australian New Zealnd Intelligent Information Systems Conference",
    "year": 1994,
    "citationCount": 1139,
    "openAccessPdf": {
      "url": "https://researchcommons.waikato.ac.nz/bitstreams/f22a699a-4480-4981-b7cd-da5e2053b9aa/download",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ANZIIS.1994.396988?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ANZIIS.1994.396988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144189431",
        "name": "G. Holmes"
      },
      {
        "authorId": "2074980634",
        "name": "A. Donkin"
      },
      {
        "authorId": "9419406",
        "name": "I. Witten"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5",
    "title": "A Review on Multi-Label Learning Algorithms",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2014,
    "citationCount": 2999,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TKDE.2013.39?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TKDE.2013.39, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3039887",
        "name": "Min-Ling Zhang"
      },
      {
        "authorId": "145624000",
        "name": "Zhi-Hua Zhou"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6c10262a5d4230c7c85fbe528b8bbd9444116bca",
    "title": "Finding Density Functionals with Machine Learning",
    "venue": "Physical Review Letters",
    "year": 2011,
    "citationCount": 488,
    "openAccessPdf": {
      "url": "https://link.aps.org/accepted/10.1103/PhysRevLett.108.253002",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1112.5441, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "27796226",
        "name": "John C. Snyder"
      },
      {
        "authorId": "48041657",
        "name": "M. Rupp"
      },
      {
        "authorId": "39960184",
        "name": "K. Hansen"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "2544144",
        "name": "K. Burke"
      }
    ],
    "abstract": "Machine learning is used to approximate density functionals. For the model problem of the kinetic energy of noninteracting fermions in 1D, mean absolute errors below 1 kcal/mol on test densities similar to the training set are reached with fewer than 100 training densities. A predictor identifies if a test density is within the interpolation region. Via principal component analysis, a projected functional derivative finds highly accurate self-consistent densities. The challenges for application of our method to real electronic structure problems are discussed."
  },
  {
    "paperId": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
    "title": "Advances in kernel methods: support vector learning",
    "venue": "",
    "year": 1999,
    "citationCount": 5535,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/299094?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/299094, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "2676309",
        "name": "C. Burges"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2f2ade8c4944a96a44e6f70ef403b80b058d1725",
    "title": "Towards Making Systems Forget with Machine Unlearning",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2015,
    "citationCount": 855,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/7160813/7163005/07163042.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/SP.2015.35?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SP.2015.35, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3139121",
        "name": "Yinzhi Cao"
      },
      {
        "authorId": "2390877432",
        "name": "Junfeng Yang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a154e688baa929c335dd9a673592797ec3c27281",
    "title": "Learning from positive and unlabeled data: a survey",
    "venue": "Machine-mediated learning",
    "year": 2018,
    "citationCount": 625,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-020-05877-5.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1811.04820, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144292894",
        "name": "Jessa Bekker"
      },
      {
        "authorId": "144815446",
        "name": "Jesse Davis"
      }
    ],
    "abstract": "Learning from positive and unlabeled data or PU learning is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the machine learning literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art in PU learning. It proposes seven key research questions that commonly arise in this field and provides a broad overview of how the field has tried to address them."
  },
  {
    "paperId": "64be9999b68e12d260ba7423f6b55ffd41552ad3",
    "title": "Deep Learning Applications in Medical Image Analysis",
    "venue": "IEEE Access",
    "year": 2018,
    "citationCount": 1143,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/access.2017.2788044",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2017.2788044?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2017.2788044, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34812292",
        "name": "Justin Ker"
      },
      {
        "authorId": "46659335",
        "name": "Lipo Wang"
      },
      {
        "authorId": "39917910",
        "name": "J. Rao"
      },
      {
        "authorId": "48508646",
        "name": "Tchoyoson C. C. Lim"
      }
    ],
    "abstract": "The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions."
  },
  {
    "paperId": "cc7827a17a7759a04aa389290d1a874db56e85e5",
    "title": "Meta-Learning: A Survey",
    "venue": "Automated Machine Learning",
    "year": 2018,
    "citationCount": 801,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_2.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.03548, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2065501634",
        "name": "Joaquin Vanschoren"
      }
    ],
    "abstract": "Meta-learning, or learning to learn, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or meta-data, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving field."
  },
  {
    "paperId": "90972e7394b5fc884470cf78a657aae3932a8d8a",
    "title": "Using Machine Learning to Detect Cyberbullying",
    "venue": "2011 10th International Conference on Machine Learning and Applications and Workshops",
    "year": 2011,
    "citationCount": 435,
    "openAccessPdf": {
      "url": "http://webpages.ursinus.edu/akontostathis/ReynoldsKontostathisEdwardsFINAL.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMLA.2011.152?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMLA.2011.152, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145951266",
        "name": "Kelly Reynolds"
      },
      {
        "authorId": "1713751",
        "name": "April Kontostathis"
      },
      {
        "authorId": "38000101",
        "name": "Lynne Edwards"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1f93588bb075eed40ffdfae2f7907c946e5974d9",
    "title": "Deep Learning in Alzheimer's Disease: Diagnostic Classification and Prognostic Prediction Using Neuroimaging Data",
    "venue": "Frontiers in Aging Neuroscience",
    "year": 2019,
    "citationCount": 550,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fnagi.2019.00220/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.00931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2665454",
        "name": "T. Jo"
      },
      {
        "authorId": "2177008",
        "name": "K. Nho"
      },
      {
        "authorId": "7992909",
        "name": "A. Saykin"
      }
    ],
    "abstract": "Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8% for AD classification and 83.7% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0% for AD classification and 84.2% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as—omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms."
  },
  {
    "paperId": "a351ffd1634b0930bd51ff225a8836e540269947",
    "title": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features",
    "venue": "European Conference on Machine Learning",
    "year": 1999,
    "citationCount": 9606,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/BFb0026683.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BFb0026683?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BFb0026683, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4f6487d61ba6c2afa44be0e870599bb292e27638",
    "title": "Uncovering social spammers: social honeypots + machine learning",
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "year": 2010,
    "citationCount": 756,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1835449.1835522?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1835449.1835522, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2848353",
        "name": "Kyumin Lee"
      },
      {
        "authorId": "1697232",
        "name": "James Caverlee"
      },
      {
        "authorId": "2068783178",
        "name": "Steve Webb"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5a6b2b9bc3b51ff187826fc2dc21a967e04125ed",
    "title": "Model-based reinforcement learning: A survey",
    "venue": "",
    "year": 2018,
    "citationCount": 719,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "97784972",
        "name": "Fengji Yi"
      },
      {
        "authorId": "151480898",
        "name": "Wenlong Fu"
      },
      {
        "authorId": "2108951911",
        "name": "Huan Liang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1242d79573397094c5670f55e58c8333cced0beb",
    "title": "Deep Learning: A Primer for Radiologists.",
    "venue": "Radiographics",
    "year": 2017,
    "citationCount": 946,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1148/rg.2017170077?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1148/rg.2017170077, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "38162399",
        "name": "G. Chartrand"
      },
      {
        "authorId": "34842677",
        "name": "P. Cheng"
      },
      {
        "authorId": "37627814",
        "name": "Eugene Vorontsov"
      },
      {
        "authorId": "3325894",
        "name": "M. Drozdzal"
      },
      {
        "authorId": "3622148",
        "name": "S. Turcotte"
      },
      {
        "authorId": "1972076",
        "name": "C. Pal"
      },
      {
        "authorId": "1781469",
        "name": "S. Kadoury"
      },
      {
        "authorId": "2080173111",
        "name": "A. Tang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2a4ba0c1699965381fb2ba802157a89edd217943",
    "title": "Data Mining and Machine Learning in Cybersecurity",
    "venue": "",
    "year": 2011,
    "citationCount": 371,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1201/b10867?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/b10867, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145201255",
        "name": "S. Dua"
      },
      {
        "authorId": "48505005",
        "name": "Xian Du"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cb8a1b8d87a3fef15635eb4a32173f9c6f966055",
    "title": "A Survey on Deep Learning",
    "venue": "ACM Computing Surveys",
    "year": 2018,
    "citationCount": 831,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3234150?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3234150, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1997924",
        "name": "Samira Pouyanfar"
      },
      {
        "authorId": "8062083",
        "name": "Saad Sadiq"
      },
      {
        "authorId": "39588413",
        "name": "Yilin Yan"
      },
      {
        "authorId": "2229900",
        "name": "Haiman Tian"
      },
      {
        "authorId": "2868174",
        "name": "Yudong Tao"
      },
      {
        "authorId": "39611894",
        "name": "Maria E. Presa-Reyes"
      },
      {
        "authorId": "144987531",
        "name": "Mei-Ling Shyu"
      },
      {
        "authorId": "1705664",
        "name": "Shu‐Ching Chen"
      },
      {
        "authorId": "153093860",
        "name": "S. S. Iyengar"
      }
    ],
    "abstract": "The field of machine learning is witnessing its golden era as deep learning slowly becomes the leader in this domain. Deep learning uses multiple layers to represent the abstractions of data to build computational models. Some key enabler deep learning algorithms such as generative adversarial networks, convolutional neural networks, and model transfers have completely changed our perception of information processing. However, there exists an aperture of understanding behind this tremendously fast-paced domain, because it was never previously represented from a multiscope perspective. The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level. Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth. This article presents a comprehensive review of historical and recent state-of-the-art approaches in visual, audio, and text processing; social network analysis; and natural language processing, followed by the in-depth analysis on pivoting and groundbreaking advances in deep learning applications. It was also undertaken to review the issues faced in deep learning such as unsupervised learning, black-box models, and online learning and to illustrate how these challenges can be transformed into prolific future research avenues."
  },
  {
    "paperId": "3fa5f45ddbd5184f10bfb92e367493c5a344f207",
    "title": "Machine-Learning Research Four Current Directions",
    "venue": "",
    "year": 1997,
    "citationCount": 1017,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1609/AIMAG.V18I4.1324?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/AIMAG.V18I4.1324, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "42a7f3e90aa4929d7f01b6124b87f82f7735aa88",
    "title": "Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting",
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "citationCount": 484,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1904.00310, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2145429743",
        "name": "Xilai Li"
      },
      {
        "authorId": "34872128",
        "name": "Yingbo Zhou"
      },
      {
        "authorId": "47353858",
        "name": "Tianfu Wu"
      },
      {
        "authorId": "2166511",
        "name": "R. Socher"
      },
      {
        "authorId": "2228109",
        "name": "Caiming Xiong"
      }
    ],
    "abstract": "Addressing catastrophic forgetting is one of the key challenges in continual learning where machine learning systems are trained with sequential or streaming tasks. Despite recent remarkable progress in state-of-the-art deep learning, deep neural networks (DNNs) are still plagued with the catastrophic forgetting problem. This paper presents a conceptually simple yet general and effective framework for handling catastrophic forgetting in continual learning with DNNs. The proposed method consists of two components: a neural structure optimization component and a parameter learning and/or fine-tuning component. By separating the explicit neural structure learning and the parameter estimation, not only is the proposed method capable of evolving neural structures in an intuitively meaningful way, but also shows strong capabilities of alleviating catastrophic forgetting in experiments. Furthermore, the proposed method outperforms all other baselines on the permuted MNIST dataset, the split CIFAR100 dataset and the Visual Domain Decathlon dataset in continual learning setting."
  },
  {
    "paperId": "57e4afe9ca74414fa02f2e0a929b64dc9a03334d",
    "title": "Application of Machine Learning To Epileptic Seizure Detection",
    "venue": "International Conference on Machine Learning",
    "year": 2010,
    "citationCount": 587,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2614750",
        "name": "Ali H. Shoeb"
      },
      {
        "authorId": "1724429",
        "name": "J. Guttag"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "26b342333376fd7bf162f24f2e9a9de062f41d36",
    "title": "Optimization for machine learning",
    "venue": "",
    "year": 2010,
    "citationCount": 703,
    "openAccessPdf": {
      "url": "https://minds.wisconsin.edu/bitstream/1793/64910/2/95-01.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/mitpress/8996.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/mitpress/8996.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3072326",
        "name": "S. Sra"
      },
      {
        "authorId": "2388416",
        "name": "Sebastian Nowozin"
      },
      {
        "authorId": "144731788",
        "name": "Stephen J. Wright"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5a9e85af0bc45472e9c14e956819f1324085aaa1",
    "title": "A Review of Machine Learning Algorithms for Text-Documents Classification",
    "venue": "",
    "year": 2010,
    "citationCount": 658,
    "openAccessPdf": {
      "url": "https://doi.org/10.4304/jait.1.1.4-20",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.4304/JAIT.1.1.4-20?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4304/JAIT.1.1.4-20, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144828657",
        "name": "B. Baharudin"
      },
      {
        "authorId": "1704695",
        "name": "L. Lee"
      },
      {
        "authorId": "39488669",
        "name": "Khairullah Khan"
      }
    ],
    "abstract": "With the increasing availability of electronic documents and the rapid growth of the World Wide Web, the task of automatic categorization of documents became the key method for organizing the information and know- ledge discovery. Proper classification of e-documents, online news, blogs, e-mails and digital libraries need text mining, machine learning and natural language processing tech- niques to get meaningful knowledge. The aim of this paper is to highlight the important techniques and methodologies that are employed in text documents classification, while at the same time making awareness of some of the interesting challenges that remain to be solved, focused mainly on text representation and machine learning techniques. This paper provides a review of the theory and methods of document classification and text mining, focusing on the existing litera- ture."
  },
  {
    "paperId": "7550a05bf00f7b24aed9c1ac3ef000575388d21c",
    "title": "Making large scale SVM learning practical",
    "venue": "",
    "year": 1998,
    "citationCount": 5626,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.17877/DE290R-14262?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17877/DE290R-14262, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f34f684f7a4210db05a852da446e5aa3d8b0bd58",
    "title": "Adversarial Machine Learning",
    "venue": "IEEE Internet Computing",
    "year": 2011,
    "citationCount": 270,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/MIC.2011.112?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MIC.2011.112, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1787610",
        "name": "J. D. Tygar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5bf9cebe3658cfbf7f67c0a2680c8233509aa5e4",
    "title": "UCI Repository of Machine Learning Database",
    "venue": "",
    "year": 1998,
    "citationCount": 1077,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "28978752",
        "name": "D. Newman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "035256a8a6d8a73af2adb38245f4130daa1f0535",
    "title": "Machine Learning in Bioinformatics",
    "venue": "Encyclopedia of Database Systems",
    "year": 2008,
    "citationCount": 811,
    "openAccessPdf": {
      "url": "http://www.ics.uci.edu/%7Exhx/courses/CS174/lectures/ML_in_Bioinform.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-0-387-39940-9_3007?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-0-387-39940-9_3007, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144999310",
        "name": "P. Larrañaga"
      },
      {
        "authorId": "145892659",
        "name": "Borja Calvo"
      },
      {
        "authorId": "145585784",
        "name": "Roberto Santana"
      },
      {
        "authorId": "1687365",
        "name": "C. Bielza"
      },
      {
        "authorId": "2086344475",
        "name": "Josu Galdiano"
      },
      {
        "authorId": "1788277",
        "name": "Iñaki Inza"
      },
      {
        "authorId": "144762651",
        "name": "J. A. Lozano"
      },
      {
        "authorId": "2708156",
        "name": "Ruben Armañanzas"
      },
      {
        "authorId": "1800760",
        "name": "Guzmán Santafé"
      },
      {
        "authorId": "2110404467",
        "name": "Aritz Pérez Martínez"
      },
      {
        "authorId": "145689219",
        "name": "V. Robles"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "19bb0dce99466077e9bc5a2ad4941607fc28b40c",
    "title": "Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 4186,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145520115",
        "name": "M. Belkin"
      },
      {
        "authorId": "1770745",
        "name": "P. Niyogi"
      },
      {
        "authorId": "1808676",
        "name": "Vikas Sindhwani"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bcce96a2a074448953fc61a29a84afbdfc8db55a",
    "title": "Online Learning and Online Convex Optimization",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2012,
    "citationCount": 2320,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1561/2200000018?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1561/2200000018, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1389955537",
        "name": "Shai Shalev-Shwartz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ab4850b6151ca9a9337dbba94115bde342876d50",
    "title": "From machine learning to machine reasoning",
    "venue": "Machine-mediated learning",
    "year": 2011,
    "citationCount": 297,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5335-x.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1102.1808, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "52184096",
        "name": "L. Bottou"
      }
    ],
    "abstract": "A plausible definition of “reasoning” could be “algebraically manipulating previously acquired knowledge in order to answer a new question”. This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated “all-purpose” inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
  },
  {
    "paperId": "0ba86604228b555475496e200f31878df3aabd6e",
    "title": "Never-Ending Learning",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2015,
    "citationCount": 1100,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3191513",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3191513?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3191513, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40975594",
        "name": "Tom Michael Mitchell"
      },
      {
        "authorId": "50056360",
        "name": "William W. Cohen"
      },
      {
        "authorId": "1842532",
        "name": "Estevam Hruschka"
      },
      {
        "authorId": "2406435",
        "name": "Partha P. Talukdar"
      },
      {
        "authorId": "2119660368",
        "name": "Bo Yang"
      },
      {
        "authorId": "31779043",
        "name": "J. Betteridge"
      },
      {
        "authorId": "143818235",
        "name": "Andrew Carlson"
      },
      {
        "authorId": "40135250",
        "name": "Bhavana Dalvi"
      },
      {
        "authorId": "40642935",
        "name": "Matt Gardner"
      },
      {
        "authorId": "16411658",
        "name": "B. Kisiel"
      },
      {
        "authorId": "2517825",
        "name": "Jayant Krishnamurthy"
      },
      {
        "authorId": "1914797",
        "name": "N. Lao"
      },
      {
        "authorId": "2406799",
        "name": "Kathryn Mazaitis"
      },
      {
        "authorId": "35645263",
        "name": "Thahir Mohamed"
      },
      {
        "authorId": "3115592",
        "name": "Ndapandula Nakashole"
      },
      {
        "authorId": "144888672",
        "name": "Emmanouil Antonios Platanios"
      },
      {
        "authorId": "1863425",
        "name": "Alan Ritter"
      },
      {
        "authorId": "32402038",
        "name": "M. Samadi"
      },
      {
        "authorId": "1717452",
        "name": "Burr Settles"
      },
      {
        "authorId": "2108772203",
        "name": "Richard C. Wang"
      },
      {
        "authorId": "2129412",
        "name": "Derry Tanti Wijaya"
      },
      {
        "authorId": "1726095131",
        "name": "A. Gupta"
      },
      {
        "authorId": "39717886",
        "name": "Xinlei Chen"
      },
      {
        "authorId": "2407368",
        "name": "Abulhair Saparov"
      },
      {
        "authorId": "2062798496",
        "name": "Malcolm Greaves"
      },
      {
        "authorId": "122360608",
        "name": "Joel Welling"
      }
    ],
    "abstract": "Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a neverending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidenceweighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL."
  },
  {
    "paperId": "713a14e98f65a74652956dae94874eeab61a71cd",
    "title": "The changing science of machine learning",
    "venue": "Machine-mediated learning",
    "year": 2011,
    "citationCount": 158,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10994-011-5242-y.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-011-5242-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-011-5242-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "80ab1a48aac6c2716cb52334ca2f0872adfe3a6b",
    "title": "Extreme learning machine: algorithm, theory and applications",
    "venue": "Artificial Intelligence Review",
    "year": 2013,
    "citationCount": 527,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-013-9405-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-013-9405-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145613107",
        "name": "Shifei Ding"
      },
      {
        "authorId": "2112672447",
        "name": "Han Zhao"
      },
      {
        "authorId": "2108132137",
        "name": "Yanan Zhang"
      },
      {
        "authorId": "29279000",
        "name": "Xinzheng Xu"
      },
      {
        "authorId": "2066146121",
        "name": "Ru Nie"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f308f4305a7295d89ca6d287c351ce117952a710",
    "title": "Machine Learning: The ingredients of machine learning",
    "venue": "",
    "year": 2012,
    "citationCount": 1,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9780511973000.003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9780511973000.003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144474086",
        "name": "P. Flach"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "eb0c1e3d880e361b7ff61e5ac1d489cb75c55ece",
    "title": "Adaptive computation and machine learning",
    "venue": "",
    "year": 1998,
    "citationCount": 949,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5b59992ca6b77aaec066a0d3142336d2cb1028f1",
    "title": "A survey of deep learning-based network anomaly detection",
    "venue": "Cluster Computing",
    "year": 2017,
    "citationCount": 697,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10586-017-1117-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10586-017-1117-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1905560",
        "name": "Donghwoon Kwon"
      },
      {
        "authorId": "2109871406",
        "name": "Hyunjoo Kim"
      },
      {
        "authorId": "2109199266",
        "name": "Jinoh Kim"
      },
      {
        "authorId": "2637314",
        "name": "S. Suh"
      },
      {
        "authorId": "2107699",
        "name": "Ikkyun Kim"
      },
      {
        "authorId": "3317011",
        "name": "Kuinam J. Kim"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "05357314fe2da7c2248b03d89b7ab9e358cbf01e",
    "title": "Learning with Kernels: support vector machines, regularization, optimization, and beyond",
    "venue": "Adaptive computation and machine learning series",
    "year": 2001,
    "citationCount": 5206,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.7551/mitpress/4175.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/mitpress/4175.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "39f1cbef12f64dcdb3a7683f9e70f436a7742328",
    "title": "Applications of Deep Learning and Reinforcement Learning to Biological Data",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2017,
    "citationCount": 686,
    "openAccessPdf": {
      "url": "http://dspace.stir.ac.uk/bitstream/1893/26814/1/1711.03985.pdf",
      "status": "GREEN",
      "license": "public-domain",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1711.03985, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144774721",
        "name": "M. Mahmud"
      },
      {
        "authorId": "4216715",
        "name": "M. S. Kaiser"
      },
      {
        "authorId": "144664815",
        "name": "A. Hussain"
      },
      {
        "authorId": "47323504",
        "name": "S. Vassanelli"
      }
    ],
    "abstract": "Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)–machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives."
  },
  {
    "paperId": "464ebd4c86542e1610d67a9bc8810b8a7c109efe",
    "title": "Convex incremental extreme learning machine",
    "venue": "Neurocomputing",
    "year": 2007,
    "citationCount": 1113,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.NEUCOM.2007.02.009?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.NEUCOM.2007.02.009, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "2146071327",
        "name": "Lei Chen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c4ae802491724aee021f31f02327b9671cead3dc",
    "title": "Types of Machine Learning Algorithms",
    "venue": "",
    "year": 2010,
    "citationCount": 491,
    "openAccessPdf": {
      "url": "https://doi.org/10.5772/9385",
      "status": "HYBRID",
      "license": "CCBYNCSA",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.5772/9385?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5772/9385, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145298622",
        "name": "T. Ayodele"
      }
    ],
    "abstract": "• Supervised learning --where the algorithm generates a function that maps inputs to desired outputs. One standard formulation of the supervised learning task is the classification problem: the learner is required to learn (to approximate the behavior of) a function which maps a vector into one of several classes by looking at several input-output examples of the function. • Unsupervised learning --which models a set of inputs: labeled examples are not available. • Semi-supervised learning --which combines both labeled and unlabeled examples to generate an appropriate function or classifier. • Reinforcement learning --where the algorithm learns a policy of how to act given an observation of the world. Every action has some impact in the environment, and the environment provides feedback that guides the learning algorithm. • Transduction --similar to supervised learning, but does not explicitly construct a function: instead, tries to predict new outputs based on training inputs, training outputs, and new inputs. • Learning to learn --where the algorithm learns its own inductive bias based on previous experience."
  },
  {
    "paperId": "298af26244e3ad836c1aa5cf5855d05f5197063d",
    "title": "Machine Learning Methods Without Tears: A Primer for Ecologists",
    "venue": "The Quarterly review of biology",
    "year": 2008,
    "citationCount": 708,
    "openAccessPdf": {
      "url": "http://rydberg.biology.colostate.edu/poff/Public/poffpubs/Olden_etal_2008_Machine_QBR.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1086/587826?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1086/587826, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2008387",
        "name": "J. Olden"
      },
      {
        "authorId": "34870951",
        "name": "J. Lawler"
      },
      {
        "authorId": "2239503633",
        "name": "N. L. Poff"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b51a3a7d676df7947a0b28fb902a5a9f0bdf54ee",
    "title": "IAM Graph Database Repository for Graph Based Pattern Recognition and Machine Learning",
    "venue": "SSPR/SPR",
    "year": 2008,
    "citationCount": 600,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-89689-0_33.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-89689-0_33?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-89689-0_33, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1759104",
        "name": "Kaspar Riesen"
      },
      {
        "authorId": "1720945",
        "name": "H. Bunke"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "22feb6532228392457664becc48b3096d9858505",
    "title": "Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 2571,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1004.2316, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2041910832",
        "name": "Sumio Watanabe"
      }
    ],
    "abstract": "In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown. In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss. In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems. First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable. Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent. Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to 2λ/n, where λ is the real log canonical threshold and n is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine. We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion."
  },
  {
    "paperId": "fb829c5e6b406bb325fa5a02e05073df12b1772b",
    "title": "Classes of Kernels for Machine Learning: A Statistics Perspective",
    "venue": "Journal of machine learning research",
    "year": 2002,
    "citationCount": 834,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1877479",
        "name": "M. Genton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "23dac921784d65530ba798109ded94996c533d47",
    "title": "The SHOGUN Machine Learning Toolbox",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 305,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1756006.1859911?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1756006.1859911, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3029782",
        "name": "S. Sonnenburg"
      },
      {
        "authorId": "2414086",
        "name": "G. Rätsch"
      },
      {
        "authorId": "2574834",
        "name": "S. Henschel"
      },
      {
        "authorId": "3263887",
        "name": "Christian Widmer"
      },
      {
        "authorId": "2094634",
        "name": "Jonas Behr"
      },
      {
        "authorId": "2281542",
        "name": "A. Zien"
      },
      {
        "authorId": "1933978557",
        "name": "F. D. Bona"
      },
      {
        "authorId": "49345823",
        "name": "Alexander Binder"
      },
      {
        "authorId": "2140119",
        "name": "Christian Gehl"
      },
      {
        "authorId": "1778663",
        "name": "Vojtech Franc"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e",
    "title": "Online Learning for Matrix Factorization and Sparse Coding",
    "venue": "Journal of machine learning research",
    "year": 2009,
    "citationCount": 2661,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/0908.0050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2599292",
        "name": "J. Mairal"
      },
      {
        "authorId": "144570279",
        "name": "F. Bach"
      },
      {
        "authorId": "144189388",
        "name": "J. Ponce"
      },
      {
        "authorId": "1699339",
        "name": "G. Sapiro"
      }
    ],
    "abstract": "Sparse coding--that is, modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set in order to adapt it to specific data. Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis. In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems. A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets."
  },
  {
    "paperId": "e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
    "title": "Unsupervised Learning by Probabilistic Latent Semantic Analysis",
    "venue": "Machine-mediated learning",
    "year": 2004,
    "citationCount": 2702,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1007617005950.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1007617005950?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1007617005950, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4050c80ba36c6f86b0684a59be70182557b0770c",
    "title": "Ensemble deep learning in bioinformatics",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 274,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-020-0217-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-020-0217-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2112823459",
        "name": "Yue Cao"
      },
      {
        "authorId": "26339028",
        "name": "Thomas A. Geddes"
      },
      {
        "authorId": "49307536",
        "name": "J. Yang"
      },
      {
        "authorId": "1745108",
        "name": "Pengyi Yang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1f135e98e867ffcde5b359e7b817bbe21f80cfce",
    "title": "Deep Learning and Its Application to LHC Physics",
    "venue": "Annual Review of Nuclear and Particle Science",
    "year": 2018,
    "citationCount": 401,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1806.11484",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1806.11484, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "104284017",
        "name": "D. Guest"
      },
      {
        "authorId": "2258272391",
        "name": "Kyle Cranmer"
      },
      {
        "authorId": "104317636",
        "name": "D. Whiteson"
      }
    ],
    "abstract": "Machine learning has played an important role in the analysis of high-energy physics data for decades. The emergence of deep learning in 2012 allowed for machine learning tools which could adeptly handle higher-dimensional and more complex problems than previously feasible. This review is aimed at the reader who is familiar with high-energy physics but not machine learning. The connections between machine learning and high-energy physics data analysis are explored, followed by an introduction to the core concepts of neural networks, examples of the key results demonstrating the power of deep learning for analysis of LHC data, and discussion of future prospects and concerns."
  },
  {
    "paperId": "012a69efefbea1802d51eae2c2a3d782cad09981",
    "title": "International journal of machine learning and cybernetics",
    "venue": "International Journal of Machine Learning and Cybernetics",
    "year": 2010,
    "citationCount": 112,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s13042-010-0010-z.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-010-0010-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-010-0010-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "f7eb3e6221dc7bbe5eda0ce796755f5d71e7d61a",
    "title": "Machine learning in adversarial environments",
    "venue": "Machine-mediated learning",
    "year": 2010,
    "citationCount": 137,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-010-5207-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-010-5207-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1754215",
        "name": "P. Laskov"
      },
      {
        "authorId": "144990248",
        "name": "R. Lippmann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0948365ef39ef153e61e9569ade541cf881c7c2a",
    "title": "Learning the Kernel Matrix with Semidefinite Programming",
    "venue": "Journal of machine learning research",
    "year": 2002,
    "citationCount": 2570,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1725533",
        "name": "Gert R. G. Lanckriet"
      },
      {
        "authorId": "1685083",
        "name": "N. Cristianini"
      },
      {
        "authorId": "1745169",
        "name": "P. Bartlett"
      },
      {
        "authorId": "1701847",
        "name": "L. Ghaoui"
      },
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ff2c491ad5d6df1ac66a75ca4ce63c1cf79452c8",
    "title": "Weka: Practical machine learning tools and techniques with Java implementations",
    "venue": "",
    "year": 1999,
    "citationCount": 803,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "9419406",
        "name": "I. Witten"
      },
      {
        "authorId": "1767318",
        "name": "E. Frank"
      },
      {
        "authorId": "33614647",
        "name": "Leonard E. Trigg"
      },
      {
        "authorId": "118860642",
        "name": "M. Hall"
      },
      {
        "authorId": "144189431",
        "name": "G. Holmes"
      },
      {
        "authorId": "1718927",
        "name": "S. Cunningham"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "13ba53b0a88648a05d55ebb7e5eb1640820c67bc",
    "title": "Machine learning and data mining",
    "venue": "Communications of the ACM",
    "year": 1999,
    "citationCount": 815,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/319382.319388",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/319382.319388?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/319382.319388, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2237646190",
        "name": "Tom M. Mitchell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e7b677c6a4595514f41f317484150793b5f75a89",
    "title": "Archetypal analysis for machine learning",
    "venue": "2010 IEEE International Workshop on Machine Learning for Signal Processing",
    "year": 2010,
    "citationCount": 193,
    "openAccessPdf": {
      "url": "https://backend.orbit.dtu.dk/ws/files/5525563/AAMachineLearning.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.neucom.2011.06.033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.neucom.2011.06.033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3416561",
        "name": "Morten Mørup"
      },
      {
        "authorId": "2280917429",
        "name": "L. K. Hansen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "75e56ef7924972fde2ffc32d7071cd182d0f0f21",
    "title": "Selection of Relevant Features in Machine Learning",
    "venue": "",
    "year": 1994,
    "citationCount": 847,
    "openAccessPdf": {
      "url": "http://www.aaai.org/Papers/Symposia/Fall/1994/FS-94-02/FS94-02-034.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.21236/ada292575?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21236/ada292575, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "12439a6ff384e95ee2262ee982bc055534e30487",
    "title": "Online dictionary learning for sparse coding",
    "venue": "International Conference on Machine Learning",
    "year": 2009,
    "citationCount": 2403,
    "openAccessPdf": {
      "url": "https://conservancy.umn.edu/bitstreams/3b39023f-fe59-47f1-bd0b-cab83cba2bdf/download",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1553374.1553463?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1553374.1553463, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2599292",
        "name": "J. Mairal"
      },
      {
        "authorId": "144570279",
        "name": "F. Bach"
      },
      {
        "authorId": "144189388",
        "name": "J. Ponce"
      },
      {
        "authorId": "1699339",
        "name": "G. Sapiro"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "23c3953fb45536c9129e86ac7a23098bd9f1381d",
    "title": "Machine Learning for Sequential Data: A Review",
    "venue": "SSPR/SPR",
    "year": 2002,
    "citationCount": 759,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/3-540-70659-3_2.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-70659-3_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-70659-3_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d91ea30f4f9de817b29bb4ece00f43cb971822b4",
    "title": "Machine Learning Benchmarks and Random Forest Regression",
    "venue": "",
    "year": 2004,
    "citationCount": 726,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3013332",
        "name": "M. Segal"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c0927ffb79810318daab8821068629975cab67ad",
    "title": "Deep Learning for Classification of Malware System Call Sequences",
    "venue": "Australasian Conference on Artificial Intelligence",
    "year": 2016,
    "citationCount": 491,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-319-50127-7_11?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-319-50127-7_11, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2582104",
        "name": "Bojan Kolosnjaji"
      },
      {
        "authorId": "2403031",
        "name": "Apostolis Zarras"
      },
      {
        "authorId": "1396893935",
        "name": "George D. Webster"
      },
      {
        "authorId": "49601001",
        "name": "C. Eckert"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bad620c25920edbaba8836032459b135669171c3",
    "title": "Machine Learning and Its Applications to Biology",
    "venue": "PLoS Comput. Biol.",
    "year": 2007,
    "citationCount": 613,
    "openAccessPdf": {
      "url": "https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.0030116&type=printable",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC1904382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2490889",
        "name": "A. Tarca"
      },
      {
        "authorId": "33361123",
        "name": "V. Carey"
      },
      {
        "authorId": "145793137",
        "name": "Xue-wen Chen"
      },
      {
        "authorId": "2142580259",
        "name": "R. Romero"
      },
      {
        "authorId": "1775019",
        "name": "S. Drăghici"
      }
    ],
    "abstract": "The term machine learning refers to a set of topics dealing with the creation and evaluation of algorithms that facilitate pattern recognition, classification, and prediction, based on models derived from existing data. Two facets of mechanization should be acknowledged when considering machine learning in broad terms. Firstly, it is intended that the classification and prediction tasks can be accomplished by a suitably programmed computing machine. That is, the product of machine learning is a classifier that can be feasibly used on available hardware. Secondly, it is intended that the creation of the classifier should itself be highly mechanized, and should not involve too much human input. This second facet is inevitably vague, but the basic objective is that the use of automatic algorithm construction methods can minimize the possibility that human biases could affect the selection and performance of the algorithm. Both the creation of the algorithm and its operation to classify objects or predict events are to be based on concrete, observable data. \n \nThe history of relations between biology and the field of machine learning is long and complex. An early technique [1] for machine learning called the perceptron constituted an attempt to model actual neuronal behavior, and the field of artificial neural network (ANN) design emerged from this attempt. Early work on the analysis of translation initiation sequences [2] employed the perceptron to define criteria for start sites in Escherichia coli. Further artificial neural network architectures such as the adaptive resonance theory (ART) [3] and neocognitron [4] were inspired from the organization of the visual nervous system. In the intervening years, the flexibility of machine learning techniques has grown along with mathematical frameworks for measuring their reliability, and it is natural to hope that machine learning methods will improve the efficiency of discovery and understanding in the mounting volume and complexity of biological data. \n \nThis tutorial is structured in four main components. Firstly, a brief section reviews definitions and mathematical prerequisites. Secondly, the field of supervised learning is described. Thirdly, methods of unsupervised learning are reviewed. Finally, a section reviews methods and examples as implemented in the open source data analysis and visualization language R (http://www.r-project.org)."
  },
  {
    "paperId": "50feafd2cdafdfb1eead14388f6210f6b467eaa0",
    "title": "Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies",
    "venue": "IEEE Transactions on Systems Man and Cybernetics Part C (Applications and Reviews)",
    "year": 2008,
    "citationCount": 447,
    "openAccessPdf": {
      "url": "http://www.soft-computing.de/SMC0805.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSMCC.2008.919172?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSMCC.2008.919172, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2157835870",
        "name": "Yaochu Jin"
      },
      {
        "authorId": "1718432",
        "name": "B. Sendhoff"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "028165965fdf066821e1b65ac1de3ae6c503c30d",
    "title": "Editorial: On Machine Learning",
    "venue": "Machine-mediated learning",
    "year": 1986,
    "citationCount": 861,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022687019898.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1022687019898?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1022687019898, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "83cf4b2f39bcc802b09fd59b69e23068447b26b7",
    "title": "Multi-Task Learning for Multiple Language Translation",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2015,
    "citationCount": 636,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/P15-1166.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P15-1166, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9532787",
        "name": "Daxiang Dong"
      },
      {
        "authorId": "40354707",
        "name": "Hua Wu"
      },
      {
        "authorId": "48692318",
        "name": "W. He"
      },
      {
        "authorId": "3046102",
        "name": "Dianhai Yu"
      },
      {
        "authorId": "144270731",
        "name": "Haifeng Wang"
      }
    ],
    "abstract": "In this paper, we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages. Our solution is inspired by the recently proposed neural machine translation model which generalizes machine translation as a sequence learning problem. We extend the neural machine translation to a multi-task learning framework which shares source language representation and separates the modeling of different target language translation. Our framework can be applied to situations where either large amounts of parallel data or limited parallel data is available. Experiments show that our multi-task learning model is able to achieve significantly higher translation quality over individually learned model in both situations on the data sets publicly available."
  },
  {
    "paperId": "9874b4cfd9e8ef89fd0b753af18c14cbc7c42744",
    "title": "What do you mean by collaborative learning",
    "venue": "",
    "year": 1999,
    "citationCount": 2660,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1799133",
        "name": "P. Dillenbourg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8df9c71f09eb0dabf5adf17bee0f6b36190b52b2",
    "title": "Representational Learning with Extreme Learning Machine for Big Data Liyanaarachchi",
    "venue": "",
    "year": null,
    "citationCount": 310,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3276764",
        "name": "L. C. Kasun"
      },
      {
        "authorId": "2986982",
        "name": "Hongming Zhou"
      },
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "1807914",
        "name": "C. Vong"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "49047883d555a536420faa0ac3c0684b70822643",
    "title": "Searching for exotic particles in high-energy physics with deep learning",
    "venue": "Nature Communications",
    "year": 2014,
    "citationCount": 1268,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/ncomms5308.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1402.4735, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144902513",
        "name": "P. Baldi"
      },
      {
        "authorId": "47696458",
        "name": "Peter Sadowski"
      },
      {
        "authorId": "104317636",
        "name": "D. Whiteson"
      }
    ],
    "abstract": "Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine-learning approaches are often used. Standard approaches have relied on ‘shallow’ machine-learning models that have a limited capacity to learn complex nonlinear functions of the inputs, and rely on a painstaking search through manually constructed nonlinear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Here, using benchmark data sets, we show that deep-learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8% over the best current approaches. This demonstrates that deep-learning approaches can improve the power of collider searches for exotic particles. High-energy particle colliders are important for finding new particles, but huge volumes of data must be searched through to locate them. Here, the authors show the use of deep-learning methods on benchmark data sets as an approach to improving such new particle searches."
  },
  {
    "paperId": "9512facd37bba2ff1ece31900c08901bb011f1ce",
    "title": "Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2015,
    "citationCount": 425,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/9569/9428",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v29i1.9569?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v29i1.9569, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2121022",
        "name": "Shike Mei"
      },
      {
        "authorId": "1832364",
        "name": "Xiaojin Zhu"
      }
    ],
    "abstract": "\n \n We investigate a problem at the intersection of machine learning and security: training-set attacks on machine learners. In such attacks an attacker contaminates the training data so that a specific learning algorithm would produce a model profitable to the attacker. Understanding training-set attacks is important as more intelligent agents (e.g. spam filters and robots) are equipped with learning capability and can potentially be hacked via data they receive from the environment. This paper identifies the optimal training-set attack on a broad family of machine learners. First we show that optimal training-set attack can be formulated as a bilevel optimization problem. Then we show that for machine learners with certain Karush-Kuhn-Tucker conditions we can solve the bilevel problem efficiently using gradient methods on an implicit function. As examples, we demonstrate optimal training-set attacks on Support VectorMachines, logistic regression, and linear regression with extensive experiments. Finally, we discuss potential defenses against such attacks.\n \n"
  },
  {
    "paperId": "cf171d57f8232ba90a0696f8cb46144b39380d0b",
    "title": "Bioinformatics - The Machine Learning Approach",
    "venue": "Computers and Chemistry",
    "year": 2000,
    "citationCount": 780,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0097-8485(00)80015-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0097-8485(00)80015-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "16491491",
        "name": "G. Grant"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "00ec8123dd2ba03afab7c1fa02f774062f769181",
    "title": "Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 318,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "15316342",
        "name": "Rodrigo Toro Icarte"
      },
      {
        "authorId": "1758085",
        "name": "Toryn Q. Klassen"
      },
      {
        "authorId": "2682734",
        "name": "R. Valenzano"
      },
      {
        "authorId": "1683896",
        "name": "Sheila A. McIlraith"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "08dc94471605308669c8d3d8284ba94fcc93e345",
    "title": "Deep Learning in Microscopy Image Analysis: A Survey",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2018,
    "citationCount": 359,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2017.2766168?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2017.2766168, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2082604",
        "name": "Fuyong Xing"
      },
      {
        "authorId": "1877955",
        "name": "Yuanpu Xie"
      },
      {
        "authorId": "143729223",
        "name": "H. Su"
      },
      {
        "authorId": "12217443",
        "name": "Fujun Liu"
      },
      {
        "authorId": "29163569",
        "name": "Lin Yang"
      }
    ],
    "abstract": "Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning."
  },
  {
    "paperId": "403a730841c1e8e9e8062df22ff8f43537afd6ee",
    "title": "Feature Selection for Machine Learning: Comparing a Correlation-Based Filter Approach to the Wrapper",
    "venue": "The Florida AI Research Society",
    "year": 1999,
    "citationCount": 655,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "118860642",
        "name": "M. Hall"
      },
      {
        "authorId": "2226870",
        "name": "L. A. Smith"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9a24a993288119c9fd94cf2b43e394ad72dd59ee",
    "title": "Efficient Learning Machines",
    "venue": "Apress",
    "year": 2015,
    "citationCount": 572,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/978-1-4302-5990-9.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4302-5990-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4302-5990-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144707373",
        "name": "M. Awad"
      },
      {
        "authorId": "49862773",
        "name": "R. Khanna"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fcb926027ba5001f8f69dc0f1de5ded7d003b6af",
    "title": "A comparison of machine learning techniques for phishing detection",
    "venue": "APWG Symposium on Electronic Crime Research",
    "year": 2007,
    "citationCount": 486,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1299015.1299021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1299015.1299021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1403307248",
        "name": "Saeed Abu-Nimeh"
      },
      {
        "authorId": "2635516",
        "name": "D. Nappa"
      },
      {
        "authorId": "37457992",
        "name": "Xinlei Wang"
      },
      {
        "authorId": "145531251",
        "name": "S. Nair"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "78a907839eadb15730ed51b574009067a5ac394a",
    "title": "Orange: From Experimental Machine Learning to Interactive Data Mining",
    "venue": "European Conference on Principles of Data Mining and Knowledge Discovery",
    "year": 2004,
    "citationCount": 517,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-540-30116-5_58.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-30116-5_58?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-30116-5_58, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2701105",
        "name": "J. Demšar"
      },
      {
        "authorId": "1775384",
        "name": "B. Zupan"
      },
      {
        "authorId": "1770649",
        "name": "Gregor Leban"
      },
      {
        "authorId": "1772593",
        "name": "Tomaž Curk"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3efcb97c1de1c87832a7a1d99e91801992a938ec",
    "title": "Crafting Papers on Machine Learning",
    "venue": "International Conference on Machine Learning",
    "year": 2000,
    "citationCount": 685,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "50a869bcd6d45ec7fdb317877c3d2a047c2cfc38",
    "title": "Overfitting and undercomputing in machine learning",
    "venue": "CSUR",
    "year": 1995,
    "citationCount": 709,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/212094.212114",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/212094.212114?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/212094.212114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b0485fba23aabda526358f31cb5a382b66a08270",
    "title": "Classification Using Machine Learning Techniques",
    "venue": "",
    "year": 2005,
    "citationCount": 513,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "67128225",
        "name": "M. Ikonomakis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "db2d99084f3d25d3934976f9d9fdb6b882593a9d",
    "title": "Introduction to machine learning",
    "venue": "Adaptive computation and machine learning",
    "year": 2004,
    "citationCount": 511,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1439122425",
        "name": "Ethem Alpaydin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1776b5ba5d2b17f6e6a043d57d36126e2af90315",
    "title": "Algorithmic Learning in a Random World",
    "venue": "",
    "year": 2005,
    "citationCount": 1704,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-031-06649-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-031-06649-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145675281",
        "name": "Vladimir Vovk"
      },
      {
        "authorId": "1793317",
        "name": "A. Gammerman"
      },
      {
        "authorId": "145500409",
        "name": "G. Shafer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "28d2503b0f86dd3947bf745efdd609dee7975cd8",
    "title": "TensorLy: Tensor Learning in Python",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 389,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1610.09555, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3125761",
        "name": "Jean Kossaifi"
      },
      {
        "authorId": "1780393",
        "name": "Yannis Panagakis"
      },
      {
        "authorId": "145387780",
        "name": "M. Pantic"
      }
    ],
    "abstract": "Tensors are higher-order extensions of matrices. While matrix methods form the cornerstone of traditional machine learning and data analysis, tensor methods have been gaining increasing traction. However, software support for tensor operations is not on the same footing. In order to bridge this gap, we have developed TensorLy, a Python library that provides a high-level API for tensor methods and deep tensorized neural networks. TensorLy aims to follow the same standards adopted by the main projects of the Python scientific community, and to seamlessly integrate with them. Its BSD license makes it suitable for both academic and commercial applications. TensorLy's backend system allows users to perform computations with several libraries such as NumPy or PyTorch to name but a few. They can be scaled on multiple CPU or GPU machines. In addition, using the deep-learning frameworks as backend allows to easily design and train deep tensorized neural networks. TensorLy is available at https://github.com/tensorly/tensorly"
  },
  {
    "paperId": "066dd3d09eb5815e8be1da560abd1abe08f87cb9",
    "title": "OP-ELM: Optimally Pruned Extreme Learning Machine",
    "venue": "IEEE Transactions on Neural Networks",
    "year": 2010,
    "citationCount": 767,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNN.2009.2036259?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNN.2009.2036259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3194493",
        "name": "Yoan Miché"
      },
      {
        "authorId": "2500799",
        "name": "A. Sorjamaa"
      },
      {
        "authorId": "144224330",
        "name": "P. Bas"
      },
      {
        "authorId": "1738231",
        "name": "O. Simula"
      },
      {
        "authorId": "1696508",
        "name": "C. Jutten"
      },
      {
        "authorId": "1731049",
        "name": "A. Lendasse"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "32d12b621e75cdb5942896c16421496bdfd4a6fa",
    "title": "Ontology Matching: A Machine Learning Approach",
    "venue": "Handbook on Ontologies",
    "year": 2004,
    "citationCount": 581,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-24750-0_19?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-24750-0_19, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3030274",
        "name": "A. Doan"
      },
      {
        "authorId": "2224716",
        "name": "Jayant Madhavan"
      },
      {
        "authorId": "1740213",
        "name": "Pedro M. Domingos"
      },
      {
        "authorId": "1770962",
        "name": "A. Halevy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ae6fdc00ec8c2299f101ddd428bfd82a0b55bac6",
    "title": "Practical feature subset selection for machine learning",
    "venue": "",
    "year": 1998,
    "citationCount": 571,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "118860642",
        "name": "M. Hall"
      },
      {
        "authorId": "2226870",
        "name": "L. A. Smith"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ae73fa99d777efd07ed5a73cdc695191862f9d9e",
    "title": "Drug Design by Machine Learning: Support Vector Machines for Pharmaceutical Data Analysis",
    "venue": "Computers and Chemistry",
    "year": 2001,
    "citationCount": 645,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0097-8485(01)00094-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0097-8485(01)00094-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2916240",
        "name": "R. Burbidge"
      },
      {
        "authorId": "80170770",
        "name": "M. Trotter"
      },
      {
        "authorId": "31557997",
        "name": "B. Buxton"
      },
      {
        "authorId": "2732041",
        "name": "S. Holden"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f455013a3e35fd660eab52f7f4dcb78d1faac266",
    "title": "Elements of Machine Learning",
    "venue": "",
    "year": 1995,
    "citationCount": 627,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2248765336",
        "name": "Pat Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "160a4786dd643d9f758b9cc0758bdd2581524941",
    "title": "Machine learning for detection and diagnosis of disease.",
    "venue": "Annual Review of Biomedical Engineering",
    "year": 2006,
    "citationCount": 388,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1146/ANNUREV.BIOENG.8.061505.095802?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/ANNUREV.BIOENG.8.061505.095802, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1812793",
        "name": "P. Sajda"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a3db81e35f1890511c38d685a2f57de476820518",
    "title": "Interactive machine learning",
    "venue": "International Conference on Intelligent User Interfaces",
    "year": 2003,
    "citationCount": 461,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/604045.604056?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/604045.604056, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3141061",
        "name": "J. Fails"
      },
      {
        "authorId": "1733794",
        "name": "D. Olsen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2ff6fcebe5561433a2d2abeb8b30b2fbf3c0e303",
    "title": "Introduction to Semi-Supervised Learning",
    "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
    "year": 2009,
    "citationCount": 2254,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-031-01548-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-031-01548-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1832364",
        "name": "Xiaojin Zhu"
      },
      {
        "authorId": "2417893",
        "name": "A. Goldberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "bbfad4e88fd8bfbbd77ba53a56fe2886ecc147da",
    "title": "Applications of machine learning and rule induction",
    "venue": "CACM",
    "year": 1995,
    "citationCount": 582,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/219717.219768?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/219717.219768, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      },
      {
        "authorId": "2259532335",
        "name": "H. Simon"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1409df3208e6e05f4f788037355bb5bf7c151c5e",
    "title": "Machine Learning and Data Mining: Introduction to Principles and Algorithms",
    "venue": "",
    "year": 2007,
    "citationCount": 343,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1533/9780857099440?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1533/9780857099440, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143986204",
        "name": "I. Kononenko"
      },
      {
        "authorId": "1719813",
        "name": "M. Kukar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "47c862bf4542415702ff1084f2a3aac33d0e13ea",
    "title": "Proceedings of the 24th international conference on Machine learning",
    "venue": "International Conference on Machine Learning",
    "year": 2007,
    "citationCount": 250,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1744700",
        "name": "Zoubin Ghahramani"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ab08f2a0b98fe7938d08875eb6125fa518620222",
    "title": "The Need for Open Source Software in Machine Learning",
    "venue": "Journal of machine learning research",
    "year": 2007,
    "citationCount": 236,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1314498.1314577?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1314498.1314577, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3029782",
        "name": "S. Sonnenburg"
      },
      {
        "authorId": "2522031",
        "name": "M. Braun"
      },
      {
        "authorId": "1706780",
        "name": "Cheng Soon Ong"
      },
      {
        "authorId": "1751569",
        "name": "Samy Bengio"
      },
      {
        "authorId": "52184096",
        "name": "L. Bottou"
      },
      {
        "authorId": "144282963",
        "name": "G. Holmes"
      },
      {
        "authorId": "1688882",
        "name": "Yann LeCun"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "145366908",
        "name": "Fernando C Pereira"
      },
      {
        "authorId": "3472959",
        "name": "C. Rasmussen"
      },
      {
        "authorId": "152597562",
        "name": "Gunnar Rätsch"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      },
      {
        "authorId": "145467703",
        "name": "Pascal Vincent"
      },
      {
        "authorId": "145183709",
        "name": "J. Weston"
      },
      {
        "authorId": "143957317",
        "name": "R. C. Williamson"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b8eb7da56dae58f77788c33a57b5b810ca930527",
    "title": "The Geometry of ROC Space: Understanding Machine Learning Metrics through ROC Isometrics",
    "venue": "International Conference on Machine Learning",
    "year": 2003,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "47840704",
        "name": "Peter A. Flach"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fc82788021963ff8e318ffe955829bc68e48943a",
    "title": "Machine Learning of Temporal Relations",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2006,
    "citationCount": 301,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.3115/1220175.1220270",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P06-1095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1729172",
        "name": "I. Mani"
      },
      {
        "authorId": "145539145",
        "name": "M. Verhagen"
      },
      {
        "authorId": "2107124",
        "name": "Ben Wellner"
      },
      {
        "authorId": "2495244",
        "name": "Chong Min Lee"
      },
      {
        "authorId": "1707726",
        "name": "J. Pustejovsky"
      }
    ],
    "abstract": "This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts. To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data. This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions."
  },
  {
    "paperId": "463565c30b7a9c12c2ef0558a51cfc7b05055737",
    "title": "Semi-Supervised Learning (Adaptive Computation and Machine Learning)",
    "venue": "",
    "year": 2006,
    "citationCount": 276,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1730609",
        "name": "O. Chapelle"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "2281542",
        "name": "A. Zien"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5dcb588150d84ef6d1b1ed6ca96e2fd62399de2c",
    "title": "Readings in Machine Learning",
    "venue": "",
    "year": 1991,
    "citationCount": 409,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1734317",
        "name": "J. Shavlik"
      },
      {
        "authorId": "67136395",
        "name": "T. Deitterich"
      },
      {
        "authorId": "144299726",
        "name": "Thomas G. Dietterich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e45ead3629cdda9ab60a28b6040623ea84fc1a31",
    "title": "Machine Learning for User Modeling",
    "venue": "User modeling and user-adapted interaction",
    "year": 2001,
    "citationCount": 409,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1011117102175.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1011117102175?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1011117102175, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2257171667",
        "name": "Geoffrey I. Webb"
      },
      {
        "authorId": "1694780",
        "name": "M. Pazzani"
      },
      {
        "authorId": "1691741",
        "name": "Daniel Billsus"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "58de638505046e7de5fe7cc0660b4c6d79247488",
    "title": "Machine Learning for Information Extraction in Informal Domains",
    "venue": "Machine-mediated learning",
    "year": 2000,
    "citationCount": 401,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1007601113994.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1007601113994?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1007601113994, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1758106",
        "name": "Dayne Freitag"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7b7222ac076d211d7fcae7d012bebcc4ea71e952",
    "title": "An Empirical Comparison of Pattern Recognition, Neural Nets, and Machine Learning Classification Methods",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 1989,
    "citationCount": 538,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145700185",
        "name": "S. Weiss"
      },
      {
        "authorId": "2092055",
        "name": "I. Kapouleas"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "adb4ea2c0f3eff8a17c97a67f28b923e8e5bdff1",
    "title": "Multimodal learning with deep Boltzmann machines",
    "venue": "Journal of machine learning research",
    "year": 2012,
    "citationCount": 1766,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/2627435.2697059?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/2627435.2697059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2897313",
        "name": "Nitish Srivastava"
      },
      {
        "authorId": "145124475",
        "name": "R. Salakhutdinov"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "675b93244f917d5dc2c79b89d2936d81d077e663",
    "title": "Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)",
    "venue": "Neural Information Processing Systems",
    "year": 2004,
    "citationCount": 298,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1809791",
        "name": "K. Chellapilla"
      },
      {
        "authorId": "2812486",
        "name": "Patrice Y. Simard"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "158edd3fe6212306487e7173a5de9383a55b59bb",
    "title": "Advanced Lectures on Machine Learning",
    "venue": "Lecture Notes in Computer Science",
    "year": 2004,
    "citationCount": 300,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/b100712?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/b100712, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1698617",
        "name": "O. Bousquet"
      },
      {
        "authorId": "1728654",
        "name": "U. V. Luxburg"
      },
      {
        "authorId": "2414086",
        "name": "G. Rätsch"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "43456f4e5f2a7c56b781afe2e2d4e4aed297ceb0",
    "title": "Bayesian Inference: An Introduction to Principles and Practice in Machine Learning",
    "venue": "Advanced Lectures on Machine Learning",
    "year": 2003,
    "citationCount": 308,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-28650-9_3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-28650-9_3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2831141",
        "name": "Michael E. Tipping"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b379c5eb2f8cc501e855d295fa5712294ca2b3ed",
    "title": "Application of Machine Learning Algorithms to KDD Intrusion Detection Dataset within Misuse Detection Context",
    "venue": "International Conference on Machine Learning; Models, Technologies and Applications",
    "year": 2003,
    "citationCount": 329,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2656269",
        "name": "Maheshkumar Sabhnani"
      },
      {
        "authorId": "1744384",
        "name": "G. Serpen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b9af24fa3faf6dbdc5e952857697588708fad8f5",
    "title": "Guest Editors' Introduction: On Applied Research in Machine Learning",
    "venue": "Machine-mediated learning",
    "year": 1998,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1007442505281.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1007442505281?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1007442505281, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1752722",
        "name": "F. Provost"
      },
      {
        "authorId": "1726733",
        "name": "Ron Kohavi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3ecdaaa55313520b50ae17de9f4f6650403754a3",
    "title": "Book Review: C4.5: Programs for Machine Learning by J. Ross Quinlan. Morgan Kaufmann Publishers, Inc., 1993",
    "venue": "Machine-mediated learning",
    "year": 1994,
    "citationCount": 330,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022645310020.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1022645310020?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1022645310020, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1744109",
        "name": "S. Salzberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7d89abfe87ed7d1b40391d37364560656d208117",
    "title": "Learning Memory Access Patterns",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 221,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1803.02329, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "33798741",
        "name": "Milad Hashemi"
      },
      {
        "authorId": "2329092656",
        "name": "Kevin Swersky"
      },
      {
        "authorId": "2119124568",
        "name": "Jamie A. Smith"
      },
      {
        "authorId": "46369381",
        "name": "Grant Ayers"
      },
      {
        "authorId": "2655459",
        "name": "Heiner Litz"
      },
      {
        "authorId": "1698747",
        "name": "Jichuan Chang"
      },
      {
        "authorId": "117272782",
        "name": "Christos Kozyrakis"
      },
      {
        "authorId": "1770926",
        "name": "Parthasarathy Ranganathan"
      }
    ],
    "abstract": "The explosion in workload complexity and the recent slow-down in Moore's law scaling call for new approaches towards efficient computing. Researchers are now beginning to use recent advances in machine learning in software optimizations, augmenting or replacing traditional heuristics and data structures. However, the space of machine learning for computer hardware architecture is only lightly explored. In this paper, we demonstrate the potential of deep learning to address the von Neumann bottleneck of memory performance. We focus on the critical problem of learning memory access patterns, with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing, and show how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets, we find that neural networks consistently demonstrate superior performance in terms of precision and recall. This work represents the first step towards practical neural-network based prefetching, and opens a wide range of exciting directions for machine learning in computer architecture research."
  },
  {
    "paperId": "1bf05a4ad4b6dd4b6d14d6d2dc7a9354dd1f4425",
    "title": "A Machine Learning Approach to Workflow Management",
    "venue": "European Conference on Machine Learning",
    "year": 2000,
    "citationCount": 235,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/3-540-45164-1_19.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-45164-1_19?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-45164-1_19, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2325415",
        "name": "J. Herbst"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c5ca3b6ad0e74ab8a83d77ebef0c5a498ba5d781",
    "title": "On-line Algorithms in Machine Learning",
    "venue": "Online Algorithms",
    "year": 1996,
    "citationCount": 265,
    "openAccessPdf": {
      "url": "http://www-stat.wharton.upenn.edu/~steele/Courses/9xx/Resources2/BlumSurveyOLA.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BFb0029575?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BFb0029575, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1690967",
        "name": "Avrim Blum"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e9415d9a6e0065b46acd99ba4ff8b89bd1435fc8",
    "title": "Machine Learning and Software Engineering",
    "venue": "14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.",
    "year": 2002,
    "citationCount": 221,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1023760326768?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1023760326768, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1711711",
        "name": "Du Zhang"
      },
      {
        "authorId": "145118476",
        "name": "J. Tsai"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "06757c457ec442eb35af6ea45d8d0e2339415178",
    "title": "The Interplay of Optimization and Machine Learning Research",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 163,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2065549778",
        "name": "Kristin P. Bennett"
      },
      {
        "authorId": "1399027884",
        "name": "E. Parrado-Hernández"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3a3b9a78c02bb3bbc18f7eb13041f4186fb9dec5",
    "title": "An Insight into Extreme Learning Machines: Random Neurons, Random Features and Kernels",
    "venue": "Cognitive Computation",
    "year": 2014,
    "citationCount": 936,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s12559-014-9255-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s12559-014-9255-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a54657b8de38a18f30fd154d713f9522f705166c",
    "title": "Computational complexity of machine learning",
    "venue": "ACM distinguished dissertations",
    "year": 1990,
    "citationCount": 284,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2056642528",
        "name": "M. Kearns"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "180882b3f2ea5dfe0a554deead2c0ceb837ee933",
    "title": "Machine learning as an experimental science",
    "venue": "Machine-mediated learning",
    "year": 2004,
    "citationCount": 134,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/BF00115008.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF00115008?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF00115008, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713919",
        "name": "P. Langley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5052871d430b803b4c59f459bb26b1f76e56736e",
    "title": "Evaluation and selection of biases in machine learning",
    "venue": "Machine-mediated learning",
    "year": 1995,
    "citationCount": 129,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/BF00993472.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF00993472?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF00993472, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145152778",
        "name": "D. Spears"
      },
      {
        "authorId": "144980202",
        "name": "Marie desJardins"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d1e5263787d888da20a28254fd7bd581618e3a06",
    "title": "An Overview of Machine Learning",
    "venue": "",
    "year": 1983,
    "citationCount": 260,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-662-12405-5_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-662-12405-5_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143712374",
        "name": "J. Carbonell"
      },
      {
        "authorId": "2421006",
        "name": "R. Michalski"
      },
      {
        "authorId": "40975594",
        "name": "Tom Michael Mitchell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1671a665c636bec7d2eaff137d74e9b7f074892f",
    "title": "Learning Algorithms for the Classification Restricted Boltzmann Machine",
    "venue": "Journal of machine learning research",
    "year": 2012,
    "citationCount": 319,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/2503308.2188407?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/2503308.2188407, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1777528",
        "name": "H. Larochelle"
      },
      {
        "authorId": "50363843",
        "name": "Michael I. Mandel"
      },
      {
        "authorId": "1996134",
        "name": "Razvan Pascanu"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "467568f1777bc51a15a5100516cd4fe8de62b9ab",
    "title": "Transfer Learning for Reinforcement Learning Domains: A Survey",
    "venue": "Journal of machine learning research",
    "year": 2009,
    "citationCount": 1984,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1577069.1755839?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1577069.1755839, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39286677",
        "name": "Matthew E. Taylor"
      },
      {
        "authorId": "144848112",
        "name": "P. Stone"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "65df2d9b3c656ca85e4d66c327cfd8c8d1182df3",
    "title": "Machine Learning: Neural Networks, Genetic Algorithms, and Fuzzy Systems",
    "venue": "",
    "year": 1994,
    "citationCount": 539,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1108/k.1999.28.3.317.5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/k.1999.28.3.317.5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1750050",
        "name": "H. Adeli"
      },
      {
        "authorId": "2830443",
        "name": "S. Hung"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "85d727b119304dde458bcd8cf5cb87a906fb41ba",
    "title": "Using AUC and accuracy in evaluating learning algorithms",
    "venue": "IEEE Transactions on Knowledge and Data Engineering",
    "year": 2005,
    "citationCount": 2030,
    "openAccessPdf": {
      "url": "http://www.cs.ust.hk/~qyang/537/Papers/AUC-evaluation.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TKDE.2005.50?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TKDE.2005.50, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2110151928",
        "name": "Jin Huang"
      },
      {
        "authorId": "1688204",
        "name": "C. Ling"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "22faafeba7d7443da14c1e23e549b94e40d7d6ee",
    "title": "“Memo” Functions and Machine Learning",
    "venue": "Nature",
    "year": 1968,
    "citationCount": 581,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/218019A0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/218019A0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145878706",
        "name": "D. Michie"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9a4da6802d1eca17a07ded017a87bef7001189c4",
    "title": "Introduction to Machine Learning (Adaptive Computation and Machine Learning)",
    "venue": "",
    "year": 2004,
    "citationCount": 373,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1691898",
        "name": "Ethem Alpaydin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b",
    "title": "Deep Learning for Content-Based Image Retrieval: A Comprehensive Study",
    "venue": "ACM Multimedia",
    "year": 2014,
    "citationCount": 912,
    "openAccessPdf": {
      "url": "https://ink.library.smu.edu.sg/sis_research/2320",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2647868.2654948?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2647868.2654948, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2041852738",
        "name": "Ji Wan"
      },
      {
        "authorId": "47858913",
        "name": "Dayong Wang"
      },
      {
        "authorId": "1741126",
        "name": "S. Hoi"
      },
      {
        "authorId": "2406415",
        "name": "Pengcheng Wu"
      },
      {
        "authorId": "1704030",
        "name": "Jianke Zhu"
      },
      {
        "authorId": "1699819",
        "name": "Yongdong Zhang"
      },
      {
        "authorId": "30821609",
        "name": "Jintao Li"
      }
    ],
    "abstract": "Learning effective feature representations and similarity measures are crucial to the retrieval performance of a content-based image retrieval (CBIR) system. Despite extensive research efforts for decades, it remains one of the most challenging open problems that considerably hinders the successes of real-world CBIR systems. The key challenge has been attributed to the well-known ``semantic gap'' issue that exists between low-level image pixels captured by machines and high-level semantic concepts perceived by human. Among various techniques, machine learning has been actively investigated as a possible direction to bridge the semantic gap in the long term. Inspired by recent successes of deep learning techniques for computer vision and other applications, in this paper, we attempt to address an open problem: if deep learning is a hope for bridging the semantic gap in CBIR and how much improvements in CBIR tasks can be achieved by exploring the state-of-the-art deep learning techniques for learning feature representations and similarity measures. Specifically, we investigate a framework of deep learning with application to CBIR tasks with an extensive set of empirical studies by examining a state-of-the-art deep learning method (Convolutional Neural Networks) for CBIR tasks under varied settings. From our empirical studies, we find some encouraging results and summarize some important insights for future research."
  },
  {
    "paperId": "298a09325dce98155779f9640ccae8fa5ddca62d",
    "title": "Machine-Learning Applications of Algorithmic Randomness",
    "venue": "International Conference on Machine Learning",
    "year": 1999,
    "citationCount": 297,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145675281",
        "name": "Vladimir Vovk"
      },
      {
        "authorId": "1793317",
        "name": "A. Gammerman"
      },
      {
        "authorId": "144884649",
        "name": "C. Saunders"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "72282cfbb493c487f9f43a6270b5bd9d94b57d94",
    "title": "Machine Learning: ECML-98",
    "venue": "Lecture Notes in Computer Science",
    "year": 1998,
    "citationCount": 388,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/bfm:978-3-540-69781-7/1?pdf=chapter%20toc",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BFb0026664?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BFb0026664, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2838186",
        "name": "C. Nédellec"
      },
      {
        "authorId": "2321708",
        "name": "C. Rouveirol"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e2d4321c99b74859b8aa57daac7df4f1c11291cb",
    "title": "The children's machine: rethinking school in the age of the computer",
    "venue": "",
    "year": 1993,
    "citationCount": 2038,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5860/choice.31-1648?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5860/choice.31-1648, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145008014",
        "name": "S. Papert"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7",
    "title": "Learning Question Classifiers",
    "venue": "International Conference on Computational Linguistics",
    "year": 2002,
    "citationCount": 1660,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/C02-1150, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153901204",
        "name": "Xin Li"
      },
      {
        "authorId": "144590225",
        "name": "D. Roth"
      }
    ],
    "abstract": "In order to respond correctly to a free form factual question given a large collection of texts, one needs to understand the question to a level that allows determining some of the constraints the question imposes on a possible answer. These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.This paper presents a machine learning approach to question classification. We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into fine-grained classes. We show accurate results on a large collection of free-form questions used in TREC 10."
  },
  {
    "paperId": "4a6a88fcd374e4fdf2120f65b82c1382bdccfa2d",
    "title": "Genetic Algorithms in Machine Learning",
    "venue": "Machine Learning and Its Applications",
    "year": 2001,
    "citationCount": 142,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-44673-7_7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-44673-7_7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2113093",
        "name": "J. Shapiro"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "db64f424710d57025c5fb42a564551f093a4d111",
    "title": "The Extreme Value Machine",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2015,
    "citationCount": 316,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/tpami.2017.2707495",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1506.06112, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39886114",
        "name": "Ethan M. Rudd"
      },
      {
        "authorId": "34939951",
        "name": "Lalit P. Jain"
      },
      {
        "authorId": "2613438",
        "name": "W. Scheirer"
      },
      {
        "authorId": "32163276",
        "name": "T. Boult"
      }
    ],
    "abstract": "It is often desirable to be able to recognize when inputs to a recognition function learned in a supervised manner correspond to classes unseen at training time. With this ability, new class labels could be assigned to these inputs by a human operator, allowing them to be incorporated into the recognition function—ideally under an efficient incremental update mechanism. While good algorithms that assume inputs from a fixed set of classes exist, e.g. , artificial neural networks and kernel machines, it is not immediately obvious how to extend them to perform incremental learning in the presence of unknown query classes. Existing algorithms take little to no distributional information into account when learning recognition functions and lack a strong theoretical foundation. We address this gap by formulating a novel, theoretically sound classifier—the Extreme Value Machine (EVM). The EVM has a well-grounded interpretation derived from statistical Extreme Value Theory (EVT), and is the first classifier to be able to perform nonlinear kernel-free variable bandwidth incremental learning. Compared to other classifiers in the same deep network derived feature space, the EVM is accurate and efficient on an established benchmark partition of the ImageNet dataset."
  },
  {
    "paperId": "884895a86fe15cb9601df4a15a1475c07f28da3c",
    "title": "Boosting for transfer learning",
    "venue": "International Conference on Machine Learning",
    "year": 2007,
    "citationCount": 1844,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1273496.1273521?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1273496.1273521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1752769",
        "name": "Wenyuan Dai"
      },
      {
        "authorId": "152290618",
        "name": "Qiang Yang"
      },
      {
        "authorId": "1701421",
        "name": "Gui-Rong Xue"
      },
      {
        "authorId": "1811427",
        "name": "Yong Yu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "02e68b069d9cf13c082049429ffed18a5ca5f6d0",
    "title": "Support Vector Machines for Multiple-Instance Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2002,
    "citationCount": 1644,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2054883307",
        "name": "Stuart Andrews"
      },
      {
        "authorId": "1765700",
        "name": "Ioannis Tsochantaridis"
      },
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "48e752c719d33ff55b3b3bec3538727f8ce69399",
    "title": "Ontology Learning for the Semantic Web",
    "venue": "IEEE Intelligent Systems",
    "year": 2002,
    "citationCount": 2266,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/bfm:978-1-4615-0925-7/1",
      "status": "CLOSED",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/5254.920602?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/5254.920602, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1806905",
        "name": "A. Maedche"
      },
      {
        "authorId": "1752093",
        "name": "Steffen Staab"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4417f78b31546227784941bbd6f6532a177e60b8",
    "title": "Deep Learning using Linear Support Vector Machines",
    "venue": "",
    "year": 2013,
    "citationCount": 923,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1306.0239, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34312504",
        "name": "Yichuan Tang"
      }
    ],
    "abstract": "Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these \"deep learning\" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge."
  },
  {
    "paperId": "7975195638f3574ac02975df6f4048558ec1bc96",
    "title": "Extreme learning machines: a survey",
    "venue": "International Journal of Machine Learning and Cybernetics",
    "year": 2011,
    "citationCount": 1904,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-011-0019-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-011-0019-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "70129091",
        "name": "Dianhui Wang"
      },
      {
        "authorId": "1770395",
        "name": "Yuan Lan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b3852f0113fcf8a3913c55ae92393ae6ccde347e",
    "title": "Self-taught learning: transfer learning from unlabeled data",
    "venue": "International Conference on Machine Learning",
    "year": 2007,
    "citationCount": 1803,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1273496.1273592?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1273496.1273592, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2979876",
        "name": "Rajat Raina"
      },
      {
        "authorId": "2078284037",
        "name": "Alexis Battle"
      },
      {
        "authorId": "1697141",
        "name": "Honglak Lee"
      },
      {
        "authorId": "1409971380",
        "name": "Ben Packer"
      },
      {
        "authorId": "34699434",
        "name": "A. Ng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2c5135a0531bc5ad7dd890f018e67a40529f5bcb",
    "title": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data",
    "venue": "Journal of machine learning research",
    "year": 2005,
    "citationCount": 1669,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "38070424",
        "name": "R. Ando"
      },
      {
        "authorId": "2117881943",
        "name": "Tong Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5ed59f49c1bb7de06cfa2a9467d5efb535103277",
    "title": "Temporal Difference Learning and TD-Gammon",
    "venue": "CACM",
    "year": 1995,
    "citationCount": 2171,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/203330.203343",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/203330.203343?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/203330.203343, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1699108",
        "name": "G. Tesauro"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0628fdf728d0aba31be803a7d834c7f4b569408d",
    "title": "Imbalanced Learning: Foundations, Algorithms, and Applications",
    "venue": "",
    "year": 2013,
    "citationCount": 876,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9781118646106?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9781118646106, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2198278",
        "name": "Haibo He"
      },
      {
        "authorId": "2363386",
        "name": "Yunqian Ma"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c4f759fbf9c29ffaccbe753e2ee9194681829b03",
    "title": "Evolutionary extreme learning machine",
    "venue": "Pattern Recognition",
    "year": 2005,
    "citationCount": 805,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.patcog.2005.03.028?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.patcog.2005.03.028, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50736254",
        "name": "Q. Zhu"
      },
      {
        "authorId": "145587600",
        "name": "A. K. Qin"
      },
      {
        "authorId": "1688355",
        "name": "P. Suganthan"
      },
      {
        "authorId": "145678691",
        "name": "G. Huang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0ca26f9a98dda0abb737692f72ffa682df14cb2f",
    "title": "Sparse Bayesian learning for basis selection",
    "venue": "IEEE Transactions on Signal Processing",
    "year": 2004,
    "citationCount": 1478,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSP.2004.831016?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSP.2004.831016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2242717",
        "name": "D. Wipf"
      },
      {
        "authorId": "144876925",
        "name": "B. Rao"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "66f44806cd46a27f02ceb74bdfd9ad6e77e044ca",
    "title": "Toward an Online Anomaly Intrusion Detection System Based on Deep Learning",
    "venue": "International Conference on Machine Learning and Applications",
    "year": 2016,
    "citationCount": 245,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMLA.2016.0040?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMLA.2016.0040, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8837455",
        "name": "Khaled Alrawashdeh"
      },
      {
        "authorId": "145554708",
        "name": "C. Purdy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a8582979cc4337bd6349d55ac6a7112a07add3a5",
    "title": "Single-machine scheduling with learning considerations",
    "venue": "European Journal of Operational Research",
    "year": 1999,
    "citationCount": 738,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/S0377-2217(98)00246-X?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/S0377-2217(98)00246-X, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3353406",
        "name": "D. Biskup"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "141e6c1dd532504611266d08458dbe2a0dbb4e98",
    "title": "Multiple kernel learning, conic duality, and the SMO algorithm",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 1653,
    "openAccessPdf": {
      "url": "http://www.cs.berkeley.edu/~jordan/papers/skm_icml.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015424?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015424, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144570279",
        "name": "F. Bach"
      },
      {
        "authorId": "1725533",
        "name": "Gert R. G. Lanckriet"
      },
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
    "title": "Deep learning with COTS HPC systems",
    "venue": "International Conference on Machine Learning",
    "year": 2013,
    "citationCount": 743,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144638694",
        "name": "Adam Coates"
      },
      {
        "authorId": "2570381",
        "name": "Brody Huval"
      },
      {
        "authorId": "2156632012",
        "name": "Tao Wang"
      },
      {
        "authorId": "25629078",
        "name": "David J. Wu"
      },
      {
        "authorId": "2301680",
        "name": "Bryan Catanzaro"
      },
      {
        "authorId": "34699434",
        "name": "A. Ng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "177944150565195ee9c3e28dc6b032200cfda059",
    "title": "Collaborative Learning: Cognitive and Computational Approaches",
    "venue": "",
    "year": 1999,
    "citationCount": 1624,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2270495524",
        "name": "Tia G. B. Hansen"
      },
      {
        "authorId": "1401491831",
        "name": "L. Dirckinck-Holmfeld"
      },
      {
        "authorId": "2380182180",
        "name": "R. Lewis"
      },
      {
        "authorId": "2270593090",
        "name": "J. Rugelj"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e4de0f69cd867dbcae88211ac05318be17615a66",
    "title": "Regularized Extreme Learning Machine",
    "venue": "IEEE Symposium on Computational Intelligence and Data Mining",
    "year": 2009,
    "citationCount": 447,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/CIDM.2009.4938676?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CIDM.2009.4938676, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2275074507",
        "name": "W. Deng"
      },
      {
        "authorId": "2817677",
        "name": "Qinghua Zheng"
      },
      {
        "authorId": "2118537230",
        "name": "Lin Chen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6fdb77260fc83dff91c44fea0f31a2cb8ed13d04",
    "title": "Scaling learning algorithms towards AI",
    "venue": "",
    "year": 2007,
    "citationCount": 1365,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "1688882",
        "name": "Yann LeCun"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d26a48aff2abc3460c1018d5b410766f698d696c",
    "title": "Large Scale Multiple Kernel Learning",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 1414,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3029782",
        "name": "S. Sonnenburg"
      },
      {
        "authorId": "152597562",
        "name": "Gunnar Rätsch"
      },
      {
        "authorId": "1754319",
        "name": "C. Schäfer"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fbc913faf39b1e369dfcdcfefb354d846a46573c",
    "title": "Learning With Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
    "venue": "",
    "year": 2001,
    "citationCount": 1446,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1198/jasa.2003.s269?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1198/jasa.2003.s269, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2285968829",
        "name": "Christopher K. I Williams"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6ce53f261fc6e115ff5723968e9b69be31a670f3",
    "title": "Evaluating Learning Algorithms: A Classification Perspective",
    "venue": "",
    "year": 2011,
    "citationCount": 997,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1743642",
        "name": "N. Japkowicz"
      },
      {
        "authorId": "40225085",
        "name": "Mohak Shah"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6f0cde3fcab0044f386b5b8a4244c371507bec15",
    "title": "A Survey on Metric Learning for Feature Vectors and Structured Data",
    "venue": "arXiv.org",
    "year": 2013,
    "citationCount": 697,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1306.6709, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1702915",
        "name": "A. Bellet"
      },
      {
        "authorId": "1749327",
        "name": "Amaury Habrard"
      },
      {
        "authorId": "1738336",
        "name": "M. Sebban"
      }
    ],
    "abstract": "The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come."
  },
  {
    "paperId": "a92d7de31100a0fee816f0cb61b4a2a5a2d5e37a",
    "title": "Semi-Supervised Learning",
    "venue": "",
    "year": 2006,
    "citationCount": 1182,
    "openAccessPdf": {
      "url": "https://www.molgen.mpg.de/3659531/MITPress--SemiSupervised-Learning.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/MITPRESS/9780262033589.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/MITPRESS/9780262033589.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1730609",
        "name": "O. Chapelle"
      },
      {
        "authorId": "2258042514",
        "name": "Bernhard Schlkopf"
      },
      {
        "authorId": "2281542",
        "name": "A. Zien"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "98f8a0055bb28133efcff359a92937324d0e6f51",
    "title": "A Perspective View and Survey of Meta-Learning",
    "venue": "Artificial Intelligence Review",
    "year": 2002,
    "citationCount": 1254,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1019956318069?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1019956318069, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34706692",
        "name": "R. Vilalta"
      },
      {
        "authorId": "2089204999",
        "name": "Youssef Drissi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a13efb90f0b56417bf5dd5b6219681c4259ff355",
    "title": "The Cerebellum: A Neuronal Learning Machine?",
    "venue": "Science",
    "year": 1996,
    "citationCount": 634,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.272.5265.1126?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.272.5265.1126, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144545670",
        "name": "J. Raymond"
      },
      {
        "authorId": "2486944",
        "name": "S. Lisberger"
      },
      {
        "authorId": "3002354",
        "name": "M. Mauk"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "605402e235bd62437baf3c9ebefe77fb4d92ee95",
    "title": "The Helmholtz Machine",
    "venue": "Neural Computation",
    "year": 1995,
    "citationCount": 1359,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1162/neco.1995.7.5.889?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/neco.1995.7.5.889, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1790646",
        "name": "P. Dayan"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      },
      {
        "authorId": "1764325",
        "name": "Radford M. Neal"
      },
      {
        "authorId": "1804104",
        "name": "R. Zemel"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "73e1c4a1152a75ec7310adfb4b8daea16d627bc7",
    "title": "Learning to learn with the informative vector machine",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 392,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015382?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145306271",
        "name": "Neil D. Lawrence"
      },
      {
        "authorId": "144189092",
        "name": "John C. Platt"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e541c475457a731d7d434c4302867fc45af5876f",
    "title": "Active Learning",
    "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
    "year": 2012,
    "citationCount": 695,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4419-1428-6_489?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4419-1428-6_489, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1717452",
        "name": "Burr Settles"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "efbeedfbf13db70878618553f0c4a0fec6f493fe",
    "title": "Learning Collaborative Information Filters",
    "venue": "International Conference on Machine Learning",
    "year": 1998,
    "citationCount": 1259,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1691741",
        "name": "Daniel Billsus"
      },
      {
        "authorId": "1694780",
        "name": "M. Pazzani"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a",
    "title": "Automatic differentiation in PyTorch",
    "venue": "",
    "year": 2017,
    "citationCount": 15748,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3407277",
        "name": "Adam Paszke"
      },
      {
        "authorId": "39793298",
        "name": "Sam Gross"
      },
      {
        "authorId": "2127604",
        "name": "Soumith Chintala"
      },
      {
        "authorId": "114250963",
        "name": "Gregory Chanan"
      },
      {
        "authorId": "2052812305",
        "name": "E. Yang"
      },
      {
        "authorId": "2253681376",
        "name": "Zachary DeVito"
      },
      {
        "authorId": "3370429",
        "name": "Zeming Lin"
      },
      {
        "authorId": "3050846",
        "name": "Alban Desmaison"
      },
      {
        "authorId": "3029482",
        "name": "L. Antiga"
      },
      {
        "authorId": "1977806",
        "name": "Adam Lerer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3a288c63576fc385910cb5bc44eaea75b442e62e",
    "title": "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction",
    "venue": "arXiv.org",
    "year": 2018,
    "citationCount": 10892,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.03426, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "31785573",
        "name": "Leland McInnes"
      },
      {
        "authorId": "2062756303",
        "name": "John Healy"
      }
    ],
    "abstract": "UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning."
  },
  {
    "paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
    "title": "Overcoming catastrophic forgetting in neural networks",
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "year": 2016,
    "citationCount": 8542,
    "openAccessPdf": {
      "url": "https://www.pnas.org/content/pnas/114/13/3521.full.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1612.00796, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2066516991",
        "name": "J. Kirkpatrick"
      },
      {
        "authorId": "1996134",
        "name": "Razvan Pascanu"
      },
      {
        "authorId": "3422052",
        "name": "Neil C. Rabinowitz"
      },
      {
        "authorId": "144056327",
        "name": "J. Veness"
      },
      {
        "authorId": "2755582",
        "name": "Guillaume Desjardins"
      },
      {
        "authorId": "2228824",
        "name": "Andrei A. Rusu"
      },
      {
        "authorId": "8181864",
        "name": "Kieran Milan"
      },
      {
        "authorId": "34660073",
        "name": "John Quan"
      },
      {
        "authorId": "34505275",
        "name": "Tiago Ramalho"
      },
      {
        "authorId": "1398898827",
        "name": "A. Grabska-Barwinska"
      },
      {
        "authorId": "48987704",
        "name": "D. Hassabis"
      },
      {
        "authorId": "2388737",
        "name": "C. Clopath"
      },
      {
        "authorId": "2106164",
        "name": "D. Kumaran"
      },
      {
        "authorId": "2315504",
        "name": "R. Hadsell"
      }
    ],
    "abstract": "Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially. The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially."
  },
  {
    "paperId": "26bc9195c6343e4d7f434dd65b4ad67efe2be27a",
    "title": "XGBoost: A Scalable Tree Boosting System",
    "venue": "Knowledge Discovery and Data Mining",
    "year": 2016,
    "citationCount": 45449,
    "openAccessPdf": {
      "url": "http://dl.acm.org/ft_gateway.cfm?id=2939785&type=pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.02754, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1913774",
        "name": "Tianqi Chen"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      }
    ],
    "abstract": "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
  },
  {
    "paperId": "c0883f5930a232a9c1ad601c978caede29155979",
    "title": "“Why Should I Trust You?”: Explaining the Predictions of Any Classifier",
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2016,
    "citationCount": 18988,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/N16-3020.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1602.04938, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "78846919",
        "name": "Marco Tulio Ribeiro"
      },
      {
        "authorId": "34650964",
        "name": "Sameer Singh"
      },
      {
        "authorId": "1730156",
        "name": "Carlos Guestrin"
      }
    ],
    "abstract": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted."
  },
  {
    "paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e",
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2017,
    "citationCount": 4767,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/N18-1101.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1704.05426, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "81840293",
        "name": "Adina Williams"
      },
      {
        "authorId": "10666396",
        "name": "Nikita Nangia"
      },
      {
        "authorId": "3644767",
        "name": "Samuel R. Bowman"
      }
    ],
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement."
  },
  {
    "paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e",
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2017,
    "citationCount": 4767,
    "openAccessPdf": {
      "url": "https://www.aclweb.org/anthology/N18-1101.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1704.05426, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "81840293",
        "name": "Adina Williams"
      },
      {
        "authorId": "10666396",
        "name": "Nikita Nangia"
      },
      {
        "authorId": "3644767",
        "name": "Samuel R. Bowman"
      }
    ],
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement."
  },
  {
    "paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb",
    "title": "Explaining and Harnessing Adversarial Examples",
    "venue": "International Conference on Learning Representations",
    "year": 2014,
    "citationCount": 20674,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1412.6572, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "1789737",
        "name": "Jonathon Shlens"
      },
      {
        "authorId": "2574060",
        "name": "Christian Szegedy"
      }
    ],
    "abstract": "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset."
  },
  {
    "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
    "title": "Dropout: a simple way to prevent neural networks from overfitting",
    "venue": "Journal of machine learning research",
    "year": 2014,
    "citationCount": 41695,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/2627435.2670313?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/2627435.2670313, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2897313",
        "name": "Nitish Srivastava"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      },
      {
        "authorId": "2064160",
        "name": "A. Krizhevsky"
      },
      {
        "authorId": "1701686",
        "name": "I. Sutskever"
      },
      {
        "authorId": "145124475",
        "name": "R. Salakhutdinov"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f3de86aeb442216a8391befcacb49e58b478f512",
    "title": "Distributed Representations of Sentences and Documents",
    "venue": "International Conference on Machine Learning",
    "year": 2014,
    "citationCount": 9543,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1405.4053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2827616",
        "name": "Quoc V. Le"
      },
      {
        "authorId": "2047446108",
        "name": "Tomas Mikolov"
      }
    ],
    "abstract": "Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
  },
  {
    "paperId": "46bed4c578e96e05fa3e5704620c4ffa0746d78f",
    "title": "A Learning Machine: Part I",
    "venue": "IBM Journal of Research and Development",
    "year": 1958,
    "citationCount": 422,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1147/rd.21.0002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1147/rd.21.0002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40425341",
        "name": "R. Friedberg"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b",
    "title": "Adversarial examples in the physical world",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "citationCount": 6353,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1607.02533",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1607.02533, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145714153",
        "name": "Alexey Kurakin"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "1751569",
        "name": "Samy Bengio"
      }
    ],
    "abstract": "Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera."
  },
  {
    "paperId": "8603193192a64f0c9943989d209e7492689045c1",
    "title": "Artificial Intelligence A Modern Approach 3rd Edition",
    "venue": "",
    "year": 2020,
    "citationCount": 895,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [],
    "abstract": null
  },
  {
    "paperId": "8592e46a5435d18bba70557846f47290b34c1aa5",
    "title": "Learning and relearning in Boltzmann machines",
    "venue": "",
    "year": 1986,
    "citationCount": 1417,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/mitpress/3349.003.0005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/mitpress/3349.003.0005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      },
      {
        "authorId": "1714528",
        "name": "T. Sejnowski"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "de42b848775f9fa1e4bff758ae04a54099c0c381",
    "title": "and Machine",
    "venue": "",
    "year": 1977,
    "citationCount": 1425,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2265978845",
        "name": "Okan Bulut"
      },
      {
        "authorId": "2282204504",
        "name": "Yi Zheng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "09879f7956dddc2a9328f5c1472feeb8402bcbcf",
    "title": "Density estimation using Real NVP",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "citationCount": 4028,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1605.08803, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46573521",
        "name": "Laurent Dinh"
      },
      {
        "authorId": "1407546424",
        "name": "Jascha Narain Sohl-Dickstein"
      },
      {
        "authorId": "1751569",
        "name": "Samy Bengio"
      }
    ],
    "abstract": "Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations."
  },
  {
    "paperId": "81a4fd3004df0eb05d6c1cef96ad33d5407820df",
    "title": "A Comprehensive Survey on Graph Neural Networks",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2019,
    "citationCount": 9916,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/tnnls.2020.2978386",
      "status": "HYBRID",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1901.00596, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2109557884",
        "name": "Zonghan Wu"
      },
      {
        "authorId": "2585415",
        "name": "Shirui Pan"
      },
      {
        "authorId": "31370754",
        "name": "Fengwen Chen"
      },
      {
        "authorId": "2062835",
        "name": "Guodong Long"
      },
      {
        "authorId": "48934799",
        "name": "Chengqi Zhang"
      },
      {
        "authorId": "144019071",
        "name": "Philip S. Yu"
      }
    ],
    "abstract": "Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field."
  },
  {
    "paperId": "81600fd653a828d69f6160705be6814dd101beb7",
    "title": "From local explanations to global understanding with explainable AI for trees",
    "venue": "Nature Machine Intelligence",
    "year": 2020,
    "citationCount": 6054,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7326367",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-019-0138-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-019-0138-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "23451726",
        "name": "Scott M. Lundberg"
      },
      {
        "authorId": "6579861",
        "name": "G. Erion"
      },
      {
        "authorId": "2616600",
        "name": "Hugh Chen"
      },
      {
        "authorId": "50731529",
        "name": "A. DeGrave"
      },
      {
        "authorId": "3869000",
        "name": "J. Prutkin"
      },
      {
        "authorId": "2447936",
        "name": "B. Nair"
      },
      {
        "authorId": "2740105",
        "name": "R. Katz"
      },
      {
        "authorId": "3538555",
        "name": "J. Himmelfarb"
      },
      {
        "authorId": "34451449",
        "name": "N. Bansal"
      },
      {
        "authorId": "2180463",
        "name": "Su-In Lee"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "22d6d9c1b7ac2738b51d93be45ac8f753f81867c",
    "title": "Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2013,
    "citationCount": 499,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPAMI.2012.277?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPAMI.2012.277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1797022",
        "name": "Hoo-Chang Shin"
      },
      {
        "authorId": "145945500",
        "name": "M. Orton"
      },
      {
        "authorId": "50070934",
        "name": "D. Collins"
      },
      {
        "authorId": "97784505",
        "name": "S. Doran"
      },
      {
        "authorId": "144544800",
        "name": "M. Leach"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d516daff247f7157fccde6649ace91d969cd1973",
    "title": "The mythos of model interpretability",
    "venue": "Queue",
    "year": 2016,
    "citationCount": 3996,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1606.03490",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.03490, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32219137",
        "name": "Zachary Chase Lipton"
      }
    ],
    "abstract": "In machine learning, the concept of interpretability is both important and slippery."
  },
  {
    "paperId": "08ad8fad21f6ec4cda4d56be1ca5e146b7c913a1",
    "title": "Understanding Black-box Predictions via Influence Functions",
    "venue": "International Conference on Machine Learning",
    "year": 2017,
    "citationCount": 3217,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.04730, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2572525",
        "name": "Pang Wei Koh"
      },
      {
        "authorId": "145419642",
        "name": "Percy Liang"
      }
    ],
    "abstract": "How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks."
  },
  {
    "paperId": "273dfbcb68080251f5e9ff38b4413d7bd84b10a1",
    "title": "LIBSVM: A library for support vector machines",
    "venue": "TIST",
    "year": 2011,
    "citationCount": 44419,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1961189.1961199?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1961189.1961199, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": null,
        "name": "Chih-Chung Chang"
      },
      {
        "authorId": "1711460",
        "name": "Chih-Jen Lin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f216444d4f2959b4520c61d20003fa30a199670a",
    "title": "Siamese Neural Networks for One-Shot Image Recognition",
    "venue": "",
    "year": 2015,
    "citationCount": 4504,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2054250597",
        "name": "Gregory R. Koch"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3a9b175324ba11bc0e16c0633912d897b2fac4e2",
    "title": "The Pascal Visual Object Classes (VOC) Challenge",
    "venue": "International Journal of Computer Vision",
    "year": 2010,
    "citationCount": 15498,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11263-009-0275-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11263-009-0275-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3056091",
        "name": "M. Everingham"
      },
      {
        "authorId": "1681236",
        "name": "L. Gool"
      },
      {
        "authorId": null,
        "name": "Christopher K. I. Williams"
      },
      {
        "authorId": "2248114177",
        "name": "J. Winn"
      },
      {
        "authorId": "2255783916",
        "name": "Andrew Zisserman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5cbe278b65a81602a864184bbca37de91448a5f5",
    "title": "Competition-level code generation with AlphaCode",
    "venue": "Science",
    "year": 2022,
    "citationCount": 1758,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2203.07814",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.07814, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47002813",
        "name": "Yujia Li"
      },
      {
        "authorId": "2114950020",
        "name": "David Choi"
      },
      {
        "authorId": "8270717",
        "name": "Junyoung Chung"
      },
      {
        "authorId": "1684887",
        "name": "Nate Kushman"
      },
      {
        "authorId": "4337102",
        "name": "Julian Schrittwieser"
      },
      {
        "authorId": "37212795",
        "name": "Rémi Leblond"
      },
      {
        "authorId": "2152472076",
        "name": "Tom"
      },
      {
        "authorId": "2152469120",
        "name": "Eccles"
      },
      {
        "authorId": "2058168486",
        "name": "James Keeling"
      },
      {
        "authorId": "49423009",
        "name": "Felix Gimeno"
      },
      {
        "authorId": "2152469362",
        "name": "A. D. Lago"
      },
      {
        "authorId": "2067208983",
        "name": "T. Hubert"
      },
      {
        "authorId": "2070068655",
        "name": "Peter Choy"
      },
      {
        "authorId": "2154435638",
        "name": "Cyprien de"
      },
      {
        "authorId": "2152471553",
        "name": "Masson d’Autume"
      },
      {
        "authorId": "2256699276",
        "name": "Igor Babuschkin"
      },
      {
        "authorId": "1425082935",
        "name": "Xinyun Chen"
      },
      {
        "authorId": "2421691",
        "name": "Po-Sen Huang"
      },
      {
        "authorId": "1851564",
        "name": "Johannes Welbl"
      },
      {
        "authorId": "2071666",
        "name": "Sven Gowal"
      },
      {
        "authorId": "2079024030",
        "name": "Alexey"
      },
      {
        "authorId": "152394142",
        "name": "Cherepanov"
      },
      {
        "authorId": "2065370007",
        "name": "James Molloy"
      },
      {
        "authorId": "3187297",
        "name": "D. Mankowitz"
      },
      {
        "authorId": "2152471960",
        "name": "Esme Sutherland Robson"
      },
      {
        "authorId": "143967473",
        "name": "Pushmeet Kohli"
      },
      {
        "authorId": "2152472162",
        "name": "Nando de"
      },
      {
        "authorId": "2152469135",
        "name": "Freitas"
      },
      {
        "authorId": "2645384",
        "name": "K. Kavukcuoglu"
      },
      {
        "authorId": "1689108",
        "name": "O. Vinyals"
      }
    ],
    "abstract": "Programming is a powerful and ubiquitous problem-solving tool. Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, such as competitive programming problems. Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3% in simulated evaluations on recent programming competitions on the Codeforces platform. AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then filtering and clustering those programs to a maximum of just 10 submissions. This result marks the first time an artificial intelligence system has performed competitively in programming competitions. Description Machine learning systems can program too Computer programming competitions are popular tests among programmers that require critical thinking informed by experience and creating solutions to unforeseen problems, both of which are key aspects of human intelligence but challenging to mimic by machine learning models. Using self-supervised learning and an encoder-decoder transformer architecture, Li et al. developed AlphaCode, a deep-learning model that can achieve approximately human-level performance on the Codeforces platform, which regularly hosts these competitions and attracts numerous participants worldwide (see the Perspective by Kolter). The development of such coding platforms could have a huge impact on programmers’ productivity. It may even change the culture of programming by shifting human work to formulating problems, with machine learning being the main one responsible for generating and executing codes. —YS Modern machine learning systems can achieve average human-level performance in popular competitive programming contests."
  },
  {
    "paperId": "8e0be569ea77b8cb29bb0e8b031887630fe7a96c",
    "title": "Random Forests",
    "venue": "Machine-mediated learning",
    "year": 2001,
    "citationCount": 107544,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1010933404324?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1010933404324, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2423230",
        "name": "L. Breiman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7e640729cca5a82c205bf95f346867097446838c",
    "title": "Statistical Comparisons of Classifiers over Multiple Data Sets",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 12413,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2701105",
        "name": "J. Demšar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ccf6a69a7f33bcf052aa7def176d3b9de495beb7",
    "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings",
    "venue": "Neural Information Processing Systems",
    "year": 2016,
    "citationCount": 3424,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1607.06520, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2843215",
        "name": "Tolga Bolukbasi"
      },
      {
        "authorId": "2782886",
        "name": "Kai-Wei Chang"
      },
      {
        "authorId": "145085305",
        "name": "James Y. Zou"
      },
      {
        "authorId": "1699322",
        "name": "Venkatesh Saligrama"
      },
      {
        "authorId": "2186481",
        "name": "A. Kalai"
      }
    ],
    "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias."
  },
  {
    "paperId": "cba71f24d5fd25ade9e60ef38df282aa91de5b80",
    "title": "Leveraging large language models for predictive chemistry",
    "venue": "Nature Machine Intelligence",
    "year": 2024,
    "citationCount": 280,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-023-00788-1.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s42256-023-00788-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s42256-023-00788-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "134251468",
        "name": "K. Jablonka"
      },
      {
        "authorId": "1379965853",
        "name": "P. Schwaller"
      },
      {
        "authorId": "1435535615",
        "name": "Andres Ortega‐Guerrero"
      },
      {
        "authorId": "2237936700",
        "name": "Berend Smit"
      }
    ],
    "abstract": "Machine learning has transformed many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine learning approaches that incorporate chemical knowledge for each application and, therefore, require specialized expertise to develop. Here we show that GPT-3, a large language model trained on vast amounts of text extracted from the Internet, can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning it to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine learning models for many applications spanning the properties of molecules and materials to the yield of chemical reactions. Surprisingly, our fine-tuned version of GPT-3 can perform comparably to or even outperform conventional machine learning techniques, in particular in the low-data limit. In addition, we can perform inverse design by simply inverting the questions. The ease of use and high performance, especially for small datasets, can impact the fundamental approach to using machine learning in the chemical and material sciences. In addition to a literature search, querying a pre-trained large language model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models, or to provide a baseline for predictive tasks. Machine learning techniques are widely employed in chemical science, but are application specific and their development requires dedicated expertise. Jablonka and colleagues fine-tune the GPT-3 model and show that it can provide surprisingly accurate answers to a wide range of chemical questions."
  },
  {
    "paperId": "3a84214cb69ea0b34352285029f368b75718c32b",
    "title": "Understanding of a convolutional neural network",
    "venue": "International Conference on Emerging Technologies",
    "year": 2017,
    "citationCount": 3168,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICENGTECHNOL.2017.8308186?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICENGTECHNOL.2017.8308186, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2338621460",
        "name": "Saad Albawi"
      },
      {
        "authorId": "37517325",
        "name": "T. A. Mohammed"
      },
      {
        "authorId": "1410550919",
        "name": "Saad Al-Zawi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "04b23f577c20d1a0e2a67aadda555f58e6d23d6e",
    "title": "Support vector machines",
    "venue": "Data Mining and Knowledge Discovery Handbook",
    "year": 2008,
    "citationCount": 7924,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/0-387-25465-X_12.pdf",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1002/wics.49?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wics.49, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1782193",
        "name": "Ingo Steinwart"
      },
      {
        "authorId": "2534678",
        "name": "A. Christmann"
      }
    ],
    "abstract": "Support vector machines (SVMs) are a family of machine learning methods, originally introduced for the problem of classification and later generalized to various other situations. They are based on principles of statistical learning theory and convex optimization, and are currently used in various domains of application, including bioinformatics, text categorization, and computer vision. Copyright © 2009 John Wiley & Sons, Inc."
  },
  {
    "paperId": "f46714d200d69eb9cb5cce176297b89a3f5e3a2c",
    "title": "An Introduction to Convolutional Neural Networks",
    "venue": "arXiv.org",
    "year": 2015,
    "citationCount": 3631,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1511.08458, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1399833554",
        "name": "K. O’Shea"
      },
      {
        "authorId": "2053923268",
        "name": "Ryan Nash"
      }
    ],
    "abstract": "The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. \nThis document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning."
  },
  {
    "paperId": "68c1bfe375dde46777fe1ac8f3636fb651e3f0f8",
    "title": "Experiments with a New Boosting Algorithm",
    "venue": "International Conference on Machine Learning",
    "year": 1996,
    "citationCount": 9720,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1703537",
        "name": "Y. Freund"
      },
      {
        "authorId": "1716301",
        "name": "R. Schapire"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e95d3934e51107da7610acd0b1bcb6551671f9f1",
    "title": "A Practical Guide to Training Restricted Boltzmann Machines",
    "venue": "Neural Networks",
    "year": 2012,
    "citationCount": 3155,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-35289-8_32?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-35289-8_32, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "24281c886cd9339fe2fc5881faf5ed72b731a03e",
    "title": "Spark: Cluster Computing with Working Sets",
    "venue": "USENIX Workshop on Hot Topics in Cloud Computing",
    "year": 2010,
    "citationCount": 4851,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "143834867",
        "name": "M. Zaharia"
      },
      {
        "authorId": "2350830387",
        "name": "Mosharaf Chowdhury"
      },
      {
        "authorId": "2251263604",
        "name": "Michael J. Franklin"
      },
      {
        "authorId": "143838343",
        "name": "S. Shenker"
      },
      {
        "authorId": "2326149473",
        "name": "Ion Stoica"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6af440915b8a0718c93be1cf61905e41e620484a",
    "title": "Deep One-Class Classification",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 2286,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "51127632",
        "name": "Lukas Ruff"
      },
      {
        "authorId": "2948486",
        "name": "Nico Görnitz"
      },
      {
        "authorId": "39503505",
        "name": "Lucas Deecke"
      },
      {
        "authorId": "29005173",
        "name": "Shoaib Ahmed Siddiqui"
      },
      {
        "authorId": "49004415",
        "name": "Robert A. Vandermeulen"
      },
      {
        "authorId": "49345823",
        "name": "Alexander Binder"
      },
      {
        "authorId": "2067608246",
        "name": "Emmanuel Müller"
      },
      {
        "authorId": "2749512",
        "name": "M. Kloft"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a456265138c088a894301c0433dae938705a9bec",
    "title": "Deep Sets",
    "venue": "",
    "year": 2017,
    "citationCount": 2675,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.06114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1771307",
        "name": "M. Zaheer"
      },
      {
        "authorId": "2150275",
        "name": "Satwik Kottur"
      },
      {
        "authorId": "2111187",
        "name": "Siamak Ravanbakhsh"
      },
      {
        "authorId": "1719347",
        "name": "B. Póczos"
      },
      {
        "authorId": "145124475",
        "name": "R. Salakhutdinov"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      }
    ],
    "abstract": "In this paper, we study the problem of designing objective functions for machine learning problems defined on finite \\emph{sets}. In contrast to traditional objective functions defined for machine learning problems operating on finite dimensional vectors, the new objective functions we propose are operating on finite sets and are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics \\citep{poczos13aistats}, via anomaly detection in piezometer data of embankment dams \\citep{Jung15Exploration}, to cosmology \\citep{Ntampaka16Dynamical,Ravanbakhsh16ICML1}. Our main theorem characterizes the permutation invariant objective functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and image tagging."
  },
  {
    "paperId": "10f919b1a5161b560504c225cfb2d1b3a4768f80",
    "title": "Artificial intelligence in healthcare: past, present and future",
    "venue": "Stroke and vascular neurology",
    "year": 2017,
    "citationCount": 3193,
    "openAccessPdf": {
      "url": "https://svn.bmj.com/content/svnbmj/2/4/230.full.pdf",
      "status": "GOLD",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5829945, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "67092021",
        "name": "F. Jiang"
      },
      {
        "authorId": "2117937034",
        "name": "Yong Jiang"
      },
      {
        "authorId": "1976425918",
        "name": "Hui Zhi"
      },
      {
        "authorId": "1974599",
        "name": "Yi Dong"
      },
      {
        "authorId": null,
        "name": "Hao Li"
      },
      {
        "authorId": "36156845",
        "name": "Sufeng Ma"
      },
      {
        "authorId": "119918227",
        "name": "Yilong Wang"
      },
      {
        "authorId": "47454309",
        "name": "Q. Dong"
      },
      {
        "authorId": "46829048",
        "name": "Haipeng Shen"
      },
      {
        "authorId": "2108094216",
        "name": "Yongjun Wang"
      }
    ],
    "abstract": "Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment of AI."
  },
  {
    "paperId": "7365f887c938ca21a6adbef08b5a520ebbd4638f",
    "title": "Model Cards for Model Reporting",
    "venue": "FAT",
    "year": 2018,
    "citationCount": 2187,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1810.03993",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.03993, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49501003",
        "name": "Margaret Mitchell"
      },
      {
        "authorId": "81120201",
        "name": "Simone Wu"
      },
      {
        "authorId": "2064225225",
        "name": "Andrew Zaldivar"
      },
      {
        "authorId": "80940648",
        "name": "Parker Barnes"
      },
      {
        "authorId": "145177877",
        "name": "Lucy Vasserman"
      },
      {
        "authorId": "2044655623",
        "name": "Ben Hutchinson"
      },
      {
        "authorId": "79542084",
        "name": "Elena Spitzer"
      },
      {
        "authorId": "81316798",
        "name": "Inioluwa Deborah Raji"
      },
      {
        "authorId": "2076288",
        "name": "Timnit Gebru"
      }
    ],
    "abstract": "Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation."
  },
  {
    "paperId": "6adf016e7531c91100d3cf4a74f5d4c87b26b528",
    "title": "Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks",
    "venue": "IEEE Symposium on Security and Privacy",
    "year": 2015,
    "citationCount": 3179,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1511.04508",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1511.04508, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367796356",
        "name": "Nicolas Papernot"
      },
      {
        "authorId": "144061974",
        "name": "P. Mcdaniel"
      },
      {
        "authorId": "37785191",
        "name": "Xi Wu"
      },
      {
        "authorId": "1680133",
        "name": "S. Jha"
      },
      {
        "authorId": "144231976",
        "name": "A. Swami"
      }
    ],
    "abstract": "Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content filters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 800% on one of the DNNs we tested."
  },
  {
    "paperId": "43d2ed5c3c55c1100450cd74dc1031afa24d37b2",
    "title": "Collective Classification in Network Data",
    "venue": "The AI Magazine",
    "year": 2008,
    "citationCount": 4312,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/aimagazine/article/download/2157/2022",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1201/b17320-16?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/b17320-16, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40655309",
        "name": "Prithviraj Sen"
      },
      {
        "authorId": "1686834",
        "name": "Galileo Namata"
      },
      {
        "authorId": "2696727",
        "name": "M. Bilgic"
      },
      {
        "authorId": "1746034",
        "name": "L. Getoor"
      },
      {
        "authorId": "153701431",
        "name": "Brian Gallagher"
      },
      {
        "authorId": "1397398770",
        "name": "Tina Eliassi-Rad"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0af75728bec67f698a8c619645165de13780c2fa",
    "title": "Learning Multiple Tasks with Kernel Methods",
    "venue": "Journal of machine learning research",
    "year": 2005,
    "citationCount": 984,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1801089",
        "name": "T. Evgeniou"
      },
      {
        "authorId": "1708279",
        "name": "C. Micchelli"
      },
      {
        "authorId": "1704699",
        "name": "M. Pontil"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7bb6bdf4ed609e5e72d4206d1b308323e73dceec",
    "title": "An Introduction to Genetic Algorithms.",
    "venue": "Artificial Life",
    "year": 1997,
    "citationCount": 9934,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1162/artl.1997.3.1.63?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/artl.1997.3.1.63, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1403108392",
        "name": "D. Heiss-Czedik"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "88816ae492956f3004daa41357166f1181c0c1bf",
    "title": "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation",
    "venue": "Neural Computation",
    "year": 2003,
    "citationCount": 8297,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1162/089976603321780317?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/089976603321780317, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145520115",
        "name": "M. Belkin"
      },
      {
        "authorId": "1770745",
        "name": "P. Niyogi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a883cacbc8f9b021b2a63f0453307855fa075d33",
    "title": "The relationship between Precision-Recall and ROC curves",
    "venue": "International Conference on Machine Learning",
    "year": 2006,
    "citationCount": 6274,
    "openAccessPdf": {
      "url": "https://lirias.kuleuven.be/bitstream/123456789/295592/1/davisgoadrichcamera2.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1143844.1143874?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1143844.1143874, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152658362",
        "name": "Jesse Davis"
      },
      {
        "authorId": "2853980",
        "name": "Mark H. Goadrich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0b2a2ed870d9e947aca41daf751d987ab3163d74",
    "title": "Introduction to Statistical Pattern Recognition",
    "venue": "",
    "year": 2006,
    "citationCount": 4547,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/0470854774.ch1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/0470854774.ch1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1701197",
        "name": "P. Pudil"
      },
      {
        "authorId": "3176394",
        "name": "P. Somol"
      },
      {
        "authorId": "1765024",
        "name": "M. Haindl"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7",
    "title": "Random Features for Large-Scale Kernel Machines",
    "venue": "Neural Information Processing Systems",
    "year": 2007,
    "citationCount": 4531,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "31558848",
        "name": "A. Rahimi"
      },
      {
        "authorId": "9229182",
        "name": "B. Recht"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5a05b9d5de7d1d11d1aa03826ded577d4acf4f49",
    "title": "Genetic Algorithms + Data Structures = Evolution Programs",
    "venue": "Springer Berlin Heidelberg",
    "year": 1996,
    "citationCount": 12824,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-662-03315-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-662-03315-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1728743",
        "name": "Z. Michalewicz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d1b9a3b11e6c9571a1553556f82b605b2b4baec3",
    "title": "Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures",
    "venue": "Conference on Computer and Communications Security",
    "year": 2015,
    "citationCount": 3014,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/2810103.2813677",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2810103.2813677?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2810103.2813677, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2623167",
        "name": "Matt Fredrikson"
      },
      {
        "authorId": "1680133",
        "name": "S. Jha"
      },
      {
        "authorId": "1707461",
        "name": "Thomas Ristenpart"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a1874aafa8730bdd4b28f29d025141c13ee28b58",
    "title": "From Data Mining to Knowledge Discovery in Databases",
    "venue": "The AI Magazine",
    "year": 1996,
    "citationCount": 5573,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aimag.v17i3.1230?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aimag.v17i3.1230, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1695784",
        "name": "U. Fayyad"
      },
      {
        "authorId": "1398381803",
        "name": "G. Piatetsky-Shapiro"
      },
      {
        "authorId": "50860274",
        "name": "Padhraic Smyth"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d",
    "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2004,
    "citationCount": 4126,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.3115/1218955.1218990",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/cs/0409058, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144865353",
        "name": "B. Pang"
      },
      {
        "authorId": "145810617",
        "name": "Lillian Lee"
      }
    ],
    "abstract": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as \"thumbs up\" or \"thumbs down\". To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints."
  },
  {
    "paperId": "6b570069f14c7588e066f7138e1f21af59d62e61",
    "title": "Theano: A Python framework for fast computation of mathematical expressions",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 2364,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1605.02688, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1388360943",
        "name": "Rami Al-Rfou"
      },
      {
        "authorId": "1815021",
        "name": "Guillaume Alain"
      },
      {
        "authorId": "2634674",
        "name": "Amjad Almahairi"
      },
      {
        "authorId": "2065022368",
        "name": "Christof Angermüller"
      },
      {
        "authorId": "3335364",
        "name": "Dzmitry Bahdanau"
      },
      {
        "authorId": "2482072",
        "name": "Nicolas Ballas"
      },
      {
        "authorId": "3227028",
        "name": "Frédéric Bastien"
      },
      {
        "authorId": "145040409",
        "name": "Justin Bayer"
      },
      {
        "authorId": "144336979",
        "name": "A. Belikov"
      },
      {
        "authorId": "31984932",
        "name": "A. Belopolsky"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      },
      {
        "authorId": "47944877",
        "name": "Arnaud Bergeron"
      },
      {
        "authorId": "32837403",
        "name": "J. Bergstra"
      },
      {
        "authorId": "115295647",
        "name": "Valentin Bisson"
      },
      {
        "authorId": "32308836",
        "name": "Josh Bleecher Snyder"
      },
      {
        "authorId": "2065828537",
        "name": "Nicolas Bouchard"
      },
      {
        "authorId": "1395619597",
        "name": "Nicolas Boulanger-Lewandowski"
      },
      {
        "authorId": "2900675",
        "name": "Xavier Bouthillier"
      },
      {
        "authorId": "2346028",
        "name": "A. D. Brébisson"
      },
      {
        "authorId": "1967465",
        "name": "Olivier Breuleux"
      },
      {
        "authorId": "153921980",
        "name": "P. Carrier"
      },
      {
        "authorId": "1979489",
        "name": "Kyunghyun Cho"
      },
      {
        "authorId": "2292403",
        "name": "J. Chorowski"
      },
      {
        "authorId": "145791315",
        "name": "P. Christiano"
      },
      {
        "authorId": "2348758",
        "name": "Tim Cooijmans"
      },
      {
        "authorId": "40638665",
        "name": "Marc-Alexandre Côté"
      },
      {
        "authorId": "39977229",
        "name": "Myriam Côté"
      },
      {
        "authorId": "1760871",
        "name": "Aaron C. Courville"
      },
      {
        "authorId": "2921469",
        "name": "Yann Dauphin"
      },
      {
        "authorId": "2460212",
        "name": "Olivier Delalleau"
      },
      {
        "authorId": "32604218",
        "name": "Julien Demouth"
      },
      {
        "authorId": "2755582",
        "name": "Guillaume Desjardins"
      },
      {
        "authorId": "48373216",
        "name": "S. Dieleman"
      },
      {
        "authorId": "46573521",
        "name": "Laurent Dinh"
      },
      {
        "authorId": "2812151",
        "name": "Mélanie Ducoffe"
      },
      {
        "authorId": "3074927",
        "name": "Vincent Dumoulin"
      },
      {
        "authorId": "3127597",
        "name": "Samira Ebrahimi Kahou"
      },
      {
        "authorId": "1761978",
        "name": "D. Erhan"
      },
      {
        "authorId": "2113846121",
        "name": "Ziye Fan"
      },
      {
        "authorId": "2345617",
        "name": "Orhan Firat"
      },
      {
        "authorId": "39844381",
        "name": "M. Germain"
      },
      {
        "authorId": "3119801",
        "name": "Xavier Glorot"
      },
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "152130795",
        "name": "M. Graham"
      },
      {
        "authorId": "1854385",
        "name": "Çaglar Gülçehre"
      },
      {
        "authorId": "144563741",
        "name": "P. Hamel"
      },
      {
        "authorId": "1405640115",
        "name": "Iban Harlouchet"
      },
      {
        "authorId": "114956664",
        "name": "J. Heng"
      },
      {
        "authorId": "2507883",
        "name": "Balázs Hidasi"
      },
      {
        "authorId": "25056820",
        "name": "S. Honari"
      },
      {
        "authorId": "49147969",
        "name": "Arjun Jain"
      },
      {
        "authorId": "152857609",
        "name": "Sébastien Jean"
      },
      {
        "authorId": "49104216",
        "name": "Kai Jia"
      },
      {
        "authorId": "2065766621",
        "name": "Mikhail Korobov"
      },
      {
        "authorId": "144592382",
        "name": "Vivek Kulkarni"
      },
      {
        "authorId": "49071560",
        "name": "Alex Lamb"
      },
      {
        "authorId": "3087941",
        "name": "Pascal Lamblin"
      },
      {
        "authorId": "2065712703",
        "name": "Eric Larsen"
      },
      {
        "authorId": "40201308",
        "name": "César Laurent"
      },
      {
        "authorId": "98258814",
        "name": "S. Lee"
      },
      {
        "authorId": "118224452",
        "name": "S. Lefrançois"
      },
      {
        "authorId": "2066378869",
        "name": "S. Lemieux"
      },
      {
        "authorId": "2065623360",
        "name": "Nicholas Léonard"
      },
      {
        "authorId": "3146592",
        "name": "Zhouhan Lin"
      },
      {
        "authorId": "3245814",
        "name": "J. Livezey"
      },
      {
        "authorId": "40532172",
        "name": "C. Lorenz"
      },
      {
        "authorId": "102472217",
        "name": "J. Lowin"
      },
      {
        "authorId": "2087919644",
        "name": "Qianli Ma"
      },
      {
        "authorId": "1798462",
        "name": "Pierre-Antoine Manzagol"
      },
      {
        "authorId": "3422889",
        "name": "Olivier Mastropietro"
      },
      {
        "authorId": "144431879",
        "name": "R. McGibbon"
      },
      {
        "authorId": "1710604",
        "name": "R. Memisevic"
      },
      {
        "authorId": "3158246",
        "name": "B. V. Merrienboer"
      },
      {
        "authorId": "1748421",
        "name": "Vincent Michalski"
      },
      {
        "authorId": "153583218",
        "name": "Mehdi Mirza"
      },
      {
        "authorId": "40479190",
        "name": "A. Orlandi"
      },
      {
        "authorId": "1972076",
        "name": "C. Pal"
      },
      {
        "authorId": "1996134",
        "name": "Razvan Pascanu"
      },
      {
        "authorId": "145507036",
        "name": "M. Pezeshki"
      },
      {
        "authorId": "2402716",
        "name": "Colin Raffel"
      },
      {
        "authorId": "49577546",
        "name": "D. Renshaw"
      },
      {
        "authorId": "3146111",
        "name": "M. Rocklin"
      },
      {
        "authorId": "144290131",
        "name": "Adriana Romero"
      },
      {
        "authorId": "2059592992",
        "name": "Markus Roth"
      },
      {
        "authorId": "47696458",
        "name": "Peter Sadowski"
      },
      {
        "authorId": "3373139",
        "name": "J. Salvatier"
      },
      {
        "authorId": "47918629",
        "name": "François Savard"
      },
      {
        "authorId": "50764319",
        "name": "Jan Schlüter"
      },
      {
        "authorId": "47971768",
        "name": "John Schulman"
      },
      {
        "authorId": "40116153",
        "name": "Gabriel Schwartz"
      },
      {
        "authorId": "35224828",
        "name": "Iulian Serban"
      },
      {
        "authorId": "1862138",
        "name": "Dmitriy Serdyuk"
      },
      {
        "authorId": "3197429",
        "name": "S. Shabanian"
      },
      {
        "authorId": "2060864166",
        "name": "Étienne Simon"
      },
      {
        "authorId": "11115628",
        "name": "Sigurd Spieckermann"
      },
      {
        "authorId": "82487166",
        "name": "S. Subramanyam"
      },
      {
        "authorId": "3407592",
        "name": "Jakub Sygnowski"
      },
      {
        "authorId": "66454233",
        "name": "Jérémie Tanguay"
      },
      {
        "authorId": "51256193",
        "name": "Gijs van Tulder"
      },
      {
        "authorId": "153160559",
        "name": "Joseph P. Turian"
      },
      {
        "authorId": "19555508",
        "name": "S. Urban"
      },
      {
        "authorId": "120247189",
        "name": "Pascal Vincent"
      },
      {
        "authorId": "2077146",
        "name": "Francesco Visin"
      },
      {
        "authorId": "153559313",
        "name": "H. D. Vries"
      },
      {
        "authorId": "1393680089",
        "name": "David Warde-Farley"
      },
      {
        "authorId": "27358391",
        "name": "Dustin J. Webb"
      },
      {
        "authorId": "117876053",
        "name": "M. Willson"
      },
      {
        "authorId": "36303818",
        "name": "Kelvin Xu"
      },
      {
        "authorId": "2954189",
        "name": "Lijun Xue"
      },
      {
        "authorId": "2106357903",
        "name": "Li Yao"
      },
      {
        "authorId": "35097114",
        "name": "Saizheng Zhang"
      },
      {
        "authorId": "2153392903",
        "name": "Ying Zhang"
      }
    ],
    "abstract": "Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. \nThe present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it."
  },
  {
    "paperId": "892f9a2f69241feec647856cd26bed37e04fd747",
    "title": "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 2547,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.06560, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2108744219",
        "name": "Lisha Li"
      },
      {
        "authorId": "40566417",
        "name": "Kevin G. Jamieson"
      },
      {
        "authorId": "3186812",
        "name": "Giulia DeSalvo"
      },
      {
        "authorId": "2435268",
        "name": "Afshin Rostamizadeh"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      }
    ],
    "abstract": "Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems."
  },
  {
    "paperId": "98c25683fc8d6446448b734b1bcf08e1457f8d85",
    "title": "A review of feature selection techniques in bioinformatics",
    "venue": "Bioinform.",
    "year": 2007,
    "citationCount": 4267,
    "openAccessPdf": {
      "url": "https://oa.upm.es/73113/1/LARRANAGA_2007_05.pdf",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1093/bioinformatics/btm344?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/bioinformatics/btm344, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2247520360",
        "name": "Yvan Saeys"
      },
      {
        "authorId": "1788277",
        "name": "Iñaki Inza"
      },
      {
        "authorId": "2285903189",
        "name": "Pedro Larrañaga"
      }
    ],
    "abstract": "Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques. In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications."
  },
  {
    "paperId": "08b43d84e6747e370ef307e2ada50675b414514a",
    "title": "Survey of clustering algorithms",
    "venue": "IEEE Transactions on Neural Networks",
    "year": 2005,
    "citationCount": 6388,
    "openAccessPdf": {
      "url": "http://axon.cs.byu.edu/Dan/678/papers/Cluster/Xu.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNN.2005.845141?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNN.2005.845141, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144996246",
        "name": "Rui Xu"
      },
      {
        "authorId": "145033828",
        "name": "D. Wunsch"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c6d971aa7630ef28f79fc57351e5abac0b8e2ddd",
    "title": "Support vector machines",
    "venue": "",
    "year": 1998,
    "citationCount": 4256,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/5254.708428?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/5254.708428, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1716902",
        "name": "Marti A. Hearst"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a34e35dbbc6911fa7b94894dffdc0076a261b6f0",
    "title": "Neural Networks and the Bias/Variance Dilemma",
    "venue": "Neural Computation",
    "year": 1992,
    "citationCount": 3941,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1162/neco.1992.4.1.1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/neco.1992.4.1.1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3194361",
        "name": "S. Geman"
      },
      {
        "authorId": "2246319",
        "name": "E. Bienenstock"
      },
      {
        "authorId": "2330895",
        "name": "R. Doursat"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e86f71ca2948d17b003a5f068db1ecb2b77827f7",
    "title": "Concrete Problems in AI Safety",
    "venue": "arXiv.org",
    "year": 2016,
    "citationCount": 2668,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.06565, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2698777",
        "name": "Dario Amodei"
      },
      {
        "authorId": "2287268442",
        "name": "Chris Olah"
      },
      {
        "authorId": "5164568",
        "name": "J. Steinhardt"
      },
      {
        "authorId": "145791315",
        "name": "P. Christiano"
      },
      {
        "authorId": "47971768",
        "name": "John Schulman"
      },
      {
        "authorId": "30415265",
        "name": "Dandelion Mané"
      }
    ],
    "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI."
  },
  {
    "paperId": "e4a85af3f5dc41e13dc2cae9ee851953709b764e",
    "title": "Solving the quantum many-body problem with artificial neural networks",
    "venue": "Science",
    "year": 2016,
    "citationCount": 2103,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1606.02318",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.02318, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50666189",
        "name": "Giuseppe Carleo"
      },
      {
        "authorId": "1752096",
        "name": "M. Troyer"
      }
    ],
    "abstract": "Machine learning and quantum physics Elucidating the behavior of quantum interacting systems of many particles remains one of the biggest challenges in physics. Traditional numerical methods often work well, but some of the most interesting problems leave them stumped. Carleo and Troyer harnessed the power of machine learning to develop a variational approach to the quantum many-body problem (see the Perspective by Hush). The method performed at least as well as state-of-the-art approaches, setting a benchmark for a prototypical two-dimensional problem. With further development, it may well prove a valuable piece in the quantum toolbox. Science, this issue p. 602; see also p. 580 A machine-learning approach sets a computational benchmark for a prototypical two-dimensional problem. The challenge posed by the many-body problem in quantum physics originates from the difficulty of describing the nontrivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine learning of the wave function can reduce this complexity to a tractable computational form for some notable cases of physical interest. We introduce a variational representation of quantum states based on artificial neural networks with a variable number of hidden neurons. A reinforcement-learning scheme we demonstrate is capable of both finding the ground state and describing the unitary time evolution of complex interacting quantum systems. Our approach achieves high accuracy in describing prototypical interacting spins models in one and two dimensions."
  },
  {
    "paperId": "993d736b0174abf2f713bea9d9642b85a2313cae",
    "title": "Estimating Attributes: Analysis and Extensions of RELIEF",
    "venue": "European Conference on Machine Learning",
    "year": 1994,
    "citationCount": 3251,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2F3-540-57868-4_57.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-57868-4_57?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-57868-4_57, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143986204",
        "name": "I. Kononenko"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
    "title": "Sequence Transduction with Recurrent Neural Networks",
    "venue": "arXiv.org",
    "year": 2012,
    "citationCount": 1999,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1211.3711, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1753223",
        "name": "Alex Graves"
      }
    ],
    "abstract": "Many machine learning tasks can be expressed as the transformation---or \\emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \\emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus."
  },
  {
    "paperId": "bb144c04b9eb44579b19d21c3d5954401408440b",
    "title": "Orange: data mining toolbox in python",
    "venue": "Journal of machine learning research",
    "year": 2013,
    "citationCount": 1988,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/2567709.2567736?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/2567709.2567736, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2701105",
        "name": "J. Demšar"
      },
      {
        "authorId": "1772593",
        "name": "Tomaž Curk"
      },
      {
        "authorId": "48828579",
        "name": "Ales Erjavec"
      },
      {
        "authorId": "88256002",
        "name": "C. Gorup"
      },
      {
        "authorId": "2820151",
        "name": "Tomaž Hočevar"
      },
      {
        "authorId": "40337361",
        "name": "Mitar Milutinovic"
      },
      {
        "authorId": "145703442",
        "name": "M. Mozina"
      },
      {
        "authorId": "2448692",
        "name": "M. Polajnar"
      },
      {
        "authorId": "3110092",
        "name": "Marko Toplak"
      },
      {
        "authorId": "1851562",
        "name": "A. Staric"
      },
      {
        "authorId": "2789798",
        "name": "Miha Štajdohar"
      },
      {
        "authorId": "2256143",
        "name": "Lan Umek"
      },
      {
        "authorId": "2761087",
        "name": "Lan Zagar"
      },
      {
        "authorId": "3105120",
        "name": "Jure Zbontar"
      },
      {
        "authorId": "2095762",
        "name": "M. Zitnik"
      },
      {
        "authorId": "1775384",
        "name": "B. Zupan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d079a2f877f554e00f71a6975435d8325987bdf5",
    "title": "Return of Frustratingly Easy Domain Adaptation",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2015,
    "citationCount": 1940,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/10306/10165",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1511.05547, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2636783",
        "name": "Baochen Sun"
      },
      {
        "authorId": "33221685",
        "name": "Jiashi Feng"
      },
      {
        "authorId": "2903226",
        "name": "Kate Saenko"
      }
    ],
    "abstract": "\n \n Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data have labels, including some that perform very well despite being ``frustratingly easy'' to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efficient method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. Even though it is extraordinarily simple--it can be implemented in four lines of Matlab code--CORAL performs remarkably well in extensive evaluations on standard benchmark datasets.\n \n"
  },
  {
    "paperId": "41fef1a197fab9684a4608b725d3ae72e1ab4b39",
    "title": "Sparse Feature Learning for Deep Belief Networks",
    "venue": "Neural Information Processing Systems",
    "year": 2007,
    "citationCount": 937,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1706809",
        "name": "Marc'Aurelio Ranzato"
      },
      {
        "authorId": "90841478",
        "name": "Y-Lan Boureau"
      },
      {
        "authorId": "1688882",
        "name": "Yann LeCun"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "eec471897375942fd690b736c2753bb19d907273",
    "title": "Gradient boosting machines, a tutorial",
    "venue": "Front. Neurorobot.",
    "year": 2013,
    "citationCount": 3002,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2013.00021/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3885826, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2551434",
        "name": "Alexey Natekin"
      },
      {
        "authorId": "143873832",
        "name": "A. Knoll"
      }
    ],
    "abstract": "Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions. This article gives a tutorial introduction into the methodology of gradient boosting methods with a strong focus on machine learning aspects of modeling. A theoretical information is complemented with descriptive examples and illustrations which cover all the stages of the gradient boosting model design. Considerations on handling the model complexity are discussed. Three practical examples of gradient boosting applications are presented and comprehensively analyzed."
  },
  {
    "paperId": "0407b605b8f55db72e2545586bfe8e946b691b70",
    "title": "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
    "venue": "International Conference on Learning Representations",
    "year": 2013,
    "citationCount": 1557,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1312.6211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153440022",
        "name": "I. Goodfellow"
      },
      {
        "authorId": "153583218",
        "name": "Mehdi Mirza"
      },
      {
        "authorId": "2058614620",
        "name": "Xia Da"
      },
      {
        "authorId": "1760871",
        "name": "Aaron C. Courville"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated."
  },
  {
    "paperId": "47c528344fedb6cb67a38e43d095b41c34715330",
    "title": "Adaptive Federated Optimization",
    "venue": "International Conference on Learning Representations",
    "year": 2020,
    "citationCount": 1690,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.00295, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1981186",
        "name": "Sashank J. Reddi"
      },
      {
        "authorId": "143676545",
        "name": "Zachary B. Charles"
      },
      {
        "authorId": "1771307",
        "name": "M. Zaheer"
      },
      {
        "authorId": "40449749",
        "name": "Zachary Garrett"
      },
      {
        "authorId": "1387453057",
        "name": "Keith Rush"
      },
      {
        "authorId": "32139366",
        "name": "Jakub Konecný"
      },
      {
        "authorId": "152663162",
        "name": "Sanjiv Kumar"
      },
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      }
    ],
    "abstract": "Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Due to the heterogeneity of the client datasets, standard federated optimization methods such as Federated Averaging (FedAvg) are often difficult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including Adagrad, Adam, and Yogi, and analyze their convergence in the presence of heterogeneous data for general nonconvex settings. Our results highlight the interplay between client heterogeneity and communication efficiency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can significantly improve the performance of federated learning."
  },
  {
    "paperId": "41bebd1951e57588e7829e44fab1bac0cc9251d2",
    "title": "Torchvision the machine-vision package of torch",
    "venue": "ACM Multimedia",
    "year": 2010,
    "citationCount": 565,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1873951.1874254?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1873951.1874254, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145607451",
        "name": "S. Marcel"
      },
      {
        "authorId": "145835170",
        "name": "Yann Rodriguez"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ebfa3fb595ca0299ab5249c69374c98b74bb62b3",
    "title": "A Tutorial on the Cross-Entropy Method",
    "venue": "Annals of Operations Research",
    "year": 2005,
    "citationCount": 3000,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/S10479-005-5724-Z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/S10479-005-5724-Z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34932490",
        "name": "P. Boer"
      },
      {
        "authorId": "1704242",
        "name": "Dirk P. Kroese"
      },
      {
        "authorId": "1712535",
        "name": "Shie Mannor"
      },
      {
        "authorId": "35064932",
        "name": "R. Rubinstein"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "043f084e379a44608c470059c2aa174a323e9774",
    "title": "Counterfactual Fairness",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 1717,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1703.06856, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1940272",
        "name": "Matt J. Kusner"
      },
      {
        "authorId": "48678411",
        "name": "Joshua R. Loftus"
      },
      {
        "authorId": "2052380526",
        "name": "Chris Russell"
      },
      {
        "authorId": "2187716",
        "name": "Ricardo Silva"
      }
    ],
    "abstract": "Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school."
  },
  {
    "paperId": "e0cf9c51192f63c3a9e3b23aa07ee5654fc97b68",
    "title": "Large Margin Methods for Structured and Interdependent Output Variables",
    "venue": "Journal of machine learning research",
    "year": 2005,
    "citationCount": 2323,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1765700",
        "name": "Ioannis Tsochantaridis"
      },
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      },
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      },
      {
        "authorId": "1783941",
        "name": "Y. Altun"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "c80d112ce59c72f943dc7b3e56e4c77dc3af1146",
    "title": "CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy",
    "venue": "International Conference on Machine Learning",
    "year": 2016,
    "citationCount": 1773,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3429011",
        "name": "Nathan Dowlin"
      },
      {
        "authorId": "1388775848",
        "name": "Ran Gilad-Bachrach"
      },
      {
        "authorId": "39763956",
        "name": "Kim Laine"
      },
      {
        "authorId": "2679550",
        "name": "K. Lauter"
      },
      {
        "authorId": "1813607",
        "name": "M. Naehrig"
      },
      {
        "authorId": "2372116",
        "name": "J. Wernsing"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "38d8230a7aeae6554497b253848ad5bf677e4fb3",
    "title": "PennyLane: Automatic differentiation of hybrid quantum-classical computations",
    "venue": "arXiv.org",
    "year": 2018,
    "citationCount": 1276,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3201137",
        "name": "V. Bergholm"
      },
      {
        "authorId": "2070140",
        "name": "J. Izaac"
      },
      {
        "authorId": "3048564",
        "name": "M. Schuld"
      },
      {
        "authorId": "3348073",
        "name": "C. Gogolin"
      },
      {
        "authorId": "2059757810",
        "name": "Ankit Khandelwal"
      },
      {
        "authorId": "3399181",
        "name": "N. Killoran"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2be40f5336afa68b49fef41e009b7172c2c9fdeb",
    "title": "POT: Python Optimal Transport",
    "venue": "Journal of machine learning research",
    "year": 2021,
    "citationCount": 918,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145258331",
        "name": "Rémi Flamary"
      },
      {
        "authorId": "145374281",
        "name": "N. Courty"
      },
      {
        "authorId": "1797840",
        "name": "Alexandre Gramfort"
      },
      {
        "authorId": "2454785",
        "name": "Mokhtar Z. Alaya"
      },
      {
        "authorId": "2563078",
        "name": "Aurélie Boisbunon"
      },
      {
        "authorId": "31838855",
        "name": "Stanislas Chambon"
      },
      {
        "authorId": "2047549155",
        "name": "Adrien Corenflos"
      },
      {
        "authorId": "2254311303",
        "name": "Nemo Fournier"
      },
      {
        "authorId": "144808881",
        "name": "N. Gayraud"
      },
      {
        "authorId": "41155854",
        "name": "H. Janati"
      },
      {
        "authorId": "145898069",
        "name": "I. Redko"
      },
      {
        "authorId": "3437110",
        "name": "Antoine Rolet"
      },
      {
        "authorId": "33555382",
        "name": "A. Schutz"
      },
      {
        "authorId": "36326783",
        "name": "Danica J. Sutherland"
      },
      {
        "authorId": "2576923",
        "name": "R. Tavenard"
      },
      {
        "authorId": "1505823696",
        "name": "Alexander Tong"
      },
      {
        "authorId": "46193733",
        "name": "Titouan Vayer"
      },
      {
        "authorId": "2086994888",
        "name": "A. Mueller"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2c9022fe0af15568a885e59d475ec8f95726e51b",
    "title": "Metrics for Multi-Class Classification: an Overview",
    "venue": "arXiv.org",
    "year": 2020,
    "citationCount": 1094,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2008.05756, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "114313889",
        "name": "Margherita Grandini"
      },
      {
        "authorId": "2064595648",
        "name": "Enrico Bagli"
      },
      {
        "authorId": "1491293345",
        "name": "Giorgio Visani"
      }
    ],
    "abstract": "Classification tasks in machine learning involving more than two classes are known by the name of \"multi-class classification\". Performance indicators are very useful when the aim is to evaluate and compare different classification models or machine learning techniques. Many metrics come in handy to test the ability of a multi-class classifier. Those metrics turn out to be useful at different stage of the development process, e.g. comparing the performance of two different models or analysing the behaviour of the same model by tuning different parameters. In this white paper we review a list of the most promising multi-class metrics, we highlight their advantages and disadvantages and show their possible usages during the development of a classification model."
  },
  {
    "paperId": "7f57e9939560562727344c1c987416285ef76cda",
    "title": "Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition",
    "venue": "Conference on Computer and Communications Security",
    "year": 2016,
    "citationCount": 1702,
    "openAccessPdf": {
      "url": "http://dl.acm.org/ft_gateway.cfm?id=2978392&type=pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2976749.2978392?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2976749.2978392, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "36301492",
        "name": "Mahmood Sharif"
      },
      {
        "authorId": "38181360",
        "name": "Sruti Bhagavatula"
      },
      {
        "authorId": "41224057",
        "name": "Lujo Bauer"
      },
      {
        "authorId": "1746214",
        "name": "M. Reiter"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6d5965a76f88a8ebab4fc9c43a3ae2630628966a",
    "title": "Learning and evaluating classifiers under sample selection bias",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 910,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015425?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015425, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1735228",
        "name": "B. Zadrozny"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "52e2bd533323ddf97073d034bae40a46eda55f34",
    "title": "Twitter Sentiment Classiﬁcation using Distant Supervision",
    "venue": "",
    "year": 2009,
    "citationCount": 2704,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2072476634",
        "name": "Alec Go"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b8d7788f25dfaf0f9fe2e6c441d75ca7cd3bc09a",
    "title": "Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution",
    "venue": "International Conference on Machine Learning",
    "year": 2003,
    "citationCount": 2735,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "143676604",
        "name": "Lei Yu"
      },
      {
        "authorId": "2146397025",
        "name": "Huan Liu"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "609e5cc1da126d7f760d1444b43b4fae41602841",
    "title": "Less is More: Active Learning with Support Vector Machines",
    "venue": "International Conference on Machine Learning",
    "year": 2000,
    "citationCount": 977,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1761866",
        "name": "Greg Schohn"
      },
      {
        "authorId": "50742419",
        "name": "David A. Cohn"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b57c54350769ffa59ff57f79ee5aad918844d298",
    "title": "Differentially Private Empirical Risk Minimization",
    "venue": "Journal of machine learning research",
    "year": 2009,
    "citationCount": 1536,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/0912.0071, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "38120884",
        "name": "Kamalika Chaudhuri"
      },
      {
        "authorId": "1806678",
        "name": "C. Monteleoni"
      },
      {
        "authorId": "9208982",
        "name": "A. Sarwate"
      }
    ],
    "abstract": "Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or financial records, are analyzed. We provide general techniques to produce privacy-preserving approximations of classifiers learned via (regularized) empirical risk minimization (ERM). These algorithms are private under the ε-differential privacy definition due to Dwork et al. (2006). First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classification. Then we propose a new method, objective perturbation, for privacy-preserving machine learning algorithm design. This method entails perturbing the objective function before optimizing over classifiers. If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels. We further present a privacy-preserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines. We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets. Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance."
  },
  {
    "paperId": "602f31242e577d2d05f918a3080fd50095e7faed",
    "title": "Factors in automatic musical genre classification of audio signals",
    "venue": "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics",
    "year": 2003,
    "citationCount": 2299,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ASPAA.2003.1285840?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ASPAA.2003.1285840, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2286187694",
        "name": "Tao Li"
      },
      {
        "authorId": "1693065",
        "name": "G. Tzanetakis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "83040001210751239553269727b9ea53e152af71",
    "title": "Building Machines that Learn and Think Like People",
    "venue": "Adaptive Agents and Multi-Agent Systems",
    "year": 2018,
    "citationCount": 1918,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1763295",
        "name": "J. Tenenbaum"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7333e127b62eb545d81830df2a66b98c0693a32b",
    "title": "Quantile Regression Forests",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 1813,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1941834",
        "name": "N. Meinshausen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "44e915a220ce74badf755aae870fa0b69ee2b82a",
    "title": "Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval",
    "venue": "European Conference on Machine Learning",
    "year": 1998,
    "citationCount": 2448,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007%2FBFb0026666.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BFb0026666?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BFb0026666, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35153517",
        "name": "D. Lewis"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5e095981ebf4d389e9356bd56e59e0ade1b42e88",
    "title": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text",
    "venue": "J. Am. Medical Informatics Assoc.",
    "year": 2011,
    "citationCount": 1252,
    "openAccessPdf": {
      "url": "https://academic.oup.com/jamia/article-pdf/18/5/552/33015279/18-5-552.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1136/amiajnl-2011-000203?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/amiajnl-2011-000203, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1723337",
        "name": "Özlem Uzuner"
      },
      {
        "authorId": "10208174",
        "name": "B. South"
      },
      {
        "authorId": "1807069",
        "name": "Shuying Shen"
      },
      {
        "authorId": "1807331",
        "name": "S. Duvall"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ba10b8f9ee40b68053af9e6c2383aa2c6e39e9be",
    "title": "Text Classification Algorithms: A Survey",
    "venue": "Inf.",
    "year": 2019,
    "citationCount": 1388,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2078-2489/10/4/150/pdf?version=1556181437",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1904.08067, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2060243",
        "name": "Kamran Kowsari"
      },
      {
        "authorId": "26417934",
        "name": "K. Meimandi"
      },
      {
        "authorId": "26408890",
        "name": "Mojtaba Heidarysafa"
      },
      {
        "authorId": "51266150",
        "name": "Sanjana Mendu"
      },
      {
        "authorId": "1771388",
        "name": "Laura E. Barnes"
      },
      {
        "authorId": "2115530197",
        "name": "Donald E. Brown"
      }
    ],
    "abstract": "In recent years, there has been an exponential growth in the number of complex documentsand texts that require a deeper understanding of machine learning methods to be able to accuratelyclassify texts in many applications. Many machine learning approaches have achieved surpassingresults in natural language processing. The success of these learning algorithms relies on their capacityto understand complex models and non-linear relationships within data. However, finding suitablestructures, architectures, and techniques for text classification is a challenge for researchers. In thispaper, a brief overview of text classification algorithms is discussed. This overview covers differenttext feature extractions, dimensionality reduction methods, existing algorithms and techniques, andevaluations methods. Finally, the limitations of each technique and their application in real-worldproblems are discussed."
  },
  {
    "paperId": "f7d997a640f2b804676cadb8030d8b2c7bd79d85",
    "title": "On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 2114,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1756006.1859921?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1756006.1859921, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8974886",
        "name": "G. Cawley"
      },
      {
        "authorId": "28280741",
        "name": "N. L. C. Talbot"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ade03d0c772c35dc8e865bdb41d7bc54d5b782d1",
    "title": "kernlab - An S4 Package for Kernel Methods in R",
    "venue": "",
    "year": 2004,
    "citationCount": 1942,
    "openAccessPdf": {
      "url": "https://doi.org/10.18637/jss.v011.i09",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.18637/JSS.V011.I09?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.18637/JSS.V011.I09, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1713164",
        "name": "Alexandros Karatzoglou"
      },
      {
        "authorId": "116865041",
        "name": "A. Smola"
      },
      {
        "authorId": "1764952",
        "name": "K. Hornik"
      },
      {
        "authorId": "2144516",
        "name": "A. Zeileis"
      }
    ],
    "abstract": "kernlab is an extensible package for kernel-based machine learning methods in R. It takes advantage of R's new S4 ob ject model and provides a framework for creating and using kernel-based algorithms. The package contains dot product primitives (kernels), implementations of support vector machines and the relevance vector machine, Gaussian processes, a ranking algorithm, kernel PCA, kernel CCA, and a spectral clustering algorithm. Moreover it provides a general purpose quadratic programming solver, and an incomplete Cholesky decomposition method."
  },
  {
    "paperId": "561c3fa53d36405186da9cab02bd68635c3738aa",
    "title": "Molecular graph convolutions: moving beyond fingerprints",
    "venue": "Journal of Computer-Aided Molecular Design",
    "year": 2016,
    "citationCount": 1519,
    "openAccessPdf": {
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5028207",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.00856, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3157072",
        "name": "S. Kearnes"
      },
      {
        "authorId": "144336638",
        "name": "Kevin McCloskey"
      },
      {
        "authorId": "2930707",
        "name": "Marc Berndl"
      },
      {
        "authorId": "1806271",
        "name": "V. Pande"
      },
      {
        "authorId": "119508204",
        "name": "Patrick F. Riley"
      }
    ],
    "abstract": "Molecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement."
  },
  {
    "paperId": "223841a71f5bce4cb03040e229d13e9a71b78ec3",
    "title": "Persistence Images: A Stable Vector Representation of Persistent Homology",
    "venue": "Journal of machine learning research",
    "year": 2015,
    "citationCount": 747,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1507.06217, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "115215183",
        "name": "Henry Adams"
      },
      {
        "authorId": "47341214",
        "name": "T. Emerson"
      },
      {
        "authorId": "152768617",
        "name": "M. Kirby"
      },
      {
        "authorId": "38798140",
        "name": "R. Neville"
      },
      {
        "authorId": "143725670",
        "name": "C. Peterson"
      },
      {
        "authorId": "2258173",
        "name": "Patrick D. Shipman"
      },
      {
        "authorId": "1884544",
        "name": "Sofya Chepushtanova"
      },
      {
        "authorId": "2064220414",
        "name": "Eric M. Hanson"
      },
      {
        "authorId": "15439144",
        "name": "Francis C. Motta"
      },
      {
        "authorId": "2492737",
        "name": "Lori Ziegelmeier"
      }
    ],
    "abstract": "Many datasets can be viewed as a noisy sampling of an underlying space, and tools from topological data analysis can characterize this structure for the purpose of knowledge discovery. One such tool is persistent homology, which provides a multiscale description of the homological features within a dataset. A useful representation of this homological information is a persistence diagram (PD). Efforts have been made to map PDs into spaces with additional structure valuable to machine learning tasks. We convert a PD to a finite-dimensional vector representation which we call a persistence image (PI), and prove the stability of this transformation with respect to small perturbations in the inputs. The discriminatory power of PIs is compared against existing methods, showing significant performance gains. We explore the use of PIs with vector-based machine learning tools, such as linear sparse support vector machines, which identify features containing discriminating topological information. Finally, high accuracy inference of parameter values from the dynamic output of a discrete dynamical system (the linked twist map) and a partial differential equation (the anisotropic Kuramoto-Sivashinsky equation) provide a novel application of the discriminatory power of PIs."
  },
  {
    "paperId": "c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3",
    "title": "Generalizing from a Few Examples",
    "venue": "ACM Computing Surveys",
    "year": 2019,
    "citationCount": 1964,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1904.05046, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2115793087",
        "name": "Yaqing Wang"
      },
      {
        "authorId": "3259992",
        "name": "Quanming Yao"
      },
      {
        "authorId": "145193332",
        "name": "J. Kwok"
      },
      {
        "authorId": "1726587",
        "name": "L. Ni"
      }
    ],
    "abstract": "Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research.1"
  },
  {
    "paperId": "38f23fe236b152cd4983c8f30d305a568afd0d3e",
    "title": "A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2019,
    "citationCount": 1709,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/5962385/9591206/09233366.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1907.07374, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "71352570",
        "name": "Erico Tjoa"
      },
      {
        "authorId": "145836900",
        "name": "Cuntai Guan"
      }
    ],
    "abstract": "Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged."
  },
  {
    "paperId": "0a5ff7336879c99513dca6fce6ef44984ebf3f55",
    "title": "Clipper: A Low-Latency Online Prediction Serving System",
    "venue": "Symposium on Networked Systems Design and Implementation",
    "year": 2016,
    "citationCount": 740,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1612.03079, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50564124",
        "name": "D. Crankshaw"
      },
      {
        "authorId": "2153692009",
        "name": "Xin Wang"
      },
      {
        "authorId": "40916418",
        "name": "Giulio Zhou"
      },
      {
        "authorId": "143666627",
        "name": "M. Franklin"
      },
      {
        "authorId": "49988044",
        "name": "Joseph E. Gonzalez"
      },
      {
        "authorId": "2055174324",
        "name": "Ion Stoica"
      }
    ],
    "abstract": "Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment. \nIn this paper, we introduce Clipper, a general-purpose low-latency prediction serving system. Interposing between end-user applications and a wide range of machine learning frameworks, Clipper introduces a modular architecture to simplify model deployment across frameworks and applications. Furthermore, by introducing caching, batching, and adaptive model selection techniques, Clipper reduces prediction latency and improves prediction throughput, accuracy, and robustness without modifying the underlying machine learning frameworks. We evaluate Clipper on four common machine learning benchmark datasets and demonstrate its ability to meet the latency, accuracy, and throughput demands of online serving applications. Finally, we compare Clipper to the TensorFlow Serving system and demonstrate that we are able to achieve comparable throughput and latency while enabling model composition and online learning to improve accuracy and render more robust predictions."
  },
  {
    "paperId": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
    "title": "Support-Vector Networks",
    "venue": "Machine-mediated learning",
    "year": 1995,
    "citationCount": 42710,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022627411411.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1022627411411?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1022627411411, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145115014",
        "name": "Corinna Cortes"
      },
      {
        "authorId": "50560492",
        "name": "V. Vapnik"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e35338965b359217c3c8360f4c5d3e79beb5f9bc",
    "title": "A Comparison of ARIMA and LSTM in Forecasting Time Series",
    "venue": "International Conference on Machine Learning and Applications",
    "year": 2018,
    "citationCount": 941,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMLA.2018.00227?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMLA.2018.00227, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1410227947",
        "name": "Sima Siami‐Namini"
      },
      {
        "authorId": "3463155",
        "name": "Neda Tavakoli"
      },
      {
        "authorId": "2336007",
        "name": "A. Namin"
      }
    ],
    "abstract": "Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as \"epoch\" in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior."
  },
  {
    "paperId": "28f7cc049f3f4a4db81f0d0a608a4f57636cc35b",
    "title": "Quantum-chemical insights from deep tensor neural networks",
    "venue": "Nature Communications",
    "year": 2016,
    "citationCount": 1349,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/ncomms13890.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.08259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "33075217",
        "name": "Kristof T. Schütt"
      },
      {
        "authorId": "2552481",
        "name": "F. Arbabzadah"
      },
      {
        "authorId": "7631063",
        "name": "Stefan Chmiela"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "2462983",
        "name": "A. Tkatchenko"
      }
    ],
    "abstract": "Learning from data has led to paradigm shifts in a multitude of disciplines, including web, text and image search, speech recognition, as well as bioinformatics. Can machine learning enable similar breakthroughs in understanding quantum many-body systems? Here we develop an efficient deep learning approach that enables spatially and chemically resolved insights into quantum-mechanical observables of molecular systems. We unify concepts from many-body Hamiltonians with purpose-designed deep tensor neural networks, which leads to size-extensive and uniformly accurate (1 kcal mol−1) predictions in compositional and configurational chemical space for molecules of intermediate size. As an example of chemical relevance, the model reveals a classification of aromatic rings with respect to their stability. Further applications of our model for predicting atomic energies and local chemical potentials in molecules, reliable isomer energies, and molecules with peculiar electronic structure demonstrate the potential of machine learning for revealing insights into complex quantum-chemical systems. Machine learning is an increasingly popular approach to analyse data and make predictions. Here the authors develop a ‘deep learning’ framework for quantitative predictions and qualitative understanding of quantum-mechanical observables of chemical systems, beyond properties trivially contained in the training data."
  },
  {
    "paperId": "7786bc6c25ba38ff0135f1bdad192f6b3c4ad0b3",
    "title": "ALVINN, an autonomous land vehicle in a neural network",
    "venue": "",
    "year": 2015,
    "citationCount": 2298,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "48855558",
        "name": "D. Pomerleau"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "79f2626046fdc56edfaca840874e355cac734b9a",
    "title": "Ad click prediction: a view from the trenches",
    "venue": "Knowledge Discovery and Data Mining",
    "year": 2013,
    "citationCount": 1013,
    "openAccessPdf": {
      "url": "http://dl.acm.org/ft_gateway.cfm?id=2488200&type=pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2487575.2488200?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2487575.2488200, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145057514",
        "name": "H. B. McMahan"
      },
      {
        "authorId": "144510728",
        "name": "Gary Holt"
      },
      {
        "authorId": "1733143",
        "name": "D. Sculley"
      },
      {
        "authorId": "2114084357",
        "name": "Michael Young"
      },
      {
        "authorId": "49236095",
        "name": "D. Ebner"
      },
      {
        "authorId": "36185845",
        "name": "Julian Grady"
      },
      {
        "authorId": "145945637",
        "name": "Lan Nie"
      },
      {
        "authorId": "2054375101",
        "name": "Todd Phillips"
      },
      {
        "authorId": "143698521",
        "name": "Eugene Davydov"
      },
      {
        "authorId": "145973657",
        "name": "D. Golovin"
      },
      {
        "authorId": "7489841",
        "name": "S. Chikkerur"
      },
      {
        "authorId": "144645397",
        "name": "Dan Liu"
      },
      {
        "authorId": "145233583",
        "name": "M. Wattenberg"
      },
      {
        "authorId": "2259962018",
        "name": "A. M. Hrafnkelsson"
      },
      {
        "authorId": "67119094",
        "name": "T. Boulos"
      },
      {
        "authorId": "143702704",
        "name": "J. Kubica"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8005391ce6f7a2f7161a113c7ec23366663c3abd",
    "title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges",
    "venue": "WIREs Data. Mining. Knowl. Discov.",
    "year": 2021,
    "citationCount": 676,
    "openAccessPdf": {
      "url": "https://epub.ub.uni-muenchen.de/108819/1/WIREs_Data_Min___Knowl_-_2023_-_Bischl_-_Hyperparameter_optimization__Foundations__algorithms__best_practices__and_open.pdf",
      "status": "GREEN",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2107.05847, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1686924",
        "name": "B. Bischl"
      },
      {
        "authorId": "143780936",
        "name": "Martin Binder"
      },
      {
        "authorId": "143962282",
        "name": "Michel Lang"
      },
      {
        "authorId": "1397278576",
        "name": "Tobias Pielok"
      },
      {
        "authorId": "145444740",
        "name": "Jakob Richter"
      },
      {
        "authorId": "51123419",
        "name": "Stefan Coors"
      },
      {
        "authorId": "29252434",
        "name": "Janek Thomas"
      },
      {
        "authorId": "153364381",
        "name": "Theresa Ullmann"
      },
      {
        "authorId": "2071187711",
        "name": "Marc Becker"
      },
      {
        "authorId": "1751504",
        "name": "A. Boulesteix"
      },
      {
        "authorId": "25309765",
        "name": "Difan Deng"
      },
      {
        "authorId": "145963266",
        "name": "M. Lindauer"
      }
    ],
    "abstract": "Most machine learning algorithms are configured by a set of hyperparameters whose values must be carefully chosen and which often considerably impact performance. To avoid a time‐consuming and irreproducible manual process of trial‐and‐error to find well‐performing hyperparameter configurations, various automatic hyperparameter optimization (HPO) methods—for example, based on resampling error estimation for supervised machine learning—can be employed. After introducing HPO from a general perspective, this paper reviews important HPO methods, from simple techniques such as grid or random search to more advanced methods like evolution strategies, Bayesian optimization, Hyperband, and racing. This work gives practical recommendations regarding important choices to be made when conducting HPO, including the HPO algorithms themselves, performance evaluation, how to combine HPO with machine learning pipelines, runtime improvements, and parallelization."
  },
  {
    "paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f",
    "title": "Rectified Linear Units Improve Restricted Boltzmann Machines",
    "venue": "International Conference on Machine Learning",
    "year": 2010,
    "citationCount": 18143,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2073603971",
        "name": "Vinod Nair"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4a6e74d4bf4fd0106891e5518692a77c7aa8811d",
    "title": "Outlier Detection in High Dimensional Data",
    "venue": "Regular Issue",
    "year": 2021,
    "citationCount": 587,
    "openAccessPdf": {
      "url": "https://doi.org/10.35940/ijeat.e2675.0610521",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.35940/ijeat.e2675.0610521?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35940/ijeat.e2675.0610521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1682418",
        "name": "C. Aggarwal"
      },
      {
        "authorId": "144019071",
        "name": "Philip S. Yu"
      }
    ],
    "abstract": "Artificial intelligence (AI) is the science that allows\ncomputers to replicate human intelligence in areas such as\ndecision-making, text processing, visual perception. Artificial\nIntelligence is the broader field that contains several subfields\nsuch as machine learning, robotics, and computer vision.\nMachine Learning is a branch of Artificial Intelligence that\nallows a machine to learn and improve at a task over time. Deep\nLearning is a subset of machine learning that makes use of deep\nartificial neural networks for training. The paper proposed on\noutlier detection for multivariate high dimensional data for\nAutoencoder unsupervised model."
  },
  {
    "paperId": "a5e8141d4e323ff7f1f49dbbce293b0d6f739464",
    "title": "Very Simple Classification Rules Perform Well on Most Commonly Used Datasets",
    "venue": "Machine-mediated learning",
    "year": 1993,
    "citationCount": 1831,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022631118932.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1022631118932?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1022631118932, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1796214",
        "name": "R. Holte"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0ef7d9e618cbb507d69f8ebcdc60b8a1f3135bff",
    "title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 1225,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015332?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015332, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2117881943",
        "name": "Tong Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6120cc252bc74239012f11b8b075cb7cb16bee26",
    "title": "An Introduction to Variational Methods for Graphical Models",
    "venue": "Machine-mediated learning",
    "year": 1999,
    "citationCount": 4558,
    "openAccessPdf": {
      "url": "http://www.cis.upenn.edu/~mkearns/papers/barbados/jgjs-var.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1007665907178?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1007665907178, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1694621",
        "name": "Michael I. Jordan"
      },
      {
        "authorId": "1744700",
        "name": "Zoubin Ghahramani"
      },
      {
        "authorId": "35132120",
        "name": "T. Jaakkola"
      },
      {
        "authorId": "1796044",
        "name": "L. Saul"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a9763afda62e960c35c80681f805ddecbef14a92",
    "title": "Images of Organization",
    "venue": "",
    "year": 1988,
    "citationCount": 6880,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1097/00000446-198803000-00042?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/00000446-198803000-00042, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49811299",
        "name": "J. Alexander"
      },
      {
        "authorId": "2053884612",
        "name": "G. Morgan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fae8bbf868681b83d91b2fec6c840d4d2b32005b",
    "title": "Intrinsic Motivation and Reinforcement Learning",
    "venue": "Intrinsically Motivated Learning in Natural and Artificial Systems",
    "year": 2013,
    "citationCount": 261,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-32375-1_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-32375-1_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1730590",
        "name": "A. Barto"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
    "title": "An empirical evaluation of deep architectures on problems with many factors of variation",
    "venue": "International Conference on Machine Learning",
    "year": 2007,
    "citationCount": 1182,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1273496.1273556?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1273496.1273556, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1777528",
        "name": "H. Larochelle"
      },
      {
        "authorId": "1761978",
        "name": "D. Erhan"
      },
      {
        "authorId": "1760871",
        "name": "Aaron C. Courville"
      },
      {
        "authorId": "32837403",
        "name": "J. Bergstra"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "24e6cf0796237f21c780a3f0c996817f57b3a1bd",
    "title": "Support-vector networks",
    "venue": "Machine-mediated learning",
    "year": 2004,
    "citationCount": 8889,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/BF00994018.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF00994018?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF00994018, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152547641",
        "name": "Corinna Cortes"
      },
      {
        "authorId": "50560492",
        "name": "V. Vapnik"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "554f3b32b956035fbfabba730c6f0300d6955dce",
    "title": "Learning logical definitions from relations",
    "venue": "Machine-mediated learning",
    "year": 1990,
    "citationCount": 1100,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/BF00117105.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/BF00117105?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/BF00117105, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145341779",
        "name": "J. R. Quinlan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e75b3c12da067552fda910a5bbed8b4d0e82dbcb",
    "title": " Neural Network Methods for Natural Language Processing",
    "venue": "Computational Linguistics",
    "year": 2017,
    "citationCount": 792,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/bfm%3A978-3-031-02165-7%2F1",
      "status": "GREEN",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2200/S00762ED1V01Y201703HLT037?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2200/S00762ED1V01Y201703HLT037, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2089067",
        "name": "Yoav Goldberg"
      }
    ],
    "abstract": "Neural networks are a family of powerful machine learning models. This book focuses on the application of neural network models to natural language data. The first half of the book (Parts I and II) covers the basics of supervised machine learning and feed-forward neural networks, the basics of working with machine learning over language data, and the use of vector-based rather than symbolic representations for words. It also covers the computation-graph abstraction, which allows to easily define and train arbitrary neural networks, and is the basis behind the design of contemporary neural network software libraries.\r\n\r\nThe second part of the book (Parts III and IV) introduces more specialized neural network architectures, including 1D convolutional neural networks, recurrent neural networks, conditioned-generation models, and attention-based models. These architectures and techniques are the driving force behind state-of-the-art algorithms for machine translation, syntactic parsing, and many other applications. Finally, we also discuss tree-shaped networks, structured prediction, and the prospects of multi-task learning."
  },
  {
    "paperId": "864e7db59f2ccfec1ee9f6eba79566ac7b0634df",
    "title": "Convolutional Pose Machines",
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2016,
    "citationCount": 2843,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1602.00134",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1602.00134, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2797981",
        "name": "S. Wei"
      },
      {
        "authorId": "20569810",
        "name": "V. Ramakrishna"
      },
      {
        "authorId": "1733113",
        "name": "T. Kanade"
      },
      {
        "authorId": "1774867",
        "name": "Yaser Sheikh"
      }
    ],
    "abstract": "Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image-dependent spatial models for the task of pose estimation. The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation. We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision, thereby replenishing back-propagated gradients and conditioning the learning procedure. We demonstrate state-of-the-art performance and outperform competing methods on standard benchmarks including the MPII, LSP, and FLIC datasets."
  },
  {
    "paperId": "5966d7c7f60898d610812e24c64d4d57855ad86a",
    "title": "Semantics derived automatically from language corpora contain human-like biases",
    "venue": "Science",
    "year": 2016,
    "citationCount": 2886,
    "openAccessPdf": {
      "url": "https://researchportal.bath.ac.uk/files/168480066/CaliskanEtAl_authors_full.pdf",
      "status": "GREEN",
      "license": "other-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1608.07187, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144537437",
        "name": "Aylin Caliskan"
      },
      {
        "authorId": "145315445",
        "name": "J. Bryson"
      },
      {
        "authorId": "47735253",
        "name": "Arvind Narayanan"
      }
    ],
    "abstract": "Machines learn what people know implicitly AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan et al. now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs—for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior. Science, this issue p. 183; see also p. 133 Computers can learn which words go together more or less often and can thus mimic human performance on a test of implicit bias. Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology."
  },
  {
    "paperId": "990a02f20529f5ce3b382f1d54648afaab391179",
    "title": "Poisoning Attacks against Support Vector Machines",
    "venue": "International Conference on Machine Learning",
    "year": 2012,
    "citationCount": 1715,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1206.6389, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1684175",
        "name": "B. Biggio"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "1754215",
        "name": "P. Laskov"
      }
    ],
    "abstract": "We investigate a family of poisoning attacks against Support Vector Machines (SVM). Such attacks inject specially crafted training data that increases the SVM's test error. Central to the motivation for these attacks is the fact that most learning algorithms assume that their training data comes from a natural or well-behaved distribution. However, this assumption does not generally hold in security-sensitive settings. As we demonstrate, an intelligent adversary can, to some extent, predict the change of the SVM's decision function due to malicious input and use this ability to construct malicious data. \n \nThe proposed attack uses a gradient ascent strategy in which the gradient is computed based on properties of the SVM's optimal solution. This method can be kernelized and enables the attack to be constructed in the input space even for non-linear kernels. We experimentally demonstrate that our gradient ascent procedure reliably identifies good local maxima of the non-convex validation error surface, which significantly increases the classifier's test error."
  },
  {
    "paperId": "80196cdfcd0c6ce2953bf65a7f019971e2026386",
    "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures",
    "venue": "International Conference on Machine Learning",
    "year": 2018,
    "citationCount": 1717,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1802.01561, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2311318",
        "name": "L. Espeholt"
      },
      {
        "authorId": "2794457",
        "name": "Hubert Soyer"
      },
      {
        "authorId": "1708654",
        "name": "R. Munos"
      },
      {
        "authorId": "34838386",
        "name": "K. Simonyan"
      },
      {
        "authorId": "3255983",
        "name": "Volodymyr Mnih"
      },
      {
        "authorId": "2056968992",
        "name": "Tom Ward"
      },
      {
        "authorId": "2895238",
        "name": "Yotam Doron"
      },
      {
        "authorId": "9559485",
        "name": "Vlad Firoiu"
      },
      {
        "authorId": "3367786",
        "name": "Tim Harley"
      },
      {
        "authorId": "2768462",
        "name": "Iain Dunning"
      },
      {
        "authorId": "34313265",
        "name": "S. Legg"
      },
      {
        "authorId": "2645384",
        "name": "K. Kavukcuoglu"
      }
    ],
    "abstract": "In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. A key challenge is to handle the increased amount of data and extended training time. We have developed a new distributed agent IMPALA (Importance Weighted Actor-Learner Architecture) that not only uses resources more efficiently in single-machine training but also scales to thousands of machines without sacrificing data efficiency or resource utilisation. We achieve stable learning at high throughput by combining decoupled acting and learning with a novel off-policy correction method called V-trace. We demonstrate the effectiveness of IMPALA for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the DeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our results show that IMPALA is able to achieve better performance than previous agents with less data, and crucially exhibits positive transfer between tasks as a result of its multi-task approach."
  },
  {
    "paperId": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
    "title": "Transductive Inference for Text Classification using Support Vector Machines",
    "venue": "International Conference on Machine Learning",
    "year": 1999,
    "citationCount": 3247,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4ec06dda674cd5f93351f0ab5871391671f9b974",
    "title": "Medical Image Analysis using Convolutional Neural Networks: A Review",
    "venue": "Journal of medical systems",
    "year": 2017,
    "citationCount": 1156,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1709.02250, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9514351",
        "name": "A. Qayyum"
      },
      {
        "authorId": "144608640",
        "name": "S. Anwar"
      },
      {
        "authorId": "144974259",
        "name": "Muhammad Majid"
      },
      {
        "authorId": "1387433697",
        "name": "M. Awais"
      },
      {
        "authorId": "3436574",
        "name": "M. Alnowami"
      }
    ],
    "abstract": "The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted."
  },
  {
    "paperId": "7547fd7c5e4bc3b8b8bf714583684ff187e8a382",
    "title": "An assessment of support vector machines for land cover classi(cid:142) cation",
    "venue": "",
    "year": 2002,
    "citationCount": 1435,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "3343280",
        "name": "Chengquan Huang"
      },
      {
        "authorId": "1693428",
        "name": "L. Davis"
      },
      {
        "authorId": "145181457",
        "name": "J. Townshend"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "965b92478205bb51f9cd158c2a9734b542242bec",
    "title": "The FLUXCOM ensemble of global land-atmosphere energy fluxes",
    "venue": "Scientific Data",
    "year": 2018,
    "citationCount": 571,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41597-019-0076-8.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1812.04951, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "95799904",
        "name": "M. Jung"
      },
      {
        "authorId": "50417779",
        "name": "S. Koirala"
      },
      {
        "authorId": "2058489397",
        "name": "U. Weber"
      },
      {
        "authorId": "40638530",
        "name": "K. Ichii"
      },
      {
        "authorId": "5536084",
        "name": "F. Gans"
      },
      {
        "authorId": "1397959153",
        "name": "Gustau Camps-Valls"
      },
      {
        "authorId": "2184976",
        "name": "D. Papale"
      },
      {
        "authorId": "2139023",
        "name": "C. Schwalm"
      },
      {
        "authorId": "2591511",
        "name": "G. Tramontana"
      },
      {
        "authorId": "2530948",
        "name": "M. Reichstein"
      }
    ],
    "abstract": "Although a key driver of Earth’s climate system, global land-atmosphere energy fluxes are poorly constrained. Here we use machine learning to merge energy flux measurements from FLUXNET eddy covariance towers with remote sensing and meteorological data to estimate global gridded net radiation, latent and sensible heat and their uncertainties. The resulting FLUXCOM database comprises 147 products in two setups: (1) 0.0833° resolution using MODIS remote sensing data (RS) and (2) 0.5° resolution using remote sensing and meteorological data (RS + METEO). Within each setup we use a full factorial design across machine learning methods, forcing datasets and energy balance closure corrections. For RS and RS + METEO setups respectively, we estimate 2001–2013 global (±1 s.d.) net radiation as 75.49 ± 1.39 W m−2 and 77.52 ± 2.43 W m−2, sensible heat as 32.39 ± 4.17 W m−2 and 35.58 ± 4.75 W m−2, and latent heat flux as 39.14 ± 6.60 W m−2 and 39.49 ± 4.51 W m−2 (as evapotranspiration, 75.6 ± 9.8 × 103 km3 yr−1 and 76 ± 6.8 × 103 km3 yr−1). FLUXCOM products are suitable to quantify global land-atmosphere interactions and benchmark land surface model simulations. Design Type(s) modeling and simulation objective • factorial design Measurement Type(s) energy Technology Type(s) machine learning Factor Type(s) machine learning • Energy Balance • temporal_interval • geographic location Sample Characteristic(s) Earth (Planet) • land • vegetation layer • climate system Design Type(s) modeling and simulation objective • factorial design Measurement Type(s) energy Technology Type(s) machine learning Factor Type(s) machine learning • Energy Balance • temporal_interval • geographic location Sample Characteristic(s) Earth (Planet) • land • vegetation layer • climate system Machine-accessible metadata file describing the reported data (ISA-Tab format)"
  },
  {
    "paperId": "db9dd36e19c8169e0b0e0ca2ccb38ecea2ba0713",
    "title": "Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA",
    "venue": "Journal of machine learning research",
    "year": 2017,
    "citationCount": 634,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1722782",
        "name": "Lars Kotthoff"
      },
      {
        "authorId": "143928655",
        "name": "C. Thornton"
      },
      {
        "authorId": "2470869",
        "name": "H. Hoos"
      },
      {
        "authorId": "144661829",
        "name": "F. Hutter"
      },
      {
        "authorId": "1388404060",
        "name": "Kevin Leyton-Brown"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "3335c340c20609b4e6de481c9eaf67ecd6c960dc",
    "title": "Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science",
    "venue": "Annual Conference on Genetic and Evolutionary Computation",
    "year": 2016,
    "citationCount": 571,
    "openAccessPdf": {
      "url": "http://dl.acm.org/ft_gateway.cfm?id=2908918&type=pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.06212, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3297552",
        "name": "Randal S. Olson"
      },
      {
        "authorId": "39248319",
        "name": "Nathan Bartley"
      },
      {
        "authorId": "1800213",
        "name": "R. Urbanowicz"
      },
      {
        "authorId": "152512193",
        "name": "J. Moore"
      }
    ],
    "abstract": "As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design."
  },
  {
    "paperId": "29650544fded20dd5b2fc49f60f9a3ad30d0e275",
    "title": "Speech Recognition Using Deep Neural Networks: A Systematic Review",
    "venue": "IEEE Access",
    "year": 2019,
    "citationCount": 887,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08632885.pdf",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2896880?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2896880, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2513768",
        "name": "Ali Bou Nassif"
      },
      {
        "authorId": "144304225",
        "name": "I. Shahin"
      },
      {
        "authorId": "73774606",
        "name": "Imtinan B. Attili"
      },
      {
        "authorId": "2063215",
        "name": "Mohammad Azzeh"
      },
      {
        "authorId": "40241708",
        "name": "Khaled Shaalan"
      }
    ],
    "abstract": "Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics."
  },
  {
    "paperId": "0ea2f1f5c470c4947b48bbd21245fb327282f3b4",
    "title": "Stock market's price movement prediction with LSTM neural networks",
    "venue": "IEEE International Joint Conference on Neural Network",
    "year": 2017,
    "citationCount": 725,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.2017.7966019?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.2017.7966019, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2112887403",
        "name": "David M. Q. Nelson"
      },
      {
        "authorId": "38964525",
        "name": "A. Pereira"
      },
      {
        "authorId": "153714464",
        "name": "Renato A. de Oliveira"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b249fe4e5e2bada6655ce5d61e7f50da5d471cb4",
    "title": "Domain Generalization: A Survey",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2021,
    "citationCount": 1264,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2103.02503",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2103.02503, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "9368124",
        "name": "Kaiyang Zhou"
      },
      {
        "authorId": "2117940996",
        "name": "Ziwei Liu"
      },
      {
        "authorId": "143970608",
        "name": "Y. Qiao"
      },
      {
        "authorId": "145406421",
        "name": "T. Xiang"
      },
      {
        "authorId": "1717179",
        "name": "Chen Change Loy"
      }
    ],
    "abstract": "Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d. assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions."
  },
  {
    "paperId": "b5028fb7d55d3045cda0c290ded57c4c0b3cfdc9",
    "title": "Foundations of Rule Learning",
    "venue": "Cognitive Technologies",
    "year": 2012,
    "citationCount": 367,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-75197-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-75197-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1747752",
        "name": "Johannes Fürnkranz"
      },
      {
        "authorId": "1767339",
        "name": "D. Gamberger"
      },
      {
        "authorId": "1730104",
        "name": "N. Lavrač"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "10b496ad48513f8585aa56f2c682159357858960",
    "title": "Understanding Data Augmentation for Classification: When to Warp?",
    "venue": "International Conference on Digital Image Computing: Techniques and Applications",
    "year": 2016,
    "citationCount": 949,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/1609.08764",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1609.08764, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2442657",
        "name": "S. Wong"
      },
      {
        "authorId": "3010116",
        "name": "Adam Gatt"
      },
      {
        "authorId": "2851301",
        "name": "V. Stamatescu"
      },
      {
        "authorId": "1877198",
        "name": "M. McDonnell"
      }
    ],
    "abstract": "In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting."
  },
  {
    "paperId": "1626c940a64ad96a7ed53d7d6c0df63c6696956b",
    "title": "Restricted Boltzmann machines for collaborative filtering",
    "venue": "International Conference on Machine Learning",
    "year": 2007,
    "citationCount": 2062,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1273496.1273596?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1273496.1273596, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145124475",
        "name": "R. Salakhutdinov"
      },
      {
        "authorId": "1714004",
        "name": "A. Mnih"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b34fc78de28be598e21118d7cb9d84d63374addc",
    "title": "Analysis of Dimensionality Reduction Techniques on Big Data",
    "venue": "IEEE Access",
    "year": 2020,
    "citationCount": 644,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09036908.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.2980942?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.2980942, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "38608914",
        "name": "G. T. Reddy"
      },
      {
        "authorId": "49247239",
        "name": "M. P. K. Reddy"
      },
      {
        "authorId": "51017707",
        "name": "Kuruva Lakshmanna"
      },
      {
        "authorId": "46234199",
        "name": "Rajesh Kaluri"
      },
      {
        "authorId": "32336300",
        "name": "D. Rajput"
      },
      {
        "authorId": "2176030144",
        "name": "Gautam Srivastava"
      },
      {
        "authorId": "2287603163",
        "name": "Ieee Thar Baker Senior Member"
      },
      {
        "authorId": "2176030144",
        "name": "Gautam Srivastava"
      }
    ],
    "abstract": "Due to digitization, a huge volume of data is being generated across several sectors such as healthcare, production, sales, IoT devices, Web, organizations. Machine learning algorithms are used to uncover patterns among the attributes of this data. Hence, they can be used to make predictions that can be used by medical practitioners and people at managerial level to make executive decisions. Not all the attributes in the datasets generated are important for training the machine learning algorithms. Some attributes might be irrelevant and some might not affect the outcome of the prediction. Ignoring or removing these irrelevant or less important attributes reduces the burden on machine learning algorithms. In this work two of the prominent dimensionality reduction techniques, Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are investigated on four popular Machine Learning (ML) algorithms, Decision Tree Induction, Support Vector Machine (SVM), Naive Bayes Classifier and Random Forest Classifier using publicly available Cardiotocography (CTG) dataset from University of California and Irvine Machine Learning Repository. The experimentation results prove that PCA outperforms LDA in all the measures. Also, the performance of the classifiers, Decision Tree, Random Forest examined is not affected much by using PCA and LDA.To further analyze the performance of PCA and LDA the eperimentation is carried out on Diabetic Retinopathy (DR) and Intrusion Detection System (IDS) datasets. Experimentation results prove that ML algorithms with PCA produce better results when dimensionality of the datasets is high. When dimensionality of datasets is low it is observed that the ML algorithms without dimensionality reduction yields better results."
  },
  {
    "paperId": "9dc134b18c06577354d50c12a8972b965d3bbacd",
    "title": "Learning to Decode Cognitive States from Brain Images",
    "venue": "Machine-mediated learning",
    "year": 2004,
    "citationCount": 766,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/B:MACH.0000035475.85309.1b.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/B:MACH.0000035475.85309.1b?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/B:MACH.0000035475.85309.1b, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40975594",
        "name": "Tom Michael Mitchell"
      },
      {
        "authorId": "2491371",
        "name": "R. Hutchinson"
      },
      {
        "authorId": "3139923",
        "name": "R. Niculescu"
      },
      {
        "authorId": "144637670",
        "name": "Francisco Pereira"
      },
      {
        "authorId": "2144657667",
        "name": "Xuerui Wang"
      },
      {
        "authorId": "2065109",
        "name": "M. Just"
      },
      {
        "authorId": "6809972",
        "name": "Sharlene D. Newman"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ec76f55da5c6df30f6e4c9e4945bd3304d508ef7",
    "title": "Fuzzy support vector machines",
    "venue": "IEEE Trans. Neural Networks",
    "year": 2002,
    "citationCount": 1483,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/72.991432?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/72.991432, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2146245769",
        "name": "Chun-fu Lin"
      },
      {
        "authorId": "9437199",
        "name": "Sheng-de Wang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b3b3c562a45d7710d6f62ad8f210ebca9a47d23f",
    "title": "Who should fix this bug?",
    "venue": "International Conference on Software Engineering",
    "year": 2006,
    "citationCount": 1091,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1134285.1134336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1134285.1134336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2226695",
        "name": "J. Anvik"
      },
      {
        "authorId": "47799990",
        "name": "L. Hiew"
      },
      {
        "authorId": "1739674",
        "name": "G. Murphy"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4f51a64793d3b2a60e9e5846c31dae023cf5c69a",
    "title": "Unmasking Clever Hans predictors and assessing what machines really learn",
    "venue": "Nature Communications",
    "year": 2019,
    "citationCount": 1092,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41467-019-08987-4.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1902.10178, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3633358",
        "name": "S. Lapuschkin"
      },
      {
        "authorId": "15252080",
        "name": "S. Wäldchen"
      },
      {
        "authorId": "49345823",
        "name": "Alexander Binder"
      },
      {
        "authorId": "144535526",
        "name": "G. Montavon"
      },
      {
        "authorId": "1699054",
        "name": "W. Samek"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": "Current learning machines have successfully solved hard application problems, reaching high accuracy and displaying seemingly intelligent behavior. Here we apply recent techniques for explaining decisions of state-of-the-art learning machines and analyze various tasks from computer vision and arcade games. This showcases a spectrum of problem-solving behaviors ranging from naive and short-sighted, to well-informed and strategic. We observe that standard performance evaluation metrics can be oblivious to distinguishing these diverse problem solving behaviors. Furthermore, we propose our semi-automated Spectral Relevance Analysis that provides a practically effective way of characterizing and validating the behavior of nonlinear learning machines. This helps to assess whether a learned model indeed delivers reliably for the problem that it was conceived for. Furthermore, our work intends to add a voice of caution to the ongoing excitement about machine intelligence and pledges to evaluate and judge some of these recent successes in a more nuanced manner. Nonlinear machine learning methods have good predictive ability but the lack of transparency of the algorithms can limit their use. Here the authors investigate how these methods approach learning in order to assess the dependability of their decision making."
  },
  {
    "paperId": "430c95aab5bc85404f9651eb2137a12e2c4d5fe7",
    "title": "Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers",
    "venue": "Journal of machine learning research",
    "year": 2000,
    "citationCount": 1645,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1943813",
        "name": "Erin L. Allwein"
      },
      {
        "authorId": "2242588011",
        "name": "Rob Schapire"
      },
      {
        "authorId": "2067174432",
        "name": "Y. Singer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "49b8dff62cccc26023c876460234bf29084a382f",
    "title": "Transductive Learning via Spectral Graph Partitioning",
    "venue": "International Conference on Machine Learning",
    "year": 2003,
    "citationCount": 763,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "36cd89332d305d01605d6d08cd8452c8a752138a",
    "title": "Designing neural networks through neuroevolution",
    "venue": "Nature Machine Intelligence",
    "year": 2019,
    "citationCount": 634,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s42256-018-0006-z.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/S42256-018-0006-Z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/S42256-018-0006-Z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1846883",
        "name": "Kenneth O. Stanley"
      },
      {
        "authorId": "2552141",
        "name": "J. Clune"
      },
      {
        "authorId": "39799304",
        "name": "J. Lehman"
      },
      {
        "authorId": "1686788",
        "name": "R. Miikkulainen"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "77703a2783f64dfceb638aa9eebd9c9c501bb835",
    "title": "The Case against Accuracy Estimation for Comparing Induction Algorithms",
    "venue": "International Conference on Machine Learning",
    "year": 1998,
    "citationCount": 1249,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1752722",
        "name": "F. Provost"
      },
      {
        "authorId": "145421658",
        "name": "Tom Fawcett"
      },
      {
        "authorId": "1726733",
        "name": "Ron Kohavi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f8b012720a2322dcf4ed9ac4d61d6be11d9ebd10",
    "title": "Concepts of Artificial Intelligence for Computer-Assisted Drug Discovery.",
    "venue": "Chemical Reviews",
    "year": 2019,
    "citationCount": 682,
    "openAccessPdf": {
      "url": "https://doi.org/10.1021/acs.chemrev.8b00728",
      "status": "HYBRID",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1021/acs.chemrev.8b00728?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acs.chemrev.8b00728, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2150439478",
        "name": "Xin Yang"
      },
      {
        "authorId": "2115568943",
        "name": "Yifei Wang"
      },
      {
        "authorId": "2060877077",
        "name": "Ryan Byrne"
      },
      {
        "authorId": "144522872",
        "name": "G. Schneider"
      },
      {
        "authorId": "144824105",
        "name": "Sheng-yong Yang"
      }
    ],
    "abstract": "Artificial intelligence (AI), and, in particular, deep learning as a subcategory of AI, provides opportunities for the discovery and development of innovative drugs. Various machine learning approaches have recently (re)emerged, some of which may be considered instances of domain-specific AI which have been successfully employed for drug discovery and design. This review provides a comprehensive portrayal of these machine learning techniques and of their applications in medicinal chemistry. After introducing the basic principles, alongside some application notes, of the various machine learning algorithms, the current state-of-the art of AI-assisted pharmaceutical discovery is discussed, including applications in structure- and ligand-based virtual screening, de novo drug design, physicochemical and pharmacokinetic property prediction, drug repurposing, and related aspects. Finally, several challenges and limitations of the current methods are summarized, with a view to potential future directions for AI-assisted drug discovery and design."
  },
  {
    "paperId": "b8e37682c847844a4b5c4851239fdc3357d5577b",
    "title": "Lecture Notes in Artificial Intelligence",
    "venue": "",
    "year": 1999,
    "citationCount": 2512,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145050036",
        "name": "P. Brézillon"
      },
      {
        "authorId": "2238004513",
        "name": "Paolo Bouquet"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "45a9e2aa04e91bb511f36c365ef4daa274fe583c",
    "title": "Applying Support Vector Machines to Imbalanced Datasets",
    "venue": "European Conference on Machine Learning",
    "year": 2004,
    "citationCount": 1266,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-30115-8_7.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-30115-8_7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-30115-8_7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2559584",
        "name": "Rehan Akbani"
      },
      {
        "authorId": "1719127",
        "name": "Stephen Kwek"
      },
      {
        "authorId": "1743642",
        "name": "N. Japkowicz"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "cc1cad12521b5aab43fdda5b4dec67586aef1f87",
    "title": "Kernel Methods for Relation Extraction",
    "venue": "Journal of machine learning research",
    "year": 2002,
    "citationCount": 1295,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.3115/1118693.1118703",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/W02-1010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3190501",
        "name": "D. Zelenko"
      },
      {
        "authorId": "2939759",
        "name": "Chinatsu Aone"
      },
      {
        "authorId": "49754061",
        "name": "A. Richardella"
      }
    ],
    "abstract": "We present an application of kernel methods to extracting relations from unstructured natural language sources. We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels. We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text. We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results."
  },
  {
    "paperId": "05c08de1bf91cd52ea1d22e7238e33958b574a23",
    "title": "The responsibility gap: Ascribing responsibility for the actions of learning automata",
    "venue": "Ethics and Information Technology",
    "year": 2004,
    "citationCount": 737,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10676-004-3422-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10676-004-3422-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "40558676",
        "name": "A. Matthias"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "8ce2c4a374e8b37e3eef080c956f22cfc6ea25d6",
    "title": "Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "citationCount": 461,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1606.04316, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1792368",
        "name": "A. Benavoli"
      },
      {
        "authorId": "1680295",
        "name": "Giorgio Corani"
      },
      {
        "authorId": "2701105",
        "name": "J. Demšar"
      },
      {
        "authorId": "1825163",
        "name": "Marco Zaffalon"
      }
    ],
    "abstract": "The machine learning community adopted the use of null hypothesis significance testing (NHST) in order to ensure the statistical validity of results. Many scientific fields however realized the shortcomings of frequentist reasoning and in the most radical cases even banned its use in publications. We should do the same: just as we have embraced the Bayesian paradigm in the development of new machine learning methods, so we should also use it in the analysis of our own results. We argue for abandonment of NHST by exposing its fallacies and, more importantly, offer better - more sound and useful - alternatives for it."
  },
  {
    "paperId": "f84f2cc648a338a6b1317d039c018dbfb8989b9b",
    "title": "sbi: A toolkit for simulation-based inference",
    "venue": "Journal of Open Source Software",
    "year": 2020,
    "citationCount": 275,
    "openAccessPdf": {
      "url": "https://joss.theoj.org/papers/10.21105/joss.02505.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.21105/joss.02505?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21105/joss.02505, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1402501005",
        "name": "Álvaro Tejero-Cantero"
      },
      {
        "authorId": "2547666",
        "name": "Jan Boelts"
      },
      {
        "authorId": "51073369",
        "name": "Michael Deistler"
      },
      {
        "authorId": "5542005",
        "name": "Jan-Matthis Lueckmann"
      },
      {
        "authorId": "49089615",
        "name": "Conor Durkan"
      },
      {
        "authorId": "7169768",
        "name": "Pedro J. Gonccalves"
      },
      {
        "authorId": "46925410",
        "name": "David S. Greenberg"
      },
      {
        "authorId": "1825793727",
        "name": "Jakob H. Macke Computational Neuroengineering"
      },
      {
        "authorId": "93204176",
        "name": "D. Electrical"
      },
      {
        "authorId": "5545125",
        "name": "Computer Engineering"
      },
      {
        "authorId": "94265418",
        "name": "T. U. Munich"
      },
      {
        "authorId": "1515575796",
        "name": "School of Informatics"
      },
      {
        "authorId": "95994788",
        "name": "U. Edinburgh"
      },
      {
        "authorId": "1825797491",
        "name": "Neural Systems Analysis"
      },
      {
        "authorId": "1825802443",
        "name": "Center of Advanced European Studies"
      },
      {
        "authorId": "2088945415",
        "name": "Research"
      },
      {
        "authorId": "2056821341",
        "name": "Bonn"
      },
      {
        "authorId": "1825802830",
        "name": "Model-Driven Machine Learning"
      },
      {
        "authorId": "102823056",
        "name": "Centre for Materials"
      },
      {
        "authorId": "1825802240",
        "name": "Coastal Research"
      },
      {
        "authorId": "100505404",
        "name": "Helmholtz-Zentrum Geesthacht"
      },
      {
        "authorId": "1825802941",
        "name": "Machine Learning in Science"
      },
      {
        "authorId": "103323820",
        "name": "U. Tubingen"
      },
      {
        "authorId": "1825804660",
        "name": "Empirical Inference"
      },
      {
        "authorId": "102301817",
        "name": "Max Planck Institute for the Physics of Complex Systems"
      },
      {
        "authorId": "102989781",
        "name": "Tubingen"
      }
    ],
    "abstract": "e Equally contributing authors 1 Computational Neuroengineering, Department of Electrical and Computer Engineering, Technical University of Munich 2 School of Informatics, University of Edinburgh 3 Neural Systems Analysis, Center of Advanced European Studies and Research (caesar), Bonn 4 Model-Driven Machine Learning, Centre for Materials and Coastal Research, Helmholtz-Zentrum Geesthacht 5 Machine Learning in Science, University of Tübingen 6 Empirical Inference, Max Planck Institute for Intelligent Systems, Tübingen DOI: 10.21105/joss.02505"
  },
  {
    "paperId": "ac12c9b9e35e58b55d85a97c47886a7371c14afa",
    "title": "Data mining in bioinformatics using Weka",
    "venue": "Bioinform.",
    "year": 2004,
    "citationCount": 929,
    "openAccessPdf": {
      "url": "https://academic.oup.com/bioinformatics/article-pdf/20/15/2479/48906042/bioinformatics_20_15_2479.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1093/BIOINFORMATICS/BTH261?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/BIOINFORMATICS/BTH261, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1767318",
        "name": "E. Frank"
      },
      {
        "authorId": "118860642",
        "name": "M. Hall"
      },
      {
        "authorId": "33614647",
        "name": "Leonard E. Trigg"
      },
      {
        "authorId": "2084564300",
        "name": "G. Holmes"
      },
      {
        "authorId": "9419406",
        "name": "I. Witten"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "784220a5a2ad452282f8af006a6cb5715d54d0ed",
    "title": "Link-Based Classification",
    "venue": "Encyclopedia of Machine Learning and Data Mining",
    "year": 2003,
    "citationCount": 909,
    "openAccessPdf": {
      "url": "https://drum.lib.umd.edu/bitstreams/adc0c6ae-f26a-4621-969a-447d92930cc9/download",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4899-7687-1_100268?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4899-7687-1_100268, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2117523996",
        "name": "Qing Lu"
      },
      {
        "authorId": "1746034",
        "name": "L. Getoor"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fd0934a6008ecb9035b5b1e0b91ac890e2e5bd3d",
    "title": "A connectionist machine for genetic hillclimbing",
    "venue": "",
    "year": 1987,
    "citationCount": 861,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4613-1997-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4613-1997-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3308302",
        "name": "D. Ackley"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "dd135a89b5075af5cbef5becaf419457cdd77cc9",
    "title": "An Introduction to Restricted Boltzmann Machines",
    "venue": "Iberoamerican Congress on Pattern Recognition",
    "year": 2012,
    "citationCount": 622,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/978-3-642-33275-3_2.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-33275-3_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-33275-3_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35988982",
        "name": "Asja Fischer"
      },
      {
        "authorId": "1748824",
        "name": "C. Igel"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "55e36d6b45c91a0daa49234bd47b856470d6825c",
    "title": "Identifying Sarcasm in Twitter: A Closer Look",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2011,
    "citationCount": 681,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://aclanthology.org/P11-2102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1398275867",
        "name": "Roberto I. González-Ibáñez"
      },
      {
        "authorId": "2295928",
        "name": "S. Muresan"
      },
      {
        "authorId": "2468444",
        "name": "Nina Wacholder"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a2403c1ce02120f7bd383e395b561ff7c64d52ec",
    "title": "A System for Massively Parallel Hyperparameter Tuning",
    "venue": "Conference on Machine Learning and Systems",
    "year": 2018,
    "citationCount": 443,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.05934, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51517360",
        "name": "Liam Li"
      },
      {
        "authorId": "40566417",
        "name": "Kevin G. Jamieson"
      },
      {
        "authorId": "2435268",
        "name": "Afshin Rostamizadeh"
      },
      {
        "authorId": "2308319",
        "name": "Ekaterina Gonina"
      },
      {
        "authorId": "2086100700",
        "name": "Jonathan Ben-tzur"
      },
      {
        "authorId": "1775622",
        "name": "Moritz Hardt"
      },
      {
        "authorId": "9229182",
        "name": "B. Recht"
      },
      {
        "authorId": "145532827",
        "name": "Ameet Talwalkar"
      }
    ],
    "abstract": "Modern learning models are characterized by large hyperparameter spaces and long training times. These properties, coupled with the rise of parallel computing and the growing demand to productionize machine learning workloads, motivate the need to develop mature hyperparameter optimization functionality in distributed computing settings. We address this challenge by first introducing a simple and robust hyperparameter optimization algorithm called ASHA, which exploits parallelism and aggressive early-stopping to tackle large-scale hyperparameter optimization problems. Our extensive empirical results show that ASHA outperforms existing state-of-the-art hyperparameter optimization methods; scales linearly with the number of workers in distributed settings; and is suitable for massive parallelism, as demonstrated on a task with 500 workers. We then describe several design decisions we encountered, along with our associated solutions, when integrating ASHA in Determined AI's end-to-end production-quality machine learning system that offers hyperparameter tuning as a service."
  },
  {
    "paperId": "be515da1f59addd8259764ddf1a4f10ec7be066c",
    "title": "K-Nearest Neighbors",
    "venue": "",
    "year": 2013,
    "citationCount": 601,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-38652-7_2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-38652-7_2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144309134",
        "name": "Oliver Kramer"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "797928abfe0d189383325fe6322ced2226bcd457",
    "title": "Use of the Zero-Norm with Linear Models and Kernel Methods",
    "venue": "Journal of machine learning research",
    "year": 2003,
    "citationCount": 873,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145183709",
        "name": "J. Weston"
      },
      {
        "authorId": "1766703",
        "name": "A. Elisseeff"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      },
      {
        "authorId": "2831141",
        "name": "Michael E. Tipping"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9a064737d605703bc477f38a34bbab5f2ff58635",
    "title": "Network intrusion detection",
    "venue": "IEEE Network",
    "year": 1994,
    "citationCount": 1394,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-0-85729-504-0_15?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-0-85729-504-0_15, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2266257290",
        "name": "Biswanath Mukherjee"
      },
      {
        "authorId": "40404678",
        "name": "Todd L. Heberlein"
      },
      {
        "authorId": "2278961577",
        "name": "Karl N. Levitt"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a53da9916b87fa295837617c16ef2ca6462cafb8",
    "title": "Classification using discriminative restricted Boltzmann machines",
    "venue": "International Conference on Machine Learning",
    "year": 2008,
    "citationCount": 818,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1390156.1390224?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1390156.1390224, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1777528",
        "name": "H. Larochelle"
      },
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e044a4b5be1563fccc46e8f7552935b99365f90a",
    "title": "Learning with Support Vector Machines",
    "venue": "Learning with Support Vector Machines",
    "year": 2011,
    "citationCount": 302,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.2200/S00324ED1V01Y201102AIM010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2200/S00324ED1V01Y201102AIM010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145990261",
        "name": "C. Campbell"
      },
      {
        "authorId": "144359603",
        "name": "Yiming Ying"
      }
    ],
    "abstract": "Support Vectors Machines have become a well established tool within machine learning. They work well in practice and have now been used across a wide range of applications from recognizing hand-written digits, to face identification, text categorisation, bioinformatics, and database marketing. In this book we give an introductory overview of this subject. We start with a simple Support Vector Machine for performing binary classification before considering multi-class classification and learning in the presence of noise. We show that this framework can be extended to many other scenarios such as prediction with real-valued outputs, novelty detection and the handling of complex output structures such as parse trees. Finally, we give an overview of the main types of kernels which are used in practice and how to learn and make predictions from multiple types of input data. Table of Contents: Support Vector Machines for Classification / Kernel-based Models / Learning with Kernels"
  },
  {
    "paperId": "fe5cb4375f213abdbd34d25b02dc7e48794d286d",
    "title": "AutoML to Date and Beyond: Challenges and Opportunities",
    "venue": "ACM Computing Surveys",
    "year": 2020,
    "citationCount": 280,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2010.10777",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.10777, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2692077",
        "name": "Shubhra (Santu) Karmaker"
      },
      {
        "authorId": "2148762506",
        "name": "Md. Mahadi Hassan"
      },
      {
        "authorId": "35651709",
        "name": "Micah J. Smith"
      },
      {
        "authorId": "2112281287",
        "name": "Lei Xu"
      },
      {
        "authorId": "143869012",
        "name": "Chengxiang Zhai"
      },
      {
        "authorId": "1803567",
        "name": "K. Veeramachaneni"
      }
    ],
    "abstract": "As big data becomes ubiquitous across domains, and more and more stakeholders aspire to make the most of their data, demand for machine learning tools has spurred researchers to explore the possibilities of automated machine learning (AutoML). AutoML tools aim to make machine learning accessible for non-machine learning experts (domain experts), to improve the efficiency of machine learning, and to accelerate machine learning research. But although automation and efficiency are among AutoML’s main selling points, the process still requires human involvement at a number of vital steps, including understanding the attributes of domain-specific data, defining prediction problems, creating a suitable training dataset, and selecting a promising machine learning technique. These steps often require a prolonged back-and-forth that makes this process inefficient for domain experts and data scientists alike and keeps so-called AutoML systems from being truly automatic. In this review article, we introduce a new classification system for AutoML systems, using a seven-tiered schematic to distinguish these systems based on their level of autonomy. We begin by describing what an end-to-end machine learning pipeline actually looks like, and which subtasks of the machine learning pipeline have been automated so far. We highlight those subtasks that are still done manually—generally by a data scientist—and explain how this limits domain experts’ access to machine learning. Next, we introduce our novel level-based taxonomy for AutoML systems and define each level according to the scope of automation support provided. Finally, we lay out a roadmap for the future, pinpointing the research required to further automate the end-to-end machine learning pipeline and discussing important challenges that stand in the way of this ambitious goal."
  },
  {
    "paperId": "f620ec7bc0632be5518718cb81e2bfb57c81e950",
    "title": "Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 653,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1756006.1953015?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1756006.1953015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143651750",
        "name": "Miloš Radovanović"
      },
      {
        "authorId": "1728442",
        "name": "A. Nanopoulos"
      },
      {
        "authorId": "144395551",
        "name": "M. Ivanović"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "71d9222b39d0539322b6083de6790fc630129b9f",
    "title": "Why Are We Using Black Box Models in AI When We Don’t Need To? A Lesson From An Explainable AI Competition",
    "venue": "1.2",
    "year": 2019,
    "citationCount": 367,
    "openAccessPdf": {
      "url": "https://hdsr.mitpress.mit.edu/pub/f9kuryi8/download/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1162/99608f92.5a8a3a3d?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/99608f92.5a8a3a3d, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48395540",
        "name": "C. Rudin"
      },
      {
        "authorId": "46546677",
        "name": "Joanna Radin"
      }
    ],
    "abstract": "In 2018, a landmark challenge in artificial intelligence (AI) took place, namely, the Explainable Machine Learning Challenge. The goal of the competition was to create a complicated black box model for the dataset and explain how it worked. One team did not follow the rules. Instead of sending in a black box, they created a model that was fully interpretable. This leads to the question of whether the real world of machine learning is similar to the Explainable Machine Learning Challenge, where black box models are used even when they are not needed. We discuss this team’s thought processes during the competition and their implications, which reach far beyond the competition itself.Keywords: interpretability, explainability, machine learning, finance"
  },
  {
    "paperId": "4e11ebdc3e4f30d774458fab9e4b45ff0d0aa971",
    "title": "Logical and relational learning",
    "venue": "Cognitive Technologies",
    "year": 2008,
    "citationCount": 487,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-540-68856-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-540-68856-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1740042",
        "name": "L. D. Raedt"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "509c27bd45b5d9444949331ed8f5a3681c2ece68",
    "title": "Incremental learning with support vector machines",
    "venue": "Proceedings 2001 IEEE International Conference on Data Mining",
    "year": 2001,
    "citationCount": 599,
    "openAccessPdf": {
      "url": "http://www.stefan-rueping.de/publications/rueping-2001-b.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICDM.2001.989589?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICDM.2001.989589, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1804144",
        "name": "S. Rüping"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ec7c68427a26f812532b1c913c68fcf84b7de58e",
    "title": "Beyond the point cloud: from transductive to semi-supervised learning",
    "venue": "International Conference on Machine Learning",
    "year": 2005,
    "citationCount": 511,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1102351.1102455?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1102351.1102455, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1808676",
        "name": "Vikas Sindhwani"
      },
      {
        "authorId": "1770745",
        "name": "P. Niyogi"
      },
      {
        "authorId": "145520115",
        "name": "M. Belkin"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1402ac4469c3fc64eff02674f96a71bf3feedd7a",
    "title": "Preference Learning",
    "venue": "Encyclopedia of Machine Learning and Data Mining",
    "year": 2010,
    "citationCount": 324,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4899-7687-1_667?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4899-7687-1_667, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1747752",
        "name": "Johannes Fürnkranz"
      },
      {
        "authorId": "1691955",
        "name": "Eyke Hüllermeier"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "ea4feb953b86f6a099d61ffa70d21c59be99f76a",
    "title": "Enhancing Supervised Learning with Unlabeled Data",
    "venue": "International Conference on Machine Learning",
    "year": 2000,
    "citationCount": 566,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "32150954",
        "name": "S. Goldman"
      },
      {
        "authorId": "2150921406",
        "name": "Yan Zhou"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "23d2d8b687d31b11573473a7c7792b7ec08d0745",
    "title": "Learning Kernel Classifiers: Theory and Algorithms",
    "venue": "",
    "year": 2001,
    "citationCount": 575,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.7551/MITPRESS/4170.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7551/MITPRESS/4170.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3234984",
        "name": "R. Herbrich"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0ca966cb390b442b10cb76aa3fddee6b613f4f0f",
    "title": "Incorporating Diversity in Active Learning with Support Vector Machines",
    "venue": "International Conference on Machine Learning",
    "year": 2003,
    "citationCount": 559,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2047100972",
        "name": "K. Brinker"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1b286f0984301793f711899aa3294974f60ffed9",
    "title": "PRoNTo: Pattern Recognition for Neuroimaging Toolbox",
    "venue": "Neuroinformatics",
    "year": 2013,
    "citationCount": 426,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s12021-013-9178-1.pdf",
      "status": "HYBRID",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3722452, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3212089",
        "name": "Jessica Schrouff"
      },
      {
        "authorId": "145062631",
        "name": "M. J. Rosa"
      },
      {
        "authorId": "2311938",
        "name": "J. M. Rondina"
      },
      {
        "authorId": "50104860",
        "name": "A. Marquand"
      },
      {
        "authorId": "145606181",
        "name": "C. Chu"
      },
      {
        "authorId": "3985221",
        "name": "J. Ashburner"
      },
      {
        "authorId": "143652704",
        "name": "C. Phillips"
      },
      {
        "authorId": "1994765",
        "name": "Jonas Richiardi"
      },
      {
        "authorId": "144762404",
        "name": "J. Miranda"
      }
    ],
    "abstract": "In the past years, mass univariate statistical analyses of neuroimaging data have been complemented by the use of multivariate pattern analyses, especially based on machine learning models. While these allow an increased sensitivity for the detection of spatially distributed effects compared to univariate techniques, they lack an established and accessible software framework. The goal of this work was to build a toolbox comprising all the necessary functionalities for multivariate analyses of neuroimaging data, based on machine learning models. The “Pattern Recognition for Neuroimaging Toolbox” (PRoNTo) is open-source, cross-platform, MATLAB-based and SPM compatible, therefore being suitable for both cognitive and clinical neuroscience research. In addition, it is designed to facilitate novel contributions from developers, aiming to improve the interaction between the neuroimaging and machine learning communities. Here, we introduce PRoNTo by presenting examples of possible research questions that can be addressed with the machine learning framework implemented in PRoNTo, and cannot be easily investigated with mass univariate statistical analysis."
  },
  {
    "paperId": "3e06c979b01b1c235017495d7d3a2769bb6a81bc",
    "title": "Learning to Learn: Introduction and Overview",
    "venue": "Learning to Learn",
    "year": 1998,
    "citationCount": 606,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4615-5529-2_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4615-5529-2_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144867807",
        "name": "S. Thrun"
      },
      {
        "authorId": "144442133",
        "name": "L. Pratt"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "356125478f5d06b564b420755a4944254045bbbe",
    "title": "Support vector learning",
    "venue": "",
    "year": 1997,
    "citationCount": 641,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "dde691805cfa7d6f1bb88c7411c1c3377b6cdc67",
    "title": "Lifelong Learning Algorithms",
    "venue": "Learning to Learn",
    "year": 1998,
    "citationCount": 557,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4615-5529-2_8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4615-5529-2_8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144867807",
        "name": "S. Thrun"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "008abebf4a9404db9050c9d2fbca769f4faf3ca6",
    "title": "Learning by Transduction",
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "year": 1998,
    "citationCount": 546,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1301.7375, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1793317",
        "name": "A. Gammerman"
      },
      {
        "authorId": "145675281",
        "name": "Vladimir Vovk"
      },
      {
        "authorId": "50560492",
        "name": "V. Vapnik"
      }
    ],
    "abstract": "We describe a method for predicting a classification of an object given classifications of the objects in the training set, assuming that the pairs object/classification are generated by an i.i.d. process from a continuous probability distribution. Our method is a modification of Vapnik's support-vector machine; its main novelty is that it gives not only the prediction itself but also a practicable measure of the evidence found in support of that prediction. We also describe a procedure for assigning degrees of confidence to predictions made by the support vector machine. Some experimental results are presented, and possible extensions of the algorithms are discussed."
  },
  {
    "paperId": "e5ecac3aa41e359aa3a5d25943d0af72ff91df25",
    "title": "Support vector machines : theory and applications",
    "venue": "",
    "year": 2005,
    "citationCount": 706,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/B95439?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/B95439, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "46659335",
        "name": "Lipo Wang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "7b7f767edd532f1f156a31c2efc550e7a0b0279e",
    "title": "Incremental Support Vector Learning: Analysis, Implementation and Applications",
    "venue": "Journal of machine learning research",
    "year": 2006,
    "citationCount": 378,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1754215",
        "name": "P. Laskov"
      },
      {
        "authorId": "2140119",
        "name": "Christian Gehl"
      },
      {
        "authorId": "2059863974",
        "name": "Stefan Krüger"
      },
      {
        "authorId": "145034054",
        "name": "K. Müller"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d18f64aa830075ed3e10206907f32c8fb2aa189d",
    "title": "INTRODUCTION TO STATISTICAL LEARNING THEORY AND SUPPORT VECTOR MACHINES",
    "venue": "",
    "year": 2000,
    "citationCount": 442,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2228341882",
        "name": "Xuegong Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1889b9c3e8bc1118448b95fca38d6eff0bfca64d",
    "title": "Learning the Kernel with Hyperkernels",
    "venue": "Journal of machine learning research",
    "year": 2005,
    "citationCount": 371,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1706780",
        "name": "Cheng Soon Ong"
      },
      {
        "authorId": "46234526",
        "name": "Alex Smola"
      },
      {
        "authorId": "143957317",
        "name": "R. C. Williamson"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5fe5ed2a3b50becdbbcd17e7733653d5ef6ac398",
    "title": "Hidden Markov Support Vector Machines",
    "venue": "International Conference on Machine Learning",
    "year": 2003,
    "citationCount": 577,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1783941",
        "name": "Y. Altun"
      },
      {
        "authorId": "1765700",
        "name": "Ioannis Tsochantaridis"
      },
      {
        "authorId": "143936663",
        "name": "Thomas Hofmann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e37226a2f099c9a1ad13edce395ccca29225193c",
    "title": "Support Vector Machines Under Adversarial Label Noise",
    "venue": "Asian Conference on Machine Learning",
    "year": 2011,
    "citationCount": 407,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "1684175",
        "name": "B. Biggio"
      },
      {
        "authorId": "39743720",
        "name": "B. Nelson"
      },
      {
        "authorId": "1754215",
        "name": "P. Laskov"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6b0966c51d66e3097fc9f9d704bc43fdd963e90e",
    "title": "Learning in Humans and Machines: Towards an Interdisciplinary Learning Science",
    "venue": "",
    "year": 1995,
    "citationCount": 477,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2926339",
        "name": "H. Spada"
      },
      {
        "authorId": "50405957",
        "name": "Reimann"
      },
      {
        "authorId": "20779579",
        "name": "P. Reimann"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "9308cfdabf5303534b97d9ce5bfbb2c919a3f9cb",
    "title": "WEKA: The Waikato Environment for Knowledge Analysis",
    "venue": "",
    "year": 1996,
    "citationCount": 567,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2072119972",
        "name": "Stephen R. Garner"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "480ddeb902c15861ef8f294f00c543dae508ee9b",
    "title": "Optimization Techniques for Semi-Supervised Support Vector Machines",
    "venue": "Journal of machine learning research",
    "year": 2008,
    "citationCount": 447,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1390681.1390688?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1390681.1390688, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1730609",
        "name": "O. Chapelle"
      },
      {
        "authorId": "1808676",
        "name": "Vikas Sindhwani"
      },
      {
        "authorId": "144106136",
        "name": "S. Keerthi"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "6b945d00f77367422965531dd3d01694822c52c1",
    "title": "Ensembles of Learning Machines",
    "venue": "Italian Workshop on Neural Nets",
    "year": 2002,
    "citationCount": 327,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-45808-5_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-45808-5_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "37659088",
        "name": "G. Valentini"
      },
      {
        "authorId": "144493859",
        "name": "F. Masulli"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "679bc3cf9f52b0a1d8ff2b5ed4718ce6e44f9a56",
    "title": "The Bayesian backfitting relevance vector machine",
    "venue": "International Conference on Machine Learning",
    "year": 2004,
    "citationCount": 203,
    "openAccessPdf": {
      "url": "http://homepages.inf.ed.ac.uk/svijayak/publications/dsouza-ICML2004.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/1015330.1015358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1015330.1015358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "31979282",
        "name": "Aaron D'Souza"
      },
      {
        "authorId": "144575699",
        "name": "S. Vijayakumar"
      },
      {
        "authorId": "1567974152",
        "name": "Stefan Schaal"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0fe97c88452d8d8603d9ba883a0721da46ba84f4",
    "title": "The Set Covering Machine",
    "venue": "Journal of machine learning research",
    "year": 2003,
    "citationCount": 151,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "143858557",
        "name": "M. Marchand"
      },
      {
        "authorId": "1404459229",
        "name": "J. Shawe-Taylor"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "47fc921add1421ff8adb730df7aa9e7f865bfdeb",
    "title": "Toward Practical Smile Detection",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2009,
    "citationCount": 331,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPAMI.2009.42?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPAMI.2009.42, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143973061",
        "name": "J. Whitehill"
      },
      {
        "authorId": "2724380",
        "name": "G. Littlewort"
      },
      {
        "authorId": "2039025",
        "name": "Ian R. Fasel"
      },
      {
        "authorId": "2218905",
        "name": "M. Bartlett"
      },
      {
        "authorId": "1741200",
        "name": "J. Movellan"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "b7d89441fcf28ca1a365af4d739709a7075a5db2",
    "title": "Knowledge Discovery with Support Vector Machines",
    "venue": "",
    "year": 2009,
    "citationCount": 325,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470503065.fmatter",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/9780470503065?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9780470503065, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1775719",
        "name": "L. Hamel"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "886b9cd28b77e1a73da7112b95196e661ae8d5a1",
    "title": "Explanation-Based Learning: An Alternative View",
    "venue": "Machine-mediated learning",
    "year": 1986,
    "citationCount": 314,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1023/A:1022898111663.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1023/A:1022898111663?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1023/A:1022898111663, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1802807",
        "name": "G. DeJong"
      },
      {
        "authorId": "1797655",
        "name": "R. Mooney"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "02d82f970d201c631424af3c617ceb25884da4a7",
    "title": "PyBrain",
    "venue": "Journal of machine learning research",
    "year": 2010,
    "citationCount": 222,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.5555/1756006.1756030?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5555/1756006.1756030, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1725157",
        "name": "T. Schaul"
      },
      {
        "authorId": "145040409",
        "name": "Justin Bayer"
      },
      {
        "authorId": "1688276",
        "name": "D. Wierstra"
      },
      {
        "authorId": "2116961006",
        "name": "Yi Sun"
      },
      {
        "authorId": "12527511",
        "name": "M. Felder"
      },
      {
        "authorId": "1702866",
        "name": "Frank Sehnke"
      },
      {
        "authorId": "1692802",
        "name": "Thomas Rückstieß"
      },
      {
        "authorId": "2055652029",
        "name": "Jürgen Schmidhuber"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "f50e54684086a91bb481f76f7180c1ef3c4cb312",
    "title": "Deep Convolutional Transfer Learning Network: A New Method for Intelligent Fault Diagnosis of Machines With Unlabeled Data",
    "venue": "IEEE transactions on industrial electronics (1982. Print)",
    "year": 2019,
    "citationCount": 977,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TIE.2018.2877090?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TIE.2018.2877090, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2110660923",
        "name": "Liang Guo"
      },
      {
        "authorId": "1829456",
        "name": "Y. Lei"
      },
      {
        "authorId": "3372340",
        "name": "Saibo Xing"
      },
      {
        "authorId": "2059615925",
        "name": "Tao Yan"
      },
      {
        "authorId": "2217450625",
        "name": "Naipeng Li"
      }
    ],
    "abstract": "The success of intelligent fault diagnosis of machines relies on the following two conditions: 1) labeled data with fault information are available; and 2) the training and testing data are drawn from the same probability distribution. However, for some machines, it is difficult to obtain massive labeled data. Moreover, even though labeled data can be obtained from some machines, the intelligent fault diagnosis method trained with such labeled data possibly fails in classifying unlabeled data acquired from the other machines due to data distribution discrepancy. These problems limit the successful applications of intelligent fault diagnosis of machines with unlabeled data. As a potential tool, transfer learning adapts a model trained in a source domain to its application in a target domain. Based on the transfer learning, we propose a new intelligent method named deep convolutional transfer learning network (DCTLN). A DCTLN consists of two modules: condition recognition and domain adaptation. The condition recognition module is constructed by a one-dimensional (1-D) convolutional neural network (CNN) to automatically learn features and recognize health conditions of machines. The domain adaptation module facilitates the 1-D CNN to learn domain-invariant features by maximizing domain recognition errors and minimizing the probability distribution distance. The effectiveness of the proposed method is verified using six transfer fault diagnosis experiments."
  },
  {
    "paperId": "16b3c8f6f1dffd31271c59c11e17241e51377d68",
    "title": "An Introduction to Statistical Learning",
    "venue": "Springer Texts in Statistics",
    "year": 2013,
    "citationCount": 9311,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4614-7138-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4614-7138-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144026427",
        "name": "Gareth M. James"
      },
      {
        "authorId": "2113693105",
        "name": "D. Witten"
      },
      {
        "authorId": "1784682",
        "name": "T. Hastie"
      },
      {
        "authorId": "1761784",
        "name": "R. Tibshirani"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "818e627defcd36477b6d39ec5fc4d02a479e7c37",
    "title": "Trends in extreme learning machines: A review",
    "venue": "Neural Networks",
    "year": 2015,
    "citationCount": 1658,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1016/J.NEUNET.2014.10.001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/J.NEUNET.2014.10.001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143983679",
        "name": "Gao Huang"
      },
      {
        "authorId": "145678691",
        "name": "G. Huang"
      },
      {
        "authorId": "1760750",
        "name": "Shiji Song"
      },
      {
        "authorId": "3527062",
        "name": "Keyou You"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "fc8cda36a0972e7de1ac3a7bcb81dc32da79bee4",
    "title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
    "venue": "IEEE Transactions on Neural Networks",
    "year": 2003,
    "citationCount": 9471,
    "openAccessPdf": {
      "url": "http://cds.cern.ch/record/791819/files/0262194759_TOC.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1198/jasa.2003.s270?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1198/jasa.2003.s270, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2285968829",
        "name": "Christopher K. I Williams"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "0e90a73f03902cbe915af1aff54ea7f0b3373680",
    "title": "An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods",
    "venue": "The AI Magazine",
    "year": 2001,
    "citationCount": 8989,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aimag.v22i2.1566?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aimag.v22i2.1566, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2146325920",
        "name": "Tong Zhang"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a675fe5a7d99ac6f7ff91fa084462faefe616148",
    "title": "What video games have to teach us about learning and literacy",
    "venue": "Conference on Computability in Europe",
    "year": 2007,
    "citationCount": 9146,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/950566.950595?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/950566.950595, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34622402",
        "name": "J. Gee"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
    "title": "Learning Multiple Layers of Features from Tiny Images",
    "venue": "",
    "year": 2009,
    "citationCount": 39205,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2064160",
        "name": "A. Krizhevsky"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "d04d6db5f0df11d0cff57ec7e15134990ac07a4f",
    "title": "Learning Deep Architectures for AI",
    "venue": "Found. Trends Mach. Learn.",
    "year": 2007,
    "citationCount": 8719,
    "openAccessPdf": {
      "url": "http://www.iro.umontreal.ca/~bengioy/papers/ftml.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1561/2200000006?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1561/2200000006, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1751762",
        "name": "Yoshua Bengio"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4609f6bdc3beab00c9beceaa12dd8101fefe6f1c",
    "title": "An overview of statistical learning theory",
    "venue": "IEEE Trans. Neural Networks",
    "year": 1999,
    "citationCount": 6185,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/72.788640?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/72.788640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50560492",
        "name": "V. Vapnik"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
    "title": "A Learning Algorithm for Boltzmann Machines",
    "venue": "Cognitive Sciences",
    "year": 1985,
    "citationCount": 4126,
    "openAccessPdf": {
      "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog0901_7",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1016/B978-0-08-051581-6.50053-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/B978-0-08-051581-6.50053-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3308302",
        "name": "D. Ackley"
      },
      {
        "authorId": "1695689",
        "name": "Geoffrey E. Hinton"
      },
      {
        "authorId": "1714528",
        "name": "T. Sejnowski"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "1fcbefeb0beae4470cf40df74cd116b1d4bdcae4",
    "title": "An introduction to kernel-based learning algorithms",
    "venue": "IEEE Trans. Neural Networks",
    "year": 2001,
    "citationCount": 3757,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/72.914517?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/72.914517, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145034054",
        "name": "K. Müller"
      },
      {
        "authorId": "2459012",
        "name": "S. Mika"
      },
      {
        "authorId": "152597562",
        "name": "Gunnar Rätsch"
      },
      {
        "authorId": "34628173",
        "name": "K. Tsuda"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "51886def908b16d11685ea23eb2124dfe961754f",
    "title": "Semi-Supervised and Unsupervised Extreme Learning Machines",
    "venue": "IEEE Transactions on Cybernetics",
    "year": 2014,
    "citationCount": 727,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TCYB.2014.2307349?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TCYB.2014.2307349, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "143983679",
        "name": "Gao Huang"
      },
      {
        "authorId": "1760750",
        "name": "Shiji Song"
      },
      {
        "authorId": "2694479",
        "name": "J. Gupta"
      },
      {
        "authorId": "145253556",
        "name": "Cheng Wu"
      }
    ],
    "abstract": "Extreme learning machines (ELMs) have proven to be efficient and effective learning mechanisms for pattern classification and regression. However, ELMs are primarily applied to supervised learning problems. Only a few existing research papers have used ELMs to explore unlabeled data. In this paper, we extend ELMs for both semi-supervised and unsupervised tasks based on the manifold regularization, thus greatly expanding the applicability of ELMs. The key advantages of the proposed algorithms are as follows: 1) both the semi-supervised ELM (SS-ELM) and the unsupervised ELM (US-ELM) exhibit learning capability and computational efficiency of ELMs; 2) both algorithms naturally handle multiclass classification or multicluster clustering; and 3) both algorithms are inductive and can handle unseen data at test time directly. Moreover, it is shown in this paper that all the supervised, semi-supervised, and unsupervised ELMs can actually be put into a unified framework. This provides new perspectives for understanding the mechanism of random feature mapping, which is the key concept in ELM theory. Empirical study on a wide range of data sets demonstrates that the proposed algorithms are competitive with the state-of-the-art semi-supervised or unsupervised learning algorithms in terms of accuracy and efficiency."
  },
  {
    "paperId": "fd8ce955dc0c570b66305dfbc65e4ed5f37658d0",
    "title": "Induction: Processes of Inference, Learning, and Discovery",
    "venue": "IEEE Expert",
    "year": 1987,
    "citationCount": 2314,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/mex.1987.4307100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/mex.1987.4307100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "94653581",
        "name": "J. H. Holland"
      },
      {
        "authorId": "2009767",
        "name": "K. Holyoak"
      },
      {
        "authorId": "2518186",
        "name": "R. Nisbett"
      },
      {
        "authorId": "1756123",
        "name": "P. Thagard"
      },
      {
        "authorId": "1743808",
        "name": "S. Smoliar"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "2c4986b03ab15bdad01f808a6786bee01e3800a1",
    "title": "Learning to classify text using support vector machines - methods, theory and algorithms",
    "venue": "The Kluwer International Series in Engineering and Computer Science",
    "year": 2002,
    "citationCount": 1625,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-1-4615-0907-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-1-4615-0907-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1680188",
        "name": "T. Joachims"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "77e379fd57ea44638fc628623e383eccada82689",
    "title": "Kernel Methods for Deep Learning",
    "venue": "Neural Information Processing Systems",
    "year": 2009,
    "citationCount": 821,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "6572037",
        "name": "Youngmin Cho"
      },
      {
        "authorId": "1796044",
        "name": "L. Saul"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "4673a47a4f6719e350196f4086a65d08f946df25",
    "title": "Learning by Design: Good Video Games as Learning Machines",
    "venue": "",
    "year": 2005,
    "citationCount": 803,
    "openAccessPdf": {
      "url": "http://www.academiccolab.org/resources/documents/Game Paper.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.2304/elea.2005.2.1.5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2304/elea.2005.2.1.5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34622402",
        "name": "J. Gee"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "52e2ac397f0c8d5f533959905df899bc328d9f85",
    "title": "Reinforcement Learning with Hierarchies of Machines",
    "venue": "Neural Information Processing Systems",
    "year": 1997,
    "citationCount": 922,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "145726861",
        "name": "Ronald E. Parr"
      },
      {
        "authorId": "145107462",
        "name": "Stuart J. Russell"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "424a6e62084d919bfc2e39a507c263e5991ebdad",
    "title": "Self-Normalizing Neural Networks",
    "venue": "Neural Information Processing Systems",
    "year": 2017,
    "citationCount": 2700,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1706.02515, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1994964",
        "name": "G. Klambauer"
      },
      {
        "authorId": "2465270",
        "name": "Thomas Unterthiner"
      },
      {
        "authorId": "144831680",
        "name": "Andreas Mayr"
      },
      {
        "authorId": "3308557",
        "name": "Sepp Hochreiter"
      }
    ],
    "abstract": "Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are \"scaled exponential linear units\" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: this http URL."
  },
  {
    "paperId": "6bdb186ec4726e00a8051119636d4df3b94043b5",
    "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
    "venue": "ACM Multimedia",
    "year": 2014,
    "citationCount": 14799,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1408.5093, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "39978391",
        "name": "Yangqing Jia"
      },
      {
        "authorId": "1782282",
        "name": "Evan Shelhamer"
      },
      {
        "authorId": "7408951",
        "name": "Jeff Donahue"
      },
      {
        "authorId": "3049736",
        "name": "Sergey Karayev"
      },
      {
        "authorId": "2117314646",
        "name": "Jonathan Long"
      },
      {
        "authorId": "2983898",
        "name": "Ross B. Girshick"
      },
      {
        "authorId": "1687120",
        "name": "S. Guadarrama"
      },
      {
        "authorId": "1753210",
        "name": "Trevor Darrell"
      }
    ],
    "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia."
  },
  {
    "paperId": "3127190433230b3dc1abd0680bb58dced4bcd90e",
    "title": "Large Scale Distributed Deep Networks",
    "venue": "Neural Information Processing Systems",
    "year": 2012,
    "citationCount": 4028,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "49959210",
        "name": "J. Dean"
      },
      {
        "authorId": "32131713",
        "name": "G. Corrado"
      },
      {
        "authorId": "3089272",
        "name": "R. Monga"
      },
      {
        "authorId": "2118440152",
        "name": "Kai Chen"
      },
      {
        "authorId": "145139947",
        "name": "M. Devin"
      },
      {
        "authorId": "2827616",
        "name": "Quoc V. Le"
      },
      {
        "authorId": "1715548",
        "name": "Mark Z. Mao"
      },
      {
        "authorId": "1706809",
        "name": "Marc'Aurelio Ranzato"
      },
      {
        "authorId": "33666044",
        "name": "A. Senior"
      },
      {
        "authorId": "2080690",
        "name": "P. Tucker"
      },
      {
        "authorId": "143781496",
        "name": "Ke Yang"
      },
      {
        "authorId": "34699434",
        "name": "A. Ng"
      }
    ],
    "abstract": null
  },
  {
    "paperId": "e50f4d3316d13841c287dcdf5479d7820d593571",
    "title": "Factorization Machines with libFM",
    "venue": "TIST",
    "year": 2012,
    "citationCount": 1335,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2168752.2168771?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2168752.2168771, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2843982",
        "name": "Steffen Rendle"
      }
    ],
    "abstract": null
  }
]